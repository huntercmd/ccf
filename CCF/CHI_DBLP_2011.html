 
<head>
<meta name="HunterCmd" charset="utf-8">

<link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
<link id="cssfile" rel="stylesheet" type="text/css" href="https://rawcdn.githack.com/huntercmd/blog/master/config/css/light.css">
<script src="https://rawcdn.githack.com/huntercmd/blog/d9beff1/config/css/skin.js"></script>
<script src="https://rawcdn.githack.com/huntercmd/blog/master/config/css/classie.js"></script>


<title>HunterCmd</title>
</head>

<body class="cbp-spmenu-push">

<nav class="cbp-spmenu cbp-spmenu-vertical cbp-spmenu-left" id="menu-s1" style="width: 320px;overflow: auto;
">

<h1>Table of contents</h1>
<ul>
<li><a href="#CHI 2011:Vancouver, BC, Canada">CHI 2011:Vancouver, BC, Canada</a><ul>
<li><a href="#Paper Num: 409 || Session Num: 105">Paper Num: 409 || Session Num: 105</a></li>
<li><a href="#Health 1: technology challenges    5">Health 1: technology challenges    5</a><ul>
<li><a href="#1. Classroom-based assistive technology: collective use of interactive visual schedules by students with autism.">1. Classroom-based assistive technology: collective use of interactive visual schedules by students with autism.</a></li>
<li><a href="#2. Privacy risks emerging from the adoption of innocuous wearable sensors in the mobile environment.">2. Privacy risks emerging from the adoption of innocuous wearable sensors in the mobile environment.</a></li>
<li><a href="#3. Interaction design for cancer patients: do we need to take into account the effects of illness and medication?">3. Interaction design for cancer patients: do we need to take into account the effects of illness and medication?</a></li>
<li><a href="#4. Simulating the feel of brain-computer interfaces for design, development and social interaction.">4. Simulating the feel of brain-computer interfaces for design, development and social interaction.</a></li>
<li><a href="#5. Characterizing patient-friendly "micro-explanations"of medical events.">5. Characterizing patient-friendly "micro-explanations"of medical events.</a></li>
</ul>
</li>
<li><a href="#Telepresence    4">Telepresence    4</a><ul>
<li><a href="#6. "Now, i have a body": uses and social norms for mobile remote presence in the workplace.">6. "Now, i have a body": uses and social norms for mobile remote presence in the workplace.</a></li>
<li><a href="#7. Hands on hitchcock: embodied reference to a moving scene.">7. Hands on hitchcock: embodied reference to a moving scene.</a></li>
<li><a href="#8. Exploring camera viewpoint control models for a multi-tasking setting in teleoperation.">8. Exploring camera viewpoint control models for a multi-tasking setting in teleoperation.</a></li>
<li><a href="#9. Zoom cameras and movable displays enhance social telepresence.">9. Zoom cameras and movable displays enhance social telepresence.</a></li>
</ul>
</li>
<li><a href="#Olfaction, breath & biofeedback    4">Olfaction, breath &amp; biofeedback    4</a><ul>
<li><a href="#10. Breath control of amusement rides.">10. Breath control of amusement rides.</a></li>
<li><a href="#11. Time characteristics of olfaction in a single breath.">11. Time characteristics of olfaction in a single breath.</a></li>
<li><a href="#12. Augmented reality flavors: gustatory display based on edible marker and cross-modal interaction.">12. Augmented reality flavors: gustatory display based on edible marker and cross-modal interaction.</a></li>
<li><a href="#13. Biofeedback game design: using direct and indirect physiological control to enhance game interaction.">13. Biofeedback game design: using direct and indirect physiological control to enhance game interaction.</a></li>
</ul>
</li>
<li><a href="#Research methods    4">Research methods    4</a><ul>
<li><a href="#14. Confessions from a grounded theory PhD: experiences and lessons learnt.">14. Confessions from a grounded theory PhD: experiences and lessons learnt.</a></li>
<li><a href="#15. Reflexivity in digital anthropology.">15. Reflexivity in digital anthropology.</a></li>
<li><a href="#16. Comparing activity theory with distributed cognition for video analysis: beyond "kicking the tires".">16. Comparing activity theory with distributed cognition for video analysis: beyond "kicking the tires".</a></li>
<li><a href="#17. The aligned rank transform for nonparametric factorial analyses using only anova procedures.">17. The aligned rank transform for nonparametric factorial analyses using only anova procedures.</a></li>
</ul>
</li>
<li><a href="#Machine learning    3">Machine learning    3</a><ul>
<li><a href="#18. Human model evaluation in interactive supervised learning.">18. Human model evaluation in interactive supervised learning.</a></li>
<li><a href="#19. CueT: human-guided fast and accurate network alarm triage.">19. CueT: human-guided fast and accurate network alarm triage.</a></li>
<li><a href="#20. Apolo: making sense of large network data by combining rich user interaction and machine learning.">20. Apolo: making sense of large network data by combining rich user interaction and machine learning.</a></li>
</ul>
</li>
<li><a href="#Mid-air pointing & gestures    4">Mid-air pointing &amp; gestures    4</a><ul>
<li><a href="#21. Mid-air pan-and-zoom on wall-sized displays.">21. Mid-air pan-and-zoom on wall-sized displays.</a></li>
<li><a href="#22. Gesture select: : acquiring remote targets on large displays without pointing.">22. Gesture select: : acquiring remote targets on large displays without pointing.</a></li>
<li><a href="#23. User-defined motion gestures for mobile interaction.">23. User-defined motion gestures for mobile interaction.</a></li>
<li><a href="#24. Gesture avatar: a technique for operating mobile user interfaces using gestures.">24. Gesture avatar: a technique for operating mobile user interfaces using gestures.</a></li>
</ul>
</li>
<li><a href="#Twitter systems    4">Twitter systems    4</a><ul>
<li><a href="#25. Speak little and well: recommending conversations in online social streams.">25. Speak little and well: recommending conversations in online social streams.</a></li>
<li><a href="#26. Twitinfo: aggregating and visualizing microblogs for event exploration.">26. Twitinfo: aggregating and visualizing microblogs for event exploration.</a></li>
<li><a href="#27. Tweets from Justin Bieber's heart: the dynamics of the location field in user profiles.">27. Tweets from Justin Bieber's heart: the dynamics of the location field in user profiles.</a></li>
<li><a href="#28. An open, social microcalender for the enterprise: timely?">28. An open, social microcalender for the enterprise: timely?</a></li>
</ul>
</li>
<li><a href="#Sex & bodies    3">Sex &amp; bodies    3</a><ul>
<li><a href="#29. Pleasure is your birthright: digitally enabled designer sex toys as a case of third-wave HCI.">29. Pleasure is your birthright: digitally enabled designer sex toys as a case of third-wave HCI.</a></li>
<li><a href="#30. Designing a phone broadcasting system for urban sex workers in India.">30. Designing a phone broadcasting system for urban sex workers in India.</a></li>
<li><a href="#31. Bodily orientations around mobiles: lessons learnt in vanuatu.">31. Bodily orientations around mobiles: lessons learnt in vanuatu.</a></li>
</ul>
</li>
<li><a href="#Watching together    4">Watching together    4</a><ul>
<li><a href="#32. We want more: human-computer collaboration in mobile social video remixing of music concerts.">32. We want more: human-computer collaboration in mobile social video remixing of music concerts.</a></li>
<li><a href="#33. Knowing funny: genre perception and categorization in social video sharing.">33. Knowing funny: genre perception and categorization in social video sharing.</a></li>
<li><a href="#34. Real-time nonverbal opinion sharing through mobile phones during sports events.">34. Real-time nonverbal opinion sharing through mobile phones during sports events.</a></li>
<li><a href="#35. Are we in sync?: synchronization requirements for watching online video together.">35. Are we in sync?: synchronization requirements for watching online video together.</a></li>
</ul>
</li>
<li><a href="#Health 2: persuasive systems    5">Health 2: persuasive systems    5</a><ul>
<li><a href="#36. Designing for peer involvement in weight management.">36. Designing for peer involvement in weight management.</a></li>
<li><a href="#37. Mining behavioral economics to design persuasive technology for healthy choices.">37. Mining behavioral economics to design persuasive technology for healthy choices.</a></li>
<li><a href="#38. Means based adaptive persuasive systems.">38. Means based adaptive persuasive systems.</a></li>
<li><a href="#39. Side effects and "gateway" tools: advocating a broader look at evaluating persuasive systems.">39. Side effects and "gateway" tools: advocating a broader look at evaluating persuasive systems.</a></li>
<li><a href="#40. I will do it, but i don't like it: user reactions to preference-inconsistent recommendations.">40. I will do it, but i don't like it: user reactions to preference-inconsistent recommendations.</a></li>
</ul>
</li>
<li><a href="#Brain & bio-sensor interactions    4">Brain &amp; bio-sensor interactions    4</a><ul>
<li><a href="#41. Embodiment in brain-computer interaction.">41. Embodiment in brain-computer interaction.</a></li>
<li><a href="#42. Now where was I?: physiologically-triggered bookmarking.">42. Now where was I?: physiologically-triggered bookmarking.</a></li>
<li><a href="#43. This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.">43. This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.</a></li>
<li><a href="#44. Sensing cognitive multitasking for a brain-based adaptive user interface.">44. Sensing cognitive multitasking for a brain-based adaptive user interface.</a></li>
</ul>
</li>
<li><a href="#Gestures    3">Gestures    3</a><ul>
<li><a href="#45. RemoteTouch: touch-screen-like interaction in the tv viewing environment.">45. RemoteTouch: touch-screen-like interaction in the tv viewing environment.</a></li>
<li><a href="#46. Experimental analysis of touch-screen gesture designs in mobile environments.">46. Experimental analysis of touch-screen gesture designs in mobile environments.</a></li>
<li><a href="#47. Usable gestures for blind people: understanding preference and performance.">47. Usable gestures for blind people: understanding preference and performance.</a></li>
</ul>
</li>
<li><a href="#Designing for values, democracy & peace    4">Designing for values, democracy &amp; peace    4</a><ul>
<li><a href="#48. Fit4life: the design of a persuasive technology promoting healthy behavior and ideal weight.">48. Fit4life: the design of a persuasive technology promoting healthy behavior and ideal weight.</a></li>
<li><a href="#49. Many bills: engaging citizens through visualizations of congressional legislation.">49. Many bills: engaging citizens through visualizations of congressional legislation.</a></li>
<li><a href="#50. HCI for peace: a call for constructive action.">50. HCI for peace: a call for constructive action.</a></li>
<li><a href="#51. Evaluating a pattern-based visual support approach for humanitarian landmine clearance.">51. Evaluating a pattern-based visual support approach for humanitarian landmine clearance.</a></li>
</ul>
</li>
<li><a href="#Driving    4">Driving    4</a><ul>
<li><a href="#52. Hang on a sec!: effects of proactive mediation of phone conversations while driving.">52. Hang on a sec!: effects of proactive mediation of phone conversations while driving.</a></li>
<li><a href="#53. Fast or safe?: how performance objectives determine modality output choices while interacting on the move.">53. Fast or safe?: how performance objectives determine modality output choices while interacting on the move.</a></li>
<li><a href="#54. Gestural interaction on the steering wheel: reducing the visual demand.">54. Gestural interaction on the steering wheel: reducing the visual demand.</a></li>
<li><a href="#55. Usability of car dashboard displays for elder drivers.">55. Usability of car dashboard displays for elder drivers.</a></li>
</ul>
</li>
<li><a href="#Meetings & interaction spaces    2">Meetings &amp; interaction spaces    2</a><ul>
<li><a href="#56. Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment.">56. Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment.</a></li>
<li><a href="#57. What did i miss?: in-meeting review using multimodal accelerated instant replay (air">57. What did i miss?: in-meeting review using multimodal accelerated instant replay (air) conferencing.</a> conferencing.)</li>
</ul>
</li>
<li><a href="#Art, music & movement    5">Art, music &amp; movement    5</a><ul>
<li><a href="#58. MOGCLASS: evaluation of a collaborative system of mobile devices for classroom music education of young children.">58. MOGCLASS: evaluation of a collaborative system of mobile devices for classroom music education of young children.</a></li>
<li><a href="#59. Buzzing to play: lessons learned from an in the wild study of real-time vibrotactile feedback.">59. Buzzing to play: lessons learned from an in the wild study of real-time vibrotactile feedback.</a></li>
<li><a href="#60. PossessedHand: techniques for controlling human hands using electrical muscles stimuli.">60. PossessedHand: techniques for controlling human hands using electrical muscles stimuli.</a></li>
<li><a href="#61. Design interventions for open-air museums: applying and extending the principles of 'assembly'.">61. Design interventions for open-air museums: applying and extending the principles of 'assembly'.</a></li>
<li><a href="#62. MoBoogie: creative expression through whole body musical interaction.">62. MoBoogie: creative expression through whole body musical interaction.</a></li>
</ul>
</li>
<li><a href="#Facebook    4">Facebook    4</a><ul>
<li><a href="#63. Life "modes" in social media.">63. Life "modes" in social media.</a></li>
<li><a href="#64. Social capital on facebook: differentiating uses and users.">64. Social capital on facebook: differentiating uses and users.</a></li>
<li><a href="#65. Farmer's tale: a facebook game to promote volunteerism.">65. Farmer's tale: a facebook game to promote volunteerism.</a></li>
<li><a href="#66. Identifying social capital in the facebook interface.">66. Identifying social capital in the facebook interface.</a></li>
</ul>
</li>
<li><a href="#Health 3: online communities & social interaction    5">Health 3: online communities &amp; social interaction    5</a><ul>
<li><a href="#67. Competing online viewpoints and models of chronic illness.">67. Competing online viewpoints and models of chronic illness.</a></li>
<li><a href="#68. Using interface cues in online health community boards to change impressions and encourage user contribution.">68. Using interface cues in online health community boards to change impressions and encourage user contribution.</a></li>
<li><a href="#69. ACES: promoting empathy towards aphasia through language distortion emulation software.">69. ACES: promoting empathy towards aphasia through language distortion emulation software.</a></li>
<li><a href="#70. Cueing for drooling in Parkinson's disease.">70. Cueing for drooling in Parkinson's disease.</a></li>
<li><a href="#71. Evaluating swabbing: a touchscreen input method for elderly users with tremor.">71. Evaluating swabbing: a touchscreen input method for elderly users with tremor.</a></li>
</ul>
</li>
<li><a href="#Human-robot interaction    3">Human-robot interaction    3</a><ul>
<li><a href="#72. Direct manipulation through surrogate objects.">72. Direct manipulation through surrogate objects.</a></li>
<li><a href="#73. An actuated physical puppet as an input device for controlling a digital manikin.">73. An actuated physical puppet as an input device for controlling a digital manikin.</a></li>
<li><a href="#74. Roboshop: multi-layered sketching interface for robot housework assignment and management.">74. Roboshop: multi-layered sketching interface for robot housework assignment and management.</a></li>
</ul>
</li>
<li><a href="#Tagging    3">Tagging    3</a><ul>
<li><a href="#75. Examining the impact of collaborative tagging on sensemaking in nutrition management.">75. Examining the impact of collaborative tagging on sensemaking in nutrition management.</a></li>
<li><a href="#76. Using tags to encourage reflection and annotation on data during nomadic inquiry.">76. Using tags to encourage reflection and annotation on data during nomadic inquiry.</a></li>
<li><a href="#77. User perceptions of the role and value of tags.">77. User perceptions of the role and value of tags.</a></li>
</ul>
</li>
<li><a href="#HCI for all    4">HCI for all    4</a><ul>
<li><a href="#78. Towards a feminist HCI methodology: social science, feminism, and HCI.">78. Towards a feminist HCI methodology: social science, feminism, and HCI.</a></li>
<li><a href="#79. Out there.">79. Out there.</a></li>
<li><a href="#80. How HCI talks about sexuality: discursive strategies, blind spots, and opportunities for future research.">80. How HCI talks about sexuality: discursive strategies, blind spots, and opportunities for future research.</a></li>
<li><a href="#81. In the shadow of misperception: assistive technology use and social interactions.">81. In the shadow of misperception: assistive technology use and social interactions.</a></li>
</ul>
</li>
<li><a href="#Emotional states    5">Emotional states    5</a><ul>
<li><a href="#82. Identifying emotional states using keystroke dynamics.">82. Identifying emotional states using keystroke dynamics.</a></li>
<li><a href="#83. PAM: a photographic affect meter for frequent, in situ measurement of affect.">83. PAM: a photographic affect meter for frequent, in situ measurement of affect.</a></li>
<li><a href="#84. Affective computational priming and creativity.">84. Affective computational priming and creativity.</a></li>
<li><a href="#85. Upset now?: emotion contagion in distributed groups.">85. Upset now?: emotion contagion in distributed groups.</a></li>
<li><a href="#86. Emotion regulation for frustrating driving contexts.">86. Emotion regulation for frustrating driving contexts.</a></li>
</ul>
</li>
<li><a href="#Identity & virtual social interactions    5">Identity &amp; virtual social interactions    5</a><ul>
<li><a href="#87. Introverted elves & conscientious gnomes: the expression of personality in world of warcraft.">87. Introverted elves &amp; conscientious gnomes: the expression of personality in world of warcraft.</a></li>
<li><a href="#88. Starcraft from the stands: understanding the game spectator.">88. Starcraft from the stands: understanding the game spectator.</a></li>
<li><a href="#89. Do men heal more when in drag?: conflicting identity cues between user and avatar.">89. Do men heal more when in drag?: conflicting identity cues between user and avatar.</a></li>
<li><a href="#90. Is the media equation a flash in the pan?: the durability and longevity of social responses to computers.">90. Is the media equation a flash in the pan?: the durability and longevity of social responses to computers.</a></li>
<li><a href="#91. What drives customization?: control or identity?">91. What drives customization?: control or identity?</a></li>
</ul>
</li>
<li><a href="#Gestures, body & touch    5">Gestures, body &amp; touch    5</a><ul>
<li><a href="#92. Your noise is my command: sensing gestures using the body as an antenna.">92. Your noise is my command: sensing gestures using the body as an antenna.</a></li>
<li><a href="#93. Sensor synaesthesia: touch in motion, and motion in touch.">93. Sensor synaesthesia: touch in motion, and motion in touch.</a></li>
<li><a href="#94. Data miming: inferring spatial object descriptions from human gesture.">94. Data miming: inferring spatial object descriptions from human gesture.</a></li>
<li><a href="#95. Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces.">95. Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces.</a></li>
<li><a href="#96. The impact on musculoskeletal system during multitouch tablet interactions.">96. The impact on musculoskeletal system during multitouch tablet interactions.</a></li>
</ul>
</li>
<li><a href="#Pointing 1    5">Pointing 1    5</a><ul>
<li><a href="#97. TorusDesktop: pointing via the backdoor is sometimes shorter.">97. TorusDesktop: pointing via the backdoor is sometimes shorter.</a></li>
<li><a href="#98. Comet and target ghost: techniques for selecting moving targets.">98. Comet and target ghost: techniques for selecting moving targets.</a></li>
<li><a href="#99. Acquiring and pointing: an empirical study of pen-tilt-based interaction.">99. Acquiring and pointing: an empirical study of pen-tilt-based interaction.</a></li>
<li><a href="#100. On the costs of multiple trajectory pointing methods.">100. On the costs of multiple trajectory pointing methods.</a></li>
<li><a href="#101. Cursor relocation techniques to help older adults find 'lost' cursors.">101. Cursor relocation techniques to help older adults find 'lost' cursors.</a></li>
</ul>
</li>
<li><a href="#Ambient & peripheral computing    4">Ambient &amp; peripheral computing    4</a><ul>
<li><a href="#102. Enhancing interactional synchrony with an ambient display.">102. Enhancing interactional synchrony with an ambient display.</a></li>
<li><a href="#103. Issues in evaluating ambient displays in the wild: two case studies.">103. Issues in evaluating ambient displays in the wild: two case studies.</a></li>
<li><a href="#104. Does MoodyBoard make internet use more secure?: evaluating an ambient security visualization tool.">104. Does MoodyBoard make internet use more secure?: evaluating an ambient security visualization tool.</a></li>
<li><a href="#105. Peripheral computing during presentations: perspectives on costs and preferences.">105. Peripheral computing during presentations: perspectives on costs and preferences.</a></li>
</ul>
</li>
<li><a href="#Museums & public exhibitions    1">Museums &amp; public exhibitions    1</a><ul>
<li><a href="#106. An exploratory study of input modalities for mobile devices used with museum exhibits.">106. An exploratory study of input modalities for mobile devices used with museum exhibits.</a></li>
</ul>
</li>
<li><a href="#Everyday information management    3">Everyday information management    3</a><ul>
<li><a href="#107. "I lie to myself that i have freedom in my own schedule": productivity tools and experiences of busyness.">107. "I lie to myself that i have freedom in my own schedule": productivity tools and experiences of busyness.</a></li>
<li><a href="#108. Homebrew databases: complexities of everyday information management in nonprofit organizations.">108. Homebrew databases: complexities of everyday information management in nonprofit organizations.</a></li>
<li><a href="#109. How a freeform spatial interface supports simple problem solving tasks.">109. How a freeform spatial interface supports simple problem solving tasks.</a></li>
</ul>
</li>
<li><a href="#Low-cost ICT4D    3">Low-cost ICT4D    3</a><ul>
<li><a href="#110. Utilizing multimedia capabilities of mobile phones to support teaching in schools in rural panama.">110. Utilizing multimedia capabilities of mobile phones to support teaching in schools in rural panama.</a></li>
<li><a href="#111. Infrastructures for low-cost laptop use in Mexican schools.">111. Infrastructures for low-cost laptop use in Mexican schools.</a></li>
<li><a href="#112. Utilizing DVD players as low-cost offline internet browsers.">112. Utilizing DVD players as low-cost offline internet browsers.</a></li>
</ul>
</li>
<li><a href="#Predicting & modeling human behaviors    4">Predicting &amp; modeling human behaviors    4</a><ul>
<li><a href="#113. Importance-driven compositing window management.">113. Importance-driven compositing window management.</a></li>
<li><a href="#114. Content and hierarchy in pixel-based methods for reverse engineering interface structure.">114. Content and hierarchy in pixel-based methods for reverse engineering interface structure.</a></li>
<li><a href="#115. Client TouchPoint modeling: understanding client interactions in the context of service delivery.">115. Client TouchPoint modeling: understanding client interactions in the context of service delivery.</a></li>
<li><a href="#116. Using predictive human performance models to inspire and support UI design recommendations.">116. Using predictive human performance models to inspire and support UI design recommendations.</a></li>
</ul>
</li>
<li><a href="#Death & bereavement    3">Death &amp; bereavement    3</a><ul>
<li><a href="#117. Matters of life and death: locating the end of life in lifespan-oriented hci research.">117. Matters of life and death: locating the end of life in lifespan-oriented hci research.</a></li>
<li><a href="#118. I said your name in an empty room: grieving and continuing bonds on facebook.">118. I said your name in an empty room: grieving and continuing bonds on facebook.</a></li>
<li><a href="#119. Dealing with death in design: developing systems for the bereaved.">119. Dealing with death in design: developing systems for the bereaved.</a></li>
</ul>
</li>
<li><a href="#Non-flat Displays    4">Non-flat Displays    4</a><ul>
<li><a href="#120. Touch input on curved surfaces.">120. Touch input on curved surfaces.</a></li>
<li><a href="#121. Audience behavior around large interactive cylindrical screens.">121. Audience behavior around large interactive cylindrical screens.</a></li>
<li><a href="#122. Motionbeam: a metaphor for character interaction with handheld projectors.">122. Motionbeam: a metaphor for character interaction with handheld projectors.</a></li>
<li><a href="#123. 3d projection on physical objects: design insights from five real life cases.">123. 3d projection on physical objects: design insights from five real life cases.</a></li>
</ul>
</li>
<li><a href="#Design theory    2">Design theory    2</a><ul>
<li><a href="#124. The new good: exploring the potential of philosophy of technology to contribute to human-computer interaction.">124. The new good: exploring the potential of philosophy of technology to contribute to human-computer interaction.</a></li>
<li><a href="#125. Understanding interaction design practices.">125. Understanding interaction design practices.</a></li>
</ul>
</li>
<li><a href="#Microblogging behavior    5">Microblogging behavior    5</a><ul>
<li><a href="#126. "Voluntweeters": self-organizing by digital volunteers in times of crisis.">126. "Voluntweeters": self-organizing by digital volunteers in times of crisis.</a></li>
<li><a href="#127. Social media ownership: using twitter as a window onto current attitudes and beliefs.">127. Social media ownership: using twitter as a window onto current attitudes and beliefs.</a></li>
<li><a href="#128. Fragile online relationship: a first look at unfollow dynamics in twitter.">128. Fragile online relationship: a first look at unfollow dynamics in twitter.</a></li>
<li><a href="#129. The impact of network structure on breaking ties in online social networks: unfollowing on twitter.">129. The impact of network structure on breaking ties in online social networks: unfollowing on twitter.</a></li>
<li><a href="#130. Computing political preference among twitter followers.">130. Computing political preference among twitter followers.</a></li>
</ul>
</li>
<li><a href="#Inter-cultural interaction    5">Inter-cultural interaction    5</a><ul>
<li><a href="#131. Online contribution practices in countries that engage in internet blocking and censorship.">131. Online contribution practices in countries that engage in internet blocking and censorship.</a></li>
<li><a href="#132. Real-time collaborative editing behavior in USA and Japanese distributed teams.">132. Real-time collaborative editing behavior in USA and Japanese distributed teams.</a></li>
<li><a href="#133. Cultural differences on visual self-presentation through social networking site profile images.">133. Cultural differences on visual self-presentation through social networking site profile images.</a></li>
<li><a href="#134. MonoTrans2: a new human computation system to support monolingual translation.">134. MonoTrans2: a new human computation system to support monolingual translation.</a></li>
<li><a href="#135. Culture or fluency?: unpacking interactions between culture and communication medium.">135. Culture or fluency?: unpacking interactions between culture and communication medium.</a></li>
</ul>
</li>
<li><a href="#Eye tracking    4">Eye tracking    4</a><ul>
<li><a href="#136. Skim reading by satisficing: evidence from eye tracking.">136. Skim reading by satisficing: evidence from eye tracking.</a></li>
<li><a href="#137. Older web users' eye movements: experience counts.">137. Older web users' eye movements: experience counts.</a></li>
<li><a href="#138. Retrospective think-aloud method: using eye movements as an extra cue for participants' verbalizations.">138. Retrospective think-aloud method: using eye movements as an extra cue for participants' verbalizations.</a></li>
<li><a href="#139. Triggered think-aloud protocol: using eye tracking to improve usability test moderation.">139. Triggered think-aloud protocol: using eye tracking to improve usability test moderation.</a></li>
</ul>
</li>
<li><a href="#Families    4">Families    4</a><ul>
<li><a href="#140. Learning patterns of pick-ups and drop-offs to support busy family coordination.">140. Learning patterns of pick-ups and drop-offs to support busy family coordination.</a></li>
<li><a href="#141. Mediated parent-child contact in work-separated families.">141. Mediated parent-child contact in work-separated families.</a></li>
<li><a href="#142. Hello, is grandma there? let's read! StoryVisit: family video chat and connected e-books.">142. Hello, is grandma there? let's read! StoryVisit: family video chat and connected e-books.</a></li>
<li><a href="#143. Family portals: connecting families through a multifamily media space.">143. Family portals: connecting families through a multifamily media space.</a></li>
</ul>
</li>
<li><a href="#Search & information seeking    4">Search &amp; information seeking    4</a><ul>
<li><a href="#144. The information flaneur: a fresh look at information seeking.">144. The information flaneur: a fresh look at information seeking.</a></li>
<li><a href="#145. No clicks, no problem: using cursor movements to understand and improve search.">145. No clicks, no problem: using cursor movements to understand and improve search.</a></li>
<li><a href="#146. Enhancing credibility judgment of web search results.">146. Enhancing credibility judgment of web search results.</a></li>
<li><a href="#147. Augmenting web pages and search results to support credibility assessment.">147. Augmenting web pages and search results to support credibility assessment.</a></li>
</ul>
</li>
<li><a href="#Expression & perception    5">Expression &amp; perception    5</a><ul>
<li><a href="#148. Using fast interaction to create intense experiences.">148. Using fast interaction to create intense experiences.</a></li>
<li><a href="#149. A VJ centered exploration of expressive interaction.">149. A VJ centered exploration of expressive interaction.</a></li>
<li><a href="#150. Placing a value on aesthetics in online casual games.">150. Placing a value on aesthetics in online casual games.</a></li>
<li><a href="#151. Kinetic tiles.">151. Kinetic tiles.</a></li>
<li><a href="#152. SandCanvas: a multi-touch art medium inspired by sand animation.">152. SandCanvas: a multi-touch art medium inspired by sand animation.</a></li>
</ul>
</li>
<li><a href="#Flexible grips & gestures    4">Flexible grips &amp; gestures    4</a><ul>
<li><a href="#153. Evaluating effects of structural holds on pointing and dragging performance with flexible displays.">153. Evaluating effects of structural holds on pointing and dragging performance with flexible displays.</a></li>
<li><a href="#154. PaperPhone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays.">154. PaperPhone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays.</a></li>
<li><a href="#155. Pinstripe: eyes-free continuous input on interactive clothing.">155. Pinstripe: eyes-free continuous input on interactive clothing.</a></li>
<li><a href="#156. Grips and gestures on a multi-touch pen.">156. Grips and gestures on a multi-touch pen.</a></li>
</ul>
</li>
<li><a href="#3D interaction    4">3D interaction    4</a><ul>
<li><a href="#157. WYSIWYF: exploring and annotating volume data with a tangible handheld device.">157. WYSIWYF: exploring and annotating volume data with a tangible handheld device.</a></li>
<li><a href="#158. Eden: a professional multitouch tool for constructing virtual organic environments.">158. Eden: a professional multitouch tool for constructing virtual organic environments.</a></li>
<li><a href="#159. 2d touching of 3d stereoscopic objects.">159. 2d touching of 3d stereoscopic objects.</a></li>
<li><a href="#160. TZee: exploiting the lighting properties of multi-touch tabletops for tangible 3d interactions.">160. TZee: exploiting the lighting properties of multi-touch tabletops for tangible 3d interactions.</a></li>
</ul>
</li>
<li><a href="#Crowdsourcing    4">Crowdsourcing    4</a><ul>
<li><a href="#161. Guess who?: enriching the social graph through a crowdsourcing game.">161. Guess who?: enriching the social graph through a crowdsourcing game.</a></li>
<li><a href="#162. PhotoCity: training experts at large-scale image acquisition through a competitive game.">162. PhotoCity: training experts at large-scale image acquisition through a competitive game.</a></li>
<li><a href="#163. Cooks or cobblers?: crowd creativity through combination.">163. Cooks or cobblers?: crowd creativity through combination.</a></li>
<li><a href="#164. Human computation: a survey and taxonomy of a growing field.">164. Human computation: a survey and taxonomy of a growing field.</a></li>
</ul>
</li>
<li><a href="#User studies/ethnography in developing regions    4">User studies/ethnography in developing regions    4</a><ul>
<li><a href="#165. The times they are a-changin': mobile payments in india.">165. The times they are a-changin': mobile payments in india.</a></li>
<li><a href="#166. Folk music goes digital in India.">166. Folk music goes digital in India.</a></li>
<li><a href="#167. Designing for emerging rural users: experiences from China.">167. Designing for emerging rural users: experiences from China.</a></li>
<li><a href="#168. Adapting usability testing for oral, rural users.">168. Adapting usability testing for oral, rural users.</a></li>
</ul>
</li>
<li><a href="#Visualization & perception    4">Visualization &amp; perception    4</a><ul>
<li><a href="#169. Evaluating video visualizations of human behavior.">169. Evaluating video visualizations of human behavior.</a></li>
<li><a href="#170. Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces.">170. Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces.</a></li>
<li><a href="#171. The impact of social information on visual judgments.">171. The impact of social information on visual judgments.</a></li>
<li><a href="#172. Directing attention and influencing memory with visual saliency modulation.">172. Directing attention and influencing memory with visual saliency modulation.</a></li>
</ul>
</li>
<li><a href="#Digital content & collections    3">Digital content &amp; collections    3</a><ul>
<li><a href="#173. Freed: a system for creating multiple views of a digital collection during the design process.">173. Freed: a system for creating multiple views of a digital collection during the design process.</a></li>
<li><a href="#174. Teenagers and their virtual possessions: design opportunities and issues.">174. Teenagers and their virtual possessions: design opportunities and issues.</a></li>
<li><a href="#175. Life editing: third-party perspectives on lifelog content.">175. Life editing: third-party perspectives on lifelog content.</a></li>
</ul>
</li>
<li><a href="#Search & stuff    4">Search &amp; stuff    4</a><ul>
<li><a href="#176. Metrics for the evaluation of news site content layout in large-screen contexts.">176. Metrics for the evaluation of news site content layout in large-screen contexts.</a></li>
<li><a href="#177. YouPivot: improving recall with contextual search.">177. YouPivot: improving recall with contextual search.</a></li>
<li><a href="#178. An examination of two delivery modes for interactive search system experiments: remote and laboratory.">178. An examination of two delivery modes for interactive search system experiments: remote and laboratory.</a></li>
<li><a href="#179. Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs.">179. Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs.</a></li>
</ul>
</li>
<li><a href="#Design materiality    3">Design materiality    3</a><ul>
<li><a href="#180. Making spaces: how design workbooks work.">180. Making spaces: how design workbooks work.</a></li>
<li><a href="#181. Inspirational bits: towards a shared understanding of the digital material.">181. Inspirational bits: towards a shared understanding of the digital material.</a></li>
<li><a href="#182. Don't drop it!: pick it up and storyboard.">182. Don't drop it!: pick it up and storyboard.</a></li>
</ul>
</li>
<li><a href="#Multi-touch    5">Multi-touch    5</a><ul>
<li><a href="#183. Rock & rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations.">183. Rock &amp; rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations.</a></li>
<li><a href="#184. Multi-touch document folding: gesture models, fold directions and symmetries.">184. Multi-touch document folding: gesture models, fold directions and symmetries.</a></li>
<li><a href="#185. FingerGlass: efficient multiscale interaction on multitouch screens.">185. FingerGlass: efficient multiscale interaction on multitouch screens.</a></li>
<li><a href="#186. An interactive multi-touch sketching interface for diffusion curves.">186. An interactive multi-touch sketching interface for diffusion curves.</a></li>
<li><a href="#187. Grids & guides: multi-touch layout and alignment tools.">187. Grids &amp; guides: multi-touch layout and alignment tools.</a></li>
</ul>
</li>
<li><a href="#Pointing 2: Fitts law    5">Pointing 2: Fitts law    5</a><ul>
<li><a href="#188. Fitt's law as an explicit time/error trade-off.">188. Fitt's law as an explicit time/error trade-off.</a></li>
<li><a href="#189. Benchmarking pointing techniques with distractors: adding a density factor to Fitts' pointing paradigm.">189. Benchmarking pointing techniques with distractors: adding a density factor to Fitts' pointing paradigm.</a></li>
<li><a href="#190. The effects of task dimensionality, endpoint deviation, throughput calculation, and experiment design on pointing measures and models.">190. The effects of task dimensionality, endpoint deviation, throughput calculation, and experiment design on pointing measures and models.</a></li>
<li><a href="#191. The effects of intended use on target acquisition.">191. The effects of intended use on target acquisition.</a></li>
<li><a href="#192. Modeling and predicting pointing errors in two dimensions.">192. Modeling and predicting pointing errors in two dimensions.</a></li>
</ul>
</li>
<li><a href="#Evaluation and/or design based on many users    3">Evaluation and/or design based on many users    3</a><ul>
<li><a href="#193. Into the wild: challenges and opportunities for field trial methods.">193. Into the wild: challenges and opportunities for field trial methods.</a></li>
<li><a href="#194. When a little knowledge isn't a dangerous thing.">194. When a little knowledge isn't a dangerous thing.</a></li>
<li><a href="#195. Field trial of Tiramisu: crowd-sourcing bus arrival times to spur co-design.">195. Field trial of Tiramisu: crowd-sourcing bus arrival times to spur co-design.</a></li>
</ul>
</li>
<li><a href="#Homeless users    3">Homeless users    3</a><ul>
<li><a href="#196. Publics in practice: ubiquitous computing at a shelter for homeless mothers.">196. Publics in practice: ubiquitous computing at a shelter for homeless mothers.</a></li>
<li><a href="#197. Homeless young people and living with personal digital artifacts.">197. Homeless young people and living with personal digital artifacts.</a></li>
<li><a href="#198. Improving the safety of homeless young people with mobile phones: values, form and function.">198. Improving the safety of homeless young people with mobile phones: values, form and function.</a></li>
</ul>
</li>
<li><a href="#Visual analytics    4">Visual analytics    4</a><ul>
<li><a href="#199. Playable data: characterizing the design space of game-y infographics.">199. Playable data: characterizing the design space of game-y infographics.</a></li>
<li><a href="#200. Cardiogram: visual analytics for automotive engineers.">200. Cardiogram: visual analytics for automotive engineers.</a></li>
<li><a href="#201. KronoMiner: using multi-foci navigation for the visual exploration of time-series data.">201. KronoMiner: using multi-foci navigation for the visual exploration of time-series data.</a></li>
<li><a href="#202. LifeFlow: visualizing an overview of event sequences.">202. LifeFlow: visualizing an overview of event sequences.</a></li>
</ul>
</li>
<li><a href="#Photo sharing    4">Photo sharing    4</a><ul>
<li><a href="#203. The photostroller: supporting diverse care home residents in engaging with the world.">203. The photostroller: supporting diverse care home residents in engaging with the world.</a></li>
<li><a href="#204. Automics: souvenir generating photoware for theme parks.">204. Automics: souvenir generating photoware for theme parks.</a></li>
<li><a href="#205. Contextual dynamics of group-based sharing decisions.">205. Contextual dynamics of group-based sharing decisions.</a></li>
<li><a href="#206. Pass-them-around: collaborative use of mobile phones for photo sharing.">206. Pass-them-around: collaborative use of mobile phones for photo sharing.</a></li>
</ul>
</li>
<li><a href="#Web search & usability    5">Web search &amp; usability    5</a><ul>
<li><a href="#207. ClassSearch: facilitating the development of web search skills through social learning.">207. ClassSearch: facilitating the development of web search skills through social learning.</a></li>
<li><a href="#208. Role of available and provided resources in sensemaking.">208. Role of available and provided resources in sensemaking.</a></li>
<li><a href="#209. Characterizing the usability of interactive applications through query log analysis.">209. Characterizing the usability of interactive applications through query log analysis.</a></li>
<li><a href="#210. Determining relevancy: how software developers determine relevant information in feeds.">210. Determining relevancy: how software developers determine relevant information in feeds.</a></li>
<li><a href="#211. Measuring web page revisitation in tabbed browsing.">211. Measuring web page revisitation in tabbed browsing.</a></li>
</ul>
</li>
<li><a href="#Performing arts    3">Performing arts    3</a><ul>
<li><a href="#212. Evaluating longitudinal projects combining technology with temporal arts.">212. Evaluating longitudinal projects combining technology with temporal arts.</a></li>
<li><a href="#213. Love, hate, arousal and engagement: exploring audience responses to performing arts.">213. Love, hate, arousal and engagement: exploring audience responses to performing arts.</a></li>
<li><a href="#214. Designing from within: humanaquarium.">214. Designing from within: humanaquarium.</a></li>
</ul>
</li>
<li><a href="#Collaboration & creativity    3">Collaboration &amp; creativity    3</a><ul>
<li><a href="#215. The polymath project: lessons from a successful online collaboration in mathematics.">215. The polymath project: lessons from a successful online collaboration in mathematics.</a></li>
<li><a href="#216. Collaborative creativity: a complex systems model with distributed affect.">216. Collaborative creativity: a complex systems model with distributed affect.</a></li>
<li><a href="#217. Predicting the perceived quality of online mathematics contributions from users' reputations.">217. Predicting the perceived quality of online mathematics contributions from users' reputations.</a></li>
</ul>
</li>
<li><a href="#Wireless networks    3">Wireless networks    3</a><ul>
<li><a href="#218. Why is my internet slow?: making network speeds visible.">218. Why is my internet slow?: making network speeds visible.</a></li>
<li><a href="#219. GridOrbit: an infrastructure awareness system for increasing contribution in volunteer computing.">219. GridOrbit: an infrastructure awareness system for increasing contribution in volunteer computing.</a></li>
<li><a href="#220. How users associate wireless devices.">220. How users associate wireless devices.</a></li>
</ul>
</li>
<li><a href="#Storytelling & perceptual crossing    3">Storytelling &amp; perceptual crossing    3</a><ul>
<li><a href="#221. ShadowStory: creative and collaborative digital storytelling inspired by cultural heritage.">221. ShadowStory: creative and collaborative digital storytelling inspired by cultural heritage.</a></li>
<li><a href="#222. Designing for perceptual crossing to improve user involvement.">222. Designing for perceptual crossing to improve user involvement.</a></li>
<li><a href="#223. Limits of rereadability in procedural interactive stories.">223. Limits of rereadability in procedural interactive stories.</a></li>
</ul>
</li>
<li><a href="#Emergency response & scheduling    3">Emergency response &amp; scheduling    3</a><ul>
<li><a href="#224. Rigid structures, independent units, monitoring: organizing patterns in frontline firefighting.">224. Rigid structures, independent units, monitoring: organizing patterns in frontline firefighting.</a></li>
<li><a href="#225. Zero-fidelity simulation of fire emergency response: improving team coordination learning.">225. Zero-fidelity simulation of fire emergency response: improving team coordination learning.</a></li>
<li><a href="#226. Kairoscope: managing time perception and scheduling through social event coordination.">226. Kairoscope: managing time perception and scheduling through social event coordination.</a></li>
</ul>
</li>
<li><a href="#Learning    2">Learning    2</a><ul>
<li><a href="#227. Practical, appropriate, empirically-validated guidelines for designing educational games.">227. Practical, appropriate, empirically-validated guidelines for designing educational games.</a></li>
<li><a href="#228. The mathematical imagery trainer: from embodied interaction to conceptual learning.">228. The mathematical imagery trainer: from embodied interaction to conceptual learning.</a></li>
</ul>
</li>
<li><a href="#Time/animations    2">Time/animations    2</a><ul>
<li><a href="#229. Kineticons: using iconographic motion in graphical user interface design.">229. Kineticons: using iconographic motion in graphical user interface design.</a></li>
<li><a href="#230. Temporal distortion for animated transitions.">230. Temporal distortion for animated transitions.</a></li>
</ul>
</li>
<li><a href="#Touch 1: tactile & haptics    6">Touch 1: tactile &amp; haptics    6</a><ul>
<li><a href="#231. Tactile brush: drawing on skin with a tactile grid display.">231. Tactile brush: drawing on skin with a tactile grid display.</a></li>
<li><a href="#232. A comparative study of tactile representation techniques for landmarks on a wearable device.">232. A comparative study of tactile representation techniques for landmarks on a wearable device.</a></li>
<li><a href="#233. Handscope: enabling blind people to experience statistical graphics on websites through haptics.">233. Handscope: enabling blind people to experience statistical graphics on websites through haptics.</a></li>
<li><a href="#234. Nenya: subtle and eyes-free mobile input with a magnetically-tracked finger ring.">234. Nenya: subtle and eyes-free mobile input with a magnetically-tracked finger ring.</a></li>
<li><a href="#235. The haptic laser: multi-sensation tactile feedback for at-a-distance physical space perception and interaction.">235. The haptic laser: multi-sensation tactile feedback for at-a-distance physical space perception and interaction.</a></li>
<li><a href="#236. Interactive generator: a self-powered haptic feedback device.">236. Interactive generator: a self-powered haptic feedback device.</a></li>
</ul>
</li>
<li><a href="#Security (systems">Security (systems)    4</a>    4)<ul>
<li><a href="#237. Security through a different kind of obscurity: evaluating distortion in graphical authentication schemes.">237. Security through a different kind of obscurity: evaluating distortion in graphical authentication schemes.</a></li>
<li><a href="#238. More than skin deep: measuring effects of the underlying model on access-control system usability.">238. More than skin deep: measuring effects of the underlying model on access-control system usability.</a></li>
<li><a href="#239. Does domain highlighting help people identify phishing sites?">239. Does domain highlighting help people identify phishing sites?</a></li>
<li><a href="#240. Exploring reactive access control.">240. Exploring reactive access control.</a></li>
</ul>
</li>
<li><a href="#Home automation    3">Home automation    3</a><ul>
<li><a href="#241. Reflecting on pills and phone use: supporting awareness of functional abilities for older adults.">241. Reflecting on pills and phone use: supporting awareness of functional abilities for older adults.</a></li>
<li><a href="#242. User-centred multimodal reminders for assistive living.">242. User-centred multimodal reminders for assistive living.</a></li>
<li><a href="#243. Home automation in the wild: challenges and opportunities.">243. Home automation in the wild: challenges and opportunities.</a></li>
</ul>
</li>
<li><a href="#Sustainability 1    4">Sustainability 1    4</a><ul>
<li><a href="#244. Creek watch: pairing usefulness and usability for successful citizen science.">244. Creek watch: pairing usefulness and usability for successful citizen science.</a></li>
<li><a href="#245. Designing eco-feedback systems for everyday life.">245. Designing eco-feedback systems for everyday life.</a></li>
<li><a href="#246. BeeParking: feedback interfaces for collective behavior change.">246. BeeParking: feedback interfaces for collective behavior change.</a></li>
<li><a href="#247. GreenHat: exploring the natural environment through experts' perspectives.">247. GreenHat: exploring the natural environment through experts' perspectives.</a></li>
</ul>
</li>
<li><a href="#Mobile issues    3">Mobile issues    3</a><ul>
<li><a href="#248. Telling calls: facilitating mobile phone conversation grounding and management.">248. Telling calls: facilitating mobile phone conversation grounding and management.</a></li>
<li><a href="#249. Deep shot: a framework for migrating tasks across devices using mobile phone cameras.">249. Deep shot: a framework for migrating tasks across devices using mobile phone cameras.</a></li>
<li><a href="#250. Eyes-free multitasking: the effect of cognitive load on mobile spatial audio interfaces.">250. Eyes-free multitasking: the effect of cognitive load on mobile spatial audio interfaces.</a></li>
</ul>
</li>
<li><a href="#Website & application design    5">Website &amp; application design    5</a><ul>
<li><a href="#251. Feedlack detects missing feedback in web applications.">251. Feedlack detects missing feedback in web applications.</a></li>
<li><a href="#252. Entity-linking interfaces in user-contributed content: preference and performance.">252. Entity-linking interfaces in user-contributed content: preference and performance.</a></li>
<li><a href="#253. Bricolage: example-based retargeting for web design.">253. Bricolage: example-based retargeting for web design.</a></li>
<li><a href="#254. HyperSource: bridging the gap between source and code-related web sites.">254. HyperSource: bridging the gap between source and code-related web sites.</a></li>
<li><a href="#255. Item sampling for information architecture.">255. Item sampling for information architecture.</a></li>
</ul>
</li>
<li><a href="#New approaches to usability    5">New approaches to usability    5</a><ul>
<li><a href="#256. When designing usability questionnaires, does it hurt to be positive?">256. When designing usability questionnaires, does it hurt to be positive?</a></li>
<li><a href="#257. Synchronous remote usability testing: a new approach facilitated by virtual worlds.">257. Synchronous remote usability testing: a new approach facilitated by virtual worlds.</a></li>
<li><a href="#258. Representing users in accessibility research.">258. Representing users in accessibility research.</a></li>
<li><a href="#259. Democratising technology: making transformation using designing, performance and props.">259. Democratising technology: making transformation using designing, performance and props.</a></li>
<li><a href="#260. Post-deployment usability: a survey of current practices.">260. Post-deployment usability: a survey of current practices.</a></li>
</ul>
</li>
<li><a href="#Design Methods    4">Design Methods    4</a><ul>
<li><a href="#261. Collaboration personas: a new approach to designing workplace collaboration tools.">261. Collaboration personas: a new approach to designing workplace collaboration tools.</a></li>
<li><a href="#262. From garments to gardens: negotiating material relationships online and 'by hand'.">262. From garments to gardens: negotiating material relationships online and 'by hand'.</a></li>
<li><a href="#263. Persona cases: a technique for grounding personas.">263. Persona cases: a technique for grounding personas.</a></li>
<li><a href="#264. When the implication is not to design (technology">264. When the implication is not to design (technology).</a>.)</li>
</ul>
</li>
<li><a href="#Decision making & the web    2">Decision making &amp; the web    2</a><ul>
<li><a href="#265. Utility of human-computer interactions: toward a science of preference measurement.">265. Utility of human-computer interactions: toward a science of preference measurement.</a></li>
<li><a href="#266. Informing decisions: how people use online rating information to make choices.">266. Informing decisions: how people use online rating information to make choices.</a></li>
</ul>
</li>
<li><a href="#Security (social">Security (social)    4</a>    4)<ul>
<li><a href="#267. Oops, I did it again: mitigating repeated access control errors on facebook.">267. Oops, I did it again: mitigating repeated access control errors on facebook.</a></li>
<li><a href="#268. Integrating user feedback with heuristic security and privacy management systems.">268. Integrating user feedback with heuristic security and privacy management systems.</a></li>
<li><a href="#269. Pairing devices for social interactions: a comparative usability evaluation.">269. Pairing devices for social interactions: a comparative usability evaluation.</a></li>
<li><a href="#270. Experiencing security in interaction design.">270. Experiencing security in interaction design.</a></li>
</ul>
</li>
<li><a href="#Games    4">Games    4</a><ul>
<li><a href="#271. Building sensitising terms to understand free-play in open-ended interactive art environments.">271. Building sensitising terms to understand free-play in open-ended interactive art environments.</a></li>
<li><a href="#272. Evaluating the benefits of 3d stereo in modern video games.">272. Evaluating the benefits of 3d stereo in modern video games.</a></li>
<li><a href="#273. Target assistance for subtly balancing competitive play.">273. Target assistance for subtly balancing competitive play.</a></li>
<li><a href="#274. Data cracker: developing a visual game analytic tool for analyzing online gameplay.">274. Data cracker: developing a visual game analytic tool for analyzing online gameplay.</a></li>
</ul>
</li>
<li><a href="#Sustainability 2    4">Sustainability 2    4</a><ul>
<li><a href="#275. Ceci n'est pas une pipe bombe: authoring urban landscapes with air quality sensors.">275. Ceci n'est pas une pipe bombe: authoring urban landscapes with air quality sensors.</a></li>
<li><a href="#276. Second-hand interactions: investigating reacquisition and dispossession practices around domestic objects.">276. Second-hand interactions: investigating reacquisition and dispossession practices around domestic objects.</a></li>
<li><a href="#277. Practices in the creative reuse of e-waste.">277. Practices in the creative reuse of e-waste.</a></li>
<li><a href="#278. A phenomenology of human-electricity relations.">278. A phenomenology of human-electricity relations.</a></li>
</ul>
</li>
<li><a href="#Location sharing    5">Location sharing    5</a><ul>
<li><a href="#279. I'm the mayor of my house: examining why people use foursquare - a social-driven location sharing application.">279. I'm the mayor of my house: examining why people use foursquare - a social-driven location sharing application.</a></li>
<li><a href="#280. In the best families: tracking and relationships.">280. In the best families: tracking and relationships.</a></li>
<li><a href="#281. Opportunities exist: continuous discovery of places to perform activities.">281. Opportunities exist: continuous discovery of places to perform activities.</a></li>
<li><a href="#282. Location visualization in social media applications.">282. Location visualization in social media applications.</a></li>
<li><a href="#283. When are users comfortable sharing locations with advertisers?">283. When are users comfortable sharing locations with advertisers?</a></li>
</ul>
</li>
<li><a href="#Text entry & typing    4">Text entry &amp; typing    4</a><ul>
<li><a href="#284. Typing on flat glass: examining ten-finger expert typing patterns on touch surfaces.">284. Typing on flat glass: examining ten-finger expert typing patterns on touch surfaces.</a></li>
<li><a href="#285. CHANTI: predictive text entry using non-verbal vocal input.">285. CHANTI: predictive text entry using non-verbal vocal input.</a></li>
<li><a href="#286. AirStroke: bringing unistroke text entry to freehand gesture interfaces.">286. AirStroke: bringing unistroke text entry to freehand gesture interfaces.</a></li>
<li><a href="#287. Sampling representative phrase sets for text entry experiments: a procedure and public resource.">287. Sampling representative phrase sets for text entry experiments: a procedure and public resource.</a></li>
</ul>
</li>
<li><a href="#Touch 2: tactile & targets    4">Touch 2: tactile &amp; targets    4</a><ul>
<li><a href="#288. Enhancing physicality in touch interaction with programmable friction.">288. Enhancing physicality in touch interaction with programmable friction.</a></li>
<li><a href="#289. Surfpad: riding towards targets on a squeeze film effect.">289. Surfpad: riding towards targets on a squeeze film effect.</a></li>
<li><a href="#290. Understanding touch.">290. Understanding touch.</a></li>
<li><a href="#291. Magic desk: bringing multi-touch surfaces into desktop work.">291. Magic desk: bringing multi-touch surfaces into desktop work.</a></li>
</ul>
</li>
<li><a href="#Methods to aid & structure design    4">Methods to aid &amp; structure design    4</a><ul>
<li><a href="#292. Benefits of matching domain structure for planning software: the right stuff.">292. Benefits of matching domain structure for planning software: the right stuff.</a></li>
<li><a href="#293. Developmentally situated design (DSD">293. Developmentally situated design (DSD): making theoretical knowledge accessible to designers of children's technology.</a>: making theoretical knowledge accessible to designers of children's technology.)</li>
<li><a href="#294. A spreadsheet-based user interface for managing plural relationships in structured data.">294. A spreadsheet-based user interface for managing plural relationships in structured data.</a></li>
<li><a href="#295. Variation in importance of time-on-task with familiarity with mobile phone models.">295. Variation in importance of time-on-task with familiarity with mobile phone models.</a></li>
</ul>
</li>
<li><a href="#Touch 3: sensing    4">Touch 3: sensing    4</a><ul>
<li><a href="#296. Some like it hot: thermal feedback for mobile devices.">296. Some like it hot: thermal feedback for mobile devices.</a></li>
<li><a href="#297. HeatWave: thermal imaging for surface user interaction.">297. HeatWave: thermal imaging for surface user interaction.</a></li>
<li><a href="#298. AnglePose: robust, precise capacitive touch tracking via 3d orientation estimation.">298. AnglePose: robust, precise capacitive touch tracking via 3d orientation estimation.</a></li>
<li><a href="#299. TouchCuts and TouchZoom: enhanced target selection for touch displays using finger proximity sensing.">299. TouchCuts and TouchZoom: enhanced target selection for touch displays using finger proximity sensing.</a></li>
</ul>
</li>
<li><a href="#Authentication    6">Authentication    6</a><ul>
<li><a href="#300. Of passwords and people: measuring the effect of password-composition policies.">300. Of passwords and people: measuring the effect of password-composition policies.</a></li>
<li><a href="#301. MARASIM: a novel jigsaw based authentication scheme using tagging.">301. MARASIM: a novel jigsaw based authentication scheme using tagging.</a></li>
<li><a href="#302. Exploring implicit memory for painless password recovery.">302. Exploring implicit memory for painless password recovery.</a></li>
<li><a href="#303. Self-reported password sharing strategies.">303. Self-reported password sharing strategies.</a></li>
<li><a href="#304. On the necessity of user-friendly CAPTCHA.">304. On the necessity of user-friendly CAPTCHA.</a></li>
<li><a href="#305. A diary study of password usage in daily life.">305. A diary study of password usage in daily life.</a></li>
</ul>
</li>
<li><a href="#Cats, dogs, sports, games & books    5">Cats, dogs, sports, games &amp; books    5</a><ul>
<li><a href="#306. Understanding people and animals: the use of a positioning system in ordinary human-canine interaction.">306. Understanding people and animals: the use of a positioning system in ordinary human-canine interaction.</a></li>
<li><a href="#307. Communication technology for human-dog interaction: exploration of dog owners' experiences and expectations.">307. Communication technology for human-dog interaction: exploration of dog owners' experiences and expectations.</a></li>
<li><a href="#308. Designing sports: a framework for exertion games.">308. Designing sports: a framework for exertion games.</a></li>
<li><a href="#309. Cat cat revolution: an interspecies gaming experience.">309. Cat cat revolution: an interspecies gaming experience.</a></li>
<li><a href="#310. Antiquarian answers: book restoration as a resource for design.">310. Antiquarian answers: book restoration as a resource for design.</a></li>
</ul>
</li>
<li><a href="#User experience    5">User experience    5</a><ul>
<li><a href="#311. Which version is this?: improving the desktop experience within a copy-aware computing ecosystem.">311. Which version is this?: improving the desktop experience within a copy-aware computing ecosystem.</a></li>
<li><a href="#312. Enticing consumers via incomplete product experience: an investigation of online product interactivity designs.">312. Enticing consumers via incomplete product experience: an investigation of online product interactivity designs.</a></li>
<li><a href="#313. Old wine in new bottles or novel challenges: a critical analysis of empirical studies of user experience.">313. Old wine in new bottles or novel challenges: a critical analysis of empirical studies of user experience.</a></li>
<li><a href="#314. Perceptual analysis of talking avatar head movements: a quantitative perspective.">314. Perceptual analysis of talking avatar head movements: a quantitative perspective.</a></li>
<li><a href="#315. Diminishing returns?: revisiting perception of computing performance.">315. Diminishing returns?: revisiting perception of computing performance.</a></li>
</ul>
</li>
<li><a href="#Interaction on mobile devices    7">Interaction on mobile devices    7</a><ul>
<li><a href="#316. ShadowPuppets: supporting collocated interaction with mobile projector phones using hand shadows.">316. ShadowPuppets: supporting collocated interaction with mobile projector phones using hand shadows.</a></li>
<li><a href="#317. DoubleFlip: a motion gesture delimiter for mobile interaction.">317. DoubleFlip: a motion gesture delimiter for mobile interaction.</a></li>
<li><a href="#318. Multi-user interaction on media facades through live video on mobile devices.">318. Multi-user interaction on media facades through live video on mobile devices.</a></li>
<li><a href="#319. Interaction with magic lenses: real-world validation of a Fitts' Law model.">319. Interaction with magic lenses: real-world validation of a Fitts' Law model.</a></li>
<li><a href="#320. Xpaaand: interaction techniques for rollable displays.">320. Xpaaand: interaction techniques for rollable displays.</a></li>
<li><a href="#321. TapBack: towards richer mobile interfaces in impoverished contexts.">321. TapBack: towards richer mobile interfaces in impoverished contexts.</a></li>
<li><a href="#322. "ClearPlate" for capturing printed information: a scanner and viewfinder in one optical unit.">322. "ClearPlate" for capturing printed information: a scanner and viewfinder in one optical unit.</a></li>
</ul>
</li>
<li><a href="#Shortcuts commands & expertise    4">Shortcuts commands &amp; expertise    4</a><ul>
<li><a href="#323. Dips and ceilings: understanding and supporting transitions to expertise in user interfaces.">323. Dips and ceilings: understanding and supporting transitions to expertise in user interfaces.</a></li>
<li><a href="#324. Ambient help.">324. Ambient help.</a></li>
<li><a href="#325. Parameter selection in keyboard-based dialog boxes.">325. Parameter selection in keyboard-based dialog boxes.</a></li>
<li><a href="#326. Categorization costs for hierarchical keyboard commands.">326. Categorization costs for hierarchical keyboard commands.</a></li>
</ul>
</li>
<li><a href="#Sound interactions    5">Sound interactions    5</a><ul>
<li><a href="#327. Sasayaki: augmented voice web browsing experience.">327. Sasayaki: augmented voice web browsing experience.</a></li>
<li><a href="#328. On the audio representation of radial direction.">328. On the audio representation of radial direction.</a></li>
<li><a href="#329. Multidimensional gesture sensing at the piano keyboard.">329. Multidimensional gesture sensing at the piano keyboard.</a></li>
<li><a href="#330. Spatialized sound enhances biomechanically-induced self-motion illusion (vection">330. Spatialized sound enhances biomechanically-induced self-motion illusion (vection).</a>.)</li>
<li><a href="#331. Name that tune: musicons as reminders in the home.">331. Name that tune: musicons as reminders in the home.</a></li>
</ul>
</li>
<li><a href="#Innovation & design    1">Innovation &amp; design    1</a><ul>
<li><a href="#332. Prototyping dynamics: sharing multiple designs improves exploration, group rapport, and results.">332. Prototyping dynamics: sharing multiple designs improves exploration, group rapport, and results.</a></li>
</ul>
</li>
<li><a href="#Tabletop synchronous collaboration    2">Tabletop synchronous collaboration    2</a><ul>
<li><a href="#333. Enhancing genomic learning through tabletop interaction.">333. Enhancing genomic learning through tabletop interaction.</a></li>
<li><a href="#334. Supporting fluid tabletop collaboration across distances.">334. Supporting fluid tabletop collaboration across distances.</a></li>
</ul>
</li>
<li><a href="#Social Q & A    3">Social Q &amp; A    3</a><ul>
<li><a href="#335. Effects of community size and contact rate in synchronous social q&a.">335. Effects of community size and contact rate in synchronous social q&amp;a.</a></li>
<li><a href="#336. Redesign as an act of violence: disrupted interaction patterns and the fragmenting of a social Q&A community.">336. Redesign as an act of violence: disrupted interaction patterns and the fragmenting of a social Q&amp;A community.</a></li>
<li><a href="#337. Design lessons from the fastest q&a site in the west.">337. Design lessons from the fastest q&amp;a site in the west.</a></li>
</ul>
</li>
<li><a href="#Empowering users in developing regions    1">Empowering users in developing regions    1</a><ul>
<li><a href="#338. Towards a design model for women's empowerment in the developing world.">338. Towards a design model for women's empowerment in the developing world.</a></li>
</ul>
</li>
<li><a href="#Organizations & distributed work    3">Organizations &amp; distributed work    3</a><ul>
<li><a href="#339. Reuse in the wild: an empirical and ethnographic study of organizational content reuse.">339. Reuse in the wild: an empirical and ethnographic study of organizational content reuse.</a></li>
<li><a href="#340. Do you know dis?: a user study of a knowledge discovery tool for organizations.">340. Do you know dis?: a user study of a knowledge discovery tool for organizations.</a></li>
<li><a href="#341. What's in a move?: normal disruption and a design challenge.">341. What's in a move?: normal disruption and a design challenge.</a></li>
</ul>
</li>
<li><a href="#Reading & writing    3">Reading &amp; writing    3</a><ul>
<li><a href="#342. Finders/keepers: a longitudinal study of people managing information scraps in a micro-note tool.">342. Finders/keepers: a longitudinal study of people managing information scraps in a micro-note tool.</a></li>
<li><a href="#343. The imposition and superimposition of digital reading technology: the academic potential of e-readers.">343. The imposition and superimposition of digital reading technology: the academic potential of e-readers.</a></li>
<li><a href="#344. Active reading and its discontents: the situations, problems and ideas of readers.">344. Active reading and its discontents: the situations, problems and ideas of readers.</a></li>
</ul>
</li>
<li><a href="#Engaging youth    5">Engaging youth    5</a><ul>
<li><a href="#345. Exploratory evaluations of a computer game supporting cognitive behavioural therapy for adolescents.">345. Exploratory evaluations of a computer game supporting cognitive behavioural therapy for adolescents.</a></li>
<li><a href="#346. In the mood: engaging teenagers in psychotherapy using mobile phones.">346. In the mood: engaging teenagers in psychotherapy using mobile phones.</a></li>
<li><a href="#347. Breaking boundaries: strategies for mentoring through textile computing workshops.">347. Breaking boundaries: strategies for mentoring through textile computing workshops.</a></li>
<li><a href="#348. African American men constructing computing identity.">348. African American men constructing computing identity.</a></li>
<li><a href="#349. Brick by brick: iterating interventions to bridge the achievement gap with virtual peers.">349. Brick by brick: iterating interventions to bridge the achievement gap with virtual peers.</a></li>
</ul>
</li>
<li><a href="#Tangibles    5">Tangibles    5</a><ul>
<li><a href="#350. Tangible bots: interaction with active tangibles in tabletop interfaces.">350. Tangible bots: interaction with active tangibles in tabletop interfaces.</a></li>
<li><a href="#351. Geckos: combining magnets and pressure images to enable new tangible-object design and interaction.">351. Geckos: combining magnets and pressure images to enable new tangible-object design and interaction.</a></li>
<li><a href="#352. TUIC: enabling tangible interaction on capacitive multi-touch displays.">352. TUIC: enabling tangible interaction on capacitive multi-touch displays.</a></li>
<li><a href="#353. tBox: a 3d transformation widget designed for touch-screens.">353. tBox: a 3d transformation widget designed for touch-screens.</a></li>
<li><a href="#354. Rendering physical effects in tabletop controls.">354. Rendering physical effects in tabletop controls.</a></li>
</ul>
</li>
<li><a href="#Groups around the table    4">Groups around the table    4</a><ul>
<li><a href="#355. Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops.">355. Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops.</a></li>
<li><a href="#356. Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits.">356. Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits.</a></li>
<li><a href="#357. Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop interface.">357. Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop interface.</a></li>
<li><a href="#358. The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables.">358. The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables.</a></li>
</ul>
</li>
<li><a href="#Rehabilitation    4">Rehabilitation    4</a><ul>
<li><a href="#359. Opportunities for computing technologies to support healthy sleep behaviors.">359. Opportunities for computing technologies to support healthy sleep behaviors.</a></li>
<li><a href="#360. How to evaluate technologies for health behavior change in HCI research.">360. How to evaluate technologies for health behavior change in HCI research.</a></li>
<li><a href="#361. Motivating mobility: designing for lived motivation in stroke rehabilitation.">361. Motivating mobility: designing for lived motivation in stroke rehabilitation.</a></li>
<li><a href="#362. Group pulmonary rehabilitation delivered to the home via the internet: feasibility and patient perception.">362. Group pulmonary rehabilitation delivered to the home via the internet: feasibility and patient perception.</a></li>
</ul>
</li>
<li><a href="#Software development & product support    1">Software development &amp; product support    1</a><ul>
<li><a href="#363. Modern software product support processes and the usage of multimedia formats.">363. Modern software product support processes and the usage of multimedia formats.</a></li>
</ul>
</li>
<li><a href="#Multitasking & interruption    4">Multitasking &amp; interruption    4</a><ul>
<li><a href="#364. Ease of juggling: studying the effects of manual multitasking.">364. Ease of juggling: studying the effects of manual multitasking.</a></li>
<li><a href="#365. Designing of multimodal feedback for enhanced multitasking performance.">365. Designing of multimodal feedback for enhanced multitasking performance.</a></li>
<li><a href="#366. The effects of time constraints on user behavior for deferrable interruptions.">366. The effects of time constraints on user behavior for deferrable interruptions.</a></li>
<li><a href="#367. Why do i keep interrupting myself?: environment, habit and self-interruption.">367. Why do i keep interrupting myself?: environment, habit and self-interruption.</a></li>
</ul>
</li>
<li><a href="#Organizations & enterprise    5">Organizations &amp; enterprise    5</a><ul>
<li><a href="#368. CommentSpace: structured support for collaborative visual analysis.">368. CommentSpace: structured support for collaborative visual analysis.</a></li>
<li><a href="#369. Supporting collaborative help for individualized use.">369. Supporting collaborative help for individualized use.</a></li>
<li><a href="#370. The scale and evolution of coordination needs in large-scale distributed projects: implications for the future generation of collaborative tools.">370. The scale and evolution of coordination needs in large-scale distributed projects: implications for the future generation of collaborative tools.</a></li>
<li><a href="#371. Topika: integrating collaborative sharing with email.">371. Topika: integrating collaborative sharing with email.</a></li>
<li><a href="#372. Raconteur: integrating authored and real-time social media.">372. Raconteur: integrating authored and real-time social media.</a></li>
</ul>
</li>
<li><a href="#Books & language    5">Books &amp; language    5</a><ul>
<li><a href="#373. MicroMandarin: mobile language learning in context.">373. MicroMandarin: mobile language learning in context.</a></li>
<li><a href="#374. Augmenting the web for second language vocabulary learning.">374. Augmenting the web for second language vocabulary learning.</a></li>
<li><a href="#375. Document area identification for extending books without markers.">375. Document area identification for extending books without markers.</a></li>
<li><a href="#376. The reading desk: applying physical interactions to digital documents.">376. The reading desk: applying physical interactions to digital documents.</a></li>
<li><a href="#377. ReadN'Karaoke: visualizing prosody in children's books for expressive oral reading.">377. ReadN'Karaoke: visualizing prosody in children's books for expressive oral reading.</a></li>
</ul>
</li>
<li><a href="#Privacy    4">Privacy    4</a><ul>
<li><a href="#378. Situating the concern for information privacy through an empirical study of responses to video recording.">378. Situating the concern for information privacy through an empirical study of responses to video recording.</a></li>
<li><a href="#379. We're in it together: interpersonal management of disclosure in social network services.">379. We're in it together: interpersonal management of disclosure in social network services.</a></li>
<li><a href="#380. Privacy dictionary: a linguistic taxonomy of privacy for content analysis.">380. Privacy dictionary: a linguistic taxonomy of privacy for content analysis.</a></li>
<li><a href="#381. Social and technical challenges in parenting teens' social media use.">381. Social and technical challenges in parenting teens' social media use.</a></li>
</ul>
</li>
<li><a href="#Tactile interaction    5">Tactile interaction    5</a><ul>
<li><a href="#382. Enhancing independence and safety for blind and deaf-blind public transit riders.">382. Enhancing independence and safety for blind and deaf-blind public transit riders.</a></li>
<li><a href="#383. A haptic wristwatch for eyes-free interactions.">383. A haptic wristwatch for eyes-free interactions.</a></li>
<li><a href="#384. Detecting vibrations across the body in mobile contexts.">384. Detecting vibrations across the body in mobile contexts.</a></li>
<li><a href="#385. Tactile feedback can assist vision during mobile interactions.">385. Tactile feedback can assist vision during mobile interactions.</a></li>
<li><a href="#386. Designing tactile feedback for piezo buttons.">386. Designing tactile feedback for piezo buttons.</a></li>
</ul>
</li>
<li><a href="#Tabletop & wall displays    5">Tabletop &amp; wall displays    5</a><ul>
<li><a href="#387. LiquidText: a flexible, multitouch environment to support active reading.">387. LiquidText: a flexible, multitouch environment to support active reading.</a></li>
<li><a href="#388. Dimensions of collaboration on a tabletop interface for children with autism spectrum disorder.">388. Dimensions of collaboration on a tabletop interface for children with autism spectrum disorder.</a></li>
<li><a href="#389. MemTable: an integrated system for capture and recall of shared histories in group workspaces.">389. MemTable: an integrated system for capture and recall of shared histories in group workspaces.</a></li>
<li><a href="#390. Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation.">390. Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation.</a></li>
<li><a href="#391. Through the troll forest: exploring tabletop interaction design for children with special cognitive needs.">391. Through the troll forest: exploring tabletop interaction design for children with special cognitive needs.</a></li>
</ul>
</li>
<li><a href="#Doctor-patient care    4">Doctor-patient care    4</a><ul>
<li><a href="#392. Exploring the potential for touchless interaction in image-guided interventional radiology.">392. Exploring the potential for touchless interaction in image-guided interventional radiology.</a></li>
<li><a href="#393. AnatOnMe: facilitating doctor-patient communication using a projection-based handheld device.">393. AnatOnMe: facilitating doctor-patient communication using a projection-based handheld device.</a></li>
<li><a href="#394. Unpacking exam-room computing: negotiating computer-use in patient-physician interactions.">394. Unpacking exam-room computing: negotiating computer-use in patient-physician interactions.</a></li>
<li><a href="#395. CPOE workarounds, boundary objects, and assemblages.">395. CPOE workarounds, boundary objects, and assemblages.</a></li>
</ul>
</li>
<li><a href="#Developers & end-user programmers    5">Developers &amp; end-user programmers    5</a><ul>
<li><a href="#396. Wrangler: interactive visual specification of data transformation scripts.">396. Wrangler: interactive visual specification of data transformation scripts.</a></li>
<li><a href="#397. The concept maps method as a tool to evaluate the usability of APIs.">397. The concept maps method as a tool to evaluate the usability of APIs.</a></li>
<li><a href="#398. Shared substance: developing flexible multi-surface applications.">398. Shared substance: developing flexible multi-surface applications.</a></li>
<li><a href="#399. OldGen: mobile phone personalization for older adults.">399. OldGen: mobile phone personalization for older adults.</a></li>
<li><a href="#400. Dinah: an interface to assist non-programmers with selecting program code causing graphical output.">400. Dinah: an interface to assist non-programmers with selecting program code causing graphical output.</a></li>
</ul>
</li>
<li><a href="#Incentives & user generated content    5">Incentives &amp; user generated content    5</a><ul>
<li><a href="#401. Normative influences on thoughtful online participation.">401. Normative influences on thoughtful online participation.</a></li>
<li><a href="#402. My kind of people?: perceptions about wikipedia contributors and their motivations.">402. My kind of people?: perceptions about wikipedia contributors and their motivations.</a></li>
<li><a href="#403. Computers can't give credit: how automatic attribution falls short in an online remixing community.">403. Computers can't give credit: how automatic attribution falls short in an online remixing community.</a></li>
<li><a href="#404. Identifying shared leadership in Wikipedia.">404. Identifying shared leadership in Wikipedia.</a></li>
<li><a href="#405. Donate for credibility: how contribution incentives can improve credibility.">405. Donate for credibility: how contribution incentives can improve credibility.</a></li>
</ul>
</li>
<li><a href="#Courriel    4">Courriel    4</a><ul>
<li><a href="#406. Should I open this email?: inbox-level cues, curiosity and attention to email.">406. Should I open this email?: inbox-level cues, curiosity and attention to email.</a></li>
<li><a href="#407. Am I wasting my time organizing email?: a study of email refinding.">407. Am I wasting my time organizing email?: a study of email refinding.</a></li>
<li><a href="#408. Using email to facilitate wiki-based coordinated, collaborative authoring.">408. Using email to facilitate wiki-based coordinated, collaborative authoring.</a></li>
<li><a href="#409. F for fake: four studies on how we fall for phish.">409. F for fake: four studies on how we fall for phish.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav><h1 id="CHI 2011:Vancouver, BC, Canada">CHI 2011:Vancouver, BC, Canada</h1>
<p><a href="">Proceedings of the International Conference on Human Factors in Computing Systems, CHI 2011, Vancouver, BC, Canada, May 7-12, 2011.</a> ACM
<a href="http://dblp.uni-trier.de/db/conf/chi/chi2011.html">DBLP Link</a></p>
<h2 id="Paper Num: 409 || Session Num: 105">Paper Num: 409 || Session Num: 105</h2>
<ul>
<li><a href="#3D interaction    4">3D interaction    4</a></li>
<li><a href="#Ambient & peripheral computing    4">Ambient &amp; peripheral computing    4</a></li>
<li><a href="#Art, music & movement    5">Art, music &amp; movement    5</a></li>
<li><a href="#Authentication    6">Authentication    6</a></li>
<li><a href="#Books & language    5">Books &amp; language    5</a></li>
<li><a href="#Brain & bio-sensor interactions    4">Brain &amp; bio-sensor interactions    4</a></li>
<li><a href="#Cats, dogs, sports, games & books    5">Cats, dogs, sports, games &amp; books    5</a></li>
<li><a href="#Collaboration & creativity    3">Collaboration &amp; creativity    3</a></li>
<li><a href="#Courriel    4">Courriel    4</a></li>
<li><a href="#Crowdsourcing    4">Crowdsourcing    4</a></li>
<li><a href="#Death & bereavement    3">Death &amp; bereavement    3</a></li>
<li><a href="#Decision making & the web    2">Decision making &amp; the web    2</a></li>
<li><a href="#Design Methods    4">Design Methods    4</a></li>
<li><a href="#Design materiality    3">Design materiality    3</a></li>
<li><a href="#Design theory    2">Design theory    2</a></li>
<li><a href="#Designing for values, democracy & peace    4">Designing for values, democracy &amp; peace    4</a></li>
<li><a href="#Developers & end-user programmers    5">Developers &amp; end-user programmers    5</a></li>
<li><a href="#Digital content & collections    3">Digital content &amp; collections    3</a></li>
<li><a href="#Doctor-patient care    4">Doctor-patient care    4</a></li>
<li><a href="#Driving    4">Driving    4</a></li>
<li><a href="#Emergency response & scheduling    3">Emergency response &amp; scheduling    3</a></li>
<li><a href="#Emotional states    5">Emotional states    5</a></li>
<li><a href="#Empowering users in developing regions    1">Empowering users in developing regions    1</a></li>
<li><a href="#Engaging youth    5">Engaging youth    5</a></li>
<li><a href="#Evaluation and/or design based on many users    3">Evaluation and/or design based on many users    3</a></li>
<li><a href="#Everyday information management    3">Everyday information management    3</a></li>
<li><a href="#Expression & perception    5">Expression &amp; perception    5</a></li>
<li><a href="#Eye tracking    4">Eye tracking    4</a></li>
<li><a href="#Facebook    4">Facebook    4</a></li>
<li><a href="#Families    4">Families    4</a></li>
<li><a href="#Flexible grips & gestures    4">Flexible grips &amp; gestures    4</a></li>
<li><a href="#Games    4">Games    4</a></li>
<li><a href="#Gestures    3">Gestures    3</a></li>
<li><a href="#Gestures, body & touch    5">Gestures, body &amp; touch    5</a></li>
<li><a href="#Groups around the table    4">Groups around the table    4</a></li>
<li><a href="#HCI for all    4">HCI for all    4</a></li>
<li><a href="#Health 1: technology challenges    5">Health 1: technology challenges    5</a></li>
<li><a href="#Health 2: persuasive systems    5">Health 2: persuasive systems    5</a></li>
<li><a href="#Health 3: online communities & social interaction    5">Health 3: online communities &amp; social interaction    5</a></li>
<li><a href="#Home automation    3">Home automation    3</a></li>
<li><a href="#Homeless users    3">Homeless users    3</a></li>
<li><a href="#Human-robot interaction    3">Human-robot interaction    3</a></li>
<li><a href="#Identity & virtual social interactions    5">Identity &amp; virtual social interactions    5</a></li>
<li><a href="#Incentives & user generated content    5">Incentives &amp; user generated content    5</a></li>
<li><a href="#Innovation & design    1">Innovation &amp; design    1</a></li>
<li><a href="#Inter-cultural interaction    5">Inter-cultural interaction    5</a></li>
<li><a href="#Interaction on mobile devices    7">Interaction on mobile devices    7</a></li>
<li><a href="#Learning    2">Learning    2</a></li>
<li><a href="#Location sharing    5">Location sharing    5</a></li>
<li><a href="#Low-cost ICT4D    3">Low-cost ICT4D    3</a></li>
<li><a href="#Machine learning    3">Machine learning    3</a></li>
<li><a href="#Meetings & interaction spaces    2">Meetings &amp; interaction spaces    2</a></li>
<li><a href="#Methods to aid & structure design    4">Methods to aid &amp; structure design    4</a></li>
<li><a href="#Microblogging behavior    5">Microblogging behavior    5</a></li>
<li><a href="#Mid-air pointing & gestures    4">Mid-air pointing &amp; gestures    4</a></li>
<li><a href="#Mobile issues    3">Mobile issues    3</a></li>
<li><a href="#Multi-touch    5">Multi-touch    5</a></li>
<li><a href="#Multitasking & interruption    4">Multitasking &amp; interruption    4</a></li>
<li><a href="#Museums & public exhibitions    1">Museums &amp; public exhibitions    1</a></li>
<li><a href="#New approaches to usability    5">New approaches to usability    5</a></li>
<li><a href="#Non-flat Displays    4">Non-flat Displays    4</a></li>
<li><a href="#Olfaction, breath & biofeedback    4">Olfaction, breath &amp; biofeedback    4</a></li>
<li><a href="#Organizations & distributed work    3">Organizations &amp; distributed work    3</a></li>
<li><a href="#Organizations & enterprise    5">Organizations &amp; enterprise    5</a></li>
<li><a href="#Performing arts    3">Performing arts    3</a></li>
<li><a href="#Photo sharing    4">Photo sharing    4</a></li>
<li><a href="#Pointing 1    5">Pointing 1    5</a></li>
<li><a href="#Pointing 2: Fitts law    5">Pointing 2: Fitts law    5</a></li>
<li><a href="#Predicting & modeling human behaviors    4">Predicting &amp; modeling human behaviors    4</a></li>
<li><a href="#Privacy    4">Privacy    4</a></li>
<li><a href="#Reading & writing    3">Reading &amp; writing    3</a></li>
<li><a href="#Rehabilitation    4">Rehabilitation    4</a></li>
<li><a href="#Research methods    4">Research methods    4</a></li>
<li><a href="#Search & information seeking    4">Search &amp; information seeking    4</a></li>
<li><a href="#Search & stuff    4">Search &amp; stuff    4</a></li>
<li><a href="#Security (social">Security (social)    4</a>    4)</li>
<li><a href="#Security (systems">Security (systems)    4</a>    4)</li>
<li><a href="#Sex & bodies    3">Sex &amp; bodies    3</a></li>
<li><a href="#Shortcuts commands & expertise    4">Shortcuts commands &amp; expertise    4</a></li>
<li><a href="#Social Q & A    3">Social Q &amp; A    3</a></li>
<li><a href="#Software development & product support    1">Software development &amp; product support    1</a></li>
<li><a href="#Sound interactions    5">Sound interactions    5</a></li>
<li><a href="#Storytelling & perceptual crossing    3">Storytelling &amp; perceptual crossing    3</a></li>
<li><a href="#Sustainability 1    4">Sustainability 1    4</a></li>
<li><a href="#Sustainability 2    4">Sustainability 2    4</a></li>
<li><a href="#Tabletop & wall displays    5">Tabletop &amp; wall displays    5</a></li>
<li><a href="#Tabletop synchronous collaboration    2">Tabletop synchronous collaboration    2</a></li>
<li><a href="#Tactile interaction    5">Tactile interaction    5</a></li>
<li><a href="#Tagging    3">Tagging    3</a></li>
<li><a href="#Tangibles    5">Tangibles    5</a></li>
<li><a href="#Telepresence    4">Telepresence    4</a></li>
<li><a href="#Text entry & typing    4">Text entry &amp; typing    4</a></li>
<li><a href="#Time/animations    2">Time/animations    2</a></li>
<li><a href="#Touch 1: tactile & haptics    6">Touch 1: tactile &amp; haptics    6</a></li>
<li><a href="#Touch 2: tactile & targets    4">Touch 2: tactile &amp; targets    4</a></li>
<li><a href="#Touch 3: sensing    4">Touch 3: sensing    4</a></li>
<li><a href="#Twitter systems    4">Twitter systems    4</a></li>
<li><a href="#User experience    5">User experience    5</a></li>
<li><a href="#User studies/ethnography in developing regions    4">User studies/ethnography in developing regions    4</a></li>
<li><a href="#Visual analytics    4">Visual analytics    4</a></li>
<li><a href="#Visualization & perception    4">Visualization &amp; perception    4</a></li>
<li><a href="#Watching together    4">Watching together    4</a></li>
<li><a href="#Web search & usability    5">Web search &amp; usability    5</a></li>
<li><a href="#Website & application design    5">Website &amp; application design    5</a></li>
<li><a href="#Wireless networks    3">Wireless networks    3</a></li>
</ul>
<h2 id="Health 1: technology challenges    5">Health 1: technology challenges    5</h2>
<h3 id="1. Classroom-based assistive technology: collective use of interactive visual schedules by students with autism.">1. Classroom-based assistive technology: collective use of interactive visual schedules by students with autism.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978944">Paper Link</a>    Pages:1-10</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cramer:Meg">Meg Cramer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hirano:Sen_H=">Sen H. Hirano</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tentori:Monica">Monica Tentori</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yeganyan:Michael_T=">Michael T. Yeganyan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hayes:Gillian_R=">Gillian R. Hayes</a></p>
<p>Abstract:
vSked is an interactive and collaborative assistive technology for students with autism, combining visual schedules, choice boards, and a token-based reward system into an integrated classroom system. In this paper, we present the results of a study of three deployments of vSked over the course of a year in two autism classrooms. The results of our study demonstrate that vSked can promote student independence, reduce the quantity of educator-initiated prompts, encourage consistency and predictability, reduce the time required to transition from one activity to another. The findings from this study reveal practices surrounding the use of assistive technologies in classrooms and highlight important considerations for both the design and the evaluation of assistive technologies in the future, especially those destined for classroom use.</p>
<p>Keywords:
assistive technology; autism; visual schedules</p>
<h3 id="2. Privacy risks emerging from the adoption of innocuous wearable sensors in the mobile environment.">2. Privacy risks emerging from the adoption of innocuous wearable sensors in the mobile environment.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978945">Paper Link</a>    Pages:11-20</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Raij:Andrew">Andrew Raij</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Ghosh:Animikh">Animikh Ghosh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kumar:Santosh">Santosh Kumar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Srivastava:Mani_B=">Mani B. Srivastava</a></p>
<p>Abstract:
Wearable sensors are revolutionizing healthcare and science by enabling capture of physiological, psychological, and behavioral measurements in natural environments. However, these seemingly innocuous measurements can be used to infer potentially private behaviors such as stress, conversation, smoking, drinking, illicit drug usage, and others. We conducted a study to assess how concerned people are about disclosure of a variety of behaviors and contexts that are embedded in wearable sensor data. Our results show participants are most concerned about disclosures of conversation episodes and stress - inferences that are not yet widely publicized. These concerns are mediated by temporal and physical context associated with the data and the participant's personal stake in the data. Our results provide key guidance on the extent to which people understand the potential for harm and data characteristics researchers should focus on to reduce the perceived harm from such datasets.</p>
<p>Keywords:
information disclosure; mobile health; privacy; user study; wearable sensors</p>
<h3 id="3. Interaction design for cancer patients: do we need to take into account the effects of illness and medication?">3. Interaction design for cancer patients: do we need to take into account the effects of illness and medication?</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978946">Paper Link</a>    Pages:21-24</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Das_0002:Anita">Anita Das</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Faxvaag:Arild">Arild Faxvaag</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Svan=aelig=s:Dag">Dag Svans</a></p>
<p>Abstract:
In this paper we explore how having cancer and receiving therapy influences upon patients' ability to use an online healthcare system. The motivation is that no empirically based design guidelines are available concerning this user group. Ignoring possible effects of illness and therapy can result in systems with poor usability and user acceptance. A case-control usability test with 14 cancer patients and 14 matched controls revealed that the cancer patients experienced significantly more difficulties compared with the healthy controls using a web-based online healthcare system. We conclude that designers of online healthcare systems need to take into consideration the unique challenges of being ill and/or using medication.</p>
<p>Keywords:
cancer patients; medical informatics; patient-centred information systems; usability; user interfaces</p>
<h3 id="4. Simulating the feel of brain-computer interfaces for design, development and social interaction.">4. Simulating the feel of brain-computer interfaces for design, development and social interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978947">Paper Link</a>    Pages:25-28</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/q/Quek:Melissa">Melissa Quek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Boland:Daniel">Daniel Boland</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williamson:John">John Williamson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Murray=Smith:Roderick">Roderick Murray-Smith</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tavella:Michele">Michele Tavella</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perdikis:Serafeim">Serafeim Perdikis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schreuder:Martijn">Martijn Schreuder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tangermann:Michael">Michael Tangermann</a></p>
<p>Abstract:
We describe an approach to improving the design and development of Brain-Computer Interface (BCI) applications by simulating the error-prone characteristics and subjective feel of electroencephalogram (EEG), motor-imagery based BCIs. BCIs have the potential to enhance the quality of life of people who are severely disabled, but it is often time-consuming to test and develop the systems. Simulation of BCI characteristics allows developers to rapidly test design options, and gain both subjective and quantitative insight into expected behaviour without using an EEG cap. A further motivation for the use of simulation is that 'impairing' a person without motor disabilities in a game with a disabled BCI user can create a level playing field and help carers empathise with BCI users. We demonstrate a use of the simulator in controlling a game of Brain Pong.</p>
<p>Keywords:
brain-computer interaction; british columbiai; disability; hci; human computer interaction; motor imagery; simulation; smr; social interaction; usability</p>
<h3 id="5. Characterizing patient-friendly "micro-explanations"of medical events.">5. Characterizing patient-friendly "micro-explanations"of medical events.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978948">Paper Link</a>    Pages:29-32</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wilcox:Lauren">Lauren Wilcox</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Dan">Dan Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tan:Desney_S=">Desney S. Tan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gatewood:Justin">Justin Gatewood</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Horvitz:Eric">Eric Horvitz</a></p>
<p>Abstract:
Patients' basic understanding of clinical events has been shown to dramatically improve patient care. We propose that the automatic generation of very short micro-explanations, suitable for real-time delivery in clinical settings, can transform patient care by giving patients greater awareness of key events in their electronic medical record. We present results of a survey study indicating that it may be possible to automatically generate such explanations by extracting individual sentences from consumer-facing Web pages. We further inform future work by characterizing physician and non-physician responses to a variety of Web-extracted explanations of medical lab tests.</p>
<p>Keywords:
electronic medical records; personal health records</p>
<h2 id="Telepresence    4">Telepresence    4</h2>
<h3 id="6. "Now, i have a body": uses and social norms for mobile remote presence in the workplace.">6. "Now, i have a body": uses and social norms for mobile remote presence in the workplace.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978950">Paper Link</a>    Pages:33-42</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Min_Kyung">Min Kyung Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Takayama:Leila">Leila Takayama</a></p>
<p>Abstract:
As geographically distributed teams become increasingly common, there are more pressing demands for communication work practices and technologies that support distributed collaboration. One set of technologies that are emerging on the commercial market is mobile remote presence (MRP) systems, physically embodied videoconferencing systems that remote workers use to drive through a workplace, communicating with locals there. Our interviews, observations, and survey results from people, who had 2-18 months of MRP use, showed how remotely-controlled mobility enabled remote workers to live and work with local coworkers almost as if they were physically there. The MRP supported informal communications and connections between distributed coworkers. We also found that the mobile embodiment of the remote worker evoked orientations toward the MRP both as a person and as a machine, leading to formation of new usage norms among remote and local coworkers.</p>
<p>Keywords:
computer supported collaborative work; human-robot interaction; mobile remote presence</p>
<h3 id="7. Hands on hitchcock: embodied reference to a moving scene.">7. Hands on hitchcock: embodied reference to a moving scene.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978951">Paper Link</a>    Pages:43-52</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Luff:Paul">Paul Luff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yamashita:Naomi">Naomi Yamashita</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kuzuoka:Hideaki">Hideaki Kuzuoka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heath:Christian">Christian Heath</a></p>
<p>Abstract:
In this paper we report on some experiments with a high fidelity media space, t-Room, an immersive system that presents full scale, real-time images of co-participants who are in similar spaces many miles apart. Although being designed to provide a coherent environment for interaction the system introduces a number of incongruities, both in time and space. Drawing on some quasi-naturalistic experiments, where the participants were required to analyse complex data, we consider how the participants manage these incongruities. We conclude by briefly discussing the resources people utilize to produce and recognize conduct in embodied spaces.</p>
<p>Keywords:
cscw; embodied interaction; interaction analysis; media spaces</p>
<h3 id="8. Exploring camera viewpoint control models for a multi-tasking setting in teleoperation.">8. Exploring camera viewpoint control models for a multi-tasking setting in teleoperation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978952">Paper Link</a>    Pages:53-62</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhu:Dingyun">Dingyun Zhu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gedeon:Tom">Tom Gedeon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Ken">Ken Taylor</a></p>
<p>Abstract:
Control of camera viewpoint plays a vital role in many teleoperation activities, as watching live video streams is still the fundamental way for operators to obtain situational awareness from remote environments. Motivated by a real-world industrial setting in mining teleoperation, we explore several possible solutions to resolve a common multi-tasking situation where an operator is required to control a robot and simultaneously perform remote camera operation. Conventional control interfaces are predominantly used in such teleoperation settings, but could overload an operator's hand-operation capability, and require frequent attention switches and thus could decrease productivity. We report on an empirical user study in a model multi-tasking teleoperation setting where the user has a main task which requires their attention. We compare three different camera viewpoint control models: (1) dual manual control, (2) natural interaction (combining eye gaze and head motion) and (3) autonomous tracking. The results indicate the advantages of using the natural interaction model, while the manual control model performed the worst.</p>
<p>Keywords:
autonomous tracking; dual manual control; multi-tasking setting; natural interaction; remote camera control</p>
<h3 id="9. Zoom cameras and movable displays enhance social telepresence.">9. Zoom cameras and movable displays enhance social telepresence.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978953">Paper Link</a>    Pages:63-72</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nakanishi:Hideyuki">Hideyuki Nakanishi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kato:Kei">Kei Kato</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Ishiguro:Hiroshi">Hiroshi Ishiguro</a></p>
<p>Abstract:
This paper shows that the augmentation of a remote person's positional movement enhances social telepresence. There are three possible ways of representing a remote person's movement toward the user in visual communication: a) the remote person's movement toward the remote camera, b) the remote camera's zooming in to enlarge the remote person's picture, and c) a forward movement of the display that is displaying the remote person. We conducted an experiment to see the relationship among these three ways and the effects of a remote camera's zooming and a display's movement on social telepresence. In the experiment, we observed that the remote person's movement lowered the reality of conversations, and the remote camera's zooming lowered the visual quality. However, social telepresence was enhanced when both the person's movement and the camera's zooming occurred simultaneously. We also observed that a 6-centimeter movement of the display enhanced social telepresence, whether the remote person moved or not.</p>
<p>Keywords:
telepresence; telerobotics; videoconferencing</p>
<h2 id="Olfaction, breath & biofeedback    4">Olfaction, breath &amp; biofeedback    4</h2>
<h3 id="10. Breath control of amusement rides.">10. Breath control of amusement rides.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978955">Paper Link</a>    Pages:73-82</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Joe">Joe Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rowland:Duncan">Duncan Rowland</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Egglestone:Stefan_Rennick">Stefan Rennick Egglestone</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benford:Steve">Steve Benford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Walker:Brendan">Brendan Walker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McAuley:Derek">Derek McAuley</a></p>
<p>Abstract:
Emerging robotic technologies are enabling the control of individual seats on rollercoasters and other thrill rides. We explore the potential of breathing as an effective and engaging way of driving this. Observations and interviews from trials of an enhanced bucking bronco ride show that breath-control is fun, challenging and intelligible, and reveal riders-x tactics as they battled the machine. We conclude that breath control is feasible and appropriate for controlling rides, unpack its important characteristics, and consider how it might be built into future ride systems. We argue that the combination of voluntary and involuntary factors in breathing is especially appealing for controlling rides as it balances game-like elements of skill and learning against the thrill of surrendering control to the machine.</p>
<p>Keywords:
affective computing; amusement ride; biosensing; breath control; breathing; bucking bronco; themepark; thrill</p>
<h3 id="11. Time characteristics of olfaction in a single breath.">11. Time characteristics of olfaction in a single breath.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978956">Paper Link</a>    Pages:83-92</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Noguchi:Daisuke">Daisuke Noguchi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sugimoto:Sayumi">Sayumi Sugimoto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bannai:Yuichi">Yuichi Bannai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Okada:Ken=ichi">Ken-ichi Okada</a></p>
<p>Abstract:
The transmission of olfactory information together with audiovisual information is now attracting much attention. However, the information is difficult to synchronize because of problems of scent lingering in the air and olfactory adaptation. We aimed at minimizing the amount of odorant presented to users in order to mitigate these problems, and developed an olfactory display that is able to present scents precisely. The display uses pulse ejection, whereby scents are emitted for only short periods of time. In this study, we aimed to mitigate the above-mentioned problems and to measure the time characteristics of olfaction in a single breath, which are difficult to measure by conventional methods. As a result, the most effective conditions for using a small amount of odorant in a single breath were revealed. These results are expected to ease the synchronization of olfactory and audiovisual information.</p>
<p>Keywords:
olfactory display; olfactory information; pulse ejection</p>
<h3 id="12. Augmented reality flavors: gustatory display based on edible marker and cross-modal interaction.">12. Augmented reality flavors: gustatory display based on edible marker and cross-modal interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978957">Paper Link</a>    Pages:93-102</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Narumi:Takuji">Takuji Narumi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nishizaka:Shinya">Shinya Nishizaka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kajinami:Takashi">Takashi Kajinami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tanikawa:Tomohiro">Tomohiro Tanikawa</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hirose:Michitaka">Michitaka Hirose</a></p>
<p>Abstract:
The main contribution of this paper is to realize computer generated augmented flavors and establish a method to integrate gustatory information into computer human interactions. There are several reasons for the scarcity of research on gustatory information. One reason is that taste sensations are affected by a number of factors, such as vision, olfaction and memories. This produces a complex cognition mechanism for a user's gustatory sensation, and makes it difficult to build up a gustatory display which produces a specific taste on demand. Our hypothesis is that the complexity of gustatory sensation can be applied to the realization of a "Pseudo-gustatory" display that presents the desired flavors by means of a cross-modal effect elicited by visual and olfactory augmented reality. We propose the Edible Marker system, which can detect the state [number/shape/6-degree-of-freedom (DOF) coordinate] of each piece of bitten or divided food in real time, and the "Pseudo-gustation" method to change the perceived taste of food by changing its appearance and scent. We construct "MetaCookie+" as an implementation and discuss its validity through an exploratory study.</p>
<p>Keywords:
augmented reality; cross-modal interaction; edible marker; gustatory display; pseudo-gustation</p>
<h3 id="13. Biofeedback game design: using direct and indirect physiological control to enhance game interaction.">13. Biofeedback game design: using direct and indirect physiological control to enhance game interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978958">Paper Link</a>    Pages:103-112</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nacke:Lennart_E=">Lennart E. Nacke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kalyn:Michael">Michael Kalyn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lough:Calvin">Calvin Lough</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a></p>
<p>Abstract:
Prior work on physiological game interaction has focused on dynamically adapting games using physiological sensors. In this paper, we propose a classification of direct and indirect physiological sensor input to augment traditional game control. To find out which sensors work best for which game mechanics, we conducted a mixed-methods study using different sensor mappings. Our results show participants have a preference for direct physiological control in games. This has two major design implications for physiologically controlled games: (1) Direct physiological sensors should be mapped intuitively to reflect an action in the virtual world; (2) Indirect physiological input is best used as a dramatic device in games to influence features altering the game world.</p>
<p>Keywords:
affective computing; affective gaming; biofeedback; entertainment; games; physiological input; psychophysiology</p>
<h2 id="Research methods    4">Research methods    4</h2>
<h3 id="14. Confessions from a grounded theory PhD: experiences and lessons learnt.">14. Confessions from a grounded theory PhD: experiences and lessons learnt.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978960">Paper Link</a>    Pages:113-122</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Furniss:Dominic">Dominic Furniss</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blandford:Ann">Ann Blandford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Curzon:Paul">Paul Curzon</a></p>
<p>Abstract:
Grounded Theory (GT) is used within HCI research, but nuances and more modern interpretations of the method are rarely discussed. This paper has two intentions: to offer guidance on practical issues when applying GT, and to clarify the space of methodological possibilities. We describe an extended GT study on understanding why practitioners choose particular usability evaluation methods. We describe five stages in this study to highlight our experiences and choices made. We draw out seven practical and methodological considerations in applying GT in a CHI context. This challenges the more traditional inductive and objective positions on GT use; it sensitizes novices of GT to these issues; and through the extended case study it provides substance for debate on issues that affect those that use qualitative methods more broadly.</p>
<p>Keywords:
constructivist; distributed cognition; grounded theory; method; qualitative; resilience engineering</p>
<h3 id="15. Reflexivity in digital anthropology.">15. Reflexivity in digital anthropology.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978961">Paper Link</a>    Pages:123-132</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rode:Jennifer_A=">Jennifer A. Rode</a></p>
<p>Abstract:
There are a variety of forms of ethnography inside and outside HCI each with valid complementary contributions. This paper looks at the practices of digital anthropology and how it contributes to reflexive design in HCI. The paper overviews key aspects its use in HCI, as well as in the anthropological approach. In doing so it relates these practices to participatory design and the socio-technical gap, and the ways ethnography can address them.</p>
<p>Keywords:
ethnography; iterative; participant-observation; rapport</p>
<h3 id="16. Comparing activity theory with distributed cognition for video analysis: beyond "kicking the tires".">16. Comparing activity theory with distributed cognition for video analysis: beyond "kicking the tires".</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978962">Paper Link</a>    Pages:133-142</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Baumer:Eric_P=_S=">Eric P. S. Baumer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tomlinson:Bill">Bill Tomlinson</a></p>
<p>Abstract:
The field of HCI is growing, not only in the variety of application areas or the volume of research conducted, but also in the number of analytical approaches for use in the evaluation and design of interactive systems. However, despite the abundance of theoretical frameworks available, relatively little work has directly compared the application of these frameworks. This paper compares video analysis methods based on two analytic frameworks - activity theory (AT) and distributed cognition (DCog) - by performing an analysis of the same system from each of the two different theoretical perspectives. The results presented here provide a better understanding of how such theoretically informed methods in practice both resemble and differ from one another. Furthermore, this comparison enables specific insights about each of the theories themselves, as well as more general discussion about the role of theory in HCI.</p>
<p>Keywords:
activity theory; distributed cognition; evaluation methodology; methodology evaluation; video analysis</p>
<h3 id="17. The aligned rank transform for nonparametric factorial analyses using only anova procedures.">17. The aligned rank transform for nonparametric factorial analyses using only anova procedures.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978963">Paper Link</a>    Pages:143-146</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Findlater:Leah">Leah Findlater</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gergle:Darren">Darren Gergle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Higgins:James_J=">James J. Higgins</a></p>
<p>Abstract:
Nonparametric data from multi-factor experiments arise often in human-computer interaction (HCI). Examples may include error counts, Likert responses, and preference tallies. But because multiple factors are involved, common nonparametric tests (e.g., Friedman) are inadequate, as they are unable to examine interaction effects. While some statistical techniques exist to handle such data, these techniques are not widely available and are complex. To address these concerns, we present the Aligned Rank Transform (ART) for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing step that "aligns" data before applying averaged ranks, after which point common ANOVA procedures can be used, making the ART accessible to anyone familiar with the F-test. Unlike most articles on the ART, which only address two factors, we generalize the ART to N factors. We also provide ARTool and ARTweb, desktop and Web-based programs for aligning and ranking data. Our re-examination of some published HCI results exhibits advantages of the ART.</p>
<p>Keywords:
analysis of variance; anova; f-test; factorial analysis; nonparametric data; statistics</p>
<h2 id="Machine learning    3">Machine learning    3</h2>
<h3 id="18. Human model evaluation in interactive supervised learning.">18. Human model evaluation in interactive supervised learning.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978965">Paper Link</a>    Pages:147-156</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fiebrink:Rebecca">Rebecca Fiebrink</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cook:Perry_R=">Perry R. Cook</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Trueman:Dan">Dan Trueman</a></p>
<p>Abstract:
Model evaluation plays a special role in interactive machine learning (IML) systems in which users rely on their assessment of a model's performance in order to determine how to improve it. A better understanding of what model criteria are important to users can therefore inform the design of user interfaces for model evaluation as well as the choice and design of learning algorithms. We present work studying the evaluation practices of end users interactively building supervised learning systems for real-world gesture analysis problems. We examine users' model evaluation criteria, which span conventionally relevant criteria such as accuracy and cost, as well as novel criteria such as unexpectedness. We observed that users employed evaluation techniques---including cross-validation and direct, real-time evaluation---not only to make relevant judgments of algorithms' performance and interactively improve the trained models, but also to learn to provide more effective training data. Furthermore, we observed that evaluation taught users about what types of models were easy or possible to build, and users sometimes used this information to modify the learning problem definition or their plans for using the trained models in practice. We discuss the implications of these findings with regard to the role of generalization accuracy in IML, the design of new algorithms and interfaces, and the scope of potential benefits of incorporating human interaction in the design of supervised learning systems.</p>
<p>Keywords:
evaluation; gesture; interactive machine learning; music</p>
<h3 id="19. CueT: human-guided fast and accurate network alarm triage.">19. CueT: human-guided fast and accurate network alarm triage.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978966">Paper Link</a>    Pages:157-166</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Amershi:Saleema">Saleema Amershi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Bongshin">Bongshin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kapoor:Ashish">Ashish Kapoor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mahajan:Ratul">Ratul Mahajan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Christian:Blaine">Blaine Christian</a></p>
<p>Abstract:
Network alarm triage refers to grouping and prioritizing a stream of low-level device health information to help operators find and fix problems. Today, this process tends to be largely manual because existing tools cannot easily evolve with the network. We present CueT, a system that uses interactive machine learning to learn from the triaging decisions of operators. It then uses that learning in novel visualizations to help them quickly and accurately triage alarms. Unlike prior interactive machine learning systems, CueT handles a highly dynamic environment where the groups of interest are not known a-priori and evolve constantly. A user study with real operators and data from a large network shows that CueT significantly improves the speed and accuracy of alarm triage compared to the network's current practice.</p>
<p>Keywords:
interactive machine learning; triage; visualization</p>
<h3 id="20. Apolo: making sense of large network data by combining rich user interaction and machine learning.">20. Apolo: making sense of large network data by combining rich user interaction and machine learning.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978967">Paper Link</a>    Pages:167-176</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chau:Duen_Horng">Duen Horng Chau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jason_I=">Jason I. Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Faloutsos:Christos">Christos Faloutsos</a></p>
<p>Abstract:
Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.</p>
<p>Keywords:
belief propagation; large network; sensemaking</p>
<h2 id="Mid-air pointing & gestures    4">Mid-air pointing &amp; gestures    4</h2>
<h3 id="21. Mid-air pan-and-zoom on wall-sized displays.">21. Mid-air pan-and-zoom on wall-sized displays.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978969">Paper Link</a>    Pages:177-186</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nancel:Mathieu">Mathieu Nancel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wagner:Julie">Julie Wagner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pietriga:Emmanuel">Emmanuel Pietriga</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chapuis:Olivier">Olivier Chapuis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mackay:Wendy_E=">Wendy E. Mackay</a></p>
<p>Abstract:
Very-high-resolution wall-sized displays offer new opportunities for interacting with large data sets. While pointing on this type of display has been studied extensively, higher-level, more complex tasks such as pan-zoom navigation have received little attention. It thus remains unclear which techniques are best suited to perform multiscale navigation in these environments. Building upon empirical data gathered from studies of pan-and-zoom on desktop computers and studies of remote pointing, we identified three key factors for the design of mid-air pan-and-zoom techniques: uni- vs. bimanual interaction, linear vs. circular movements, and level of guidance to accomplish the gestures in mid-air. After an extensive phase of iterative design and pilot testing, we ran a controlled experiment aimed at better understanding the influence of these factors on task performance. Significant effects were obtained for all three factors: bimanual interaction, linear gestures and a high level of guidance resulted in significantly improved performance. Moreover, the interaction effects among some of the dimensions suggest possible combinations for more complex, real-world tasks.</p>
<p>Keywords:
mid-air interaction techniques; multi-scale interfaces; navigation; pan &amp; zoom; wall-sized displays</p>
<h3 id="22. Gesture select: : acquiring remote targets on large displays without pointing.">22. Gesture select: : acquiring remote targets on large displays without pointing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978970">Paper Link</a>    Pages:187-196</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bragdon:Andrew">Andrew Bragdon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Ko:Hsu=Sheng">Hsu-Sheng Ko</a></p>
<p>Abstract:
When working at a large wall display, even if partially utilized, many targets are likely to be distant from the user, requiring walking, which is slow, and interrupts workflow. We propose a novel technique for selecting remote targets called Gesture Select, in which users draw an initial mark, in a target's direction; rectilinear gestures represented as icons are dynamically overlaid on targets within a region of interest; the user then continues by drawing the continuation mark corresponding to the target, to select it. Extensions to this technique to support working with remote content for an extended period, and learning gesture shortcuts are presented. A formal experiment indicates Gesture Select significantly outperformed direct selection for mid/far targets. Further analysis suggests Gesture Select performance is principally affected by the extent to which users can read the gestures, influenced by distance and perspective warping, and the gesture complexity in the ROI. The results of a second 2-D experiment with labeled targets indicate Gesture Select significantly outperformed direct selection and an existing technique.</p>
<p>Keywords:
gestures; large display; remote targets; selection</p>
<h3 id="23. User-defined motion gestures for mobile interaction.">23. User-defined motion gestures for mobile interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978971">Paper Link</a>    Pages:197-206</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ruiz:Jaime">Jaime Ruiz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lank:Edward">Edward Lank</a></p>
<p>Abstract:
Modern smartphones contain sophisticated sensors to monitor three-dimensional movement of the device. These sensors permit devices to recognize motion gestures - deliberate movements of the device by end-users to invoke commands. However, little is known about best-practices in motion gesture design for the mobile computing paradigm. To address this issue, we present the results of a guessability study that elicits end-user motion gestures to invoke commands on a smartphone device. We demonstrate that consensus exists among our participants on parameters of movement and on mappings of motion gestures onto commands. We use this consensus to develop a taxonomy for motion gestures and to specify an end-user inspired motion gesture set. We highlight the implications of this work to the design of smartphone applications and hardware. Finally, we argue that our results influence best practices in design for all gestural interfaces.</p>
<p>Keywords:
mobile interaction; motion gestures; sensors</p>
<h3 id="24. Gesture avatar: a technique for operating mobile user interfaces using gestures.">24. Gesture avatar: a technique for operating mobile user interfaces using gestures.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978972">Paper Link</a>    Pages:207-216</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/L=uuml=:Hao">Hao L</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a></p>
<p>Abstract:
Finger-based touch input has become a major interaction modality for mobile user interfaces. However, due to the low precision of finger input, small user interface components are often difficult to acquire and operate on a mobile device. It is even harder when the user is on the go and unable to pay close attention to the interface. In this paper, we present Gesture Avatar, a novel interaction technique that allows users to operate existing arbitrary user interfaces using gestures. It leverages the visibility of graphical user interfaces and the casual interaction of gestures. Gesture Avatar can be used to enhance a range of mobile interactions. A user study we conducted showed that compared to Shift (an alternative technique for target acquisition tasks), Gesture Avatar performed at a much lower error rate on various target sizes and significantly faster on small targets (1mm). It also showed that using Gesture Avatar while walking did not significantly impact its performance, which makes it suitable for mobile uses.</p>
<p>Keywords:
finger-based touch input; gestures; mobile devices; target acquisition; touchscreens</p>
<h2 id="Twitter systems    4">Twitter systems    4</h2>
<h3 id="25. Speak little and well: recommending conversations in online social streams.">25. Speak little and well: recommending conversations in online social streams.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978974">Paper Link</a>    Pages:217-226</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Jilin">Jilin Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nairn:Rowan">Rowan Nairn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chi:Ed_Huai=hsin">Ed Huai-hsin Chi</a></p>
<p>Abstract:
Conversation is a key element in online social streams such as Twitter and Facebook. However, finding interesting conversations to read is often a challenge, due to information overload and differing user preferences. In this work we explored five algorithms that recommend conversations to Twitter users, utilizing thread length, topic and tie-strength as factors. We compared the algorithms through an online user study and gathered feedback from real Twitter users. In particular, we investigated how users' purposes of using Twitter affect user preferences for different types of conversations and the performance of different algorithms. Compared to a random baseline, all algorithms recommended more interesting conversations. Further, tie-strength based algorithms performed significantly better for people who use Twitter for social purposes than for people who use Twitter for informational purpose only.</p>
<p>Keywords:
conversation; recommender system; social stream; user preference</p>
<h3 id="26. Twitinfo: aggregating and visualizing microblogs for event exploration.">26. Twitinfo: aggregating and visualizing microblogs for event exploration.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978975">Paper Link</a>    Pages:227-236</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marcus_0002:Adam">Adam Marcus</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bernstein:Michael_S=">Michael S. Bernstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Badar:Osama">Osama Badar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karger:David_R=">David R. Karger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Madden:Samuel">Samuel Madden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Robert_C=">Robert C. Miller</a></p>
<p>Abstract:
Microblogs are a tremendous repository of user-generated content about world events. However, for people trying to understand events by querying services like Twitter, a chronological log of posts makes it very difficult to get a detailed understanding of an event. In this paper, we present TwitInfo, a system for visualizing and summarizing events on Twitter. TwitInfo allows users to browse a large collection of tweets using a timeline-based display that highlights peaks of high tweet activity. A novel streaming algorithm automatically discovers these peaks and labels them meaningfully using text from the tweets. Users can drill down to subevents, and explore further via geolocation, sentiment, and popular URLs. We contribute a recall-normalized aggregate sentiment visualization to produce more honest sentiment overviews. An evaluation of the system revealed that users were able to reconstruct meaningful summaries of events in a small amount of time. An interview with a Pulitzer Prize-winning journalist suggested that the system would be especially useful for understanding a long-running event and for identifying eyewitnesses. Quantitatively, our system can identify 80-100% of manually labeled peaks, facilitating a relatively complete view of each event studied.</p>
<p>Keywords:
twitter visualization streaming aggregate sentiment</p>
<h3 id="27. Tweets from Justin Bieber's heart: the dynamics of the location field in user profiles.">27. Tweets from Justin Bieber's heart: the dynamics of the location field in user profiles.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978976">Paper Link</a>    Pages:237-246</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hecht:Brent">Brent Hecht</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Lichan">Lichan Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Suh:Bongwon">Bongwon Suh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chi:Ed_H=">Ed H. Chi</a></p>
<p>Abstract:
Little research exists on one of the most common, oldest, and most utilized forms of online social geographic information: the 'location' field found in most virtual community user profiles. We performed the first in-depth study of user behavior with regard to the location field in Twitter user profiles. We found that 34% of users did not provide real location information, frequently incorporating fake locations or sarcastic comments that can fool traditional geographic information tools. When users did input their location, they almost never specified it at a scale any more detailed than their city. In order to determine whether or not natural user behaviors have a real effect on the 'locatability' of users, we performed a simple machine learning experiment to determine whether we can identify a user's location by only looking at what that user tweets. We found that a user's country and state can in fact be determined easily with decent accuracy, indicating that users implicitly reveal location information, with or without realizing it. Implications for location-based services and privacy are discussed.</p>
<p>Keywords:
geography; location; location prediction; location-based services; privacy; social networks; twitter</p>
<h3 id="28. An open, social microcalender for the enterprise: timely?">28. An open, social microcalender for the enterprise: timely?</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978977">Paper Link</a>    Pages:247-256</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Geyer:Werner">Werner Geyer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dugan:Casey">Casey Dugan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brownholtz:Beth">Beth Brownholtz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Masli:Mikhil">Mikhil Masli</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Daly:Elizabeth_M=">Elizabeth M. Daly</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Millen:David_R=">David R. Millen</a></p>
<p>Abstract:
We present the system design and rational for a novel social microcalendar called Timely. Our system has been inspired by previous research on calendaring and popular social network applications, in particular microblogging. Timely provides an open, social space for enterprise users to share their events, socialize, and discover what else is going on in their network and beyond. A detailed analysis of the events shared by users during the site's first 47 days reveals that users willingly share their time commitments despite an existing culture of restricted calendars.</p>
<p>Keywords:
electronic calendars; gcs; microcalendar; social software</p>
<h2 id="Sex & bodies    3">Sex &amp; bodies    3</h2>
<h3 id="29. Pleasure is your birthright: digitally enabled designer sex toys as a case of third-wave HCI.">29. Pleasure is your birthright: digitally enabled designer sex toys as a case of third-wave HCI.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978979">Paper Link</a>    Pages:257-266</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Jeffrey">Jeffrey Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Shaowen">Shaowen Bardzell</a></p>
<p>Abstract:
In the past decade, HCI has become increasingly preoccupied with the deeply subjective qualities of interaction: experience, embodiment, pleasure, intimacy, and so on, an agenda sometimes grouped under the heading of "third-wave HCI"."Analytically understanding and designing for such qualities has been an ongoing challenge to the field, in part because its established theories and methodologies are comparatively weak at understanding and being responsive to human subjectivity. In this paper, we present a case study of a group of designers who have, in the past few years, revolutionized their domain - sex toys - by combining embodied pleasure, intimate experience, health and wellness, emerging technologies, high-quality design processes, and social activism. We consider the implications this case could have for researchers innovating on especially third-wave HCI design theories, methodologies, and processes.</p>
<p>Keywords:
HCI; activism; criticism; human sexuality</p>
<h3 id="30. Designing a phone broadcasting system for urban sex workers in India.">30. Designing a phone broadcasting system for urban sex workers in India.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978980">Paper Link</a>    Pages:267-276</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sambasivan:Nithya">Nithya Sambasivan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weber:Julie">Julie Weber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cutrell:Edward">Edward Cutrell</a></p>
<p>Abstract:
In this paper, we present the design, implementation, and deployment of a phone-based broadcasting system designed for reaching out to at-risk populations in urban India. We worked in collaboration with Pragati, a non-governmental organization dedicated to assisting Urban Sex Workers (USWs) in Bangalore, India, with the goal of improving Pragati's outreach to the women they serve. We conducted ethnographic action research to understand and address the needs of Pragati and the lifestyles of USWs. Responding to the unique design constraints of the USW community such as specific privacy and timing constraints, a desire to remain invisible, and the unusually high rate of mobile phone use, we designed a phone-based broadcasting system for Pragati. We then deployed the system on four different occasions and application areas. We present the results and key findings from our study, and conclude with a discussion on how designing for particularly difficult cases such as USWs can shed new light on the design of mobile applications for the developing world in general, such as challenging ubiquity and phone numbers as identity.</p>
<p>Keywords:
HCI4D; ICT4D; India; M4D; urban sex workers</p>
<h3 id="31. Bodily orientations around mobiles: lessons learnt in vanuatu.">31. Bodily orientations around mobiles: lessons learnt in vanuatu.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978981">Paper Link</a>    Pages:277-286</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Ferreira:Pedro">Pedro Ferreira</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=ouml==ouml=k:Kristina">Kristina Hk</a></p>
<p>Abstract:
Since we started carrying mobiles phones, they have altered the ways in which we orient our bodies in the world. Many of those changes are invisible to us - they have become habits, deeply engrained in our society. To make us more aware of our bodily ways of living with mobiles and open the design space for novel ways of designing mobiles and their interactions, we decided to study one of the last groups of users on earth who had not been exposed to mobiles: the people of Vanuatu. As they had so recently started using mobiles, their use was still in flux: the fragility of the mobile was unusual to them as was the need to move in order to find coverage. They were still getting used to carrying their mobiles and keeping them safe. Their encounters with mobile use exposed the need to consider somaesthetics practices when designing mobiles as they profoundly affect our bodily ways of being in the world.</p>
<p>Keywords:
embodiment; ethnography; experience; movement</p>
<h2 id="Watching together    4">Watching together    4</h2>
<h3 id="32. We want more: human-computer collaboration in mobile social video remixing of music concerts.">32. We want more: human-computer collaboration in mobile social video remixing of music concerts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978983">Paper Link</a>    Pages:287-296</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vihavainen:Sami">Sami Vihavainen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mate:Sujeet">Sujeet Mate</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sepp=auml=l=auml=:Lassi">Lassi Seppl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cricri:Francesco">Francesco Cricri</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Curcio:Igor_D=_D=">Igor D. D. Curcio</a></p>
<p>Abstract:
Recording and publishing mobile video clips from music concerts is popular. There is a high potential to increase the concert's perceived value when producing video remixes from individual video clips and using them socially. A digital production of a video remix is an interactive process between human and computer. However, it is not clear what the collaboration implications between human and computer are. We present a case study where we compare the processes and products of manual and automatic mobile video remixing. We provide results from the first systematic real world study of the subject. We draw our observations from a user trial where fans recorded mobile video clips during a rock concert. The results reveal issues on heterogeneous interests of the stakeholders, unexpected uses of the raw material, the burden of editing, diverse quality requirements, motivations for remixing, the effect of understanding the logic of automation, and the collaborative use of manual and automatic remixing.</p>
<p>Keywords:
automation; human factors; mobile; music; social; video</p>
<h3 id="33. Knowing funny: genre perception and categorization in social video sharing.">33. Knowing funny: genre perception and categorization in social video sharing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978984">Paper Link</a>    Pages:297-306</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yew:Jude">Jude Yew</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shamma:David_A=">David A. Shamma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Churchill:Elizabeth_F=">Elizabeth F. Churchill</a></p>
<p>Abstract:
Categorization of online videos is often treated as a tag suggestion task; tags can be generated by individuals or by machine classification. In this paper, we suggest categorization can be determined socially, based on people's interactions around media content without recourse to metadata that are intrinsic to the media object itself. This work bridges the gap between the human perception of genre and automatic categorization of genre in classifying online videos. We present findings from two internet surveys and from follow-up interviews where we address how people determine genre classification for videos and how social framing of video content can alter the perception and categorization of that content. From these findings, we train a Naive Bayes classifier to predict genre categories. The trained classifier achieved 82% accuracy using only social action data, without the use of content or media-specific metadata. We conclude with implications on how we categorize and organize media online as well as what our findings mean for designing and building future tools and interaction experiences.</p>
<p>Keywords:
categorization; classification; genre; interview; naive bayes; social; survey; video; youtube</p>
<h3 id="34. Real-time nonverbal opinion sharing through mobile phones during sports events.">34. Real-time nonverbal opinion sharing through mobile phones during sports events.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978985">Paper Link</a>    Pages:307-310</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shirazi:Alireza_Sahami">Alireza Sahami Shirazi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rohs:Michael">Michael Rohs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schleicher:Robert">Robert Schleicher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kratz:Sven_G=">Sven G. Kratz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller:Alexander">Alexander Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
Even with the rise of the World Wide Web, TV has remained the most pervasive entertainment medium and is nowadays often used together with other media, which allow for active participation. The idea of connecting non-collocated TV viewers via telecommunication technologies, referred to as Social TV, has recently received considerable attention. Such systems typically include set-top boxes for supporting collaboration. In this research we investigate if real-time opinion sharing about TV shows through a nonverbal (non-textual) iconic UI on mobile phones is reasonable. For this purpose we developed a mobile app, made it available to a large number of users through the Android Market, and conducted an uncontrolled user study in the wild during the soccer world cup 2010. The results of the study indicate that TV viewers who used the app had more fun and felt more connected to other viewers. We also show that by monitoring this channel it is possible to collect sentiments relevant to the broadcasted content in real-time. The collected data exemplify that the aggregated sentiments correspond to important moments, and hence can be used to generate a summary of the event.</p>
<p>Keywords:
mobile phone; sentiment support; social tv; sports</p>
<h3 id="35. Are we in sync?: synchronization requirements for watching online video together.">35. Are we in sync?: synchronization requirements for watching online video together.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978986">Paper Link</a>    Pages:311-314</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Geerts:David">David Geerts</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vaishnavi:Ishan">Ishan Vaishnavi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mekuria:Rufael">Rufael Mekuria</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Deventer:Oskar_van">Oskar van Deventer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/C=eacute=sar:Pablo">Pablo Csar</a></p>
<p>Abstract:
Synchronization between locations is an important factor for enabling remote shared experiences. Still, experimental data on what is the acceptable synchronization level is scarce. This paper discusses the synchronization requirements for watching online videos together - a popular set of services that recreate the shared experience of watching TV together by offering tools to communicate while watching. It studies the noticeability and annoyance of synchronization differences of the video being watched, as well as the impact on users' feelings of togetherness, both for voice chat and text chat. Results of an experiment with 36 participants show that when using voice chat, users notice synchronization differences sooner, are more annoyed and feel more together than when using text chat. However, users with high text chat activity notice synchronization differences similar to participants using voice chat.</p>
<p>Keywords:
entertainment; online video; social tv; synchronization</p>
<h2 id="Health 2: persuasive systems    5">Health 2: persuasive systems    5</h2>
<h3 id="36. Designing for peer involvement in weight management.">36. Designing for peer involvement in weight management.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978988">Paper Link</a>    Pages:315-324</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Maitland:Julie">Julie Maitland</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chalmers:Matthew">Matthew Chalmers</a></p>
<p>Abstract:
The problems of obesity and overweight are commonly cited as the motivation behind recent efforts to develop technology that promotes physical activity. Prompted by the social nature of many of the emerging applications, this paper presents our investigation of the sociality of weight management as experienced by a broad demographic of individuals. Our findings highlight the broad scope of peer involvement, and provide insight into the context and mechanics of related interaction that may prove valuable in informing the next generation of peer-based weight management technology for use in everyday life.</p>
<p>Keywords:
behavioral change; diet; health; obesity; physical activity; social influence; social networks; social support; weight</p>
<h3 id="37. Mining behavioral economics to design persuasive technology for healthy choices.">37. Mining behavioral economics to design persuasive technology for healthy choices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978989">Paper Link</a>    Pages:325-334</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Min_Kyung">Min Kyung Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kiesler:Sara_B=">Sara B. Kiesler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a></p>
<p>Abstract:
Influence through information and feedback has been one of the main approaches of persuasive technology. We propose another approach based on behavioral economics research on decision-making. This approach involves designing the presentation and timing of choices to encourage people to make self-beneficial decisions. We applied three behavioral economics persuasion techniques - the default option strategy, the planning strategy, and the asymmetric choice strategy - to promote healthy snacking in the workplace. We tested the strategies in three experimental case studies using a human snack deliverer, a robot, and a snack ordering website. The default and the planning strategies were effective, but they worked differently depending on whether the participants had healthy dietary lifestyles or not. We discuss designs for persuasive technologies that apply behavioral economics.</p>
<p>Keywords:
asymmetric dominance; behavioral economics; choice; default bias; health technology; healthy eating; persuasive technology; present-biased preferences; snacking</p>
<h3 id="38. Means based adaptive persuasive systems.">38. Means based adaptive persuasive systems.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978990">Paper Link</a>    Pages:335-344</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kaptein:Maurits">Maurits Kaptein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Duplinsky:Steven">Steven Duplinsky</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Markopoulos:Panos">Panos Markopoulos</a></p>
<p>Abstract:
Large differences in individual responses to persuasive strategies suggest the need for systems that rely on persuasion profiles: estimates of an individual user's susceptibility to different persuasive strategies. Establishing an empirical ground supporting decisions regarding user involvement can provide valuable guidelines for the design of such systems. We describe two studies examining the effects of choice, disclosure, and multiple strategy usage on user compliance to persuasive attempts. We show that involving users in the selection of a specific influence strategy can increase compliance, while disclosing the persuasive intent can reduce compliance. Furthermore, we demonstrate that it is not only feasible, but optimal to choose the single correct influence strategy for a given context; even more so than implementing multiple relevant and congruent influence attempts.</p>
<p>Keywords:
adaptive systems; influence strategies; online commerce; persuasive technology; recommender systems</p>
<h3 id="39. Side effects and "gateway" tools: advocating a broader look at evaluating persuasive systems.">39. Side effects and "gateway" tools: advocating a broader look at evaluating persuasive systems.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978991">Paper Link</a>    Pages:345-348</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schwanda:Victoria">Victoria Schwanda</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Ibara:Steven">Steven Ibara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reynolds:Lindsay">Lindsay Reynolds</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cosley:Dan">Dan Cosley</a></p>
<p>Abstract:
This paper argues for evaluating the impact of persuasive systems on users beyond metrics that focus on system usage, based on an interview study of 16 Wii Fit users. While exploring their experiences and reasons for abandoning the system, two main themes emerged: the tension between Wii Fit as a fitness tool and a game, and ways participants reacted to the system's feedback about their weight and performance. Some participants used Wii Fit as a "gateway fitness" tool, moving beyond it to other fitness routines. Additionally, some users had significant emotional reactions to the Wii Fitts feedback. We argue that these 'side effects' are crucial considerations for the design and long-term evaluation of persuasive technologies.</p>
<p>Keywords:
e-health interventions; persuasive technologies; wii fit</p>
<h3 id="40. I will do it, but i don't like it: user reactions to preference-inconsistent recommendations.">40. I will do it, but i don't like it: user reactions to preference-inconsistent recommendations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978992">Paper Link</a>    Pages:349-352</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schwind:Christina">Christina Schwind</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Buder:J=uuml=rgen">Jrgen Buder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hesse:Friedrich_W=">Friedrich W. Hesse</a></p>
<p>Abstract:
Recommender systems have their origin in e-commerce. In this domain the users are meant to like the recommended information. This preference-consistency is not adequate or even desirable for all domains where recommender systems are implemented. One key issue for opinion formation and informed decision making is to be aware of more than one's own perspective. However, information search is often biased, because confirming information is favored over opposing information. Therefore it would be useful to recommend information that is inconsistent to users' prior perspective to help overcome this bias. The present paper deals with an online experiment aimed at investigating the effects of preference-consistent compared to preference-inconsistent recommendations on information selection and evaluation. Results showed a significant reduction of confirmation bias in the condition with preference-inconsistent recommendations. However, participants prefer preference-consistent recommendations in terms of global, cognitive and affective evaluations. We discuss the impact of these findings for application.</p>
<p>Keywords:
confirmation bias; experimental study; recommendations</p>
<h2 id="Brain & bio-sensor interactions    4">Brain &amp; bio-sensor interactions    4</h2>
<h3 id="41. Embodiment in brain-computer interaction.">41. Embodiment in brain-computer interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978994">Paper Link</a>    Pages:353-362</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/O=Hara:Kenton">Kenton O'Hara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sellen:Abigail">Abigail Sellen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harper:Richard_H=_R=">Richard H. R. Harper</a></p>
<p>Abstract:
With emerging opportunities for using Brain-Computer Interaction (BCI) in gaming applications, there is a need to understand the opportunities and constraints of this interaction paradigm. To complement existing laboratory-based studies, there is also a call for the study of BCI in real world contexts. In this paper we present such a real world study of a simple BCI game called MindFlex, played as a social activity in the home. In particular, drawing on the philosophical traditions of embodied interaction, we highlight the importance of considering the body in BCI and not simply what is going on in the head. The study shows how people use bodily actions to facilitate control of brain activity but also to make their actions and intentions visible to, and interpretable by, others playing and watching the game. It is the public availability of these bodily actions during BCI that allows action to be socially organised, understood and coordinated with others and through which social relationships can be played out. We discuss the implications of this perspective and findings for BCI.</p>
<p>Keywords:
brain-computer interaction; embodied interaction; gaming; play</p>
<h3 id="42. Now where was I?: physiologically-triggered bookmarking.">42. Now where was I?: physiologically-triggered bookmarking.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978995">Paper Link</a>    Pages:363-372</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pan:Matthew_K=_X=_J=">Matthew K. X. J. Pan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chang:Gordon_Jih=Shiang">Gordon Jih-Shiang Chang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Himmetoglu:Gokhan_H=">Gokhan H. Himmetoglu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moon:AJung">AJung Moon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hazelton:Thomas_W=">Thomas W. Hazelton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacLean:Karon_E=">Karon E. MacLean</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Croft:Elizabeth_A=">Elizabeth A. Croft</a></p>
<p>Abstract:
This work explores a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user's physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. Here, a user's galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our prototype automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted. To test this approach's viability, we addressed questions such as: does GSR exhibit a detectable response to interruptions, and how should the interaction utilize this information? In evaluating this system in a controlled environment, we found an OR detection accuracy of 84%; users provided subjective feedback on its accuracy and utility.</p>
<p>Keywords:
galvanic skin response; human-computer interaction; interruption; orienting response; physiological signals</p>
<h3 id="43. This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.">43. This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978996">Paper Link</a>    Pages:373-382</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hirshfield:Leanne_M=">Leanne M. Hirshfield</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gulotta:Rebecca">Rebecca Gulotta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hirshfield:Stuart_H=">Stuart H. Hirshfield</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hincks:Samuel_W=">Samuel W. Hincks</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Russell:Matthew">Matthew Russell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Ward:Rachel">Rachel Ward</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williams:Tom">Tom Williams</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jacob:Robert_J=_K=">Robert J. K. Jacob</a></p>
<p>Abstract:
This project represents a first step towards bridging the gap between HCI and cognition research. Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques to non-invasively measure a range of cognitive workload states that have implications to HCI research, most directly usability testing. We present a set of usability experiments that illustrates how fNIRS brain measurement provides information about the cognitive demands placed on computer users by different interface designs.</p>
<p>Keywords:
brain; fNIRS; functional near infrared spectroscopy; usability testing; workload</p>
<h3 id="44. Sensing cognitive multitasking for a brain-based adaptive user interface.">44. Sensing cognitive multitasking for a brain-based adaptive user interface.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978997">Paper Link</a>    Pages:383-392</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Solovey:Erin_Treacy">Erin Treacy Solovey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lalooses:Francine">Francine Lalooses</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chauncey:Krysta">Krysta Chauncey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weaver:Douglas">Douglas Weaver</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Parasi:Margarita">Margarita Parasi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Scheutz:Matthias">Matthias Scheutz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sassaroli:Angelo">Angelo Sassaroli</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fantini:Sergio">Sergio Fantini</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schermerhorn:Paul_W=">Paul W. Schermerhorn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Girouard:Audrey">Audrey Girouard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jacob:Robert_J=_K=">Robert J. K. Jacob</a></p>
<p>Abstract:
Multitasking has become an integral part of work environments, even though people are not well-equipped cognitively to handle numerous concurrent tasks effectively. Systems that support such multitasking may produce better performance and less frustration. However, without understanding the user's internal processes, it is difficult to determine optimal strategies for adapting interfaces, since all multitasking activity is not identical. We describe two experiments leading toward a system that detects cognitive multitasking processes and uses this information as input to an adaptive interface. Using functional near-infrared spectroscopy sensors, we differentiate four cognitive multitasking processes. These states cannot readily be distinguished using behavioral measures such as response time, accuracy, keystrokes or screen contents. We then present our human-robot system as a proof-of-concept that uses real-time cognitive state information as input and adapts in response. This prototype system serves as a platform to study interfaces that enable better task switching, interruption management, and multitasking.</p>
<p>Keywords:
brain computer interface; fnirs; human-robot interaction; interruption; multitasking; near-infrared spectroscopy</p>
<h2 id="Gestures    3">Gestures    3</h2>
<h3 id="45. RemoteTouch: touch-screen-like interaction in the tv viewing environment.">45. RemoteTouch: touch-screen-like interaction in the tv viewing environment.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1978999">Paper Link</a>    Pages:393-402</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Choi:Sangwon">Sangwon Choi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Han:Jaehyun">Jaehyun Han</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Geehyuk">Geehyuk Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Narae">Narae Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Woohun">Woohun Lee</a></p>
<p>Abstract:
We explored the possibility of touch-screen-like interaction with a remote control in the TV-viewing environment. A shadow representing the user's thumb touches the screen, presses a button, flicks a cover-flow list, and draws a simple stroke, while the thumb stays and moves on and above the touchpad. In order to implement the concept we developed an optical touchpad for tracking the thumb hovering over its surface, and designed a TV application to demonstrate possible new interaction styles. Throughout two iterations of prototyping, we corrected some of our false expectations, and also verified its potential as a viable option for a TV remote control. This paper presents technical issues and requirements for the hover-tracking touchpad and a complete report of our user studies to explore touch-screen-like interaction for the TV.</p>
<p>Keywords:
hover-tracking touchpad; remotetouch interaction; tv remote control; tv user interface</p>
<h3 id="46. Experimental analysis of touch-screen gesture designs in mobile environments.">46. Experimental analysis of touch-screen gesture designs in mobile environments.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979000">Paper Link</a>    Pages:403-412</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bragdon:Andrew">Andrew Bragdon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nelson:Eugene">Eugene Nelson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hinckley:Ken">Ken Hinckley</a></p>
<p>Abstract:
Direct-touch interaction on mobile phones revolves around screens that compete for visual attention with users' real-world tasks and activities. This paper investigates the impact of these situational impairments on touch-screen interaction. We probe several design factors for touch-screen gestures, under various levels of environmental demands on attention, in comparison to the status-quo approach of soft buttons. We find that in the presence of environmental distractions, gestures can offer significant performance gains and reduced attentional load, while performing as well as soft buttons when the user's attention is focused on the phone. In fact, the speed and accuracy of bezel gestures did not appear to be significantly affected by environment, and some gestures could be articulated eyes-free, with one hand. Bezel-initiated gestures offered the fastest performance, and mark-based gestures were the most accurate. Bezel-initiated marks therefore may offer a promising approach for mobile touch-screen interaction that is less demanding of the user's attention.</p>
<p>Keywords:
evaluation; gestures; mobile phones; performance; touch</p>
<h3 id="47. Usable gestures for blind people: understanding preference and performance.">47. Usable gestures for blind people: understanding preference and performance.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979001">Paper Link</a>    Pages:413-422</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kane:Shaun_K=">Shaun K. Kane</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Ladner:Richard_E=">Richard E. Ladner</a></p>
<p>Abstract:
Despite growing awareness of the accessibility issues surrounding touch screen use by blind people, designers still face challenges when creating accessible touch screen interfaces. One major stumbling block is a lack of understanding about how blind people actually use touch screens. We conducted two user studies that compared how blind people and sighted people use touch screen gestures. First, we conducted a gesture elicitation study in which 10 blind and 10 sighted people invented gestures to perform common computing tasks on a tablet PC. We found that blind people have different gesture preferences than sighted people, including preferences for edge-based gestures and gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance study in which the same participants performed a set of reference gestures. We found significant differences in the speed, size, and shape of gestures performed by blind people versus those performed by sighted people. Our results suggest new design guidelines for accessible touch screen interfaces.</p>
<p>Keywords:
accessibility; blind; gesture recognition; gestures; touch screens</p>
<h2 id="Designing for values, democracy & peace    4">Designing for values, democracy &amp; peace    4</h2>
<h3 id="48. Fit4life: the design of a persuasive technology promoting healthy behavior and ideal weight.">48. Fit4life: the design of a persuasive technology promoting healthy behavior and ideal weight.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979003">Paper Link</a>    Pages:423-432</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Purpura:Stephen">Stephen Purpura</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwanda:Victoria">Victoria Schwanda</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williams:Kaiton">Kaiton Williams</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stubler:William">William Stubler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sengers:Phoebe">Phoebe Sengers</a></p>
<p>Abstract:
This is a critical design paper offering a possible scenario of use intended to provoke reflection about values and politics of design in persuasive computing. We describe the design of a system - Fit4Life - that encourages individuals to address the larger goal of reducing obesity in society by promoting individual healthy behaviors. Using the Persuasive Systems Design Model [26], this paper outlines the Fit4Life persuasion context, the technology, its use of persuasive messages, and an experimental design to test the system's efficacy. We also contribute a novel discussion of the ethical and sociocultural considerations involved in our design, an issue that has remained largely unaddressed in the existing persuasive technologies literature [29].</p>
<p>Keywords:
critical design; persuasive technology; social implications; weight loss</p>
<h3 id="49. Many bills: engaging citizens through visualizations of congressional legislation.">49. Many bills: engaging citizens through visualizations of congressional legislation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979004">Paper Link</a>    Pages:433-442</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Assogba:Yannick">Yannick Assogba</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ros:Irene">Irene Ros</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/DiMicco:Joan_Morris">Joan Morris DiMicco</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McKeon:Matt">Matt McKeon</a></p>
<p>Abstract:
US federal legislation is a common subject of discussion and advocacy on the web, inspired by the open government movement. While the contents of these bills are freely available for download, understanding them is a significant challenge to experts and average citizens alike due to their length, complex language, and obscure topics. To make these important documents more accessible to the general public, we present Many Bills (<a href="http://manybills.us">http://manybills.us</a>): a web-based set of visualization tools that reveals the underlying semantics of a bill. Using machine learning techniques, we classify each bill's sections based on existing document-level categories. We then visualize the resulting topic substructure of these bills. These visualizations provide an overview-and-detail view of bills, enabling users to read individual sections of a bill and compare topic patterns across multiple bills. Through an overview of the site's user activity and interviews with active users, this paper highlights how Many Bills makes the tasks of reading bills, identifying outlier sections in bills, and understanding congressperson's legislative activity more manageable.</p>
<p>Keywords:
government; government transparency; information visualization; legislation; text classification</p>
<h3 id="50. HCI for peace: a call for constructive action.">50. HCI for peace: a call for constructive action.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979005">Paper Link</a>    Pages:443-452</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hourcade:Juan_Pablo">Juan Pablo Hourcade</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bullock=Rest:Natasha_E=">Natasha E. Bullock-Rest</a></p>
<p>Abstract:
Peace is an important value for the human-computer interaction research community, yet it has not resulted in the development of a research sub-community or even a research agenda. In this paper we seek to address this void by first motivating the need for computing research on promoting peace and preventing war. We then review evidence on the factors that affect the likelihood that armed conflict will occur, as well as the aspects involved when individuals make moral decisions on whether or not to support a war. Based on this review, we propose a research agenda, citing research examples from the human-computer interaction literature and discussing new ideas.</p>
<p>Keywords:
causes of conflict; compassion; empathy; peace; research agenda; software; technology; war</p>
<h3 id="51. Evaluating a pattern-based visual support approach for humanitarian landmine clearance.">51. Evaluating a pattern-based visual support approach for humanitarian landmine clearance.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979006">Paper Link</a>    Pages:453-462</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jayatilaka:Lahiru_G=">Lahiru G. Jayatilaka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bertuccelli:Luca_F=">Luca F. Bertuccelli</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Staszewski:James">James Staszewski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gajos:Krzysztof_Z=">Krzysztof Z. Gajos</a></p>
<p>Abstract:
Unexploded landmines have severe post-conflict humanitarian repercussions: landmines cost lives, limbs and land. For deminers engaged in humanitarian landmine clearance, metal detectors remain the primary detection tool as more sophisticated technologies fail to get adopted due to restrictive cost, low reliability, and limited robustness. Metal detectors are, however, of limited effectiveness, as modern landmines contain only minimal amounts of metal, making them difficult to distinguish from the ubiquitous but harmless metallic clutter littering post-combat areas. We seek to improve the safety and efficiency of the demining process by developing support tools that will enable deminers to make better decisions using feedback from existing metal detectors. To this end, in this paper we propose and evaluate a novel, pattern-based visual support approach inspired by the documented strategies employed by expert deminers. In our laboratory study, participants provided with a prototype of our support tool were 80% less likely to mistake a mine for harmless clutter. A follow-up study demonstrates the potential of our pattern-based approach to enable peer decision-making support during landmine clearance. Lastly, we identify several design opportunities for further improving deminers' decision making capabilities.</p>
<p>Keywords:
decision support; demining; humanitarian landmine clearance; visual support</p>
<h2 id="Driving    4">Driving    4</h2>
<h3 id="52. Hang on a sec!: effects of proactive mediation of phone conversations while driving.">52. Hang on a sec!: effects of proactive mediation of phone conversations while driving.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979008">Paper Link</a>    Pages:463-472</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/i/Iqbal:Shamsi_T=">Shamsi T. Iqbal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Horvitz:Eric">Eric Horvitz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Ju:Yun=Cheng">Yun-Cheng Ju</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mathews:Ella">Ella Mathews</a></p>
<p>Abstract:
Conversing on cell phones while driving is a risky, yet commonplace activity. State legislatures in the U.S. have enacted rules that limit hand-held phone conversations while driving but that allow for hands-free conversations. However, studies have demonstrated that the cognitive load of conversation is a significant source of distraction that increases the likelihood of accidents. We explore in a controlled study with a driving simulator the effectiveness of proactive alerting and mediation of communications during phone conversations while driving. We study the use of auditory messages indicating upcoming critical road conditions and placing calls on hold. We found that such actions reduce driving errors and that alerts sharing details about situations were more effective than general alerts. Drivers found such a system valuable in most situations for maintaining driving safety. These results provide evidence that context-sensitive mediation systems could play a valuable role in focusing drivers' attention on the road during phone conversations.</p>
<p>Keywords:
attention; cell phones; context-sensitive systems; driving</p>
<h3 id="53. Fast or safe?: how performance objectives determine modality output choices while interacting on the move.">53. Fast or safe?: how performance objectives determine modality output choices while interacting on the move.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979009">Paper Link</a>    Pages:473-482</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brumby:Duncan_P=">Duncan P. Brumby</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davies:Samantha_C=_E=">Samantha C. E. Davies</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Janssen:Christian_P=">Christian P. Janssen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grace:Justin_J=">Justin J. Grace</a></p>
<p>Abstract:
In-car devices that use audio output have been shown to be less distracting than traditional graphical user interfaces, but can be cumbersome and slow to use. In this paper, we report an experiment that demonstrates how these performance characteristics impact whether people will elect to use an audio interface in a multitasking situation. While steering a simulated vehicle, participants had to locate a source of information in a short passage of text. The text was presented either on a visual interface, or using a text-to-speech audio interface. The relative importance of each task was varied. A no-choice/choice paradigm was used in which participants first gained experience with each of the two interfaces, before being given a choice on which interface to use on later trials. The characteristics of the interaction with the interfaces, as measured in the no-choice phase, and the relative importance of each task, had an impact on which output modality was chosen in the choice phase. Participants that prioritized the secondary task tended to select the (faster yet more distracting) visual interface over the audio interface, and as a result had poorer lane keeping performance. This work demonstrates how a user's task objective will influence modality choices with multimodal devices in multitask environments.</p>
<p>Keywords:
audio interface; driving; multitasking; performance trade-offs.; strategy selection; visual interface</p>
<h3 id="54. Gestural interaction on the steering wheel: reducing the visual demand.">54. Gestural interaction on the steering wheel: reducing the visual demand.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979010">Paper Link</a>    Pages:483-492</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/D=ouml=ring:Tanja">Tanja Dring</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kern:Dagmar">Dagmar Kern</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Paul">Paul Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pfeiffer:Max">Max Pfeiffer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sch=ouml=ning:Johannes">Johannes Schning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gruhn:Volker">Volker Gruhn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
Cars offer an increasing number of infotainment systems as well as comfort functions that can be controlled by the driver. In our research, we investigate new interaction techniques that aim to make it easier to interact with these systems while driving. We suggest utilizing the steering wheel as an additional interaction surface. In this paper, we present two user studies conducted with a working prototype of a multi-touch steering wheel. In the first, we developed a user-defined steering wheel gesture set, and in the second, we applied the identified gestures and compared their application to conventional user interaction with infotainment systems in terms of driver distraction. The main outcome was that driver's visual demand is reduced significantly by using gestural interaction on the multi-touch steering wheel.</p>
<p>Keywords:
automotive user interfaces; driver distraction; gestural input; multi-touch; user-defined gestures; visual demand</p>
<h3 id="55. Usability of car dashboard displays for elder drivers.">55. Usability of car dashboard displays for elder drivers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979011">Paper Link</a>    Pages:493-502</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Seungjun">Seungjun Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dey:Anind_K=">Anind K. Dey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Joonhwan">Joonhwan Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a></p>
<p>Abstract:
The elder population is rising worldwide; in the US, no longer being able to drive is a significant marker of loss of independence. One of the approaches to helping elders drive more safely is to investigate the use of automotive user interface technology, and specifically, to explore the instrument panel (IP) display design to help attract and manage attention and make information easier to interpret. In this paper, we explore the premise that dashboard displays can be better designed to support elder drivers, their information needs, and their cognitive capabilities. We conducted a study to understand which display design features are critically linked to issues of divided attention and driving performance. We found that contrast of size and reduced clutter are instrumental in enhancing driving performance, particularly for the elder population. Surprisingly, our results showed that color elements have a negative effect on driving performance for elders, while color elements and fills slightly improve performance. We conclude with design implications generated from this work.</p>
<p>Keywords:
automotive ui; dashboard; dashboard display; divided attention; eye tracking; interface design; senior drivers</p>
<h2 id="Meetings & interaction spaces    2">Meetings &amp; interaction spaces    2</h2>
<h3 id="56. Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment.">56. Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979013">Paper Link</a>    Pages:503-512</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Erickson:Thomas">Thomas Erickson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shami:N=_Sadat">N. Sadat Shami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kellogg:Wendy_A=">Wendy A. Kellogg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Levine:David_W=">David W. Levine</a></p>
<p>Abstract:
This paper presents the first in-depth evaluation of a large multi-format virtual conference. The conference took place in an avatar-based 3D virtual world with spatialized audio, and had keynote, poster and social sessions. We studied it by drawing on logs, a survey and interviews with 30 participants. We develop a model - Coalescence, Focused Interaction, Remixing (CoFIRe) -- of large synchronous interactions, and use it to discuss how the technology supported, or failed to support, the interactions that are the raison d'etre of conferences. We conclude by discussing the prospects for such large virtual gatherings.</p>
<p>Keywords:
CMC; CVE; collaborative virtual environment; second life; spatialized audio; synchronous interaction; virtual conference; virtual world</p>
<h3 id="57. What did i miss?: in-meeting review using multimodal accelerated instant replay (air) conferencing.">57. What did i miss?: in-meeting review using multimodal accelerated instant replay (air) conferencing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979014">Paper Link</a>    Pages:513-522</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Junuzovic:Sasa">Sasa Junuzovic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Inkpen:Kori">Kori Inkpen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hegde:Rajesh">Rajesh Hegde</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Zhengyou">Zhengyou Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tang:John_C=">John C. Tang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brooks:Christopher">Christopher Brooks</a></p>
<p>Abstract:
People sometimes miss small parts of meetings and need to quickly catch up without disrupting the rest of the meeting. We developed an Accelerated Instant Replay (AIR) Conferencing system for videoconferencing that enables users to catch up on missed content while the meeting is ongoing. AIR can replay parts of the conference using four different modalities: audio, video, conversation transcript, and shared workspace. We performed two studies to evaluate the system. The first study explored the benefit of AIR catch-up during a live meeting. The results showed that when the full videoconference was reviewed (i.e., all four modalities) at an accelerated rate, users were able to correctly recall a similar amount of information as when listening live. To better understand the benefit of full review, a follow-up study more closely examined the benefits of each of the individual modalities. The results show that users (a) preferred using audio along with any other modality to using audio alone, (b) were most confident and performed best when audio was reviewed with all other modalities, (c) compared to audio-only, had better recall of facts and explanations when reviewing audio together with the shared workspace and transcript modalities, respectively, and (d) performed similarly with audio-only and audio with video review.</p>
<p>Keywords:
audio; cscw; dvr; meetings; review; shared workspace; telepresence; transcript; video; videoconferencing</p>
<h2 id="Art, music & movement    5">Art, music &amp; movement    5</h2>
<h3 id="58. MOGCLASS: evaluation of a collaborative system of mobile devices for classroom music education of young children.">58. MOGCLASS: evaluation of a collaborative system of mobile devices for classroom music education of young children.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979016">Paper Link</a>    Pages:523-532</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhou:Yinsheng">Yinsheng Zhou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Percival:Graham">Graham Percival</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Xinxi">Xinxi Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Ye">Ye Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a></p>
<p>Abstract:
Composition, listening, and performance are essential activities in classroom music education, yet conventional music classes impose unnecessary limitations on students' ability to develop these skills. Based on in-depth fieldwork and a user-centered design approach, we created MOGCLASS, a multimodal collaborative music environment that enhances students' musical experience and improves teachers' management of the classroom. We conducted a two-round system evaluation to improve the prototype and evaluate the system: Improvements were made based on the results from an iterative design evaluation, in which a trial system was implemented. The system then underwent a second round of evaluation through a three-week between-subject controlled experiment in a local primary school. Results showed that MOGCLASS is effective in motivating students to learn music, improving the way they collaborate with other students as well as helping teachers manage the classroom.</p>
<p>Keywords:
children; education; mobile devices; music; musical instruments; user-centered design</p>
<h3 id="59. Buzzing to play: lessons learned from an in the wild study of real-time vibrotactile feedback.">59. Buzzing to play: lessons learned from an in the wild study of real-time vibrotactile feedback.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979017">Paper Link</a>    Pages:533-542</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Linden:Janet_van_der">Janet van der Linden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Johnson:Rose_M=_G=">Rose M. G. Johnson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bird:Jon">Jon Bird</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Yvonne">Yvonne Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schoonderwaldt:Erwin">Erwin Schoonderwaldt</a></p>
<p>Abstract:
Vibrotactile feedback offers much potential for facilitating and accelerating how people learn sensory-motor skills that typically take hundreds of hours to learn, such as learning to play a musical instrument, skiing or swimming. However, there is little evidence of this benefit materializing outside of research lab settings. We describe the findings of an in-the-wild study that explored how to integrate vibrotactile feedback into a real-world teaching setting. The focus of the study was on exploring how children of different ages, learning to play the violin, can use real-time vibrotactile feedback. Many of the findings were unexpected, showing how students and their teachers appropriated the technology in creative ways. We present some 'lessons learned' that are also applicable to other training settings, emphasizing the need to understand how vibrotactile feedback can switch between being foregrounded and backgrounded depending on the demands of the task, the teacher's role in making it work and when feedback is most relevant and useful. Finally, we discuss how vibrotactile feedback can provide a new language for talking about the skill being learned that may also play an instrumental role in enhancing learning.</p>
<p>Keywords:
children; in the wild study; motion capture; sensory-motor learning; vibrotactile feedback; violin teaching</p>
<h3 id="60. PossessedHand: techniques for controlling human hands using electrical muscles stimuli.">60. PossessedHand: techniques for controlling human hands using electrical muscles stimuli.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979018">Paper Link</a>    Pages:543-552</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tamaki:Emi">Emi Tamaki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miyaki:Takashi">Takashi Miyaki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rekimoto:Jun">Jun Rekimoto</a></p>
<p>Abstract:
If a device can control human hands, the device can be useful for HCI and tangible application's output. To aid the controlling of finger movement, we present PossessedHand, a device with a forearm belt that can inform when and which fingers should be moved. PossessedHand controls the user's fingers by applying electrical stimulus to the muscles around the forearm. Each muscle is stimulated via 28 electrode pads. Muscles at different depths in the forearm can be selected for simulation by varying the stimulation level. PossessedHand can automatically calibrate the system for individuals. The automatic calibration system estimates relations between each electrode pad, stimulation level and muscle movement. Experiments show that PossessedHand can control the motion of 16 joints in the hand. Further, we also discuss an application based on this device to aid in playing a musical instrument.</p>
<p>Keywords:
electric stimulation; ems; fes; hand gesture; musical performance</p>
<h3 id="61. Design interventions for open-air museums: applying and extending the principles of 'assembly'.">61. Design interventions for open-air museums: applying and extending the principles of 'assembly'.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979019">Paper Link</a>    Pages:553-556</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McLoughlin:Marc">Marc McLoughlin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Ciolfi:Luigina">Luigina Ciolfi</a></p>
<p>Abstract:
This paper presents an empirical approach to designing and deploying technologies to support visitor activities in exhibition spaces. Specifically, we focus on the concept of "assembly" and how it was extended and applied to develop an interactive installation for an open-air museum. We argue that this approach to designing for a meaningful visitor experience is particularly suited to open-air visit scenarios; we describe how we have extended the approach and applied it, detailing the resulting multi-device installation that was deployed on site, and presenting some reflections on the usefulness of the assembly concept.</p>
<p>Keywords:
assemblies; design approaches; museums; ubiquitous computing</p>
<h3 id="62. MoBoogie: creative expression through whole body musical interaction.">62. MoBoogie: creative expression through whole body musical interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979020">Paper Link</a>    Pages:557-560</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Halpern:Megan_K=">Megan K. Halpern</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tholander:Jakob">Jakob Tholander</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Evjen:Max">Max Evjen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davis:Stuart">Stuart Davis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Ehrlich:Andrew">Andrew Ehrlich</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schustak:Kyle">Kyle Schustak</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baumer:Eric_P=_S=">Eric P. S. Baumer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gay:Geri">Geri Gay</a></p>
<p>Abstract:
In this paper we describe MoBoogie, an application that allows users to manipulate and arrange music through movement. MoBoogie is designed to foster experiences in creative expression for children and potentially adults. The application responds to users' movements by changing variables in a continuous stream of music loops. Results from this study suggest that the creative expressions arose in the joint space of movement and music, and did not primarily have to be in one form or the other. This allowed users with limited experience in dance and music making to be creative in such forms of expression.</p>
<p>Keywords:
creative expression; mobile interaction; music; whole-body interaction</p>
<h2 id="Facebook    4">Facebook    4</h2>
<h3 id="63. Life "modes" in social media.">63. Life "modes" in social media.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979022">Paper Link</a>    Pages:561-570</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Ozenc:Fatih_Kursat">Fatih Kursat Ozenc</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Farnham:Shelly">Shelly Farnham</a></p>
<p>Abstract:
Current social media products such as Facebook and Twitter have not sufficiently addressed how to help users organize people and content streams across different areas of their lives. We conducted a qualitative design research study to explore how we might best leverage natural models of social organization to improve experiences of social media. We found that participants organize their social worlds based on life 'modes', i.e., family, work and social. They strategically use communication technologies to manage intimacy levels within these modes, and levels of permeability through the boundaries between these modes. Mobile communication in particular enabled participants to aggregate and share content dynamically across life modes. While exploring problems with managing their social media streams, people showed a strong need for focused sharing - the ability to share content only with appropriate audiences within certain areas of life.</p>
<p>Keywords:
boundaries; email; facebook; faceted identity; identity; modes; privacy; roles; social media; social networks; transitions</p>
<h3 id="64. Social capital on facebook: differentiating uses and users.">64. Social capital on facebook: differentiating uses and users.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979023">Paper Link</a>    Pages:571-580</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Burke:Moira">Moira Burke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marlow:Cameron">Cameron Marlow</a></p>
<p>Abstract:
Though social network site use is often treated as a monolithic activity, in which all time is equally social and its impact the same for all users, we examine how Facebook affects social capital depending upon: (1) types of site activities, contrasting one-on-one communication, broadcasts to wider audiences, and passive consumption of social news, and (2) individual differences among users, including social communication skill and self-esteem. Longitudinal surveys matched to server logs from 415 Facebook users reveal that receiving messages from friends is associated with increases in bridging social capital, but that other uses are not. However, using the site to passively consume news assists those with lower social fluency draw value from their connections. The results inform site designers seeking to increase social connectedness and the value of those connections.</p>
<p>Keywords:
computer-mediated communication; self-esteem; social capital; social network sites; social skills</p>
<h3 id="65. Farmer's tale: a facebook game to promote volunteerism.">65. Farmer's tale: a facebook game to promote volunteerism.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979024">Paper Link</a>    Pages:581-584</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jianqiang:Don_Sim">Don Sim Jianqiang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Ma:Xiaojuan">Xiaojuan Ma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Khoo:Jing_Ting">Jing Ting Khoo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bay:Swee_Ling">Swee Ling Bay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jiang:Zhenhui">Zhenhui Jiang</a></p>
<p>Abstract:
Volunteering is an important activity that brings great benefits to societies. However, encouraging volunteerism is difficult due to the altruistic nature of volunteer activities and the high resource demand in carrying them out. We have created a Facebook game called "Farmer's Tale" to attract and make it easier for people to volunteer. We evaluated people's acceptance to this novel idea and the results revealed great potential in such type of games.</p>
<p>Keywords:
persuasive games; social networking; volunteerism</p>
<h3 id="66. Identifying social capital in the facebook interface.">66. Identifying social capital in the facebook interface.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979025">Paper Link</a>    Pages:585-588</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yoder:Christian">Christian Yoder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stutzman:Fred">Fred Stutzman</a></p>
<p>Abstract:
A number of studies have identified a robust relationship between the use of social network sites, particularly Facebook, and positive outcomes such as social capital. Social network site use is often measured as a function of use frequency, network size, and a range of subjective opinions about the value of the site. This research extends this understanding by exploring the relationship between the use of particular elements of the site and social capital. Our goal in this research is to identify where, in the interface, perceived social capital is most effectively produced and transmitted. We find that, as hypothesized, public, person-to-person communication is positively associated with perceived social capital. Through the use of a structural equation model, we are able to provide in-depth exploration of the relationship between the interface elements and the outcome, perceived social capital.</p>
<p>Keywords:
behavioral modeling; facebook; privacy; social capital; social network sites; social networking</p>
<h2 id="Health 3: online communities & social interaction    5">Health 3: online communities &amp; social interaction    5</h2>
<h3 id="67. Competing online viewpoints and models of chronic illness.">67. Competing online viewpoints and models of chronic illness.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979027">Paper Link</a>    Pages:589-598</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mankoff:Jennifer">Jennifer Mankoff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kuksenok:Kateryna">Kateryna Kuksenok</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kiesler:Sara_B=">Sara B. Kiesler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rode:Jennifer_A=">Jennifer A. Rode</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Waldman:Kelly">Kelly Waldman</a></p>
<p>Abstract:
People with chronic health problems use online resources to understand and manage their condition, but many such resources can present competing and confusing viewpoints. We surveyed and interviewed with people experiencing prolonged symptoms after a Lyme disease diagnosis. We explore how competing viewpoints in online content affect participants' understanding of their disease. Our results illustrate how chronically ill people search for information and support, and work to help others over time. Participant identity and beliefs about their illness evolved, and this led many to take on new roles, creating content and advising others who were sick. What we learned about online content creation suggests a need for designs that support this journey and engage with complex issues surrounding online health resources.</p>
<p>Keywords:
community; health; interviews; search; social media</p>
<h3 id="68. Using interface cues in online health community boards to change impressions and encourage user contribution.">68. Using interface cues in online health community boards to change impressions and encourage user contribution.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979028">Paper Link</a>    Pages:599-608</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Hyang=Sook">Hyang-Sook Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sundar:S=_Shyam">S. Shyam Sundar</a></p>
<p>Abstract:
Online health message boards have become popular, as users not only gain information from other users but also share their own experiences. However, as with most venues of user-generated content, there is need to constantly make quality evaluations as one sifts through enormous amounts of content. Can interface cues, conveying (1) pedigree of users posting content and (2) popularity of the posted content, help new users efficiently make credibility assessments? Furthermore, can the assignment of these same cues to their own posts serve to motivate content generation on their part? These questions were investigated in a 2-session between-subjects experiment (N = 99) with a prototype of a message-board that experimentally varied interface cues, and found that popularity indicators are more influential than pedigree indicators for both evaluation of existing content and contribution of new content. Findings also suggest theoretical mechanisms - involving such concepts as perceived authority, bandwagon effects, sense of agency and sense of community - by which cues affect user experience, providing rich implications for designing and deploying interface cues.</p>
<p>Keywords:
authority cues; bandwagon cues; health community boards; heuristics; sense of agency; sense of community; user contribution</p>
<h3 id="69. ACES: promoting empathy towards aphasia through language distortion emulation software.">69. ACES: promoting empathy towards aphasia through language distortion emulation software.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979029">Paper Link</a>    Pages:609-618</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hailpern:Joshua_M=">Joshua M. Hailpern</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Danilevsky:Marina">Marina Danilevsky</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harris:Andrew">Andrew Harris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karahalios:Karrie">Karrie Karahalios</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dell:Gary_S=">Gary S. Dell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hengst:Julie">Julie Hengst</a></p>
<p>Abstract:
Individuals with aphasia, an acquired communication disorder, constantly struggle against a world that does not understand them. This lack of empathy and understanding negatively impacts their quality of life. While aphasic individuals may appear to have lost cognitive functioning, their impairment relates to receptive and expressive language, not to thinking processes. We introduce a novel system and model, Aphasia Characteristics Emulation Software (ACES), enabling users (e.g., caregivers, speech therapists and family) to experience, firsthand, the communication-distorting effects of aphasia. By allowing neurologically typical individuals to "walk in another's shoes," we aim to increase patience, awareness and understanding. ACES was grounded in the communication science and psychological literature, and informed by an initial pilot study. Results from an evaluation of 64 participants indicate that ACES provides a rich experience that increases understanding and empathy for aphasia.</p>
<p>Keywords:
aphasia; assistive technology; disabilities; empathy; emulation software; language; speech</p>
<h3 id="70. Cueing for drooling in Parkinson's disease.">70. Cueing for drooling in Parkinson's disease.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979030">Paper Link</a>    Pages:619-622</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McNaney:Roisin">Roisin McNaney</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lindsay:Stephen">Stephen Lindsay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Ladha:Karim">Karim Ladha</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Ladha:Cassim">Cassim Ladha</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schofield:Guy">Guy Schofield</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pl=ouml=tz:Thomas">Thomas Pltz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hammerla:Nils_Y=">Nils Y. Hammerla</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jackson:Daniel">Daniel Jackson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Walker:Richard">Richard Walker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Nick">Nick Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
We present the development of a socially acceptable cueing device for drooling in Parkinson's disease (PD). Sialorrhea, or drooling, is a significant problem associated with PD and has a strong negative emotional impact on those who experience it. Previous studies have shown the potential for managing drooling by using a cueing device. However, the devices used in these studies were deemed unacceptable by their users due to factors such as hearing impairment and social embarrassment. We conducted exploratory scoping work and high fidelity iterative prototyping with people with PD to get their input on the design of a cueing aid and this has given us an insight into challenges that confront users with PD and limit device usability and acceptability. The key finding from working with people with PD was the need for the device to be socially acceptable.</p>
<p>Keywords:
Parkinson's disease; drooling; participatory design; swallowing</p>
<h3 id="71. Evaluating swabbing: a touchscreen input method for elderly users with tremor.">71. Evaluating swabbing: a touchscreen input method for elderly users with tremor.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979031">Paper Link</a>    Pages:623-626</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wacharamanotham:Chat">Chat Wacharamanotham</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hurtmanns:Jan">Jan Hurtmanns</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mertens:Alexander">Alexander Mertens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kronenbuerger:Martin">Martin Kronenbuerger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schlick:Christopher_M=">Christopher M. Schlick</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borchers:Jan_O=">Jan O. Borchers</a></p>
<p>Abstract:
Elderly users suffering from hand tremor have difficulties interacting with touchscreens because of finger oscillation. It has been previously observed that sliding one's finger across the screen may help reduce this oscillation. In this work, we empirically confirm this advantage by (1) measuring finger oscillation during different actions and (2) comparing error rate and user satisfaction between traditional tapping and swabbing in which the user slides his finger towards a target on a screen edge to select it. We found that oscillation is generally reduced during sliding. Also, compared to tapping, swabbing resulted in improved error rates and user satisfaction. We believe that swabbing will make touchscreens more accessible to senior users with tremor.</p>
<p>Keywords:
accuracy; evaluation; input methods; older adults; swabbing; tapping; touchscreen; tremor</p>
<h2 id="Human-robot interaction    3">Human-robot interaction    3</h2>
<h3 id="72. Direct manipulation through surrogate objects.">72. Direct manipulation through surrogate objects.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979033">Paper Link</a>    Pages:627-636</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kwon:Bum_Chul">Bum Chul Kwon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Javed:Waqas">Waqas Javed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Elmqvist:Niklas">Niklas Elmqvist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yi:Ji_Soo">Ji Soo Yi</a></p>
<p>Abstract:
Direct manipulation has had major influence on interface design since it was proposed by Shneiderman in 1982. Although directness generally benefits users, direct manipulation also has weaknesses. In some cases, such as when a user needs to manipulate small, attribute-rich objects or multiple objects simultaneously, indirect manipulation may be more efficient at the cost of directness or intuitiveness of the interaction. Several techniques have been developed over the years to address these issues, but these are all isolated and limited efforts with no coherent underlying principle. We propose the notion of Surrogate Interaction that ties together a large subset of these techniques through the use of a surrogate object that allow users to interact with the surrogate instead of the domain object. We believe that formalizing this family of interaction techniques will provide an additional and powerful interface design alternative for interaction designers, as well as uncover opportunities for future research.</p>
<p>Keywords:
design; direct manipulation; instrumental interaction</p>
<h3 id="73. An actuated physical puppet as an input device for controlling a digital manikin.">73. An actuated physical puppet as an input device for controlling a digital manikin.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979034">Paper Link</a>    Pages:637-646</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yoshizaki:Wataru">Wataru Yoshizaki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sugiura:Yuta">Yuta Sugiura</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chiou:Albert_C=">Albert C. Chiou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hashimoto:Sunao">Sunao Hashimoto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Inami:Masahiko">Masahiko Inami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Igarashi:Takeo">Takeo Igarashi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Akazawa:Yoshiaki">Yoshiaki Akazawa</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kawachi:Katsuaki">Katsuaki Kawachi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kagami:Satoshi">Satoshi Kagami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mochimaru:Masaaki">Masaaki Mochimaru</a></p>
<p>Abstract:
We present an actuated handheld puppet system for controlling the posture of a virtual character. Physical puppet devices have been used in the past to intuitively control character posture. In our research, an actuator is added to each joint of such an input device to provide physical feedback to the user. This enhancement offers many benefits. First, the user can upload pre-defined postures to the device to save time. Second, the system is capable of dynamically adjusting joint stiffness to counteract gravity, while allowing control to be maintained with relatively little force. Third, the system supports natural human body behaviors, such as whole-body reaching and joint coupling. This paper describes the user interface and implementation of the proposed technique and reports the results of expert evaluation. We also conducted two user studies to evaluate the effectiveness of our method.</p>
<p>Keywords:
force feedback; input device; posture; robot</p>
<h3 id="74. Roboshop: multi-layered sketching interface for robot housework assignment and management.">74. Roboshop: multi-layered sketching interface for robot housework assignment and management.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979035">Paper Link</a>    Pages:647-656</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Kexi">Kexi Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sakamoto:Daisuke">Daisuke Sakamoto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Inami:Masahiko">Masahiko Inami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Igarashi:Takeo">Takeo Igarashi</a></p>
<p>Abstract:
As various home robots come into homes, the need for efficient robot task management tools is arising. Current tools are designed for controlling individual robots independently, so they are not ideally suitable for assigning coordinated action among multiple robots. To address this problem, we developed a management tool for home robots with a graphical editing interface. The user assigns instructions by selecting a tool from a toolbox and sketching on a bird's-eye view of the environment. Layering supports the management of multiple tasks in the same room. Layered graphical representation gives a quick overview of and access to rich information tied to the physical environment. This paper describes the prototype system and reports on our evaluation of the system.</p>
<p>Keywords:
graphical user interface; home robots; housework management; human-robot interaction; sketching interface</p>
<h2 id="Tagging    3">Tagging    3</h2>
<h3 id="75. Examining the impact of collaborative tagging on sensemaking in nutrition management.">75. Examining the impact of collaborative tagging on sensemaking in nutrition management.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979037">Paper Link</a>    Pages:657-666</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mamykina:Lena">Lena Mamykina</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Andrew_D=">Andrew D. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grevet:Catherine">Catherine Grevet</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Medynskiy:Yevgeniy">Yevgeniy Medynskiy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Terry:Michael_A=">Michael A. Terry</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mynatt:Elizabeth_D=">Elizabeth D. Mynatt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davidson:Patricia_G=">Patricia G. Davidson</a></p>
<p>Abstract:
Collaborative tagging mechanisms are integral to social computing applications in a variety of domains. Their expected benefits include simplified retrieval of digital content, as well as enhanced ability of a community to makes sense of the shared content. We examine the impact of collaborative tagging in context of nutrition management. In a controlled experiment we asked individuals to assess the nutritional value of meals based on photographic images and observed the impact of different types of tags and tagging mechanisms on individuals nutritional sensemaking. The results of the study show that tags enhance individuals' ability to remember the viewed meals. However, we found that some types of tags can be detrimental to sensemaking, rather than supporting it. These findings stress the importance of tagging vocabularies and suggest a need for expert moderation of community sensemaking.</p>
<p>Keywords:
collaborative tagging; collective sensemaking; nutrition; wellness</p>
<h3 id="76. Using tags to encourage reflection and annotation on data during nomadic inquiry.">76. Using tags to encourage reflection and annotation on data during nomadic inquiry.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979038">Paper Link</a>    Pages:667-670</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kuhn:Alex">Alex Kuhn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cahill:Clara">Clara Cahill</a> ; <a href="http://dblp.uni-trier.de/pers/hd/q/Quintana:Chris">Chris Quintana</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmoll:Shannon">Shannon Schmoll</a></p>
<p>Abstract:
Nomadic inquiry may benefit from tagging when used for educational purposes to support reflection and annotation during data collection. To that end we created Zydeco, a mobile system to scaffold learners through the science inquiry process in and out of the classroom, and tested it in a museum with 42 middle school students. Students report that tags encouraged reflection and annotation during data collection, suggesting that tagging can be used to support nomadic inquiry. From this work we present some emerging design recommendations for constructing similar systems.</p>
<p>Keywords:
learner-centered design; mobile computing; mobile learning; nomadic inquiry; scaffolding; tagging</p>
<h3 id="77. User perceptions of the role and value of tags.">77. User perceptions of the role and value of tags.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979039">Paper Link</a>    Pages:671-674</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Yong=Mi">Yong-Mi Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rieh:Soo_Young">Soo Young Rieh</a></p>
<p>Abstract:
This study investigates user ideas about the role and value of tags in social media. An analysis of 45 interviews with heavy Web users reveals that user perceptions of tags differ from common assumptions held by researchers and designers of social tagging systems. Among beliefs held by participants were that tags were query suggestions or links to other pages, sites, or advertisements - although most identified tags as categories or keywords - and that tags were generated automatically by the computer system. Several participants believed that tags were intended for not only other users but also systems such as search engines. Our findings indicate that Web users, including those who are taggers themselves, experience a high level of uncertainty and confusion about the nature, purpose and value of tags.</p>
<p>Keywords:
social tagging; tags; user perceptions; value of tags</p>
<h2 id="HCI for all    4">HCI for all    4</h2>
<h3 id="78. Towards a feminist HCI methodology: social science, feminism, and HCI.">78. Towards a feminist HCI methodology: social science, feminism, and HCI.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979041">Paper Link</a>    Pages:675-684</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Shaowen">Shaowen Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Jeffrey">Jeffrey Bardzell</a></p>
<p>Abstract:
With substantial efforts in ubiquitous computing, ICT4D, and sustainable interaction design, among others, HCI is increasingly engaging with matters of social change that go beyond the immediate qualities of interaction. In doing so, HCI takes on scientific and moral concerns. This paper explores the potential for feminist social science to contribute to and potentially benefit from HCI's rising interest in social change. It describes how feminist contributions to debates in the philosophy of science have helped clarify relationships among objectivity, values, data collection and interpretation, and social consequences. Feminists have proposed and implemented strategies to pursue scientific and moral agendas together and with equal rigor. In this paper, we assess the epistemologies, methodologies, and methods of feminist social science relative to prior and ongoing research efforts in HCI. We conclude by proposing an outline of a feminist HCI methodology.</p>
<p>Keywords:
design; feminism; feminist hci; methodology; philosophy of science; post-positivism; theory; user research</p>
<h3 id="79. Out there.">79. Out there.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979042">Paper Link</a>    Pages:685-694</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Alex_S=">Alex S. Taylor</a></p>
<p>Abstract:
"Out there" is increasingly becoming a topic of concern in HCI. Thanks to various clarion calls, researchers in the field are turning their attention to technology-mediated activities that are shaped less by Euro-American sensibilities and defined more by how they are culturally and geographically distinct. Fieldwork and ethnography researchers, for instance, are beginning to investigate ICT use at religious and spiritual sites, by the socially excluded and disenfranchised, and by people in developing regions. In this paper, I concentrate on the latter focus on development to reflect on HCI's disciplinary turn "out there". Specifically, I take the following three themes as common rhetorical devices in such work: (i) the network, (ii) difference and (iii) complexity. Through examples, I discuss how each of these themes has been mobilised. I then use materials from anthropology, science and technology studies, and to a lesser extent geography and postcolonial studies to complicate and in some cases question the interpretative frames that are being applied. Thus, my hope is that this paper is seen as a thought piece that deepens our thinking around HCI's efforts to look "out there" by paying critical attention to what is going on "in here".</p>
<p>Keywords:
ICT4D; anthropology; development; ethnography; fieldwork; networks; postcolonialism.</p>
<h3 id="80. How HCI talks about sexuality: discursive strategies, blind spots, and opportunities for future research.">80. How HCI talks about sexuality: discursive strategies, blind spots, and opportunities for future research.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979043">Paper Link</a>    Pages:695-704</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kannabiran:Gopinaath">Gopinaath Kannabiran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Jeffrey">Jeffrey Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Shaowen">Shaowen Bardzell</a></p>
<p>Abstract:
The topic of sexuality has been increasingly researched inside the field of HCI. At the same time, and for many reasons, research gaps remain. In this paper, we present a critical analysis of 70 works on this topic spanning the past two decades to understand how we as an academic field talk about sexuality. We use Foucauldian discourse analysis to identify and analyze the various rules of knowledge production on this topic inside our field. By doing so, we expose not only existing gaps in current research literature, but we also gain an understanding of why some of them exist. We suggest some opportunities to make the field more amenable to this kind of research and point out future research directions on sexuality inside the field of HCI.</p>
<p>Keywords:
critical HCI; discourse; eroticepistemology; foucault; gender; hci; intimacy; sexuality; shci</p>
<h3 id="81. In the shadow of misperception: assistive technology use and social interactions.">81. In the shadow of misperception: assistive technology use and social interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979044">Paper Link</a>    Pages:705-714</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shinohara:Kristen">Kristen Shinohara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a></p>
<p>Abstract:
Few research studies focus on how the use of assistive technologies is affected by social interaction among people. We present an interview study of 20 individuals to determine how assistive technology use is affected by social and professional contexts and interactions. We found that specific assistive devices sometimes marked their users as having disabilities; that functional access took priority over feeling self-conscious when using assistive technologies; and that two misperceptions pervaded assistive technology use: (1) that assistive devices could functionally eliminate a disability, and (2) that people with disabilities would be helpless without their devices. Our findings provide further evidence that accessibility should be built into mainstream technologies. When this is not feasible, assistive devices should incorporate cutting edge technologies and strive to be designed for social acceptability, a new design approach we propose here.</p>
<p>Keywords:
accessibility; assistive devices; interface design; product design; social interactions; stigma</p>
<h2 id="Emotional states    5">Emotional states    5</h2>
<h3 id="82. Identifying emotional states using keystroke dynamics.">82. Identifying emotional states using keystroke dynamics.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979046">Paper Link</a>    Pages:715-724</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Epp:Clayton">Clayton Epp</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lippold:Michael">Michael Lippold</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a></p>
<p>Abstract:
The ability to recognize emotions is an important part of building intelligent computers. Emotionally-aware systems would have a rich context from which to make appropriate decisions about how to interact with the user or adapt their system response. There are two main problems with current system approaches for identifying emotions that limit their applicability: they can be invasive and can require costly equipment. Our solution is to determine user emotion by analyzing the rhythm of their typing patterns on a standard keyboard. We conducted a field study where we collected participants' keystrokes and their emotional states via self-reports. From this data, we extracted keystroke features, and created classifiers for 15 emotional states. Our top results include 2-level classifiers for confidence, hesitance, nervousness, relaxation, sadness, and tiredness with accuracies ranging from 77 to 88%. In addition, we show promise for anger and excitement, with accuracies of 84%.</p>
<p>Keywords:
affective computing; emotion sensing; keystroke dynamics</p>
<h3 id="83. PAM: a photographic affect meter for frequent, in situ measurement of affect.">83. PAM: a photographic affect meter for frequent, in situ measurement of affect.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979047">Paper Link</a>    Pages:725-734</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pollak:John_P=">John P. Pollak</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Adams:Phil">Phil Adams</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gay:Geri">Geri Gay</a></p>
<p>Abstract:
The assessment of emotion, or affect, is critical for anyone trying to understand human behavior. But there is a problem: affect as a state is frequently changing and difficult to recall and express, yet in research, we typically only assess it via a single questionnaire at the end of a study. This work presents PAM, the Photographic Affect Meter, a novel tool for measuring affect in which users select from a wide variety of photos the one which best suits their current mood. Our findings indicate that PAM-which takes seconds to complete and is designed to run on modern mobile phones and mobile computing devices-demonstrates strong construct validity across two studies and is very well suited for frequent sampling in context. This work provides a tool to researchers in need of frequent assessment of affect and guidance to others interested in developing similar measurement tools.</p>
<p>Keywords:
affect; emotion; health; measurement of affect; mobile computing</p>
<h3 id="84. Affective computational priming and creativity.">84. Affective computational priming and creativity.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979048">Paper Link</a>    Pages:735-744</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lewis:Sheena">Sheena Lewis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dontcheva:Mira">Mira Dontcheva</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gerber:Elizabeth">Elizabeth Gerber</a></p>
<p>Abstract:
While studies have shown that affect influences creativity, few investigate how affect influences creative performance with creativity support tools. Drawing from methods commonly used in psychology research, we present affective computational priming, a new method for manipulating affect using digitally embedded stimuli. We present two studies that explore computational techniques for inducing positive, neutral, and negative affect and examine their impact on idea generation with creativity support tools. Our results suggest that positive affective computational priming positively influences the quality of ideas generated. We discuss opportunities for future HCI research and offer practical applications of affective computational priming.</p>
<p>Keywords:
computational primes; creativity support tools; design</p>
<h3 id="85. Upset now?: emotion contagion in distributed groups.">85. Upset now?: emotion contagion in distributed groups.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979049">Paper Link</a>    Pages:745-748</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Guillory:Jamie">Jamie Guillory</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Spiegel:Jason">Jason Spiegel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Drislane:Molly">Molly Drislane</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weiss_0005:Benjamin">Benjamin Weiss</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Donner:Walter">Walter Donner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hancock:Jeffrey_T=">Jeffrey T. Hancock</a></p>
<p>Abstract:
The importance of emotion to group outcomes in FtF highlights the need to understand emotion contagion in distributed groups. The present study examines the transfer of negative emotion in online groups. Negative emotion was induced in one of three group members completing a task in CMC. The data suggest that emotion contagion took place at the group level, with partners experiencing more negative emotion, more disagreement, higher verbosity, and use of more complex language in induced groups compared to control groups. Induced groups also performed better on the group task, raising questions about the effects of negative emotion contagion in online groups.</p>
<p>Keywords:
affect; computer-mediated communication; emotion; group</p>
<h3 id="86. Emotion regulation for frustrating driving contexts.">86. Emotion regulation for frustrating driving contexts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979050">Paper Link</a>    Pages:749-752</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harris:Helen">Helen Harris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nass:Clifford">Clifford Nass</a></p>
<p>Abstract:
Driving is a challenging task because of the physical, attentional, and emotional demands. When drivers become frustrated by events their negative emotional state can escalate dangerously. This study examines behavioral and attitudinal effects of cognitively reframing frustrating events. Participants (N = 36) were asked to navigate a challenging driving course that included frustrating events such as long lights and being cut-off. Drivers were randomly assigned to three conditions. After encountering a frustrating event, drivers in a reappraisal-down condition heard voice prompts that reappraised the event in an effort to deflate negative reactions. Drivers in the second group, reappraisal-up, heard voice prompts that brought attention to the negative actions of vehicles and pedestrians. Drivers in a silent condition drove without hearing any voice prompts. Participants in the reappraisal-down condition had better driving behavior and reported less negative emotions than participants in the other conditions.</p>
<p>Keywords:
emotion regulation; in-car interfaces; voice interfaces</p>
<h2 id="Identity & virtual social interactions    5">Identity &amp; virtual social interactions    5</h2>
<h3 id="87. Introverted elves & conscientious gnomes: the expression of personality in world of warcraft.">87. Introverted elves &amp; conscientious gnomes: the expression of personality in world of warcraft.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979052">Paper Link</a>    Pages:753-762</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yee:Nick">Nick Yee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Ducheneaut:Nicolas">Nicolas Ducheneaut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nelson:Les">Les Nelson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Likarish:Peter">Peter Likarish</a></p>
<p>Abstract:
Personality inference can be used for dynamic personalization of content or system customization. In this study, we examined whether and how personality is expressed in Virtual Worlds (VWs). Survey data from 1,040 World of Warcraft players containing demographic and personality variables was paired with their VW behavioral metrics over a four-month period. Many behavioral cues in VWs were found to be related to personality. For example, Extraverts prefer group activities over solo activities. We also found that these behavioral indicators can be used to infer a player's personality.</p>
<p>Keywords:
big 5; inference; online games; personality; virtual worlds</p>
<h3 id="88. Starcraft from the stands: understanding the game spectator.">88. Starcraft from the stands: understanding the game spectator.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979053">Paper Link</a>    Pages:763-772</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cheung:Gifford">Gifford Cheung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang_0002:Jeff">Jeff Huang</a></p>
<p>Abstract:
Video games are primarily designed for the players. However, video game spectating is also a popular activity, boosted by the rise of online video sites and major gaming tournaments. In this paper, we focus on the spectator, who is emerging as an important stakeholder in video games. Our study focuses on Starcraft, a popular real-time strategy game with millions of spectators and high level tournament play. We have collected over a hundred stories of the Starcraft spectator from online sources, aiming for as diverse a group as possible. We make three contributions using this data: i) we find nine personas in the data that tell us who the spectators are and why they spectate; ii) we strive to understand how different stakeholders, like commentators, players, crowds, and game designers, affect the spectator experience; and iii) we infer from the spectators' expressions what makes the game entertaining to watch, forming a theory of distinct types of information asymmetry that create suspense for the spectator. One design implication derived from these findings is that, rather than presenting as much information to the spectator as possible, it is more important for the stakeholders to be able to decide how and when they uncover that information.</p>
<p>Keywords:
spectators; starcraft; video games</p>
<h3 id="89. Do men heal more when in drag?: conflicting identity cues between user and avatar.">89. Do men heal more when in drag?: conflicting identity cues between user and avatar.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979054">Paper Link</a>    Pages:773-776</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yee:Nick">Nick Yee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Ducheneaut:Nicolas">Nicolas Ducheneaut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yao:Mike">Mike Yao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nelson:Les">Les Nelson</a></p>
<p>Abstract:
Studies in the Proteus Effect have shown that users conform to stereotypes associated with their avatar's appearance. In this study, we used longitudinal behavioral data from 1,040 users in a virtual world to examine the behavioral outcome of conflicting gender cues between user and avatar. We found that virtual gender had a significant effect on in-game behaviors for both healing and player-vs-player activity.</p>
<p>Keywords:
avatar; gender; identity; proteus effect; stereotypes</p>
<h3 id="90. Is the media equation a flash in the pan?: the durability and longevity of social responses to computers.">90. Is the media equation a flash in the pan?: the durability and longevity of social responses to computers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979055">Paper Link</a>    Pages:777-780</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pfeifer:Laura_M=">Laura M. Pfeifer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bickmore:Timothy_W=">Timothy W. Bickmore</a></p>
<p>Abstract:
Research on social responses to computers often assesses only first-impression reactions during a single experimental session, providing limited knowledge about the lasting effect of the results. In this work, we assess the lasting strength of social desirability bias effects on an interface designed to track exercise, manipulated to have high or low personalization (text vs. anthropomorphic conversational character). After 40 days of daily interactions by 25 participants, we found that self-reported exercise was more accurate when reported to the character vs. text. We also find that, for both conditions, participants' decision to initiate a session is greater when they have done more exercise. Moreover, we show that this effect significantly increases over time for participants in the character condition, and decreases for participants in the text condition. This study demonstrates that Media Equation effects can grow stronger or weaker over time, depending upon the presentation of the interface.</p>
<p>Keywords:
longitudinal studies; media equation; self-report</p>
<h3 id="91. What drives customization?: control or identity?">91. What drives customization?: control or identity?</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979056">Paper Link</a>    Pages:781-790</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marathe:Sampada">Sampada Marathe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sundar:S=_Shyam">S. Shyam Sundar</a></p>
<p>Abstract:
Customization - an attribute that lets users take control and make changes to the presentation and functionality of the interface - is becoming a hallmark of today's interactive media devices. What do users experience when they change interface aspects like fonts and colors, skins on mobile phones, speed dial numbers, privacy settings on social networks and different command menus in software? Do they feel in control? Do they see the customized interface as a reflection of who they are? More importantly, is the feeling of being in control a major driver of usage, or does sense of identity - a personal connection with the interface - prove more vital? This paper discusses the psychology of customization, reports an empirical user study designed to explore the relationship between customization, sense of control, and sense of identity, and outlines implications for design of customizable interfaces based on the findings.</p>
<p>Keywords:
customization; sense of control; sense of identity; user experience</p>
<h2 id="Gestures, body & touch    5">Gestures, body &amp; touch    5</h2>
<h3 id="92. Your noise is my command: sensing gestures using the body as an antenna.">92. Your noise is my command: sensing gestures using the body as an antenna.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979058">Paper Link</a>    Pages:791-800</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cohn:Gabe">Gabe Cohn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris_0001:Daniel">Daniel Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Patel:Shwetak_N=">Shwetak N. Patel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tan:Desney_S=">Desney S. Tan</a></p>
<p>Abstract:
Touch sensing and computer vision have made human-computer interaction possible in environments where keyboards, mice, or other handheld implements are not available or desirable. However, the high cost of instrumenting environments limits the ubiquity of these technologies, particularly in home scenarios where cost constraints dominate installation decisions. Fortunately, home environments frequently offer a signal that is unique to locations and objects within the home: electromagnetic noise. In this work, we use the body as a receiving antenna and leverage this noise for gestural interaction. We demonstrate that it is possible to robustly recognize touched locations on an uninstrumented home wall using no specialized sensors. We conduct a series of experiments to explore the capabilities that this new sensing modality may offer. Specifically, we show robust classification of gestures such as the position of discrete touches around light switches, the particular light switch being touched, which appliances are touched, differentiation between hands, as well as continuous proximity of hand to the switch, among others. We close by discussing opportunities, limitations, and future work.</p>
<p>Keywords:
electrical noise; input; surface interaction; touch interaction</p>
<h3 id="93. Sensor synaesthesia: touch in motion, and motion in touch.">93. Sensor synaesthesia: touch in motion, and motion in touch.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979059">Paper Link</a>    Pages:801-810</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hinckley:Ken">Ken Hinckley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Song:Hyunyoung">Hyunyoung Song</a></p>
<p>Abstract:
We explore techniques for hand-held devices that leverage the multimodal combination of touch and motion. Hybrid touch + motion gestures exhibit interaction properties that combine the strengths of multi-touch with those of motion-sensing. This affords touch-enhanced motion gestures, such as one-handed zooming by holding one's thumb on the screen while tilting a device. We also consider the reverse perspective, that of motion-enhanced touch, which uses motion sensors to probe what happens underneath the surface of touch. Touching the screen induces secondary accelerations and angular velocities in the sensors. For example, our prototype uses motion sensors to distinguish gently swiping a finger on the screen from 'Sdrags with a hard onset' - to enable more expressive touch interactions.</p>
<p>Keywords:
gestures; mobile devices; motion-sensing; multimodal input; sensors; touch</p>
<h3 id="94. Data miming: inferring spatial object descriptions from human gesture.">94. Data miming: inferring spatial object descriptions from human gesture.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979060">Paper Link</a>    Pages:811-820</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Holz:Christian">Christian Holz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wilson:Andrew">Andrew Wilson</a></p>
<p>Abstract:
Speakers often use hand gestures when talking about or describing physical objects. Such gesture is particularly useful when the speaker is conveying distinctions of shape that are difficult to describe verbally. We present data miming---an approach to making sense of gestures as they are used to describe concrete physical objects. We first observe participants as they use gestures to describe real-world objects to another person. From these observations, we derive the data miming approach, which is based on a voxel representation of the space traced by the speaker's hands over the duration of the gesture. In a final proof-of-concept study, we demonstrate a prototype implementation of matching the input voxel representation to select among a database of known physical objects.</p>
<p>Keywords:
3D modeling; depth camera; gestures; object retrieval; shape descriptions</p>
<h3 id="95. Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces.">95. Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979061">Paper Link</a>    Pages:821-824</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Grandhi:Sukeshini_A=">Sukeshini A. Grandhi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Joue:Gina">Gina Joue</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mittelberg:Irene">Irene Mittelberg</a></p>
<p>Abstract:
This paper explores how interaction with systems using touchless gestures can be made intuitive and natural. Analysis of 912 video clips of gesture production from a user study of 16 subjects communicating transitive actions (manipulation of objects with or without external tools) indicated that 1) dynamic pantomimic gestures where imagined tool/object is explicitly held are performed more intuitively and easily than gestures where a body part is used to represent the tool/object or compared to static hand poses and 2) gesturing while communicating the transitive action as how the user habitually performs the action (pantomimic action) is perceived to be easier and more natural than gesturing while communicating it as an instruction. These findings provide guidelines for the characteristics of gestures and user mental models one must consciously be concerned with when designing and implementing gesture vocabularies of touchless interaction.</p>
<p>Keywords:
cognitive semiotic principles; embodiment; gestures; intuitiveness; metonymy; naturalness; user centric interaction design</p>
<h3 id="96. The impact on musculoskeletal system during multitouch tablet interactions.">96. The impact on musculoskeletal system during multitouch tablet interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979062">Paper Link</a>    Pages:825-828</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lozano:Cecil">Cecil Lozano</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jindrich:Devin_L=">Devin L. Jindrich</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kahol:Kanav">Kanav Kahol</a></p>
<p>Abstract:
HCI researchers and technologists have heralded multitouch interaction as the technology to drive computing systems into the future. However, as we move towards a world where interaction is based on human body movements that are not well documented or studied, we face a serious and a grave risk of creating technology and systems that may lead to musculoskeletal disorders (MSD's). Designers need to be empowered with objective data on the impact of multitouch interactions on the musculoskeletal system to make informed choices in interaction design. In this paper we present an experiment that documents kinematic (movement) and kinetic measures (EMG) when interacting with a multitouch tablet. Results show that multitouch interaction can induce significant stress that may lead to MSDs and care must be taken when designing multitouch interaction.</p>
<p>Keywords:
ergonomic multitouch tablet interfaces</p>
<h2 id="Pointing 1    5">Pointing 1    5</h2>
<h3 id="97. TorusDesktop: pointing via the backdoor is sometimes shorter.">97. TorusDesktop: pointing via the backdoor is sometimes shorter.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979064">Paper Link</a>    Pages:829-838</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huot:St=eacute=phane">Stphane Huot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chapuis:Olivier">Olivier Chapuis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dragicevic:Pierre">Pierre Dragicevic</a></p>
<p>Abstract:
When pointing to a target on a computer desktop, we may think we are taking the shortest possible path. But new shortcuts become possible if we allow the mouse cursor to jump from one edge of the screen to the opposite one, i.e., if we turn the desktop into a torus. We discuss the design of TORUSDESKTOP, a pointing technique that allows to wrap the cursor around screen edges to open this pointing backdoor. A dead zone and an off-screen cursor feedback make the technique more usable and more compatible with everyday desktop usage. We report on three controlled experiments conducted to refine the design of the technique and evaluate its performance. The results suggest clear benefits of using the backdoor when target distance is more than 80% the screen size in our experimental conditions.</p>
<p>Keywords:
cursor wrapping; pointing technique; torus</p>
<h3 id="98. Comet and target ghost: techniques for selecting moving targets.">98. Comet and target ghost: techniques for selecting moving targets.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979065">Paper Link</a>    Pages:839-848</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hasan:Khalad">Khalad Hasan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Irani:Pourang">Pourang Irani</a></p>
<p>Abstract:
Numerous applications such as simulations, air traffic control systems, and video surveillance systems are inherently composed of spatial objects that move in a scene. In many instances, users can benefit from tools that allow them to select these targets in real-time, without having to pause the dynamic display. However, selecting moving objects is considerably more difficult and error prone than selecting stationary targets. In this paper, we evaluate the effectiveness of several techniques that assist in selecting moving targets. We present Comet, a technique that enhances targets based on their speed and direction. We also introduce Target Ghost, which allows users to select a static proxy of the target, while leaving the motion uninterrupted. We found a speed benefit for the Comet in a 1D selection task in comparison to other cursor and target enhancements. For 2D selection, Comet outperformed Bubble cursor but only when Target Ghost was not available. We conclude with guidelines for design.</p>
<p>Keywords:
comet; moving targets selection; target ghost</p>
<h3 id="99. Acquiring and pointing: an empirical study of pen-tilt-based interaction.">99. Acquiring and pointing: an empirical study of pen-tilt-based interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979066">Paper Link</a>    Pages:849-858</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/x/Xin:Yizhong">Yizhong Xin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bi:Xiaojun">Xiaojun Bi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ren:Xiangshi">Xiangshi Ren</a></p>
<p>Abstract:
Research literature has shown that pen tilt is a promising input modality in pen-based interaction. However, the human capability to control pen tilt has not been fully evaluated. This paper systematically investigates the human ability to perform discrete target selection tasks by varying the stylus' tilt angle through two controlled experiments: pen tilt target acquiring (Experiment 1) and tilt pointing (Experiment 2). Results revealed a decreasing power relationship between angular width and selection time in Experiment 1. The results of Experiment 2 confirmed that pen tilt pointing can be modeled by Fitts' law. Based on our quantitative analysis, we discuss the human ability to control pen tilt and the implications of pen tilt use. We also propose a taxonomy of pen tilt based interaction techniques and showcase a series of possible pen tilt technique designs.</p>
<p>Keywords:
human ability; pen tilt input; pen tilt techniques; pen-based interfaces</p>
<h3 id="100. On the costs of multiple trajectory pointing methods.">100. On the costs of multiple trajectory pointing methods.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979067">Paper Link</a>    Pages:859-862</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/q/Quinn:Philip">Philip Quinn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/R=auml=ih=auml=:Kari=Jouko">Kari-Jouko Rih</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Delamarche:J=eacute=r=ocirc=me">Jrme Delamarche</a></p>
<p>Abstract:
Several enhanced pointing techniques aim to reduce the Fitts' law targeting distance by providing multiple target trajectories in the hope that a shorter path is available. However, these techniques introduce a search or decision component to pointing users must examine the alternatives available and decide upon the trajectory to use. We analyse these difficulties, present a methodology for examining them as well as other behaviour issues, and report empirical results of performance with pointer wrapping and Ninja cursors. Results show that offering multiple trajectories incurs a significant search or decision cost, and that users are therefore poor at capitalising on the theoretical benefits of reduced target distance.</p>
<p>Keywords:
fitt's law; multiple trajectories; ninja cursors; pointing; search/decision; wrapping cursors</p>
<h3 id="101. Cursor relocation techniques to help older adults find 'lost' cursors.">101. Cursor relocation techniques to help older adults find 'lost' cursors.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979068">Paper Link</a>    Pages:863-866</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hollinworth:Nic">Nic Hollinworth</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hwang:Faustina">Faustina Hwang</a></p>
<p>Abstract:
Older adult computer users often lose track of the mouse cursor and so resort to methods such as mouse shaking or searching the screen to find the cursor again. Hence, this paper describes how a standard optical mouse was modified to include a touch sensor, activated by releasing and touching the mouse, which automatically centers the mouse cursor to the screen, potentially making it easier to find a 'lost' cursor. Six older adult computer users and six younger computer users were asked to compare the touch sensitive mouse with cursor centering with two alternative techniques for locating the mouse cursor: manually shaking the mouse and using the Windows sonar facility. The time taken to click on a target following a distractor task was recorded, and results show that centering the mouse was the fastest to use, with a 35% improvement over shaking the mouse. Five out of six older participants ranked the touch sensitive mouse with cursor centering as the easiest to use.</p>
<p>Keywords:
computer mouse; fieldmouse; mouse cursor; touch sensor</p>
<h2 id="Ambient & peripheral computing    4">Ambient &amp; peripheral computing    4</h2>
<h3 id="102. Enhancing interactional synchrony with an ambient display.">102. Enhancing interactional synchrony with an ambient display.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979070">Paper Link</a>    Pages:867-876</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Balaam:Madeline">Madeline Balaam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzpatrick:Geraldine">Geraldine Fitzpatrick</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Good:Judith">Judith Good</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harris:Eric_Charles">Eric Charles Harris</a></p>
<p>Abstract:
Nonverbal communication is an essential part of face-to-face social interaction, conveying information about emotion and interpersonal relationships. The rigorous sensing capabilities of pervasive technologies and the subtle nature of ambient technologies make them ideal to support the production of nonverbal communication in social interactions. In this paper we present a study using an ambient technology that supports nonverbal communication, and specifically nonverbal behaviours associated with rapport. We show that an ambient display can influence a participant's nonverbal behaviour, and that participants are not aware of this change in their behaviour. We discuss these findings in terms of the design and ethical issues that it raises, and define an agenda for future work.</p>
<p>Keywords:
ambient display; biofeedback monitor for social interaction; face-to-face interaction; interactional synchrony; rapport; social interaction</p>
<h3 id="103. Issues in evaluating ambient displays in the wild: two case studies.">103. Issues in evaluating ambient displays in the wild: two case studies.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979071">Paper Link</a>    Pages:877-886</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hazlewood:William_R=">William R. Hazlewood</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stolterman:Erik">Erik Stolterman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Connelly:Kay">Kay Connelly</a></p>
<p>Abstract:
In this paper we discus the complex task of evaluating ambient displays, concentrating on issues within in-situ deployments. We start by describing how these technologies have been evaluated in lab settings, where the focus has been primarily on issues of usability, and argue strongly for the necessity of in-situ evaluation. We then present two case studies involving in-situ evaluations, and from these derive issues that hindered the researchers from being able to delve more deeply into the overall impact of their implementations. We conclude with our own suggestions on possible alternatives to explore for evaluating ambient displays, which are based on the issues derived from our case studies.</p>
<p>Keywords:
ambient displays; case studies; evaluation studies; feedback; methods</p>
<h3 id="104. Does MoodyBoard make internet use more secure?: evaluating an ambient security visualization tool.">104. Does MoodyBoard make internet use more secure?: evaluating an ambient security visualization tool.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979072">Paper Link</a>    Pages:887-890</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Luca:Alexander_De">Alexander De Luca</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Frauendienst:Bernhard">Bernhard Frauendienst</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Maurer:Max=Emanuel">Max-Emanuel Maurer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Seifert:Julian">Julian Seifert</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hausen:Doris">Doris Hausen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kammerer:Niels">Niels Kammerer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hussmann:Heinrich">Heinrich Hussmann</a></p>
<p>Abstract:
Internet users are targets for ever-advancing phishing- and other attacks. The risks are, for example, to disclose credit card information or passwords to unauthorized instances. One approach to help users with insecure situations is provided by MoodyBoard, which uses ambient information to highlight potential risks. In this paper, we present findings from an evaluation of this system. Two user studies were conducted in order to find out whether an ambient security tool can protect users during sensitive tasks. We designed a pilot study to find out whether users understand the warnings and a security study to see if it helps to protect users from phishing attacks. Results show that MoodyBoard users behaved significantly more secure.</p>
<p>Keywords:
MoodyBoard; ambient visualization; awareness; security</p>
<h3 id="105. Peripheral computing during presentations: perspectives on costs and preferences.">105. Peripheral computing during presentations: perspectives on costs and preferences.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979073">Paper Link</a>    Pages:891-894</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/i/Iqbal:Shamsi_T=">Shamsi T. Iqbal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grudin:Jonathan">Jonathan Grudin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Horvitz:Eric">Eric Horvitz</a></p>
<p>Abstract:
Despite the common use of mobile computing devices to communicate and access information, the effects of peripheral computing tasks on people's attention is not well understood. Studies that have identified consequences of multitasking in diverse domains have largely focused on influences on productivity. We have yet to understand perceptions and preferences regarding the use of computing devices for potentially extraneous tasks in settings such as presentations at seminars and colloquia. We explore costs and attitudes about the use of computing devices by people attending presentations. We find that audience members who use devices believe that they are missing content being presented and are concerned about social costs. Other attendees report being less offended by multitasking around them than the device users may realize.</p>
<p>Keywords:
attention; laptops; multitasking; presentation</p>
<h2 id="Museums & public exhibitions    1">Museums &amp; public exhibitions    1</h2>
<h3 id="106. An exploratory study of input modalities for mobile devices used with museum exhibits.">106. An exploratory study of input modalities for mobile devices used with museum exhibits.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979075">Paper Link</a>    Pages:895-904</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pazmino:Priscilla_Jimenez">Priscilla Jimenez Pazmino</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lyons:Leilah">Leilah Lyons</a></p>
<p>Abstract:
New mobile device features and the growing proportion of visitors carrying mobiles allow the range of museum exhibit design possibilities to be expanded. In particular, we see opportunities for using mobiles to help exhibits scale up to support variable-sized groups of visitors, and to support collaborative visitor-visitor interactions. Because exhibit use is generally one-time-only, any interfaces created for these purposes must be easily learnable, or visitors may not use the exhibit at all. To guide the design of learnable mobile interfaces, we chose to employ the Consistency design principle. Consistency was originally applied to desktop UIs, so we extended the definition to cover three new categories of consistency relevant to ubiquitous computing: Within-Device Consistency, Across-Device Consistency and Within-Context Consistency. We experimentally contrasted designs created from these categories. The results show small differences in learnability, but illustrate that even for one-off situations learnability may not be as important as usability.</p>
<p>Keywords:
collaboration; mobile devices; museums; opportunistic user interface; ubiquitous computing</p>
<h2 id="Everyday information management    3">Everyday information management    3</h2>
<h3 id="107. "I lie to myself that i have freedom in my own schedule": productivity tools and experiences of busyness.">107. "I lie to myself that i have freedom in my own schedule": productivity tools and experiences of busyness.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979077">Paper Link</a>    Pages:905-914</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Leshed:Gilly">Gilly Leshed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sengers:Phoebe">Phoebe Sengers</a></p>
<p>Abstract:
This paper examines the relationship between experiences of busyness in everyday life and the use of productivity tools, including planners, calendars and to-do lists. Field study findings demonstrate that American individuals across a demographic range have internalized a cultural emphasis of busyness as a moral value to construct positive identities as busy individuals. At the same time, they struggle with a sense of conflict around busyness, reflected in real-life experiences of clashing priorities, fantasies of downtime, and struggles with anxiety, guilt, and loss of control. Our findings also point to the ways digital and non-digital productivity tools are embedded in experiences and coping practices around busyness. Grounded in our observations we propose design principles for productivity tools that support users' identities as busy people but also address some of the perils of the American busyness ethic.</p>
<p>Keywords:
busyness; productivity tools; qualitative field study</p>
<h3 id="108. Homebrew databases: complexities of everyday information management in nonprofit organizations.">108. Homebrew databases: complexities of everyday information management in nonprofit organizations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979078">Paper Link</a>    Pages:915-924</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Voida:Amy">Amy Voida</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harmon:Ellie">Ellie Harmon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Al=Ani:Ban">Ban Al-Ani</a></p>
<p>Abstract:
Many people manage a complex assortment of digital information in their lives. Volunteer coordinators at nonprofit organizations are no exception; they collectively manage information about millions of volunteers every year. Yet current information management systems are insufficient for their needs. In this paper, we present results of a qualitative study of the information management practices of volunteer coordinators. We identify the resource constraints and the diverse and fluid information needs, stakeholders, and work contexts that motivate their information management strategies. We characterize the assemblages of information systems that volunteer coordinators have created to satisfice their needs as 'homebrew databases.' Finally, we identify additional information management challenges that result from the use of these 'homebrew databases,' highlighting deficiencies in the appropriateness and usability of databases and information management systems, more generally.</p>
<p>Keywords:
NPO; homebrew databases; information management; nonprofit; volunteer coordination; volunteer management.</p>
<h3 id="109. How a freeform spatial interface supports simple problem solving tasks.">109. How a freeform spatial interface supports simple problem solving tasks.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979079">Paper Link</a>    Pages:925-934</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kandogan:Eser">Eser Kandogan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Juho">Juho Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moran:Thomas_P=">Thomas P. Moran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pedemonte:Pablo">Pablo Pedemonte</a></p>
<p>Abstract:
We developed DataBoard, a freeform spatial interface, to support users in simple problem solving tasks. To develop a deeper understanding of the role of space and the tradeoffs between freeform and structured interaction styles in problem solving tasks, we conducted a controlled user study comparing the DataBoard with a spreadsheet and analyzed video data in detail. Beyond improvements in task performance and memory recall, our observations reveal that freeform interfaces can support users in a variety of ways: representing problems flexibly, developing strategies, executing strategies incrementally, tracking problem state easily, reducing mental computation, and verifying solutions perceptually. The spreadsheet also had advantages, and we discuss the tradeoffs.</p>
<p>Keywords:
freeform interaction; problem solving; spatial interfaces; spreadsheets</p>
<h2 id="Low-cost ICT4D    3">Low-cost ICT4D    3</h2>
<h3 id="110. Utilizing multimedia capabilities of mobile phones to support teaching in schools in rural panama.">110. Utilizing multimedia capabilities of mobile phones to support teaching in schools in rural panama.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979081">Paper Link</a>    Pages:935-944</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Baham=oacute=ndez:Elba_del_Carmen_Valderrama">Elba del Carmen Valderrama Bahamndez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Winkler:Christian">Christian Winkler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
Providing good education is one of the major challenges for humanity. In many developing regions in the world improving educational standards is seen as a central building block for improving socio-economic situation of society. Based on our research in Panama we report on how mobile phones can be used as educational tools. In contrast to personal computers mobile phones are widely available and in Panama over 80% of the children have access to phones. We report on four different studies building on one another. We conducted surveys, focus groups, and group interviews with several hundred teachers and pupils to assess opportunities, needs, and threads for using phones in teaching and learning. Based on the feedback received we created a set of use cases and finally evaluated these in a field study in a rural multigrade school in Panama. Our findings suggest that current phones with multimedia capabilities provide a valuable resource for teaching and learning across many subjects. In particular recording of audio and video, programs for drawing, and taking photos were used in very creative and constructive ways beyond the use cases envisioned by us and initial skepticism of parents turned into support.</p>
<p>Keywords:
developing countries; education; learning; mobile phones</p>
<h3 id="111. Infrastructures for low-cost laptop use in Mexican schools.">111. Infrastructures for low-cost laptop use in Mexican schools.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979082">Paper Link</a>    Pages:945-954</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cervantes:Ruy">Ruy Cervantes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Warschauer:Mark">Mark Warschauer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nardi:Bonnie_A=">Bonnie A. Nardi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sambasivan:Nithya">Nithya Sambasivan</a></p>
<p>Abstract:
In recent years, a number of low-cost laptops have been created for children's education, most notably the XO, developed by One Laptop per Child to embody principles of constructionist learning, and the ClassmatePC, designed by Intel to fit within and improve traditional education. We report on a series of field studies in Mexican elementary schools that deployed the XO or ClassmatePC. Although both devices are promoted as valuable for improving education in developing countries, our studies suggest that creating the social and technical infrastructures needed to sustain school laptop use is far more complex than what technology designers assume.</p>
<p>Keywords:
classmatepc; developing countries; education; ict4d; infrastructures; low-cost laptops; mexico; olpc; xo</p>
<h3 id="112. Utilizing DVD players as low-cost offline internet browsers.">112. Utilizing DVD players as low-cost offline internet browsers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979083">Paper Link</a>    Pages:955-958</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Paruthi:Gaurav">Gaurav Paruthi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thies:William">William Thies</a></p>
<p>Abstract:
In the developing world, computers and Internet access remain rare. However, there are other devices that can be used to deliver information, including TVs and DVD players. In this paper, we work to bridge this gap by delivering offline Internet content on DVD, for interactive playback on ordinary DVD players. Using the remote control, users can accomplish all of the major functions available in a Web browser, including navigation, hyperlinks, and search. As our driving application, we map the entirety of schools-wikipedia.org - encompassing 5,500 articles and 259,000 screens - to a double-layer DVD. We evaluate our system via a study of 20 low-income users in Bangalore, India. Using our DVD as reference, participants are able to answer factual questions with over 90% success. While most participants prefer to use a computer if one is available, for resource-poor environments the DVD platform could represent a viable and low-cost alternative.</p>
<p>Keywords:
dvd players; educational technology; hci4d; ictd; india; wikipedia</p>
<h2 id="Predicting & modeling human behaviors    4">Predicting &amp; modeling human behaviors    4</h2>
<h3 id="113. Importance-driven compositing window management.">113. Importance-driven compositing window management.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979085">Paper Link</a>    Pages:959-968</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Waldner:Manuela">Manuela Waldner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steinberger:Markus">Markus Steinberger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grasset:Rapha=euml=l">Raphal Grasset</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmalstieg:Dieter">Dieter Schmalstieg</a></p>
<p>Abstract:
In this paper we present importance-driven compositing window management, which considers windows not only as basic rectangular shapes but also integrates the importance of the windows' content using a bottom-up visual attention model. Based on this information, importance-driven compositing optimizes the spatial window layout for maximum visibility and interactivity of occluded content in combination with see-through windows. We employ this technique for emerging window manager functions to minimize information overlap caused by popping up windows or floating toolbars and to improve the access to occluded window content. An initial user study indicates that our technique provides a more effective and satisfactory access to occluded information than the well-adopted Alt+Tab window switching technique and see-through windows without optimized spatial layout.</p>
<p>Keywords:
compositing window management; space management; transparency; visual saliency</p>
<h3 id="114. Content and hierarchy in pixel-based methods for reverse engineering interface structure.">114. Content and hierarchy in pixel-based methods for reverse engineering interface structure.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979086">Paper Link</a>    Pages:969-978</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dixon:Morgan">Morgan Dixon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Leventhal:Daniel">Daniel Leventhal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fogarty:James">James Fogarty</a></p>
<p>Abstract:
The rigidity and fragmentation of GUI toolkits are fundamentally limiting the progress and impact of interaction research. Pixel-based methods offer unique potential for addressing these challenges independent of the implementation of any particular interface or toolkit. This work builds upon Prefab, which enables the modification of existing interfaces. We present new methods for hierarchical models of complex widgets, real-time interpretation of interface content, and real-time interpretation of content and hierarchy throughout an entire interface. We validate our new methods through implementations of four applications: stencil-based tutorials, ephemeral adaptation, interface translation, and end-user interface customization. We demonstrate these enhancements in complex existing applications created from different user interface toolkits running on different operating systems.</p>
<p>Keywords:
content; hierarchy; pixel-based reverse engineering; prefab</p>
<h3 id="115. Client TouchPoint modeling: understanding client interactions in the context of service delivery.">115. Client TouchPoint modeling: understanding client interactions in the context of service delivery.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979087">Paper Link</a>    Pages:979-982</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Martin:Aqueasha_M=">Aqueasha M. Martin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rankin:Yolanda_A=">Yolanda A. Rankin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bolinger:Joe">Joe Bolinger</a></p>
<p>Abstract:
Service delivery organizations oftentimes overlook opportunities to cultivate client relationships due to a lack of awareness of the totality of touchpoints, or interactions, that occur between service delivery personnel and client personnel over time. To enable service delivery organizations to strategically manage their client relationships, we introduce the first phase of the Client TouchPoint Modeling (CTM) process in which service delivery teams create a touchpoint map of their collective interactions across a client account. Participatory design sessions with service delivery personnel informed the design of a CTM TouchPoint Map prototype. Through these sessions, we also discovered a more collaborative approach to CTM, one in which service delivery team members work together to co-construct a unified account map in a way that promotes team transparency and sensemaking of the service experience.</p>
<p>Keywords:
client TouchPoints; team situational awareness</p>
<h3 id="116. Using predictive human performance models to inspire and support UI design recommendations.">116. Using predictive human performance models to inspire and support UI design recommendations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979088">Paper Link</a>    Pages:983-986</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/John:Bonnie_E=">Bonnie E. John</a></p>
<p>Abstract:
Predictive human performance modeling has traditionally been used to make quantitative comparisons between alternative designs (e.g., task execution time for skilled users) instead of identifying UI problems or making design recommendations. This note investigates how reliably novice modelers can extract design recommendations from their models. Many HCI evaluation methods have been plagued by the "evaluator effect" [3], i.e., different people using the same method find different UI problems. Our data and analyses show that predictive human performance modeling is no exception. Novice modelers using CogTool [5] display a 34% Any-Two Agreement in their design recommendations, a result in the upper quartile of evaluator effect studies. However, because these recommendations are grounded in models, they may have more reliable impact on measurable performance than recommendations arising from less formal methods.</p>
<p>Keywords:
human performance modeling; ui evaluation methods</p>
<h2 id="Death & bereavement    3">Death &amp; bereavement    3</h2>
<h3 id="117. Matters of life and death: locating the end of life in lifespan-oriented hci research.">117. Matters of life and death: locating the end of life in lifespan-oriented hci research.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979090">Paper Link</a>    Pages:987-996</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Massimi:Michael">Michael Massimi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Odom:William">William Odom</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Banks:Richard">Richard Banks</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kirk:David_S=">David S. Kirk</a></p>
<p>Abstract:
Examining developmental periods of the human lifespan has been a useful tradition for focusing HCI research (e.g., technologies for children or the elderly). In this paper, we identify the end of life as another period of the human lifespan that merits consideration by technology designers and researchers. This paper maps out current and future research in HCI at the end of life by first describing how this area raises questions concerning materiality and artifacts, social identities, temporality and methodologies. Having provided a description of the richness of this area, we then frame it against HCI traditions and practices in an orientation we term the lifespan-oriented approach. This paper maps early efforts in end of life research, structures and suggests areas for continued work, and situates the end of life among existing areas of HCI research.</p>
<p>Keywords:
bereavement; death; dying; ethics; lifespan; materiality; storytelling; temporality</p>
<h3 id="118. I said your name in an empty room: grieving and continuing bonds on facebook.">118. I said your name in an empty room: grieving and continuing bonds on facebook.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979091">Paper Link</a>    Pages:997-1000</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Getty:Emily">Emily Getty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cobb:Jessica">Jessica Cobb</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gabeler:Meryl">Meryl Gabeler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nelson:Christine">Christine Nelson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weng:Ellis">Ellis Weng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hancock:Jeffrey_T=">Jeffrey T. Hancock</a></p>
<p>Abstract:
In response to the death of a close friend or relative, bereaved individuals can use technology as part of the grieving process. We present a study that analyzes the messages of the friends and family of the deceased to their Facebook profile before and after their passing. Our analysis reveals that mourners use profiles as a way to maintain a continuing bond with the deceased, as well as a way to accomplish specific front stage bereavement communication, such as sharing memories, expressing sorrow and providing social support. These observations may improve the design of social networking technologies so that they remain useful, sensitive tools for the bereaved.</p>
<p>Keywords:
death; dying; facebook; grief; grieving; language; memorialized; mourning; posts; thanatosensitivity</p>
<h3 id="119. Dealing with death in design: developing systems for the bereaved.">119. Dealing with death in design: developing systems for the bereaved.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979092">Paper Link</a>    Pages:1001-1010</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Massimi:Michael">Michael Massimi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baecker:Ronald_M=">Ronald M. Baecker</a></p>
<p>Abstract:
Increasingly, systems are being developed and used in ways that involve end of life issues such as death, dying, and bereavement. Yet design considerations and guidelines for technologists working in this sensitive area are not well-established. We therefore report on exploratory fieldwork consisting of focus groups, observations, and consultation with bereavement experts aimed at understanding how technology might be designed to support bereaved parents. From this fieldwork, we derive a set of considerations useful for researchers and designers developing systems that deal specifically with bereavement, and with the end of life more broadly. These considerations focus on interpersonal communication, new ways of being in the world, and materiality. We conclude with a distillation of these considerations into practical design guidelines for working in this area.</p>
<p>Keywords:
bereavement; death; design; dying; memory; social support; thanatosensitive design</p>
<h2 id="Non-flat Displays    4">Non-flat Displays    4</h2>
<h3 id="120. Touch input on curved surfaces.">120. Touch input on curved surfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979094">Paper Link</a>    Pages:1011-1020</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Roudaut:Anne">Anne Roudaut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pohl:Henning">Henning Pohl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baudisch:Patrick">Patrick Baudisch</a></p>
<p>Abstract:
Advances in sensing technology are currently bringing touch input to non-planar surfaces, ranging from spherical touch screens to prototypes the size and shape of a ping-pong ball. To help interface designers create usable interfaces on such devices, we determine how touch surface curvature affects targeting. We present a user study in which participants acquired targets on surfaces of different curvature and at locations of different slope. We find that surface convexity increases pointing accuracy, and in particular reduces the offset between the input point perceived by users and the input point sensed by the device. Concave surfaces, in contrast, are subject to larger error offsets. This is likely caused by how concave surfaces hug the user's finger, thus resulting in a larger contact area. The effect of slope on targeting, in contrast, is unexpected at first sight. Some targets located downhill from the user's perspective are subject to error offsets in the opposite direction from all others. This appears to be caused by participants acquiring these targets using a different finger posture that lets them monitor the position of their fingers more effectively.</p>
<p>Keywords:
curved; flexible; form factor; industrial design; non-planar; pointing; shape of device; targeting; touch</p>
<h3 id="121. Audience behavior around large interactive cylindrical screens.">121. Audience behavior around large interactive cylindrical screens.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979095">Paper Link</a>    Pages:1021-1030</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Beyer:Gilbert">Gilbert Beyer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alt:Florian">Florian Alt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller_0001:J=ouml=rg">Jrg Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Isakovic:Karsten">Karsten Isakovic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Klose:Stefan">Stefan Klose</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schiewe:Manuel">Manuel Schiewe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haulsen:Ivo">Ivo Haulsen</a></p>
<p>Abstract:
Non-planar screens, such as columns, have been a popular means for displaying information for a long time. In con-trast to traditional displays their digital counterparts are mainly flat and rectangular due to current technological constraints. However, we envision bendable displays to be available in the future, which will allow for creating new forms of displays with new properties. In this paper we ex-plore cylindrical displays as a possible form of such novel public displays. We present a prototype and report on a user study, comparing the influence of the display shape on user behavior and user experience between flat and cylindrical displays. The results indicate that people move more in the vicinity of cylindrical displays and that there is no longer a default position when it comes to interaction. As a result, such displays are especially suitable to keep people in motion and to support gesture-like interaction.</p>
<p>Keywords:
cylindrical screens; digital columns; display formats; interactive surfaces; non-planar screens; public displays</p>
<h3 id="122. Motionbeam: a metaphor for character interaction with handheld projectors.">122. Motionbeam: a metaphor for character interaction with handheld projectors.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979096">Paper Link</a>    Pages:1031-1040</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Willis:Karl_D=_D=">Karl D. D. Willis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Poupyrev:Ivan">Ivan Poupyrev</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shiratori:Takaaki">Takaaki Shiratori</a></p>
<p>Abstract:
We present the MotionBeam metaphor for character interaction with handheld projectors. Our work draws from the tradition of pre-cinema handheld projectors that use direct physical manipulation to control projected imagery. With our prototype system, users interact and control projected characters by moving and gesturing with the handheld projector itself. This creates a unified interaction style where input and output are tied together within a single device. We introduce a set of interaction principles and present prototype applications that provide clear examples of the MotionBeam metaphor in use. Finally we describe observations and insights from a preliminary user study with our system.</p>
<p>Keywords:
character; gesture; handheld projector; interaction metaphor; interaction techniques; movement; pico projector</p>
<h3 id="123. 3d projection on physical objects: design insights from five real life cases.">123. 3d projection on physical objects: design insights from five real life cases.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979097">Paper Link</a>    Pages:1041-1050</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dalsg=aring=rd:Peter">Peter Dalsgrd</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Halskov:Kim">Kim Halskov</a></p>
<p>Abstract:
3D projection on physical objects is a particular kind of Augmented Reality that augments a physical object by projecting digital content directly onto it, rather than by using a mediating device, such as a mobile phone or a head-mounted display. In this paper, we present five cases in which we have developed installations that employ 3D projection on physical objects. The installations have been developed in collaboration with external partners and have been put into use in real-life settings such as museums, exhibitions and interaction design laboratories. On the basis of these cases, we present and discuss three central design insights concerning new potentials for well-known 3D effects, dynamics between digital world and physical world, and relations between object, content and context.</p>
<p>Keywords:
3d; architecture; augmented reality; cultural heritage; design; exhibitions; projection; visual effects</p>
<h2 id="Design theory    2">Design theory    2</h2>
<h3 id="124. The new good: exploring the potential of philosophy of technology to contribute to human-computer interaction.">124. The new good: exploring the potential of philosophy of technology to contribute to human-computer interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979099">Paper Link</a>    Pages:1051-1060</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fallman:Daniel">Daniel Fallman</a></p>
<p>Abstract:
As a result of the increased interest in issues such as engagement, affection, and meaning, contemporary human-computer interaction (HCI) has increasingly come to examine the nature of interactions between artifacts, humans, and environments through concepts such as user experience and meaning. In the transition from usability metrics to user experience, what appears lacking is a more explicit characterization of what it is HCI now strives for as a discipline--i.e. what constitutes a 'good' user experience? Through a detailed look at two contemporary philosophies of technology--Albert Borgmann's notion of the device paradigm and Don Ihde's non-neutrality of technology-mediated experience--this paper seeks to explore the potential of the philosophy of technology to contribute new insights and provide well-grounded conceptual tools for coming to terms with what may become HCI's 'new good'.</p>
<p>Keywords:
IHDE; borgmann; design; device paradigm; non-neutral technology; philosophy; philosophy of technology; theory</p>
<h3 id="125. Understanding interaction design practices.">125. Understanding interaction design practices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979100">Paper Link</a>    Pages:1061-1070</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Goodman:Elizabeth">Elizabeth Goodman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stolterman:Erik">Erik Stolterman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wakkary:Ron">Ron Wakkary</a></p>
<p>Abstract:
There is an undesirable gap between HCI research aimed at influencing interaction design practice and the practitioners in question. To close this gap, we advocate a theoretical and methodological focus on the day-to-day, lived experience of designers. To date, this type of theory-generative, experientially oriented research has focused on the users of technologies, not the designers. In contrast, we propose that HCI researchers turn their attention to producing theories of interaction design practice that resonate with practitioners themselves. In part one of this paper, we describe the mismatch between HCI research and interaction design practices. Then we present vignettes from an observational study of commercial design practice to illustrate the issues at hand. In part two, we discuss methodological and theoretical changes in research practice that might support the goal of integrating HCI research with interaction design practices. We then discuss current research methods and theories to identify changes that might enlarge our view on practice. In part three, we elaborate on our theoretically minded agenda and a kind of ideal-type theory.</p>
<p>Keywords:
interaction design; practice; theory</p>
<h2 id="Microblogging behavior    5">Microblogging behavior    5</h2>
<h3 id="126. "Voluntweeters": self-organizing by digital volunteers in times of crisis.">126. "Voluntweeters": self-organizing by digital volunteers in times of crisis.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979102">Paper Link</a>    Pages:1071-1080</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Starbird:Kate">Kate Starbird</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Palen:Leysia">Leysia Palen</a></p>
<p>Abstract:
This empirical study of "digital volunteers" in the aftermath of the January 12, 2010 Haiti earthquake describes their behaviors and mechanisms of self-organizing in the information space of a microblogging environment, where collaborators were newly found and distributed across continents. The paper explores the motivations, resources, activities and products of digital volunteers. It describes how seemingly small features of the technical environment offered structure for self-organizing, while considering how the social-technical milieu enabled individual capacities and collective action. Using social theory about self-organizing, the research offers insight about features of coordination within a setting of massive interaction.</p>
<p>Keywords:
computer-mediated communication; crisis informatics; crowdsourcing; disaster; emergency; microblogging; organizing; risk communication; self-organizing; volunteers</p>
<h3 id="127. Social media ownership: using twitter as a window onto current attitudes and beliefs.">127. Social media ownership: using twitter as a window onto current attitudes and beliefs.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979103">Paper Link</a>    Pages:1081-1090</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Catherine_C=">Catherine C. Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shipman_III:Frank_M=">Frank M. Shipman III</a></p>
<p>Abstract:
Social media, by its very nature, introduces questions about ownership. Ownership comes into play most crucially when we investigate how social media is saved or archived; how it is reused; and whether it can be removed or deleted. We investigate these social media ownership issues using a Mechanical Turk survey of Twitter users; the survey uses open-ended questions and statements of belief about realistic Twitter-based scenarios to give us a window onto current attitudes and beliefs. Our findings reveal that respondents take a liberal attitude toward saving and storing the tweets that they encounter. More caution is exercised with republishing the material, and still more with sharing the material among friends and associates. Respondents approach removal of this type of lightweight social media most cautiously. The material's provenance and the respondents' relationship to the material (whether they are the author or subject) has considerable bearing on what they feel they can do with it.</p>
<p>Keywords:
information rights; reuse; social media; survey; twitter</p>
<h3 id="128. Fragile online relationship: a first look at unfollow dynamics in twitter.">128. Fragile online relationship: a first look at unfollow dynamics in twitter.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979104">Paper Link</a>    Pages:1091-1100</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kwak:Haewoon">Haewoon Kwak</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chun:Hyunwoo">Hyunwoo Chun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moon:Sue_B=">Sue B. Moon</a></p>
<p>Abstract:
We analyze the dynamics of the behavior known as 'unfollow' in Twitter. We collected daily snapshots of the online relationships of 1.2 million Korean-speaking users for 51 days as well as all of their tweets. We found that Twitter users frequently unfollow. We then discover the major factors, including the reciprocity of the relationships, the duration of a relationship, the followees' informativeness, and the overlap of the relationships, which affect the decision to unfollow. We conduct interview with 22 Korean respondents to supplement the quantitative results. They unfollowed those who left many tweets within a short time, created tweets about uninteresting topics, or tweeted about the mundane details of their lives. To the best of our knowledge, this work is the first systematic study of the unfollow behavior in Twitter.</p>
<p>Keywords:
computer-mediated communication; online relationship; twitter; unfollow</p>
<h3 id="129. The impact of network structure on breaking ties in online social networks: unfollowing on twitter.">129. The impact of network structure on breaking ties in online social networks: unfollowing on twitter.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979105">Paper Link</a>    Pages:1101-1104</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kivran=Swaine:Funda">Funda Kivran-Swaine</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Govindan:Priya">Priya Govindan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Naaman:Mor">Mor Naaman</a></p>
<p>Abstract:
We investigate the breaking of ties between individuals in the online social network of Twitter, a hugely popular social media service. Building on sociology concepts such as strength of ties, embeddedness, and status, we explore how network structure alone influences tie breaks - the common phenomena of an individual ceasing to "follow" another in Twitter's directed social network. We examine these relationships using a dataset of 245,586 Twitter "follow" edges, and the persistence of these edges after nine months. We show that structural properties of individuals and dyads at Time 1 have a significant effect on the existence of edges at Time 2, and connect these findings to the social theories that motivated the study.</p>
<p>Keywords:
social media; social networks; tie breaks; twitter</p>
<h3 id="130. Computing political preference among twitter followers.">130. Computing political preference among twitter followers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979106">Paper Link</a>    Pages:1105-1108</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Golbeck:Jennifer">Jennifer Golbeck</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hansen:Derek_L=">Derek L. Hansen</a></p>
<p>Abstract:
There is great interest in understanding media bias and political information seeking preferences. As many media outlets create online personas, we seek to automatically estimate the political preferences of their audience, rather than of the outlet itself. In this paper, we present a novel method for computing preference among an organization's Twitter followers. We present an application of this technique to estimate political preference of the audiences of U.S. media outlets. We also discuss how these results may be used and extended.</p>
<p>Keywords:
conservative; journalism; liberal; news; politics; twitter</p>
<h2 id="Inter-cultural interaction    5">Inter-cultural interaction    5</h2>
<h3 id="131. Online contribution practices in countries that engage in internet blocking and censorship.">131. Online contribution practices in countries that engage in internet blocking and censorship.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979108">Paper Link</a>    Pages:1109-1118</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shklovski:Irina">Irina Shklovski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kotamraju:Nalini">Nalini Kotamraju</a></p>
<p>Abstract:
In this article we describe people's online contribution practices in contexts in which the government actively blocks access to or censors the Internet. We argue that people experience blocking as confusing, as a motivation for self-censorship online, as a cause of impoverishment of available content and as a real threat of personal persecution. Challenging ideas of blocking as a monolithic, abstract policy, we discuss five strategies with which Internet users navigate blocking: self-censorship, cultivating technical savvy, reliance on social ties to relay blocked content, use of already blocked sites for content production as a form of protection and practiced transparency. We also discuss strategies that forum owners and blogging platform providers employ to deal with and to avoid blocking. We conclude by advocating for more research that acknowledges the complexity of the contexts in which all Internet users contribute to the Internet and social media.</p>
<p>Keywords:
blocking; contribution; ethnography; government; internet censorship; internet non-use; internet use; lurkers; motivation; online communities; social media</p>
<h3 id="132. Real-time collaborative editing behavior in USA and Japanese distributed teams.">132. Real-time collaborative editing behavior in USA and Japanese distributed teams.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979109">Paper Link</a>    Pages:1119-1128</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Scissors:Lauren_E=">Lauren E. Scissors</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shami:N=_Sadat">N. Sadat Shami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Ishihara:Tatsuya">Tatsuya Ishihara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rohall:Steven_L=">Steven L. Rohall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Saito:Shin">Shin Saito</a></p>
<p>Abstract:
While there are tools that allow distributed teams to collaboratively edit in real time, little work examines this practice among real teams doing real work. Even less is known about how teams from different countries make use of real-time collaborative editing tools. The current work highlights results from a qualitative user study of real-world Japanese and U.S. distributed work teams who used LiveDeck, a real-time slide editing and whiteboarding tool. Through the implementation of various novel features used as probes, differences in behavior and attitudes between team members were uncovered. Differences in the use of slide navigation options, anonymity features, and pop-up 'emotes' representing nonverbal gestures are discussed.</p>
<p>Keywords:
collaborative editing; computer-mediated communication; csouth carolinaw; cultural differences; distributed teams</p>
<h3 id="133. Cultural differences on visual self-presentation through social networking site profile images.">133. Cultural differences on visual self-presentation through social networking site profile images.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979110">Paper Link</a>    Pages:1129-1132</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Chen">Chen Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jiang:Gonglue">Gonglue Jiang</a></p>
<p>Abstract:
A profile image is one of the most important personal attributes on social networking sites (SNSs). The current study examines whether self-presentation on SNSs is related to national culture and how forms of self-presentation differ between American and Chinese users. We accomplish this by analyzing profile images on two social networking sites, Facebook in the US and Renren in China. Our findings indicate that self-presentation is sensitive to national culture: Chinese users are more likely to customize their profile images than Americans. Our study suggests that there is a need to design social networking website features that better support profile construction for international users.</p>
<p>Keywords:
cultural differences; profile images; self-presentation; social networking sites</p>
<h3 id="134. MonoTrans2: a new human computation system to support monolingual translation.">134. MonoTrans2: a new human computation system to support monolingual translation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979111">Paper Link</a>    Pages:1133-1136</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hu:Chang">Chang Hu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bederson:Benjamin_B=">Benjamin B. Bederson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Resnik:Philip">Philip Resnik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kronrod:Yakov">Yakov Kronrod</a></p>
<p>Abstract:
In this paper, we present MonoTrans2, a new user interface to support monolingual translation; that is, translation by people who speak only the source or target language, but not both. Compared to previous systems, MonoTrans2 supports multiple edits in parallel, and shorter tasks with less translation context. In an experiment translating children's books, we show that MonoTrans2 is able to substantially close the gap between machine translation and human bilingual translations. The percentage of sentences rated 5 out of 5 for fluency and adequacy by both bilingual evaluators in our study increased from 10% for Google Translate output to 68% for MonoTrans2.</p>
<p>Keywords:
crowd-sourcing; distributed human computation; human computation; machine translation; monolingual; translation; translation interface; wisdom of crowds</p>
<h3 id="135. Culture or fluency?: unpacking interactions between culture and communication medium.">135. Culture or fluency?: unpacking interactions between culture and communication medium.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979112">Paper Link</a>    Pages:1137-1140</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Setlock:Leslie_D=">Leslie D. Setlock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fussell:Susan_R=">Susan R. Fussell</a></p>
<p>Abstract:
In this paper we describe two studies intended to replicate earlier work comparing American and Chinese communication in a negotiation task using several different media. In the earlier studies, the participants all spoke in English, raising the question of whether differences in fluency rather than differences in cultural background explained the results. We replicated the earlier studies using materials translated into Chinese, a native Chinese-speaking experimenter, and native Chinese participants. Counts of Chinese characters in each media show nearly the identical pattern found in the earlier studies, suggesting that cultural differences in communication styles, rather than fluency, account for the earlier findings. We describe implications of this work for tools to support intercultural communication.</p>
<p>Keywords:
CMC; collaborative work; computer-mediated communication; cultural differences; intercultural collaboration</p>
<h2 id="Eye tracking    4">Eye tracking    4</h2>
<h3 id="136. Skim reading by satisficing: evidence from eye tracking.">136. Skim reading by satisficing: evidence from eye tracking.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979114">Paper Link</a>    Pages:1141-1150</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Duggan:Geoffrey_B=">Geoffrey B. Duggan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Payne:Stephen_J=">Stephen J. Payne</a></p>
<p>Abstract:
Readers on the Web often skim through text to cope with the volume of available information. In a previous study, Duggan and Payne [11] tracked readers' eye movements as they skimmed through expository text under time pressure. This article presents novel analyses of these eye-movement data. Results indicated that readers were able to explicitly direct attention to the most important information in the text and that this improved performance on a subsequent test of memory for the meaning of text. We suggest readers achieve this by satisficing reading through text until the rate of information gain drops below threshold and then skipping to the next section of text. Further analyses of gaze patterns for paragraphs and pages supported this explanation. Combining satisficing with some form of scanning or sampling behaviour could explain patterns of reading found on the Web. A greater understanding of the way that text is read on the Web would assist many producers of online content.</p>
<p>Keywords:
information foraging; reading; skimming; speed reading; time allocation.</p>
<h3 id="137. Older web users' eye movements: experience counts.">137. Older web users' eye movements: experience counts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979115">Paper Link</a>    Pages:1151-1160</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hill:Robin_L=">Robin L. Hill</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dickinson:Anna">Anna Dickinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Arnott:John_L=">John L. Arnott</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gregor:Peter">Peter Gregor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McIver:Louise">Louise McIver</a></p>
<p>Abstract:
Eye-tracking is a valuable tool for usability research. Studies into the effect of age on eye-movement behavior tend to indicate a propensity for slower viewing and longer times spent examining information. This pattern is usually attributed to the general physiological and cognitive slow-down associated with normal aging. In this paper, however, across three different tasks based on computer and internet use (free-viewing, visual search, and browser interaction), we show that among older adults (n=18, age range: 70-93) computer experience appears to be a highly important factor in eye-movement behavior. We argue that as a consequence of the experimental environment used in modern eye-tracking studies, characteristics such as familiarity and experience with computers should be taken into account before conclusions are drawn about the raw effects of age.</p>
<p>Keywords:
ageing; experience; eye-tracking; web usability.</p>
<h3 id="138. Retrospective think-aloud method: using eye movements as an extra cue for participants' verbalizations.">138. Retrospective think-aloud method: using eye movements as an extra cue for participants' verbalizations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979116">Paper Link</a>    Pages:1161-1170</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Elling:Sanne">Sanne Elling</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lentz:Leo">Leo Lentz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jong:Menno_de">Menno de Jong</a></p>
<p>Abstract:
The retrospective think-aloud method, in which participants work in silence and verbalize their thoughts afterwards while watching a recording of their performance, is often used for the evaluation of websites. However, participants may not always be able to recall what they thought, when they only see few visual cues that help them remembering their task execution process. In our study we complemented the recording of the performance with a gaze trail of the participant" eye movements, in order to elicit more verbalizations. A comparison was made between the traditional retrospective think-aloud protocols and the variant with eye movements. Contrary to our expectations, no differences were found between the two conditions on numbers of problems, the ways these problems were detected, and types of problems. Two possible explanations for this result are that eye movements might be rather confronting and distracting for participants, and the rather generic way of probing we used. The added value might be stronger when specific questions are asked, based on the observed eye movements. Implications for usability practitioners are discussed in the conclusions of this paper.</p>
<p>Keywords:
eye-tracking; retrospective think-aloud protocols; usability testing.; verbalization</p>
<h3 id="139. Triggered think-aloud protocol: using eye tracking to improve usability test moderation.">139. Triggered think-aloud protocol: using eye tracking to improve usability test moderation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979117">Paper Link</a>    Pages:1171-1174</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Freeman:Beverly">Beverly Freeman</a></p>
<p>Abstract:
Usability practitioners often rely on research participants' verbal reports to better understand the user experience. These reports can be collected either during or after task execution, with each approach entailing unique benefits and limitations. This note presents a framework for using eye tracking data to "trigger" when and how moderators probe participants for verbal comments during task execution to supplement or elaborate participant-initiated comments. A preliminary case study suggests that this approach affords a level of efficiency and effectiveness difficult to achieve with retrospective verbalization or without the use of eye tracking. The hope is that practitioners will be encouraged to use and refine this method for the benefit of the field.</p>
<p>Keywords:
concurrent think aloud protocol; eye tracking; retrospective think aloud protocol; think aloud protocol; usability; verbal protocol</p>
<h2 id="Families    4">Families    4</h2>
<h3 id="140. Learning patterns of pick-ups and drop-offs to support busy family coordination.">140. Learning patterns of pick-ups and drop-offs to support busy family coordination.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979119">Paper Link</a>    Pages:1175-1184</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Davidoff:Scott">Scott Davidoff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Ziebart:Brian_D=">Brian D. Ziebart</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dey:Anind_K=">Anind K. Dey</a></p>
<p>Abstract:
Part of being a parent is taking responsibility for arranging and supplying transportation of children between various events. Dual-income parents frequently develop routines to help manage transportation with a minimal amount of attention. On days when families deviate from their routines, effective logistics can often depend on knowledge of the routine location, availability and intentions of other family members. Since most families rarely document their routine activities, making that needed information unavailable, coordination breakdowns are much more likely to occur. To address this problem we demonstrate the feasibility of learning family routines using mobile phone GPS. We describe how we (1) detect pick-ups and drop-offs; (2) predict which parent will perform a future pick-up or drop-off; and (3) infer if a child will be left at an activity. We discuss how these routine models give digital calendars, reminder and location systems new capabilities to help prevent breakdowns, and improve family life.</p>
<p>Keywords:
data mining; gps; graphical models; machine learning; mobile phones; routines; sensing; statistical models</p>
<h3 id="141. Mediated parent-child contact in work-separated families.">141. Mediated parent-child contact in work-separated families.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979120">Paper Link</a>    Pages:1185-1194</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yarosh:Svetlana">Svetlana Yarosh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Abowd:Gregory_D=">Gregory D. Abowd</a></p>
<p>Abstract:
Parents and children in families living with regular separation due to work develop strategies to manage being apart. We interviewed 14 pairs of parents and children (ages 7 -- 13) from work-separated families to understand their experiences and the strategies that they use to keep their family together. Parents focus on combining scheduled synchronous and spontaneous asynchronous communication to maintain a constant presence in the life of the child. Children, on the other hand, focus on other sources of support, on other activities, and on the eventual reunion. Both the remote parent and the child rely heavily on a collocated adult to maintain aware-ness and contact. We compare work-separated families with other types of separation and highlight opportunities for new designs.</p>
<p>Keywords:
children; computer-mediated communication; parents</p>
<h3 id="142. Hello, is grandma there? let's read! StoryVisit: family video chat and connected e-books.">142. Hello, is grandma there? let's read! StoryVisit: family video chat and connected e-books.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979121">Paper Link</a>    Pages:1195-1204</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Raffle:Hayes">Hayes Raffle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Revelle:Glenda">Glenda Revelle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mori:Koichi">Koichi Mori</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Ballagas:Rafael">Rafael Ballagas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Buza:Kyle">Kyle Buza</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Horii:Hiroshi">Hiroshi Horii</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kaye:Joseph">Joseph Kaye</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cook:Kristin">Kristin Cook</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Freed:Natalie">Natalie Freed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Go:Janet">Janet Go</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Spasojevic:Mirjana">Mirjana Spasojevic</a></p>
<p>Abstract:
StoryVisit allows children and long-distance adults to experience a sense of togetherness by reading children's story books together over a distance. StoryVisit combines video conferencing and connected books: remote grown-up and child readers can see and hear each other, and can also see and control the same e-book. We report on research with 61 families - over 200 users including parents, children and long-distance readers - who used StoryVisit in their homes with a long-distance reader for at least one reading session. In addition, we report qualitative findings regarding nineteen of the families who participated in telephone interviews and four families who were monitored and interviewed by researchers at home. Results show that connected e-book video chat sessions last about five times as long as the typical video chats reported in previous research on families with young children. Moreover, the addition of an animated character increased session lengths by another 50%. StoryVisit usage peaked for families with three year olds, showing that sustained distance interactions with very young children are possible if communication technologies incorporate joint activities that engage children and adults.</p>
<p>Keywords:
agent; children; dialogic reading; family communication; literacy; reading; video conferencing</p>
<h3 id="143. Family portals: connecting families through a multifamily media space.">143. Family portals: connecting families through a multifamily media space.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979122">Paper Link</a>    Pages:1205-1214</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Judge:Tejinder_K=">Tejinder K. Judge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Neustaedter:Carman">Carman Neustaedter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Steve">Steve Harrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blose:Andrew_C=">Andrew C. Blose</a></p>
<p>Abstract:
Video conferencing allows distance-separated family members to interact somewhat akin to being together at the same place and time. Yet most video conferencing systems are designed for phone-like calls between only two locations. Using such systems for long interactions or social gatherings with multiple families is cumbersome, if not impossible. For this reason, we wanted to explore how families would make use of a video system that permitted sharing everyday life over extended periods of time between multiple locations. We designed a media space called Family Portals that provides shared video between three locations and deployed it within the homes of six families. Results show that the media space increased feelings of connectedness and the focus on a triad, in contrast to a dyad, caused new styles of interaction to emerge. Despite this, families experienced new privacy challenges and non-adoption by some family members, not previously seen in dyadic family media spaces.</p>
<p>Keywords:
awareness; domestic; families; media space; video</p>
<h2 id="Search & information seeking    4">Search &amp; information seeking    4</h2>
<h3 id="144. The information flaneur: a fresh look at information seeking.">144. The information flaneur: a fresh look at information seeking.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979124">Paper Link</a>    Pages:1215-1224</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/D=ouml=rk:Marian">Marian Drk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carpendale:M=_Sheelagh_T=">M. Sheelagh T. Carpendale</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williamson:Carey">Carey Williamson</a></p>
<p>Abstract:
We introduce the information flaneur as a new human-centred view on information seeking that is grounded in interdisciplinary research. We use the metaphor of the urban flaneur making sense of a city as an inspiring lens that brings together diverse perspectives. These perspectives shift information seeking towards a more optimistic outlook: the information flaneur represents curious, creative, and critical information seeking. The resulting information-seeking model conceptualizes the interrelated nature between information activities and experiences as a continuum between horizontal exploration and vertical immersion. Motivated by enabling technological trends and inspired by the information flaneur, we present explorability as a new guiding principle for design and raise research challenges regarding the representation of information abstractions and details.</p>
<p>Keywords:
flaneur; human-computer interaction; information seeking</p>
<h3 id="145. No clicks, no problem: using cursor movements to understand and improve search.">145. No clicks, no problem: using cursor movements to understand and improve search.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979125">Paper Link</a>    Pages:1225-1234</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huang_0002:Jeff">Jeff Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/White:Ryen_W=">Ryen W. White</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dumais:Susan_T=">Susan T. Dumais</a></p>
<p>Abstract:
Understanding how people interact with search engines is important in improving search quality. Web search engines typically analyze queries and clicked results, but these actions provide limited signals regarding search interaction. Laboratory studies often use richer methods such as gaze tracking, but this is impractical at Web scale. In this paper, we examine mouse cursor behavior on search engine results pages (SERPs), including not only clicks but also cursor movements and hovers over different page regions. We: (i) report an eye-tracking study showing that cursor position is closely related to eye gaze, especially on SERPs; (ii) present a scalable approach to capture cursor movements, and an analysis of search result examination behavior evident in these large-scale cursor data; and (iii) describe two applications (estimating search result relevance and distinguishing good from bad abandonment) that demonstrate the value of capturing cursor data. Our findings help us better understand how searchers use cursors on SERPs and can help design more effective search systems. Our scalable cursor tracking method may also be useful in non-search settings.</p>
<p>Keywords:
clicks; cursor movements; implicit feedback; web search</p>
<h3 id="146. Enhancing credibility judgment of web search results.">146. Enhancing credibility judgment of web search results.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979126">Paper Link</a>    Pages:1235-1244</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yamamoto:Yusuke">Yusuke Yamamoto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tanaka:Katsumi">Katsumi Tanaka</a></p>
<p>Abstract:
In this paper, we propose a system for helping users to judge the credibility of Web search results and to search for credible Web pages. Conventional Web search engines present only titles, snippets, and URLs for users, which give few clues to judge the credibility of Web search results. Moreover, ranking algorithms of the conventional Web search engines are often based on relevance and popularity of Web pages. Towards credibility-oriented Web search, our proposed system provides users with the following three functions: (1) calculation and visualization of several scores of Web search results on the main credibility aspects, (2) prediction of user's credibility judgment model through user's credibility feedback for Web search results, and (3) re-ranking of Web search results based on user's predicted credibility model. Experimental results suggest that our system enables users - in particular, users with knowledge about search topics - to find credible Web pages from a list of Web search results more efficiently than conventional Web search interfaces.</p>
<p>Keywords:
credibility analysis; credibility feedback; web search</p>
<h3 id="147. Augmenting web pages and search results to support credibility assessment.">147. Augmenting web pages and search results to support credibility assessment.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979127">Paper Link</a>    Pages:1245-1254</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schwarz:Julia">Julia Schwarz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Meredith_Ringel">Meredith Ringel Morris</a></p>
<p>Abstract:
The presence (and, sometimes, prominence) of incorrect and misleading content on the Web can have serious consequences for people who increasingly rely on the internet as their information source for topics such as health, politics, and financial advice. In this paper, we identify and collect several page features (such as popularity among specialized user groups) that are currently difficult or impossible for end users to assess, yet provide valuable signals regarding credibility. We then present visualizations designed to augment search results and Web pages with the most promising of these features. Our lab evaluation finds that our augmented search results are particularly effective at increasing the accuracy of users'" credibility assessments, highlighting the potential of data aggregation and simple interventions to help people make more informed decisions as they search for information online.</p>
<p>Keywords:
credibility; trustworthiness; web</p>
<h2 id="Expression & perception    5">Expression &amp; perception    5</h2>
<h3 id="148. Using fast interaction to create intense experiences.">148. Using fast interaction to create intense experiences.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979129">Paper Link</a>    Pages:1255-1264</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Joe">Joe Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benford:Steve">Steve Benford</a></p>
<p>Abstract:
Several emerging strands of HCI involve connecting physical exercise activity with digital interactive systems to create intense combined experiences, for example pervasive games, GPS based exercise games and 'exertion interfaces'. Many of these systems are mobile, used outside in public, whilst moving quickly through the environment. In this paper, we argue that the combination of moving fast and interacting with a digital system allows us to create a powerfully intense experience for participants, and that key to this is careful attention to the way in which movement is combined with digital content. We study an interactive art experience in which a person runs whilst listening to poetry. Based on this study and other HCI research, we present a framework for mixing physical and interactive content, based on 3 dimensions, which describe ways that a movement activity may itself create intense experiences, followed by a set of tactics for combining intense movement and interactive content.</p>
<p>Keywords:
exertion; full body interaction; intensity; mobile; running</p>
<h3 id="149. A VJ centered exploration of expressive interaction.">149. A VJ centered exploration of expressive interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979130">Paper Link</a>    Pages:1265-1274</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hook:Jonathan">Jonathan Hook</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Green:David_Philip">David Philip Green</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McCarthy:John_C=">John C. McCarthy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Stuart">Stuart Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wright:Peter_C=">Peter C. Wright</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
This paper identifies key themes of expressive interaction for VJs. VJs are visual artists who use digital media to express themselves to an audience during a live audio-visual performance. Those designing for the expressive use of technology can gain insight from an articulation of expressive interaction from the perspective of VJ practice. This is developed using a novel qualitative methodology designed to be sensitive to the subtle and tacit nature of expression. We detail our methodology, present the results of its application to a group of VJs and conclude with a discussion of the implications our findings may have for those wishing to design for VJs, or those in related domains that involve expressive interaction with technology.</p>
<p>Keywords:
VJ; creative response; dialogue; documentary film; expressive interaction; methodology; thematic analysis</p>
<h3 id="150. Placing a value on aesthetics in online casual games.">150. Placing a value on aesthetics in online casual games.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979131">Paper Link</a>    Pages:1275-1278</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Andersen:Erik">Erik Andersen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Yun=En">Yun-En Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Snider:Rich">Rich Snider</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Szeto:Roy">Roy Szeto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Popovic:Zoran">Zoran Popovic</a></p>
<p>Abstract:
Game designers frequently invest in aesthetic improvements such as music, sound effects, and animations. However, their exact value for attracting and retaining players remains unclear. Seeking to estimate this value in two popular Flash games, we conducted a series of large-scale A/B tests in which we selectively removed aesthetic improvements and examined the effect of each component on play time, progress, and return rate. We found that music and sound effects had little or no effect on player retention in either game, while animations caused users to play more. We also found, counterintuitively, that optional rewards caused players to play less in both games. In one game, this gameplay modification affected play time three times as much as the largest aesthetic variation. Our methodology provides a way to determine where resources may be best spent during the game design and development process.</p>
<p>Keywords:
a/b testing; aesthetics; analytics; games</p>
<h3 id="151. Kinetic tiles.">151. Kinetic tiles.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979132">Paper Link</a>    Pages:1279-1282</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Hyunjung">Hyunjung Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Woohun">Woohun Lee</a></p>
<p>Abstract:
We propose and demonstrate Kinetic Tiles, modular construction units for kinetic animations. Three different design methods are explored and evaluated for kinetic animation with the Kinetic Tiles using preset movements, design via animation toolkit, and design via direct input. It is expected that the Kinetic Tiles, as a new design and architecture material, will assist designers to introduce kinetic expressions to the surfaces of everyday objects and spaces.</p>
<p>Keywords:
kinetic design; kinetic design material; kinetic interaction</p>
<h3 id="152. SandCanvas: a multi-touch art medium inspired by sand animation.">152. SandCanvas: a multi-touch art medium inspired by sand animation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979133">Paper Link</a>    Pages:1283-1292</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kazi:Rubaiat_Habib">Rubaiat Habib Kazi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chua:Kien_Chuan">Kien Chuan Chua</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davis:Richard_C=">Richard C. Davis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Low:Kok=Lim">Kok-Lim Low</a></p>
<p>Abstract:
Sand animation is a performance art technique in which an artist tells stories by creating animated images with sand. Inspired by this medium, we have developed a new multi-touch digital artistic medium named SandCanvas that simplifies the creation of sand animations. SandCanvas also goes beyond traditional sand animation with tools for mixing sand animation with video and replicating recorded free-form hand gestures. In this paper, we analyze common sand animation hand gestures, present SandCanvas's intuitive UI, and describe implementation challenges we encountered. We also present an evaluation with professional and novice artists that shows the importance and unique affordances of this new medium.</p>
<p>Keywords:
creativity; multi-touch art; sand animation; table-top computing</p>
<h2 id="Flexible grips & gestures    4">Flexible grips &amp; gestures    4</h2>
<h3 id="153. Evaluating effects of structural holds on pointing and dragging performance with flexible displays.">153. Evaluating effects of structural holds on pointing and dragging performance with flexible displays.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979135">Paper Link</a>    Pages:1293-1302</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dijkstra:Rob">Rob Dijkstra</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perez:Christopher">Christopher Perez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vertegaal:Roel">Roel Vertegaal</a></p>
<p>Abstract:
In this paper, we present a study of the effects of structural holds and rigidity of a flexible display on touch pointing and dragging performance. We discuss an observational study in which we collected common holds used when pointing on a mockup paper display. We also measured the force patterns each hold generated within the display surface. We analyzed this data to produce 3 force zones in the display for each of the four most frequently observed holds: the grip zone, rigid zone, and the flexible zone. We report on an empirical evaluation in which we compared the efficiency of pointing and dragging operations between holds, and between structural zones within holds, using a real flexible Lumalive display. Results suggest that structural force distributions in a flexible display affect the Index of Performance of both pointing and dragging tasks, irrespective of hold, with rigid parts of the display yielding a 12% average performance gain over flexible areas.</p>
<p>Keywords:
Fitt's Law; flexible displays; organic user interfaces</p>
<h3 id="154. PaperPhone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays.">154. PaperPhone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979136">Paper Link</a>    Pages:1303-1312</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lahey:Byron">Byron Lahey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Girouard:Audrey">Audrey Girouard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Burleson:Winslow">Winslow Burleson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vertegaal:Roel">Roel Vertegaal</a></p>
<p>Abstract:
Flexible displays potentially allow for interaction styles that resemble those used in paper documents. Bending the display, e.g., to page forward, shows particular promise as an interaction technique. In this paper, we present an evaluation of the effectiveness of various bend gestures in executing a set of tasks with a flexible display. We discuss a study in which users designed bend gestures for common computing actions deployed on a smartphone-inspired flexible E Ink prototype called PaperPhone. We collected a total of 87 bend gesture pairs from ten participants and their appropriateness over twenty actions in five applications. We identified six most frequently used bend gesture pairs out of 24 unique pairs. Results show users preferred bend gestures and bend gesture pairs that were conceptually simpler, e.g., along one axis, and less physically demanding. There was a strong agreement among participants to use the same three pairs in applications: (1) side of display, up/down (2) top corner, up/down (3) bottom corner, up/down. For actions with a strong directional cue, we found strong consensus on the polarity of the bend gestures (e.g., navigating left is performed with an upwards bend gesture, navigating right, downwards). This implies that bend gestures that take directional cues into account are likely more natural to users.</p>
<p>Keywords:
E Ink; bend gestures; flexible displays; organic user interfaces</p>
<h3 id="155. Pinstripe: eyes-free continuous input on interactive clothing.">155. Pinstripe: eyes-free continuous input on interactive clothing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979137">Paper Link</a>    Pages:1313-1322</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Karrer:Thorsten">Thorsten Karrer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wittenhagen:Moritz">Moritz Wittenhagen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lichtschlag:Leonhard">Leonhard Lichtschlag</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heller:Florian">Florian Heller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borchers:Jan_O=">Jan O. Borchers</a></p>
<p>Abstract:
We present Pinstripe, a textile user interface element for eyes-free, continuous value input on smart garments that uses pinching and rolling a piece of cloth between your fingers. The input granularity can be controlled in a natural way by varying the amount of cloth pinched. Pinstripe input elements physically consist of fields of parallel conductive lines sewn onto the fabric. This way, they can be invisible, and can be included across large areas of a garment. Pinstripe also addresses several problems previously identified in the placement and operation of textile UI elements on smart clothing. Two user studies evaluate ideal placement and orientation of Pinstripe elements on the users' garments as well as acceptance and perceived ease of use of this novel textile input technique.</p>
<p>Keywords:
continuous input; eyes-free interaction; smart textiles; wearable computing</p>
<h3 id="156. Grips and gestures on a multi-touch pen.">156. Grips and gestures on a multi-touch pen.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979138">Paper Link</a>    Pages:1323-1332</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Song:Hyunyoung">Hyunyoung Song</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benko:Hrvoje">Hrvoje Benko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guimbreti=egrave=re:Fran=ccedil=ois">Franois Guimbretire</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Izadi:Shahram">Shahram Izadi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cao:Xiang">Xiang Cao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hinckley:Ken">Ken Hinckley</a></p>
<p>Abstract:
This paper explores the interaction possibilities enabled when the barrel of a digital pen is augmented with a multi-touch sensor. We present a novel multi-touch pen (MTPen) prototype and discuss its alternate uses beyond those of a standard stylus, such as allowing new touch gestures to be performed using the index finger or thumb and detecting how users grip the device as a mechanism for mode switching. We also discuss the hardware and software implementation challenges in realizing our prototype, and showcase how one can combine different grips (tripod, relaxed tripod, sketch, wrap) and gestures (swipe and double tap) to enable new interaction techniques with the MTPen in a prototype drawing application. One specific aim is the elimination of some of the comfort problems associated with existing auxiliary controls on digital pens. Mechanical controls such as barrel buttons and barrel scroll wheels work best in only a few specific hand grips and pen rotations. Comparatively, our gestures can be successfully and comfortably performed regardless of the rotation of the pen or how the user grips it, offering greater flexibility in use. We describe a formal evaluation comparing MTPen gestures against the use of a barrel button for mode switching. This study shows that both swipe and double tap gestures are comparable in performance to commonly employed barrel buttons without its disadvantages.</p>
<p>Keywords:
digital pen; digital stylus; grip detection; multi-touch</p>
<h2 id="3D interaction    4">3D interaction    4</h2>
<h3 id="157. WYSIWYF: exploring and annotating volume data with a tangible handheld device.">157. WYSIWYF: exploring and annotating volume data with a tangible handheld device.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979140">Paper Link</a>    Pages:1333-1342</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Song:Peng">Peng Song</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Goh:Wooi=Boon">Wooi-Boon Goh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fu:Chi=Wing">Chi-Wing Fu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Meng:Qiang">Qiang Meng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heng:Pheng=Ann">Pheng-Ann Heng</a></p>
<p>Abstract:
Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat finger annotation technique (F3AT) is proposed to perform accurate and speedy contour drawings. Our user studies support the efficacy of our proposed visual exploration and annotation interaction designs.</p>
<p>Keywords:
accelerometer; data exploration; handheld devices; multi-touch; user interaction; visual annotation; volume data</p>
<h3 id="158. Eden: a professional multitouch tool for constructing virtual organic environments.">158. Eden: a professional multitouch tool for constructing virtual organic environments.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979141">Paper Link</a>    Pages:1343-1352</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kin:Kenrick">Kenrick Kin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Tom">Tom Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bollensdorff:Bj=ouml=rn">Bjrn Bollensdorff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/DeRose:Tony">Tony DeRose</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hartmann:Bj=ouml=rn">Bjrn Hartmann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agrawala:Maneesh">Maneesh Agrawala</a></p>
<p>Abstract:
Set construction is the process of selecting and positioning virtual geometric objects to create a virtual environment used in a computer-animated film. Set construction artists often have a clear mental image of the set composition, but find it tedious to build their intended sets with current mouse and keyboard interfaces. We investigate whether multitouch input can ease the process of set construction. Working with a professional set construction artist at Pixar Animation Studios, we designed and developed Eden, a fully functional multitouch set construction application. In this paper, we describe our design process and how we balanced the advantages and disadvantages of multitouch input to develop usable gestures for set construction. Based on our design process and the user experiences of two set construction artists, we present a general set of lessons we learned regarding the design of a multitouch interface.</p>
<p>Keywords:
Eden; camera control; gesture design; gestures; multitouch; object manipulation; set construction</p>
<h3 id="159. 2d touching of 3d stereoscopic objects.">159. 2d touching of 3d stereoscopic objects.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979142">Paper Link</a>    Pages:1353-1362</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Valkov:Dimitar">Dimitar Valkov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steinicke:Frank">Frank Steinicke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bruder:Gerd">Gerd Bruder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hinrichs:Klaus_H=">Klaus H. Hinrichs</a></p>
<p>Abstract:
Recent developments in the area of touch and display technologies have suggested to combine multi-touch systems and stereoscopic visualization. Stereoscopic perception requires each eye to see a slightly different perspective of the same scene, which results in two distinct projections on the display. Thus, if the user wants to select a 3D stereoscopic object in such a setup, the question arises where she would touch the 2D surface to indicate the selection. A user may apply different strategies, for instance touching the midpoint between the two projections, or touching one of them. In this paper we analyze the relation between the 3D positions of stereoscopically rendered objects and the on-surface touch points, where users touch the surface. We performed an experiment in which we determined the positions of the users' touches for objects, which were displayed with positive, negative or zero parallaxes. We found that users tend to touch between the projections for the two eyes with an offset towards the projection for the dominant eye. Our results give implications for the development of future touch-enabled interfaces, which support 3D stereoscopic visualization.</p>
<p>Keywords:
multi-touch; stereoscopic displays; touch screens</p>
<h3 id="160. TZee: exploiting the lighting properties of multi-touch tabletops for tangible 3d interactions.">160. TZee: exploiting the lighting properties of multi-touch tabletops for tangible 3d interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979143">Paper Link</a>    Pages:1363-1372</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Williams:Cary">Cary Williams</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Xing=Dong">Xing-Dong Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Partridge:Grant_A=">Grant A. Partridge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Millar=Usiskin:Joshua">Joshua Millar-Usiskin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Major:Arkady">Arkady Major</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Irani:Pourang">Pourang Irani</a></p>
<p>Abstract:
Manipulating 3D objects on a tabletop is inherently problematic. Tabletops lack a third degree of freedom and thus require novel solutions to support even the simplest 3D manipulations. Our solution is TZee - a passive tangible widget that enables natural interactions with 3D objects by exploiting the lighting properties of diffuse illumination (DI) multi-touch tabletops. TZee is assembled from stacked layers of acrylic glass to extend the tabletop's infrared light slightly above the surface without supplemental power. With TZee, users can intuitively scale, translate and rotate objects in all three dimensions, and also perform more sophisticated gestures, like "slicing" a volumetric object, that have not been possible with existing tabletop interaction schemes. TZee is built with affordable and accessible materials, and one tabletop surface can easily support multiple TZees. Moreover, since TZee is transparent, there are numerous possibilities to augment interactions with feedback, helpful hints, or other visual enhancements. We discuss several important design considerations and demonstrate the value of TZee with several applications.</p>
<p>Keywords:
3d user interface; input device; multi-touch surface; tangible user interface</p>
<h2 id="Crowdsourcing    4">Crowdsourcing    4</h2>
<h3 id="161. Guess who?: enriching the social graph through a crowdsourcing game.">161. Guess who?: enriching the social graph through a crowdsourcing game.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979145">Paper Link</a>    Pages:1373-1382</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Guy:Ido">Ido Guy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perer:Adam">Adam Perer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Daniel:Tal">Tal Daniel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Greenshpan:Ohad">Ohad Greenshpan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Turbahn:Itai">Itai Turbahn</a></p>
<p>Abstract:
Despite the tremendous popularity of social network sites both on the web and within enterprises, the relationship information they contain may be often incomplete or outdated. We suggest a novel crowdsourcing approach that uses a game to help enrich and expand the social network topology. The game prompts players to provide the names of people who have a relationship with individuals they know. The game was deployed for a one-month period within a large global organization. We provide an analysis of the data collected through this deployment, in comparison with the data from the organization's social network site. Our results indicate that the game rapidly collects large volumes of valid information that can be used to enrich and reinforce an existing social network site's data. We point out other aspects and benefits of using a crowdsourcing game to harvest social network information.</p>
<p>Keywords:
crowdsourcing; games; human computation; social networks</p>
<h3 id="162. PhotoCity: training experts at large-scale image acquisition through a competitive game.">162. PhotoCity: training experts at large-scale image acquisition through a competitive game.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979146">Paper Link</a>    Pages:1383-1392</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tuite:Kathleen">Kathleen Tuite</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Snavely:Noah">Noah Snavely</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hsiao:Dun=Yu">Dun-Yu Hsiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tabing:Nadine">Nadine Tabing</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Popovic:Zoran">Zoran Popovic</a></p>
<p>Abstract:
Large-scale, ground-level urban imagery has recently developed as an important element of online mapping tools such as Google's Street View. Such imagery is extremely valuable in a number of potential applications, ranging from augmented reality to 3D modeling, and from urban planning to monitoring city infrastructure. While such imagery is already available from many sources, including Street View and tourist photos on photo-sharing sites, these collections have drawbacks related to high cost, incompleteness, and accuracy. A potential solution is to leverage the community of photographers around the world to collaboratively acquire large-scale image collections. This work explores this approach through PhotoCity, an online game that trains its players to become "experts" at taking photos at targeted locations and in great density, for the purposes of creating 3D building models. To evaluate our approach, we ran a competition between two universities that resulted in the submission of over 100,000 photos, many of which were highly relevant for the 3D modeling task at hand. Although the number of players was small, we found that this was compensated for by incentives that drove players to become experts at photo collection, often capturing thousands of useful photos each.</p>
<p>Keywords:
3d modeling; crowdsourcing; data collection; games with a purpose; photography; real-world games</p>
<h3 id="163. Cooks or cobblers?: crowd creativity through combination.">163. Cooks or cobblers?: crowd creativity through combination.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979147">Paper Link</a>    Pages:1393-1402</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yu:Lixiu">Lixiu Yu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nickerson:Jeffrey_V=">Jeffrey V. Nickerson</a></p>
<p>Abstract:
A sketch combination system is introduced and tested: a crowd of 1047 participated in an iterative process of design, evaluation and combination. Specifically, participants in a crowdsourcing marketplace sketched chairs for children. One crowd created a first generation of chairs, and then successive crowds created new generations by combining the chairs made by previous crowds. Other participants evaluated the chairs. The crowd judged the chairs from the third generation more creative than those from the first generation. An analysis of the design evolution shows that participants inherited and modified presented features, and also added new features. These findings suggest that crowd based design processes may be effective, and point the way toward computer-human interactions that might further encourage crowd creativity.</p>
<p>Keywords:
conceptual combination; creativity; crowdsourcing; design sketches; human based genetic algorithms; social computing</p>
<h3 id="164. Human computation: a survey and taxonomy of a growing field.">164. Human computation: a survey and taxonomy of a growing field.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979148">Paper Link</a>    Pages:1403-1412</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/q/Quinn:Alexander_J=">Alexander J. Quinn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bederson:Benjamin_B=">Benjamin B. Bederson</a></p>
<p>Abstract:
The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However, the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal "holes" in the existing work as opportunities for new research. Since human computation is often confused with "crowdsourcing" and other terms, we explore the position of human computation with respect to these related topics.</p>
<p>Keywords:
crowdsourcing; data mining; human computation; literature review; social computing; survey; taxonomy</p>
<h2 id="User studies/ethnography in developing regions    4">User studies/ethnography in developing regions    4</h2>
<h3 id="165. The times they are a-changin': mobile payments in india.">165. The times they are a-changin': mobile payments in india.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979150">Paper Link</a>    Pages:1413-1422</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kumar:Deepti">Deepti Kumar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Martin_0001:David_B=">David B. Martin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/O=Neill:Jacki">Jacki O'Neill</a></p>
<p>Abstract:
We report on an ethnographic study of payment and banking practices in India. Currently a mobile payment mechanism is being developed in India and we were interested to see how it would fit with various current payment systems for various types of users. Therefore we studied a variety of current payment situations and gained an understanding of the banking and payment practices and needs of a diverse community. Our aim was to inform the development of interface elements, applications and services that would support the needs we uncovered. We describe our findings and the design ideas they provoked.</p>
<p>Keywords:
ecosystem; ethnography; financial inclusion; india; interaction; mobile payments; payment practices; services</p>
<h3 id="166. Folk music goes digital in India.">166. Folk music goes digital in India.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979151">Paper Link</a>    Pages:1423-1432</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kumar:Neha">Neha Kumar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chouhan:Gopal">Gopal Chouhan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Parikh:Tapan_S=">Tapan S. Parikh</a></p>
<p>Abstract:
Folk music forms in India are rich and diverse, varying from region to region across the Indian landscape. The recent explosion of new media technologies (e.g. DVDs, CDs, mobile phones) in both rural and urban India is changing how oral folk music is being performed, produced, distributed, and shared. To further understand this impact, we conducted an extended field study across four field sites in India that are rich in folk music tradition and activity. Through a process of interviews, participant observation, focus group discussion, and content analysis with a varied group of stakeholders - including folk musicians, listeners, retailers, and radio show producers - we found that 1) there are a diverse set of motivations for performing and listening to folk music, 2) new media technologies are helping folk musicians become more popular, while reducing some streams of revenue, particularly for businesses engaged only in music production and distribution, and 3) as expected, piracy is widely tolerated by musicians, both out of apathy, and an interest in reaching new audiences with their message, while increasing their own fame and associated patronage. Based on these findings, we propose some implications for the design of an appropriate folk music sharing and distribution service that addresses these various motivations of the musicians and listeners.</p>
<p>Keywords:
copyright; entertainment; folk music; ictd; media; piracy; sharing</p>
<h3 id="167. Designing for emerging rural users: experiences from China.">167. Designing for emerging rural users: experiences from China.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979152">Paper Link</a>    Pages:1433-1436</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Oreglia:Elisa">Elisa Oreglia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Ying">Ying Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Wei">Wei Zhao</a></p>
<p>Abstract:
As part of IBM's Smarter Planet initiative, we studied information-sharing practices in rural Northern China to understand if and how ICT can help rural residents improve their lives. Interviews and participant observation in two villages showed a profusion of ICT devices, as well as an abundance of face-to-face information exchanges, but a shortage of localized and easily accessible information, and a deep dependence of many rural residents on 'information brokers' such as agricultural extension workers and shop owners. Can ICT support existing practices of information sharing among rural residents, when these practices are largely based on face-to-face encounters and passive reception of information? We argue that in such an environment, ICT should build on existing social habits even if less than ideal, rather than trying to transform them, and we outline a possible way to do so.</p>
<p>Keywords:
emerging regions; intermediated technology use; rural china</p>
<h3 id="168. Adapting usability testing for oral, rural users.">168. Adapting usability testing for oral, rural users.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979153">Paper Link</a>    Pages:1437-1440</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gorman:Trina">Trina Gorman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rose:Emma_J=">Emma J. Rose</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yaaqoubi:Judith">Judith Yaaqoubi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bayor:Andrew">Andrew Bayor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kolko:Beth_E=">Beth E. Kolko</a></p>
<p>Abstract:
Traditional usability methods are of limited use when evaluating systems designed for distant, diverse populations. In this paper, we describe a study conducted in two Ghanaian villages that evaluated an audio computer designed for people living in oral cultures. Informed by ICTD and orality-grounded HCID, we modified existing usability testing practices and we reflect on the utility of these adaptations. We found that conducting a culturally appropriate study often meant forgoing more traditional approaches in favor of flexible, opportunistic methods. We acknowledge the challenges of adapting traditional usability methods for oral, rural users. However, we found that by implementing strategic modifications led by local staff, our study produced valuable, actionable results.</p>
<p>Keywords:
audio technology; ictd; illiteracy; methodologies; oral cultures; standards; usability testing; user-centered design</p>
<h2 id="Visualization & perception    4">Visualization &amp; perception    4</h2>
<h3 id="169. Evaluating video visualizations of human behavior.">169. Evaluating video visualizations of human behavior.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979155">Paper Link</a>    Pages:1441-1450</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Romero:Mario">Mario Romero</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vialard:Alice">Alice Vialard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Peponis:John">John Peponis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stasko:John_T=">John T. Stasko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Abowd:Gregory_D=">Gregory D. Abowd</a></p>
<p>Abstract:
Previously, we presented Viz-A-Vis, a VIsualiZation of Activity through computer VISion [17]. Viz-A-Vis visualizes behavior as aggregate motion over observation space. In this paper, we present two complementary user studies of Viz-A-Vis measuring its performance and discovery affordances. First, we present a controlled user study aimed at comparatively measuring behavioral analysis preference and performance for observation and search tasks. Second, we describe a study with architects measuring discovery affordances and potential impacts on their work practices. We conclude: 1) Viz-A-Vis significantly reduced search time; and 2) it increased the number and quality of insightful discoveries.</p>
<p>Keywords:
behavior; information visualization; user studies; video</p>
<h3 id="170. Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces.">170. Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979156">Paper Link</a>    Pages:1451-1460</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jakobsen:Mikkel_R=oslash=nne">Mikkel Rnne Jakobsen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
Whereas the literature is clear on the benefits of large displays and visualizations, little is known about their combination, that is, how display size affect the usability of visualizations. We describe a controlled experiment where 19 participants used focus+context, overview+detail, and zooming techniques with varying display sizes (13.8, 1.5, and 0.17 megapixels). Participants navigated geographical maps to find specific locations, compare items, and follow routes. Results show that for multi-scale navigation, classic interactive visualization techniques did not benefit from being scaled to a large display: In contrast to the literature we find similar performance on medium and large displays. Across display sizes, overview+detail works the best, in particular for comparing items. Focus+context is relatively more difficult to use at a small display size. We explain these findings and discuss the design of interactive visualization techniques for large displays.</p>
<p>Keywords:
information visualization; large high-resolution displays; multi-scale navigation; user study</p>
<h3 id="171. The impact of social information on visual judgments.">171. The impact of social information on visual judgments.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979157">Paper Link</a>    Pages:1461-1470</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hullman:Jessica">Jessica Hullman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Adar:Eytan">Eytan Adar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shah:Priti">Priti Shah</a></p>
<p>Abstract:
Social visualization systems have emerged to support collective intelligence-driven analysis of a growing influx of open data. As with many other online systems, social signals (e.g., forums, polls) are commonly integrated to drive use. Unfortunately, the same social features that can provide rapid, high-accuracy analysis are coupled with the pitfalls of any social system. Through an experiment involving over 300 subjects, we address how social information signals (social proof) affect quantitative judgments in the context of graphical perception. We identify how unbiased social signals lead to fewer errors over non-social settings and conversely, how biased signals lead to more errors. We further reflect on how systematic bias nullifies certain collective intelligence benefits, and we provide evidence of the formation of information cascades. We describe how these findings can be applied to collaborative visualization systems to produce more accurate individual interpretations in social contexts.</p>
<p>Keywords:
graphical perception; information visualization; mechanical turk; social influence; social proof</p>
<h3 id="172. Directing attention and influencing memory with visual saliency modulation.">172. Directing attention and influencing memory with visual saliency modulation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979158">Paper Link</a>    Pages:1471-1480</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Veas:Eduardo_E=">Eduardo E. Veas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=eacute=ndez:Erick">Erick Mndez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Feiner:Steven">Steven Feiner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmalstieg:Dieter">Dieter Schmalstieg</a></p>
<p>Abstract:
In augmented reality, it is often necessary to draw the user's attention to particular objects in the real world without distracting her from her task. We explore the effectiveness of directing a user's attention by imperceptibly modifying existing features of a video. We present three user studies of the effects of applying a saliency modulation technique to video; evaluating modulation awareness, attention, and memory. Our results validate the saliency modulation technique as an alternative means to convey information to the user, suggesting attention shifts and influencing recall of selected regions without perceptible changes to visual input.</p>
<p>Keywords:
augmented reality; saliency; visual attention</p>
<h2 id="Digital content & collections    3">Digital content &amp; collections    3</h2>
<h3 id="173. Freed: a system for creating multiple views of a digital collection during the design process.">173. Freed: a system for creating multiple views of a digital collection during the design process.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979160">Paper Link</a>    Pages:1481-1490</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mendels:Philip">Philip Mendels</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Frens:Joep_W=">Joep W. Frens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Overbeeke:Kees">Kees Overbeeke</a></p>
<p>Abstract:
In this paper Freed is presented, a system that enables design students to spatially organize their digital collection, define relations between collection content and reflect on it. The system features a force-based layout that allows to explore spatial organizations, and hence to gain new insights. Its main advantage over existing software, is that it empowers the students to create different views of their digital collection. A view is a spatial organization of a selection of the collection content and its relations. It can e.g. be used for a specific design activity or project phase, for organizing work around a specific topic, or for explaining the perspective of a given student or stakeholder. Feedback of design students working with Freed during their design projects, and results from a workshop as measured by a questionnaire, show positive prospects for adoption of the system during the design process.</p>
<p>Keywords:
design process; digital collection; force-based layout; multiple views; reflection</p>
<h3 id="174. Teenagers and their virtual possessions: design opportunities and issues.">174. Teenagers and their virtual possessions: design opportunities and issues.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979161">Paper Link</a>    Pages:1491-1500</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Odom:William">William Odom</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a></p>
<p>Abstract:
Over the past several years, people have increasingly acquired virtual possessions. We consider these things to include artifacts that are increasingly becoming immaterial (e.g. books, photos, music, movies) and things that have never traditionally had a lasting material form (e.g. SMS archives, social networking profiles, personal behavior logs). To date, little research exists about how people value and form attachments to virtual possessions. To investigate, we conducted a study with 21 teenagers exploring the perceived value of their virtual possessions, and the comparative similarities and differences with their material things. Findings are interpreted to detail design and research opportunities and issues in this emerging space.</p>
<p>Keywords:
interactive systems design; teenagers; virtual possessions</p>
<h3 id="175. Life editing: third-party perspectives on lifelog content.">175. Life editing: third-party perspectives on lifelog content.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979162">Paper Link</a>    Pages:1501-1510</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Byrne:Daragh">Daragh Byrne</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kelliher:Aisling">Aisling Kelliher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Gareth_J=_F=">Gareth J. F. Jones</a></p>
<p>Abstract:
Lifelog collections digitally capture and preserve personal experiences and can be mined to reveal insights and understandings of individual significance. These rich data sources also offer opportunities for learning and discovery by motivated third parties. We employ a custom-designed storytelling application in constructing meaningful lifelog summaries from third-party perspectives. This storytelling initiative was implemented as a core component in a university media-editing course. We present promising results from a preliminary study conducted to evaluate the utility and potential of our approach in creatively interpreting a unique experiential dataset.</p>
<p>Keywords:
editing; lifelog; sensecam; sensemaking; storytelling</p>
<h2 id="Search & stuff    4">Search &amp; stuff    4</h2>
<h3 id="176. Metrics for the evaluation of news site content layout in large-screen contexts.">176. Metrics for the evaluation of news site content layout in large-screen contexts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979164">Paper Link</a>    Pages:1511-1520</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nebeling:Michael">Michael Nebeling</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matulic:Fabrice">Fabrice Matulic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Norrie:Moira_C=">Moira C. Norrie</a></p>
<p>Abstract:
Despite the fact that screen sizes and average screen resolutions have dramatically increased over the past few years, little attention has been paid to the design of web sites for large, high-resolution displays that are now becoming increasingly used both in enterprise and consumer spaces. We present a study of how the visual area of the browser window is currently utilised by news web sites at different widescreen resolutions. The analysis includes measurements of space taken up by the article content, embedded ads and the remaining components as they appear in the viewport of the web browser. The results show that the spatial distribution of page elements does not scale well with larger viewing sizes, which leads to an increasing amount of unused screen real estate and unnecessary scrolling. We derive a number of device-sensitive metrics to measure the quality of web page layout in different viewing contexts, which can guide the design of flexible layout templates that scale effectively on large screens.</p>
<p>Keywords:
technical tools for usability evaluation; web design guidelines; web site adaptation to large screens</p>
<h3 id="177. YouPivot: improving recall with contextual search.">177. YouPivot: improving recall with contextual search.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979165">Paper Link</a>    Pages:1521-1530</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hailpern:Joshua_M=">Joshua M. Hailpern</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jitkoff:Nicholas">Nicholas Jitkoff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Warr:Andrew">Andrew Warr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karahalios:Karrie">Karrie Karahalios</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sesek:Robert">Robert Sesek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shkrob:Nik">Nik Shkrob</a></p>
<p>Abstract:
According to cognitive science literature, human memory is predicated on contextual cues (e.g., room, music) in the environment. During recall tasks, we associate information/activities/objects with contextual cues. However, computer systems do not leverage our natural process of using contextual cues to facilitate recall. We present a new interaction technique, Pivoting, that allows users to search for contextually related activities and find a target piece of information (often not semantically related). A sample motivation for contextual search would be, 'what was that website I was looking at when Yesterday by The Beatles was last playing?' Our interaction technique is grounded in the cognitive science literature, and is demonstrated in our system YouPivot. In addition, we present a new personal annotation method, called TimeMarks, to further support contextual recall and the pivoting process. In a pilot study, participants were quicker to identify websites, and preferred using YouPivot, compared to current tools. YouPivot demonstrates how principles of human memory can be applied to enhance the search of digital information.</p>
<p>Keywords:
contextual cue; contextual search; human memory; interface; pivot; pivoting; search; time mark; youpivot</p>
<h3 id="178. An examination of two delivery modes for interactive search system experiments: remote and laboratory.">178. An examination of two delivery modes for interactive search system experiments: remote and laboratory.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979166">Paper Link</a>    Pages:1531-1540</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kelly_0001:Diane">Diane Kelly</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gyllstrom:Karl">Karl Gyllstrom</a></p>
<p>Abstract:
We compare two delivery modes for interactive search system (ISS) experiments: remote and laboratory. Our study was completed by two groups of subjects from the same population. The first group completed the study remotely and the second group completed the study in the laboratory. We compare differences in participants, participation behaviors, search behaviors and evaluation behaviors. Overall, for most measures no significant differences were found, but there were some notable differences. Greater variance was observed in time taken and number of documents opened and saved by remote subjects. Lab subjects provided more favorable responses to exit questionnaire items and reported significantly higher satisfaction. Lab subjects also provided significantly longer responses to open questions, while remote subjects provided more null responses. These results suggest that many behaviors do not change significantly according to study mode and that results from remote ISS experiments are similar to those from laboratory experiments.</p>
<p>Keywords:
interactive search system evaluation; online experiment; remote usability study; study mode</p>
<h3 id="179. Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs.">179. Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979167">Paper Link</a>    Pages:1541-1550</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yatani:Koji">Koji Yatani</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Novati:Michael">Michael Novati</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Trusty:Andrew">Andrew Trusty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Truong:Khai_N=">Khai N. Truong</a></p>
<p>Abstract:
Many people read online reviews written by other users to learn more about a product or venue. However, the overwhelming amount of user-generated reviews and variance in length, detail and quality across the reviews make it difficult to glean useful information. In this paper, we present the iterative design of our system, called Review Spotlight. It provides a brief overview of reviews using adjective-noun word pairs, and allows the user to quickly explore the reviews in greater detail. Through a laboratory user study which required participants to perform decision making tasks, we showed that participants could form detailed impressions about restaurants and decide between two options significantly faster with Review Spotlight than with traditional review webpages.</p>
<p>Keywords:
natural language processing; summarization; user interface; user-generated reviews; word pairs</p>
<h2 id="Design materiality    3">Design materiality    3</h2>
<h3 id="180. Making spaces: how design workbooks work.">180. Making spaces: how design workbooks work.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979169">Paper Link</a>    Pages:1551-1560</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gaver:William_W=">William W. Gaver</a></p>
<p>Abstract:
In this paper, I discuss design workbooks, collections of design proposals and related materials, both as a method for design and as a design methodology. In considering them as a method, I describe a number of examples of design workbooks we have developed in our studio and describe some of the practical techniques we have used in developing them. More fundamentally, I discuss design workbooks as embodiments of a methodological approach which recognises that ideas may emerge slowly over time, that important issues and perspectives may emerge from multiple concrete ideas, potentially generated by multiple members of a team, rather than being theory-driven, and that maintaining the provisionality and vagueness of early proposals can be useful in supporting a quasi-participatory design approach that allows participants to interpret, react to and elaborate upon the ideas they present.</p>
<p>Keywords:
conceptual design; design proposals; design spaces; ideation; interaction design; research through design</p>
<h3 id="181. Inspirational bits: towards a shared understanding of the digital material.">181. Inspirational bits: towards a shared understanding of the digital material.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979170">Paper Link</a>    Pages:1561-1570</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sundstr=ouml=m:Petra">Petra Sundstrm</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Alex_S=">Alex S. Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grufberg:Katja">Katja Grufberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wirstr=ouml=m:Niklas">Niklas Wirstrm</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Belenguer:Jordi_Solsona">Jordi Solsona Belenguer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lund=eacute=n:Marcus">Marcus Lundn</a></p>
<p>Abstract:
In any design process, a medium's properties need to be considered. This is nothing new in design. Still we find that in HCI and interactive systems design the properties of a technology are often glossed over. That is, technologies are black-boxed without much thought given to how their distinctive properties open up design possibilities. In this paper we describe what we call inspirational bits as a way to become more familiar with the design material in HCI, the digital material. We describe inspirational bits as quick and dirty but fully working systems in both hardware and software built with the aim of exposing one or several of the dynamic properties of a digital material. We also show how they provide a means of sharing design knowledge across the members of a multi-disciplined design team.</p>
<p>Keywords:
design; design approach; design materials; digital materials; multi-disciplined design teams</p>
<h3 id="182. Don't drop it!: pick it up and storyboard.">182. Don't drop it!: pick it up and storyboard.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979171">Paper Link</a>    Pages:1571-1580</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wahid:Shahtab">Shahtab Wahid</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McCrickard:D=_Scott">D. Scott McCrickard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/DeGol:Joseph">Joseph DeGol</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Elias:Nina">Nina Elias</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Steve">Steve Harrison</a></p>
<p>Abstract:
Storyboards offer designers a way to illustrate a narrative. Their creation can be enabled by tools supporting sketching or widget collections. As designers often incorporate previous ideas, we contribute the notion of blending the reappropriation of artifacts and their design tradeoffs with storyboarding. We present PIC-UP, a storyboarding tool supporting reappropriation, and report on two studies--a long-term investigation with novices and interviews with experts. We discuss how it may support design thinking, tailor to different expertise levels, facilitate reappropriation during storyboarding, and assist with communication.</p>
<p>Keywords:
design tradeoffs; reappropriation; storyboard</p>
<h2 id="Multi-touch    5">Multi-touch    5</h2>
<h3 id="183. Rock & rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations.">183. Rock &amp; rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979173">Paper Link</a>    Pages:1581-1590</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel">Daniel Wigdor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benko:Hrvoje">Hrvoje Benko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pella:John">John Pella</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lombardo:Jarrod">Jarrod Lombardo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williams:Sarah">Sarah Williams</a></p>
<p>Abstract:
Direct touch manipulations enable the user to interact with the on-screen content in a direct and easy manner closely mimicking the spatial manipulations in the physical world. However, they also suffer from well-known issues of precision, occlusion and an inability to isolate different degrees of freedom in spatial manipulations. We present a set of interactions, called Rock &amp; Rails, that augment existing direct touch manipulations with shape-based gestures, thus providing on-demand gain control, occlusion avoidance, and separation of constraints in 2D manipulation tasks. Using shape gestures in combination with direct-manipulations allows us to do this without ambiguity in detection and without resorting to manipulation handles, which break the direct manipulation paradigm. Our set of interactions were evaluated by 8 expert graphic designers and were found to be easy to learn and master, as well as effective in accomplishing a precise graphical layout task.</p>
<p>Keywords:
fluid; interactive surfaces; precise multi-touch interactions; separation of constraints; shape gestures</p>
<h3 id="184. Multi-touch document folding: gesture models, fold directions and symmetries.">184. Multi-touch document folding: gesture models, fold directions and symmetries.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979174">Paper Link</a>    Pages:1591-1600</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chiu:Patrick">Patrick Chiu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liao:Chunyuan">Chunyuan Liao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Francine">Francine Chen</a></p>
<p>Abstract:
For document visualization, folding techniques provide a focus-plus-context approach with fairly high legibility on flat sections. To enable richer interaction, we explore the design space of multi-touch document folding. We discuss several design considerations for simple modeless gesturing and compatibility with standard Drag and Pinch gestures. We categorize gesture models along the characteristics of Symmetric/Asymmetric and Serial/Parallel, which yields three gesture models. We built a prototype document workspace application that integrates folding and standard gestures, and a system for testing the gesture models. A user study was conducted to compare the three models and to analyze the factors of fold direction, target symmetry, and target tolerance in user performance when folding a document to a specific shape. Our results indicate that all three factors were significant for task times, and parallelism was greater for symmetric targets.</p>
<p>Keywords:
document visualization; gesture input; multi-touch screens</p>
<h3 id="185. FingerGlass: efficient multiscale interaction on multitouch screens.">185. FingerGlass: efficient multiscale interaction on multitouch screens.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979175">Paper Link</a>    Pages:1601-1610</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/K=auml=ser:Dominik_P=">Dominik P. Kser</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agrawala:Maneesh">Maneesh Agrawala</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pauly:Mark">Mark Pauly</a></p>
<p>Abstract:
Many tasks in graphical user interfaces require users to interact with elements at various levels of precision. We present FingerGlass, a bimanual technique designed to improve the precision of graphical tasks on multitouch screens. It enables users to quickly navigate to different locations and across multiple scales of a scene using a single hand. The other hand can simultaneously interact with objects in the scene. Unlike traditional pan-zoom interfaces, FingerGlass retains contextual information during the interaction. We evaluated our technique in the context of precise object selection and translation and found that FingerGlass significantly outperforms three state-of-the-art baseline techniques in both objective and subjective measurements: users acquired and translated targets more than 50% faster than with the second-best technique in our experiment.</p>
<p>Keywords:
bimanual; fat finger problem; multiscale interaction; navigation; object translation; precise selection; touch screens</p>
<h3 id="186. An interactive multi-touch sketching interface for diffusion curves.">186. An interactive multi-touch sketching interface for diffusion curves.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979176">Paper Link</a>    Pages:1611-1614</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sun:Qian">Qian Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fu:Chi=Wing">Chi-Wing Fu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/He_0001:Ying">Ying He</a></p>
<p>Abstract:
Diffusion curves are effective 2D vector-graphics primitives, for creating smoothly-shaded drawings with rich colors and unique styles. Conventional drawing systems for diffusion curves often require users to successively layout curve geometry and then specify colors, which is rather tedious for complex drawings. This paper proposes a novel multi-touch sketching interface for efficient design of 2D vector graphics with diffusion curves. In sharp contrast to previous interfaces, we develop a family of multi-touch gestures, allowing users to simultaneously sketch multiple diffusion curves and also to interactively edit and tune curve geometry and colors. Our experiments show that this not only brings novel painting experience to users but also provides a practical and effective tool for vector graphics design, useful for styles like silk painting, Disney cartoon, art poster, and photo-realistic effects. Lastly, we conduct a user study to explore the interface's intuitive and efficient drawing capability with both professional 2D artists and novice users.</p>
<p>Keywords:
diffusion curve; multi-touch interactions; sketching; vector graphics</p>
<h3 id="187. Grids & guides: multi-touch layout and alignment tools.">187. Grids &amp; guides: multi-touch layout and alignment tools.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979177">Paper Link</a>    Pages:1615-1618</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Frisch:Mathias">Mathias Frisch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kleinau:Sebastian">Sebastian Kleinau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Langner:Ricardo">Ricardo Langner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dachselt:Raimund">Raimund Dachselt</a></p>
<p>Abstract:
Precise alignment of graphical objects and the creation of accurate layouts are crucial activities in many applications, such as graphics design tools, presentation software or graph editors. Surface computing is very promising for these application domains but not fully explored yet. In this paper we contribute two tools which support layout tasks on interactive displays: interactive grids and multi-touch alignment guides. Both tools allow the precise positioning of graphical objects in a flexible and fluent way by multi-touch input. Direct bimanual interaction and physical metaphors are applied to arrange objects along straight lines and curves. A formative user evaluation showed promising results with regard to a productive and easy use of the tools.</p>
<p>Keywords:
interactive grids; layout techniques; manual diagram layout; multi-touch alignment guides; snap-dragging</p>
<h2 id="Pointing 2: Fitts law    5">Pointing 2: Fitts law    5</h2>
<h3 id="188. Fitt's law as an explicit time/error trade-off.">188. Fitt's law as an explicit time/error trade-off.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979179">Paper Link</a>    Pages:1619-1628</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Guiard:Yves">Yves Guiard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olafsdottir:Halla_B=">Halla B. Olafsdottir</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perrault:Simon_T=">Simon T. Perrault</a></p>
<p>Abstract:
The widely-held view that Fitts' law expresses a speed/accuracy trade-off is presumably correct, but it is vague. We outline a simple resource-allocation theory of Fitts' law in which movement time and error trade for each other. The theory accounts quite accurately for the data of Fitts' (1954) seminal study, as well as some fresh data of our own. In both data sets we found the time/error trade-off to obey a power law. Our data, which we could analyze more thoroughly than Fitts', are consistent with a square-root function with a single adjustable constant. We suggest that the resource-allocation framework should help combine information and energy considerations to allow a more complete account of Fitts' law.</p>
<p>Keywords:
fitt's law; resource allocation; speed/accuracy trade-off</p>
<h3 id="189. Benchmarking pointing techniques with distractors: adding a density factor to Fitts' pointing paradigm.">189. Benchmarking pointing techniques with distractors: adding a density factor to Fitts' pointing paradigm.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979180">Paper Link</a>    Pages:1629-1638</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Blanch:Renaud">Renaud Blanch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Ortega:Michael">Michael Ortega</a></p>
<p>Abstract:
Fitts' pointing paradigm is widely used to conduct controlled experiments and to evaluate new interaction techniques enhancing target acquisition. Many of them change the behavior of the cursor according to various inputs, most notably the positions of potential targets. We propose to extend Fitts' paradigm in order to challenge those techniques with distractors (i.e., potential targets which are not the goal of the user) in a controlled manner. To reduce variability, we add a single new factor to the paradigm, the distractor density. We specify a distractors distribution, fully determined by this factor together with those of Fitts' task, aimed at reducing bias toward a specific technique. We also propose a preliminary extension of Fitts' law to take account of the sensitivity to the density of distractors as well as of the task difficulty. In an experiment, we compare five existing pointing techniques, and show that this extended protocol enables contrasted comparisons between them.</p>
<p>Keywords:
Fitts' Law; Fitts' Paradigm; distractors; pointing</p>
<h3 id="190. The effects of task dimensionality, endpoint deviation, throughput calculation, and experiment design on pointing measures and models.">190. The effects of task dimensionality, endpoint deviation, throughput calculation, and experiment design on pointing measures and models.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979181">Paper Link</a>    Pages:1639-1648</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shinohara:Kristen">Kristen Shinohara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jansen:Alex">Alex Jansen</a></p>
<p>Abstract:
Fitts' law (1954) characterizes pointing speed-accuracy performance as throughput, whose invariance to target distances (A) and sizes (W) is known. However, it is unknown whether throughput and Fitts' law models in general are invariant to task dimensionality (1-D vs. 2-D), whether univariate (SDx) or bivariate (SDx,y) endpoint deviation is used, whether throughput is calculated using the mean-of-means approach or the slope-inverse approach, or whether Guiard's (2009) Form - Scale experiment design is used instead of fully crossed A-W factors. We empirically investigate the confluence of these issues, finding that Fitts' law is largely invariant across 1-D and 2-D, provided that univariate endpoint deviation (SDx) is used in both, but that for 2-D pointing data, bivariate endpoint deviation (SDx,y) results in better Fitts' law models. Also, the mean-of-means throughput calculation exhibits lower variance across subjects and dimensionalities than the slope-inverse calculation. In light of these and other findings, we offer recommendations for pointing evaluations, especially in 2-D. We also offer an evaluation tool called Fitts Study to facilitate comparisons.</p>
<p>Keywords:
Fitt's Law; Fittsstudy; dimensionality; effective target width; endpoint deviation; throughput</p>
<h3 id="191. The effects of intended use on target acquisition.">191. The effects of intended use on target acquisition.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979182">Paper Link</a>    Pages:1649-1652</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lough:Calvin">Calvin Lough</a></p>
<p>Abstract:
Fitts's Law has been used extensively in HCI to describe 2D targeting; however, the controlled tasks generally used neglect aspects of real-world pointing, including how the intended use of a target affects its acquisition. We studied aiming to a target in four tasks requiring varying precision after acquisition. Our results present the first evidence that the intended use of a target affects its acquisition in terms of movement time and motion kinematics for computer aiming. Important for researchers who model 2D targeting, our results also have particular impact for HCI research that uses motion kinematics.</p>
<p>Keywords:
fitt's law; intention; motion kinematics; pointing</p>
<h3 id="192. Modeling and predicting pointing errors in two dimensions.">192. Modeling and predicting pointing errors in two dimensions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979183">Paper Link</a>    Pages:1653-1656</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jansen:Alex">Alex Jansen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shinohara:Kristen">Kristen Shinohara</a></p>
<p>Abstract:
Recently, Wobbrock et al. (2008) derived a predictive model of pointing accuracy to complement Fitts' law's predictive model of pointing speed. However, their model was based on one-dimensional (1-D) horizontal movement, while applications of such a model require two dimensions (2-D). In this paper, the pointing error model is investigated for 2-D pointing in a study of 21 participants performing a time-matching task on the ISO 9241-9 ring-of-circles layout. Results show that the pointing error model holds well in 2-D. If univariate endpoint deviation (SDx) is used, regressing on N=72 observed vs. predicted error rate points yields R2=.953. If bivariate endpoint deviation (SDx,y) is used, regression yields R2=.936. For both univariate and bivariate models, the magnitudes of observed and predicted error rates are comparable.</p>
<p>Keywords:
Fitt's Law; error prediction; error rates; metronome; movement time; pointing error model</p>
<h2 id="Evaluation and/or design based on many users    3">Evaluation and/or design based on many users    3</h2>
<h3 id="193. Into the wild: challenges and opportunities for field trial methods.">193. Into the wild: challenges and opportunities for field trial methods.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979185">Paper Link</a>    Pages:1657-1666</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brown:Barry_A=_T=">Barry A. T. Brown</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reeves:Stuart">Stuart Reeves</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sherwood:Scott">Scott Sherwood</a></p>
<p>Abstract:
Field trials of experimental systems in the wild have developed into a standard method within HCI - testing new systems with groups of users in relatively unconstrained settings outside of the laboratory. In this paper we discuss methodological challenges in running user trials. Using a trial of trials we examined the practices of investigators and participants - documenting demand characteristics, where users adjust their behaviour to fit the expectations of those running the trial, the interdependence of how trials are run and the result they produce, and how trial results can be dependent on the insights of a subset of trial participants. We develop three strategies that researchers can use to leverage these challenges to run better trials.</p>
<p>Keywords:
demand characteristics; ethnography.; field trials; methods</p>
<h3 id="194. When a little knowledge isn't a dangerous thing.">194. When a little knowledge isn't a dangerous thing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979186">Paper Link</a>    Pages:1667-1676</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/O=Neill:Jacki">Jacki O'Neill</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Martin_0001:David_B=">David B. Martin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Colombino:Tommaso">Tommaso Colombino</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grasso:Antonietta">Antonietta Grasso</a></p>
<p>Abstract:
In this paper we compare two departments of a public administration body carrying out similar work. In one department two sections, telephony and processing, are collocated whereas in the other they are not. We demonstrate the costs of distribution, in particular how the strictly enforced division of labour and limited visibility onto the workflow of the other section causes problems when dealing with normal, natural exceptions. The setting is one of seemingly routine bureaucratic work rather than high-skilled cooperative work, thus the impact of distribution might be considered rather surprising. We argue that a key requirement for any solution is to enable practitioners on the 'shop floor' the freedom to find elegant solutions to problems.</p>
<p>Keywords:
call centres; collocation; distributed work; ethnography; public administration</p>
<h3 id="195. Field trial of Tiramisu: crowd-sourcing bus arrival times to spur co-design.">195. Field trial of Tiramisu: crowd-sourcing bus arrival times to spur co-design.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979187">Paper Link</a>    Pages:1677-1686</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tomasic:Anthony">Anthony Tomasic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Garrod:Charles">Charles Garrod</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yoo:Daisy">Daisy Yoo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hiruncharoenvate:Chaya">Chaya Hiruncharoenvate</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aziz:Rafae">Rafae Aziz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thiruvengadam:Nikhil_Ravi">Nikhil Ravi Thiruvengadam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Yun">Yun Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steinfeld:Aaron">Aaron Steinfeld</a></p>
<p>Abstract:
Crowd-sourcing social computing systems represent a new material for HCI designers. However, these systems are difficult to work with and to prototype, because they require a critical mass of participants to investigate social behavior. Service design is an emerging research area that focuses on how customers co-produce the services that they use, and thus it appears to be a great domain to apply this new material. To investigate this relationship, we developed Tiramisu, a transit information system where commuters share GPS traces and submit problem reports. Tiramisu processes incoming traces and generates real-time arrival time predictions for buses. We conducted a field trial with 28 participants. In this paper we report on the results and reflect on the use of field trials to evaluate crowd-sourcing prototypes and on how crowd sourcing can generate co-production between citizens and public services.</p>
<p>Keywords:
crowd-sourcing; field trial; service design; transit</p>
<h2 id="Homeless users    3">Homeless users    3</h2>
<h3 id="196. Publics in practice: ubiquitous computing at a shelter for homeless mothers.">196. Publics in practice: ubiquitous computing at a shelter for homeless mothers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979189">Paper Link</a>    Pages:1687-1696</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dantec:Christopher_A=_Le">Christopher A. Le Dantec</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Farrell:Robert_G=">Robert G. Farrell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Christensen:Jim">Jim Christensen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bailey:Mark">Mark Bailey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Ellis:Jason_B=">Jason B. Ellis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kellogg:Wendy_A=">Wendy A. Kellogg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edwards:W=_Keith">W. Keith Edwards</a></p>
<p>Abstract:
Today, commodity technologies like mobile phones - once symbols of status and wealth - have become deeply woven into social and economic participation in Western society. Despite the pervasiveness of these technologies, there remain groups who may not have extensive access to them but who are nonetheless deeply affected by their presence in everyday life. In light of this, we designed, built, and deployed a ubiquitous computing system for one such overlooked group: the staff and residents at a shelter for homeless mothers. Our system connects mobile phones, a shared display, and a Web application to help staff and residents stay connected. We report on the adoption and use of this system over the course of a 30 week deployment, discussing the substantial impact our system had on shelter life and the broader implications for such socio-technical systems that sit at the juncture of social action and organizational coordination.</p>
<p>Keywords:
constructed publics; homeless; longitudinal study; qualitative methods; urban computing</p>
<h3 id="197. Homeless young people and living with personal digital artifacts.">197. Homeless young people and living with personal digital artifacts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979190">Paper Link</a>    Pages:1697-1706</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Woelfer:Jill_Palzkill">Jill Palzkill Woelfer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hendry:David_G=">David G. Hendry</a></p>
<p>Abstract:
This paper reports on an investigation of how homeless young people hold themselves in relation to personal digital artifacts. Twelve participants, aged 19-29, took part in semi-structured interviews. Participants answered questions about the acquisition and disposition of personal artifacts, digital and non-digital, including mobile phones, music players, and wallets. The analysis of the interview transcripts reveals that young people often part with their digital artifacts in order to meet immediate needs, including the need to create and reciprocate goodwill. This contingent holding of personal artifacts illuminates both the ordinary and extraordinary circumstances of homelessness. The paper concludes with a discussion of constraints and implications for the design of information systems for improving the welfare of homeless young people.</p>
<p>Keywords:
access; attachment; homeless young people; iPods; infrastructure; mobile phones; personal digital artifacts</p>
<h3 id="198. Improving the safety of homeless young people with mobile phones: values, form and function.">198. Improving the safety of homeless young people with mobile phones: values, form and function.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979191">Paper Link</a>    Pages:1707-1716</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Woelfer:Jill_Palzkill">Jill Palzkill Woelfer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Iverson:Amy">Amy Iverson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hendry:David_G=">David G. Hendry</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Friedman:Batya">Batya Friedman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gill:Brian_T=">Brian T. Gill</a></p>
<p>Abstract:
By their pervasiveness and by being worn on our bodies, mobile phones seem to have become intrinsic to safety. To examine this proposition, 43 participants, from four stakeholder groups (homeless young people, service providers, police officers, and community members), were asked to consider how homeless young people could use mobile phones to keep safe. Participants were asked to express their knowledge for place-based safety and to envision how mobile phones might be used to improve safety. Detailed analysis of the resulting data, which included value sketches, written value scenarios, and semi-structured discussion, led to specific design opportunities, related to values (e.g., supporting trust and desire to help others), function (e.g., documenting harms for future purposes), and form (e.g., leveraging social expectations for how mobile phones can be used to influence behavior). Together, these findings bound a design space for how mobile phones can be used to manage unsafe situations.</p>
<p>Keywords:
homeless young people; mobile phones; safety; security; value scenarios; value sensitive design; value sketches</p>
<h2 id="Visual analytics    4">Visual analytics    4</h2>
<h3 id="199. Playable data: characterizing the design space of game-y infographics.">199. Playable data: characterizing the design space of game-y infographics.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979193">Paper Link</a>    Pages:1717-1726</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Diakopoulos:Nicholas">Nicholas Diakopoulos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kivran=Swaine:Funda">Funda Kivran-Swaine</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Naaman:Mor">Mor Naaman</a></p>
<p>Abstract:
This work explores the intersection between infographics and games by examining how to embed meaningful visual analytic interactions into game mechanics that in turn impact user behavior around a data-driven graphic. In contrast to other methods of narrative visualization, games provide an alternate method for structuring a story, not bound by a linear arrangement but still providing structure via rules, goals, and mechanics of play. We designed two different versions of a game-y infographic, Salubrious Nation, and compared them to a non-game-y version in an online experiment. We assessed the relative merits of the game-y approach of presentation in terms of exploration of the visualization, insights and learning, and enjoyment of the experience. Based on our results, we discuss some of the benefits and drawbacks of our designs. More generally, we identify challenges and opportunities for further exploration of this new design space.</p>
<p>Keywords:
games; infographics; interaction science; visual analytics</p>
<h3 id="200. Cardiogram: visual analytics for automotive engineers.">200. Cardiogram: visual analytics for automotive engineers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979194">Paper Link</a>    Pages:1727-1736</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sedlmair:Michael">Michael Sedlmair</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Isenberg:Petra">Petra Isenberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baur:Dominikus">Dominikus Baur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mauerer:Michael">Michael Mauerer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pigorsch:Christian">Christian Pigorsch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Butz:Andreas">Andreas Butz</a></p>
<p>Abstract:
We present Cardiogram, a visual analytics system that supports automotive engineers in debugging masses of traces each consisting of millions of recorded messages from in-car communication networks. With their increasing complexity, ensuring these safety-critical networks to be error-free has become a major task and challenge for automotive engineers. To overcome shortcomings of current analysis tools, Cardiogram combines visualization techniques with a data preprocessing approach to automatically reduce complexity based on engineers' domain knowledge. In this paper, we provide the findings from an exploratory, three-year field study within a large automotive company, studying current practices of engineers, the challenges they meet and the characteristics for integrating novel visual analytics tools into their work practices. We then introduce Cardiogram, discuss how our field analysis influenced our design decisions, and present a qualitative, long-term, in-depth evaluation. Results of this study showed that our participants successfully used Cardiogram to increase the amount of analyzable information, to externalize domain knowledge, and to provide new insights into trace data. Our design approach finally led to the adoption of Cardiogram into engineers' daily practices.</p>
<p>Keywords:
automotive; field study; in-car communication; visual analytics; visualization</p>
<h3 id="201. KronoMiner: using multi-foci navigation for the visual exploration of time-series data.">201. KronoMiner: using multi-foci navigation for the visual exploration of time-series data.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979195">Paper Link</a>    Pages:1737-1746</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Jian">Jian Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chevalier:Fanny">Fanny Chevalier</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Balakrishnan:Ravin">Ravin Balakrishnan</a></p>
<p>Abstract:
The need for pattern discovery in long time-series data led researchers to develop interactive visualization tools and analytical algorithms for gaining insight into the data. Most of the literature on time-series data visualization either focus on a small number of tasks or a specific domain. We propose KronoMiner, a tool that embeds new interaction and visualization techniques as well as analytical capabilities for the visual exploration of time-series data. The interface's design has been iteratively refined based on feedback from expert users. Qualitative evaluation with an expert user not involved in the design process indicates that our prototype is promising for further research.</p>
<p>Keywords:
interactive visualization; multi-foci; time-series data; visual exploration</p>
<h3 id="202. LifeFlow: visualizing an overview of event sequences.">202. LifeFlow: visualizing an overview of event sequences.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979196">Paper Link</a>    Pages:1747-1756</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wongsuphasawat:Krist">Krist Wongsuphasawat</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/G=oacute=mez:John_Alexis_Guerra">John Alexis Guerra Gmez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Plaisant:Catherine">Catherine Plaisant</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Taowei_David">Taowei David Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taieb=Maimon:Meirav">Meirav Taieb-Maimon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shneiderman:Ben">Ben Shneiderman</a></p>
<p>Abstract:
Event sequence analysis is an important task in many domains: medical researchers may study the patterns of transfers within the hospital for quality control; transportation experts may study accident response logs to identify best practices. In many cases they deal with thousands of records. While previous research has focused on searching and browsing, overview tasks are often overlooked. We introduce a novel interactive visual overview of event sequences called \emph{LifeFlow}. LifeFlow is scalable, can summarize all possible sequences, and represents the temporal spacing of the events within sequences. Two case studies with healthcare and transportation domain experts are presented to illustrate the usefulness of LifeFlow. A user study with ten participants confirmed that after 15 minutes of training novice users were able to rapidly answer questions about the prevalence and temporal characteristics of sequences, find anomalies, and gain significant insight from the data.</p>
<p>Keywords:
information visualization; overview visualization; temporal categorical data; timestamped event sequences</p>
<h2 id="Photo sharing    4">Photo sharing    4</h2>
<h3 id="203. The photostroller: supporting diverse care home residents in engaging with the world.">203. The photostroller: supporting diverse care home residents in engaging with the world.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979198">Paper Link</a>    Pages:1757-1766</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gaver:William_W=">William W. Gaver</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Boucher:Andy">Andy Boucher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bowers:John">John Bowers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blythe:Mark">Mark Blythe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jarvis:Nadine">Nadine Jarvis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cameron:David_W=_T=">David W. T. Cameron</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kerridge:Tobie">Tobie Kerridge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wilkie:Alex">Alex Wilkie</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Phillips:Robert">Robert Phillips</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wright:Peter_C=">Peter C. Wright</a></p>
<p>Abstract:
The Photostroller is a device designed for use by residents of a care home for older people. It shows a continuous slideshow of photographs retrieved from the Flickr image website using a set of six predefined categories modified by a tuneable degree of 'semantic drift'. In this paper, we describe the design process that led to the Photostroller, and summarise observations made during a deployment in the care home that has lasted over two months at the time of writing. We suggest that the Photostroller balances constraint with openness, and control with drift, to provide an effective resource for the ludic engagement of a diverse group of older people with each other and the world outside their home.</p>
<p>Keywords:
ludic engagement; older people; research through design</p>
<h3 id="204. Automics: souvenir generating photoware for theme parks.">204. Automics: souvenir generating photoware for theme parks.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979199">Paper Link</a>    Pages:1767-1776</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Durrant:Abigail">Abigail Durrant</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rowland:Duncan">Duncan Rowland</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kirk:David_S=">David S. Kirk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benford:Steve">Steve Benford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fischer:Joel_E=">Joel E. Fischer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McAuley:Derek">Derek McAuley</a></p>
<p>Abstract:
Automics is a photo-souvenir service which utilises mobile devices to support the capture, sharing and annotation of digital images amongst groups of visitors to theme parks. The prototype service mixes individual and group photo-capture with existing in-park, on-ride photo services, to allow users to create printed photo-stories. Herein we discuss initial fieldwork in theme parks that grounded the design of Automics, our development of the service prototype, and its real-world evaluation with theme park visitors. We relate our findings on user experience of the service to a literature on mobile photoware, finding implications for the design of souvenir services.</p>
<p>Keywords:
photoware; souvenir; theme park; tourism</p>
<h3 id="205. Contextual dynamics of group-based sharing decisions.">205. Contextual dynamics of group-based sharing decisions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979200">Paper Link</a>    Pages:1777-1786</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Simon_L=">Simon L. Jones</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/O=Neill:Eamonn">Eamonn O'Neill</a></p>
<p>Abstract:
In this paper we investigate how decisions made while using a granular access control mechanism for sharing photographs are influenced by contextual factors and properties relating to the identities of contacts. We develop analytical models using logistic regression to understand relationships between variables that affect sharing decisions. We also investigate how predefined, static groups for privacy control cope with the challenge of sharing large amounts of content associated with numerous different contexts, and test whether they need to be adjusted to suit particular contexts.</p>
<p>Keywords:
context-awareness; photo sharing; privacy; social media</p>
<h3 id="206. Pass-them-around: collaborative use of mobile phones for photo sharing.">206. Pass-them-around: collaborative use of mobile phones for photo sharing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979201">Paper Link</a>    Pages:1787-1796</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lucero:Andr=eacute=s">Andrs Lucero</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Holopainen:Jussi">Jussi Holopainen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jokela:Tero">Tero Jokela</a></p>
<p>Abstract:
In this paper we explore shared collocated interactions with mobile phones. We introduce a phone-based application that allows a small group of collocated people to share photos using the metaphor of passing paper photos around. The prototype encourages people to share their devices and use them interchangeably while discussing photos face-to-face. The prototype supports ad-hoc photo sharing in different contexts by taking into account the spatial arrangement of users around a table, measured with sensors embedded in their mobile phones. Our evaluations show that people are willing to share and connect their mobile phones to engage in collaborative interactions. Participants were able to easily share their collections of photos using our proposed interaction techniques.</p>
<p>Keywords:
collocated interaction; handheld devices; photo sharing.</p>
<h2 id="Web search & usability    5">Web search &amp; usability    5</h2>
<h3 id="207. ClassSearch: facilitating the development of web search skills through social learning.">207. ClassSearch: facilitating the development of web search skills through social learning.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979203">Paper Link</a>    Pages:1797-1806</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Moraveji:Neema">Neema Moraveji</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Meredith_Ringel">Meredith Ringel Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris_0001:Daniel">Daniel Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Czerwinski:Mary">Mary Czerwinski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Riche:Nathalie_Henry">Nathalie Henry Riche</a></p>
<p>Abstract:
We explore the use of social learning - improving knowledge skills by observing peer behavior - in the domain of Web search skill acquisition, focusing specifically on co-located classroom scenarios. Through a series of interviews, pilot studies, and classroom deployments, we conclude that a peripheral display of Web search activity within a classroom facilitates both social learning and teacher-led discourse. We present the ClassSearch system for shared awareness of Web search activity, which embodies principles gleaned from our iterative design process, and show results from a ClassSearch deployment in twelve middle-school classroom sessions. Finally, we highlight design suggestions and opportunities for future work while taxonomizing the space of co-located search pedagogies.</p>
<p>Keywords:
education; search expertise; web search</p>
<h3 id="208. Role of available and provided resources in sensemaking.">208. Role of available and provided resources in sensemaking.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979204">Paper Link</a>    Pages:1807-1816</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sharma:Nikhil">Nikhil Sharma</a></p>
<p>Abstract:
Making sense of a topic often involves appropriating information and organizing themes from various existing resources. We studied how sensemakers appropriated from available online resources as well as artifacts provided by another person directly. We found that both available and provided resources affect sensemaking activities. Sensemakers added more structure in their work when online resources were easily available, but added less structure and information when they were provided relevant sensemaking artifacts from another person. We also studied how early and mature artifacts provided by another person were appropriated differently and found that mature artifacts were rated better and used more but resulted in lesser structure and information being added by the recipient. These findings have implications for the support of sensemaking activities using resources available online as well as artifacts provided by others including co-workers and friends.</p>
<p>Keywords:
collaboration; handoffs; representations; resources; sensemaking; structure</p>
<h3 id="209. Characterizing the usability of interactive applications through query log analysis.">209. Characterizing the usability of interactive applications through query log analysis.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979205">Paper Link</a>    Pages:1817-1826</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fourney:Adam">Adam Fourney</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mann:Richard">Richard Mann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Terry:Michael_A=">Michael A. Terry</a></p>
<p>Abstract:
People routinely rely on Internet search engines to support their use of interactive systems: they issue queries to learn how to accomplish tasks, troubleshoot problems, and otherwise educate themselves on products. Given this common behavior, we argue that search query logs can usefully augment traditional usability methods by revealing the primary tasks and needs of a product's user population. We term this use of search query logs CUTS - characterizing usability through search. In this paper, we introduce CUTS and describe an automated process for harvesting, ordering, labeling, filtering, and grouping search queries related to a given product. Importantly, this data set can be assembled in minutes, is timely, has a high degree of ecological validity, and is arguably less prone to self-selection bias than data gathered via traditional usability methods. We demonstrate the utility of this approach by applying it to a number of popular software and hardware systems.</p>
<p>Keywords:
query log analysis; usability</p>
<h3 id="210. Determining relevancy: how software developers determine relevant information in feeds.">210. Determining relevancy: how software developers determine relevant information in feeds.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979206">Paper Link</a>    Pages:1827-1830</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fritz:Thomas">Thomas Fritz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Murphy:Gail_C=">Gail C. Murphy</a></p>
<p>Abstract:
Finding relevant information within the vast amount of information exchanged via feeds is difficult. Previous research into this problem has largely focused on recommending relevant information based on topicality. By not considering individual and situational factors these approaches fall short. Through a formative, interview-based study, we explored how five software developers determined relevancy of items in two kinds of project news feeds. We identified four factors that the developers used to help determine relevancy and found that placement of items in source code and team contexts can ease the determination of relevancy.</p>
<p>Keywords:
context; interview study; news feeds; relevancy</p>
<h3 id="211. Measuring web page revisitation in tabbed browsing.">211. Measuring web page revisitation in tabbed browsing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979207">Paper Link</a>    Pages:1831-1834</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Haimo">Haimo Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a></p>
<p>Abstract:
Browsing the web has been shown to be a highly recurrent activity. Aimed to optimize the browsing experience, extensive previous research has been carried out on users' revisitation behavior. However, the conventional definition for revisitation, which only considers page loading activities by monitoring http requests initiated by the browser, largely underestimates users' intended revisitation activities with tabbed browsers. Thus, we introduce a goal-oriented definition and a refined revisitation measurement based on page viewings in tabbed browsers. An empirical analysis of statistics taken from a client-side log study showed that although the overall revisitation rate remained relatively constant, tabbed browsing has introduced new behaviors warrant future investigations.</p>
<p>Keywords:
effective revisitation; tabbed browsing; web revisitation</p>
<h2 id="Performing arts    3">Performing arts    3</h2>
<h3 id="212. Evaluating longitudinal projects combining technology with temporal arts.">212. Evaluating longitudinal projects combining technology with temporal arts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979209">Paper Link</a>    Pages:1835-1844</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Latulipe:Celine">Celine Latulipe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carroll:Erin_A=">Erin A. Carroll</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lottridge:Danielle_M=">Danielle M. Lottridge</a></p>
<p>Abstract:
The integration of interactive technology with temporal art such as dance is an exciting, emerging area. The design space for such collaborations is immense, with variations in sensors, visualizations, and how these interact with dancers and choreography. This paper presents the evaluation methodology and results of Dance.Draw, a longitudinal project spanning two years and three productions, which aimed to develop a deep, interdisciplinary understanding of this space. Given that this is pioneering work, there is little guidance on how to evaluate such collaborations. We describe the significant confounds in doing evaluation in this area, and we present our evolving mixed-methods approach, which includes two unique methods to address the multiple stakeholders in a holistic manner: dancer focus groups and repeated presentations. Our approach has generated insights, such as differing perspectives of audience members and the responses of dancers to technological variables. We conclude by discussing the challenges and successes of our evaluation approach.</p>
<p>Keywords:
audience evaluation; creativity; evaluation; interactive dance; performing arts; temporal arts</p>
<h3 id="213. Love, hate, arousal and engagement: exploring audience responses to performing arts.">213. Love, hate, arousal and engagement: exploring audience responses to performing arts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979210">Paper Link</a>    Pages:1845-1854</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Latulipe:Celine">Celine Latulipe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carroll:Erin_A=">Erin A. Carroll</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lottridge:Danielle_M=">Danielle M. Lottridge</a></p>
<p>Abstract:
Understanding audience responses to art and performance is a challenge. New sensors are promising for measurement of implicit and explicit audience engagement. However, the meaning of biometric data, and its relationship to engagement, is unclear. We conceptually explore the audience engagement domain to uncover opportunities and challenges in the assessment and interpretation of audience engagement data. We developed a display that linked performance videos with audience biometric data and presented it to 7 performing arts experts, to explore the measurement, interpretation and application of biometric data. Experts were intrigued by the response data and reflective in interpreting it. We deepened our inquiry with an empirical study with 49 participants who watched a video of a dance performance. We related temporal galvanic skin response (GSR) data to two self-report scales, which provided insights on interpreting this measure. Our findings, which include strong correlations, support the interpretation of GSR as a valid representation of audience engagement.</p>
<p>Keywords:
arousal; audience engagement; audience interaction; galvanic skin response; performing arts</p>
<h3 id="214. Designing from within: humanaquarium.">214. Designing from within: humanaquarium.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979211">Paper Link</a>    Pages:1855-1864</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Robyn">Robyn Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schofield:Guy">Guy Schofield</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shearer:John">John Shearer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wallace:Jayne">Jayne Wallace</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wright:Peter_C=">Peter C. Wright</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Boulanger:Pierre">Pierre Boulanger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
We present an experience-based approach to designing a collaborative interactive performance, humanaquarium. Our research explores public interaction with digital technology through the practice-based inquiry of an inter-disciplinary team of interaction designers and musicians. We present a method of designing experience from within, literally situating ourselves within the performance/use space and assuming the roles both of performers and of designers as we develop and refine the humanaquarium project over the course of a year's worth of public performances.</p>
<p>Keywords:
busking; experience-centered design; ftir; interdisciplinary design; musicianship; participatory performance; practice-based research</p>
<h2 id="Collaboration & creativity    3">Collaboration &amp; creativity    3</h2>
<h3 id="215. The polymath project: lessons from a successful online collaboration in mathematics.">215. The polymath project: lessons from a successful online collaboration in mathematics.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979213">Paper Link</a>    Pages:1865-1874</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cranshaw:Justin">Justin Cranshaw</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a></p>
<p>Abstract:
Although science is becoming increasingly collaborative, there are remarkably few success stories of online collaborations between professional scientists that actually result in real discoveries. A notable exception is the Polymath Project, a group of mathematicians who collaborate online to solve open mathematics problems. We provide an in-depth descriptive history of Polymath, using data analysis and visualization to elucidate the principles that led to its success, and the difficulties that must be addressed before the project can be scaled up. We find that although a small percentage of users created most of the content, almost all users nevertheless contributed some content that was highly influential to the task at hand. We also find that leadership played an important role in the success of the project. Based on our analysis, we present a set of design suggestions for how future collaborative mathematics sites can encourage and foster newcomer participation.</p>
<p>Keywords:
large-scale collaboration; online collaborative mathematics; online collaborative science; online communities</p>
<h3 id="216. Collaborative creativity: a complex systems model with distributed affect.">216. Collaborative creativity: a complex systems model with distributed affect.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979214">Paper Link</a>    Pages:1875-1884</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Aragon:Cecilia_R=">Cecilia R. Aragon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williams:Alison">Alison Williams</a></p>
<p>Abstract:
The study of creativity has received significant attention over the past century, with a recent increase in interest in collaborative, distributed creativity. We posit that creativity in distributed groups is fostered by software interfaces that specifically enable socio-emotional or affective communication. However, previous work on creativity and affect has primarily focused on the individual, while group creativity research has concentrated more on cognition rather than affect. In this paper we propose a new model for creativity in distributed groups, based on the theory of groups as complex systems, that includes affect as well as cognition and that explicitly calls out the interface between individuals as a key parameter of the model. We describe the model, the four stages of collaborative creativity and the causal dynamics in each stage, and demonstrate how affect and interface can facilitate the generation, selection, and amplification of ideas in the various stages of collaborative creativity. We then validate our model with data from three field sites. The data was collected from longitudinal studies of two distributed groups involved in producing creative products--astrophysicists studying supernovae and the expansion rate of the universe and children creating multimedia programming projects online-"-and interviews with staff in a multinational engineering company.</p>
<p>Keywords:
collaborative creativity; computer-mediated communication; creativity model; distributed affect; distributed groups</p>
<h3 id="217. Predicting the perceived quality of online mathematics contributions from users' reputations.">217. Predicting the perceived quality of online mathematics contributions from users' reputations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979215">Paper Link</a>    Pages:1885-1888</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tausczik:Yla_R=">Yla R. Tausczik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pennebaker:James_W=">James W. Pennebaker</a></p>
<p>Abstract:
There are two perspectives on the role of reputation in collaborative online projects such as Wikipedia or Yahoo! Answers. One, user reputation should be minimized in order to increase the number of contributions from a wide user base. Two, user reputation should be used as a heuristic to identify and promote high quality contributions. The current study examined how offline and online reputations of contributors affect perceived quality in MathOverflow, an online community with 3470 active users. On MathOverflow, users post high-level mathematics questions and answers. Community members also rate the quality of the questions and answers. This study is unique in being able to measure offline reputation of users. Both offline and online reputations were consistently and independently related to the perceived quality of authors' submissions, and there was only a moderate correlation between established offline and newly developed online reputation.</p>
<p>Keywords:
community question-answering; information quality; online reputation</p>
<h2 id="Wireless networks    3">Wireless networks    3</h2>
<h3 id="218. Why is my internet slow?: making network speeds visible.">218. Why is my internet slow?: making network speeds visible.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979217">Paper Link</a>    Pages:1889-1898</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chetty:Marshini">Marshini Chetty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haslem:David">David Haslem</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baird:Andrew">Andrew Baird</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Ofoha:Ugochi">Ugochi Ofoha</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sumner:Bethany">Bethany Sumner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grinter:Rebecca_E=">Rebecca E. Grinter</a></p>
<p>Abstract:
With widespread broadband adoption, more households report experiencing sub-optimal speeds. Not only are slow speeds frustrating, they may indicate consumers are not receiving the services they are paying for from their internet service providers. Yet, determining the speed and source of slow-downs is difficult because few tools exist for broadband management. We report on results of a field trial with 10 households using a visual network probe designed to address these problems. We describe the results of the study and provide design implications for future tools. More importantly, we argue that tools like this can educate and empower consumers by making broadband speeds and sources of slow-downs more visible.</p>
<p>Keywords:
broadband speed; broadband tools; home networks</p>
<h3 id="219. GridOrbit: an infrastructure awareness system for increasing contribution in volunteer computing.">219. GridOrbit: an infrastructure awareness system for increasing contribution in volunteer computing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979218">Paper Link</a>    Pages:1899-1908</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hincapi=eacute==Ramos:Juan_David">Juan David Hincapi-Ramos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tabard:Aur=eacute=lien">Aurlien Tabard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardram:Jakob_E=">Jakob E. Bardram</a></p>
<p>Abstract:
The success of a volunteer computing infrastructure depends on the contributions of its users. An example of such an infrastructure is the Mini-Grid, a local peer-to-peer system used for computational analysis of DNA. The speed of analysis increases as more users join the Mini-Grid. However, the invisible nature of such an infrastructure hinders adoption, as it is difficult for users to participate in an infrastructure they are not aware of. This paper introduces GridOrbit, a system designed to increase user awareness, fostering contributions to this infrastructure. We designed GridOrbit using a participatory design process with biologists, and subsequently deployed it for use in a biology laboratory. Our results indicate that the number of contributors to the Mini-Grid increased with the use of awareness technologies. In addition, our analysis presents their motives and behaviors. Finally, a characterization of user interaction with GridOrbit emerged, which enabled us to understand how awareness systems can be better designed. We see GridOrbit as an example of a broader class of technologies designed to create "Infrastructure Awareness" as a means to increase the contributions to technological infrastructures.</p>
<p>Keywords:
ambient displays; infrastructure awareness; infrastructures; public displays; volunteer computing</p>
<h3 id="220. How users associate wireless devices.">220. How users associate wireless devices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979219">Paper Link</a>    Pages:1909-1918</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chong:Ming_Ki">Ming Ki Chong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gellersen:Hans">Hans Gellersen</a></p>
<p>Abstract:
In a wireless world, users can establish connections between devices spontaneously, and unhampered by cables. However, in the absence of cables, what is the natural interaction to connect one device with another? A wide range of device association techniques have been demonstrated, but it has remained an open question what actions users would spontaneously choose for device association. We contribute a study eliciting device association actions from non-technical users without premeditation. Over 700 user-defined actions were collected for 37 different device combinations. We present a classification of user-defined actions, and observations of the users' rationale. Our findings indicate that there is no single most spontaneous action; instead five prominent categories of user-defined actions were found.</p>
<p>Keywords:
device association; input actions; spontaneous interaction; wireless devices</p>
<h2 id="Storytelling & perceptual crossing    3">Storytelling &amp; perceptual crossing    3</h2>
<h3 id="221. ShadowStory: creative and collaborative digital storytelling inspired by cultural heritage.">221. ShadowStory: creative and collaborative digital storytelling inspired by cultural heritage.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979221">Paper Link</a>    Pages:1919-1928</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lv:Fei">Fei Lv</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tian:Feng">Feng Tian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jiang:Yingying">Yingying Jiang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cao:Xiang">Xiang Cao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Luo:Wencan">Wencan Luo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Guang">Guang Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Xiaolong">Xiaolong Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dai:Guozhong">Guozhong Dai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Hongan">Hongan Wang</a></p>
<p>Abstract:
With the fast economic growth and urbanization of many developing countries come concerns that their children now have fewer opportunities to express creativity and develop collaboration skills, or to experience their local cultural heritage. We propose to address these concerns by creating technologies inspired by traditional arts, and allowing children to create and collaborate through playing with them. ShadowStory is our first attempt in this direction, a digital storytelling system inspired by traditional Chinese shadow puppetry. We present the design and implementation of ShadowStory and a 7-day field trial in a primary school. Findings illustrated that ShadowStory promoted creativity, collaboration, and intimacy with traditional culture among children, as well as interleaved children's digital and physical playing experience.</p>
<p>Keywords:
children; collaboration; creativity; cultural heritage; shadow puppet; storytelling</p>
<h3 id="222. Designing for perceptual crossing to improve user involvement.">222. Designing for perceptual crossing to improve user involvement.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979222">Paper Link</a>    Pages:1929-1938</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Deckers:Eva">Eva Deckers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wensveen:Stephan">Stephan Wensveen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ahn:Rene">Rene Ahn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Overbeeke:Kees">Kees Overbeeke</a></p>
<p>Abstract:
In this paper we describe our research on how to design for perceptive activity in artifacts in order for perceptual crossing between subject and artifact to happen. We base our research on the phenomenology of perception [19] and on ecological psychology [10]. Perceptual crossing is believed to be essential to share perception and thereby to feel involved in the situation [5,15]. We propose a theoretical model in which perceptive connections between user, artifact and event are presented. We designed an artifact to function as physical hypotheses [9] and show the design relevance of the model. In an experiment we investigate how the user's feeling of involvement is influenced in relation to differentiations of the proposed theoretical model. The results of our experiment show that indeed perceptual crossing between user and artifact influences the user's feeling of involvement with the artifact in their common space. We conclude with describing several design notions important for designing for perceptive activity in artifacts.</p>
<p>Keywords:
designing for perceptual crossing; phenomenology; research through design</p>
<h3 id="223. Limits of rereadability in procedural interactive stories.">223. Limits of rereadability in procedural interactive stories.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979223">Paper Link</a>    Pages:1939-1948</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mitchell_0001:Alex">Alex Mitchell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McGee:Kevin">Kevin McGee</a></p>
<p>Abstract:
The paper investigates the limits of what authors can vary procedurally to encourage and reward rereadability in procedural hypertext fiction. Exploring these issues raises a methodological challenge: how do we study re-reading in the context of stories that change? We have developed an adapted form of the Piagetan clinical interview to do this. Using this approach, we have determined that readers, surprisingly, do not want to experience endless variation when rereading interactive stories. Instead, they are looking for some form of closure, either in terms of "understanding the story", reaching the "best ending" for the characters in the story, or finding the "most interesting" version of the story. This has implications for the design/authoring of interactive stories and interactive art and entertainment.</p>
<p>Keywords:
interactive storytelling; narrative closure; procedural hypertext; qualitative research methodologies; rereadability</p>
<h2 id="Emergency response & scheduling    3">Emergency response &amp; scheduling    3</h2>
<h3 id="224. Rigid structures, independent units, monitoring: organizing patterns in frontline firefighting.">224. Rigid structures, independent units, monitoring: organizing patterns in frontline firefighting.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979225">Paper Link</a>    Pages:1949-1958</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Denef:Sebastian">Sebastian Denef</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Keyson:David_V=">David V. Keyson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oppermann:Reinhard">Reinhard Oppermann</a></p>
<p>Abstract:
Providing firefighters working on the frontline of interventions with ubiquitous computing support remains an open challenge. Designing meaningful solutions for this complex work environment requires reflective thought and conceptual understanding of its social configuration. This paper presents organizing patterns of firefighting frontline practice as a means to inform ubiquitous computing design processes. The patterns originate from a qualitative analysis of an extensive range of user studies conducted with French and German firefighters. As the patterns show, firefighting on the frontline is based on a rigid structure that gains its flexibility through independent units whose safety is ensured by a number of monitoring activities. We conclude that the interaction between the presented patterns forms a balanced whole and needs to be recognized by ubiquitous computing design.</p>
<p>Keywords:
ethnography; firefighting; pattern research; safety-critical work; ubiquitous computing</p>
<h3 id="225. Zero-fidelity simulation of fire emergency response: improving team coordination learning.">225. Zero-fidelity simulation of fire emergency response: improving team coordination learning.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979226">Paper Link</a>    Pages:1959-1968</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Toups:Zachary_O=">Zachary O. Toups</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kerne:Andruid">Andruid Kerne</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hamilton:William_A=">William A. Hamilton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shahzad:Nabeel">Nabeel Shahzad</a></p>
<p>Abstract:
Fire emergency responders rely on team coordination to survive and succeed in high-stress environments, but traditional education does not directly teach these essential skills. Prior simulations seek the highest possible fidelity, employing resources to capture concrete characteristics of operating environments. We take a different tack, hypothesizing that a zero-fidelity approach, focusing on human-centered aspects of work practice, will improve team coordination learning. Such an approach promotes simulation focus by developing an alternative environment that stimulates participants to engage in distributed cognition. The costs of simulation development are reduced. To supplement preparation for burn training exercises, 28 fire emergency response students played the Teaching Team Coordination game (T2eC), a zero-fidelity simulation of the distributed cognition of fire emergency response work practice. To test our hypothesis, we develop quantitative evaluation methods for impact on team coordination learning through measures of communication efficiency and cooperative activity. Results show that participants improve cooperation, become more efficient communicators, differentiate team roles through communication, and leverage multiple communication modalities. Given the context of the study amidst the educational process, qualitative data from the students and their expert instructor supports the ecological validity of the contribution of the T2eC zero-fidelity simulation to fire emergency response education.</p>
<p>Keywords:
distributed cognition; education; emergency response; games; implicit coordination; zero-fidelity simulation</p>
<h3 id="226. Kairoscope: managing time perception and scheduling through social event coordination.">226. Kairoscope: managing time perception and scheduling through social event coordination.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979227">Paper Link</a>    Pages:1969-1978</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Martin:Reed">Reed Martin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Holtzman:Henry">Henry Holtzman</a></p>
<p>Abstract:
If everyone says time is relative, why is it still so rigidly defined? There have been many attempts to address the issue of coordinating schedules, but each of these attempts runs into an issue of rigidity: in order to negotiate an event, a specific time must be designated in advance. This model is inherently poor at accommodating life's unpredictability. Kairoscope looks at time from a human perspective, focusing on time as made up of a series of events, rather than simply a series of events in time. By removing our reliance on a fixed time system, events are coordinated socially and on the fly, without worrying about precision. This paper explores the creation of Kairoscope, rooted in ideas of time perception and aiming to reduce time-related stress, optimize time usage, and increase social interaction. The result is a socially-coordinated, constantly adapting, and highly malleable guide through time.</p>
<p>Keywords:
agents and intelligent systems; automated planning and scheduling; social computing; social time</p>
<h2 id="Learning    2">Learning    2</h2>
<h3 id="227. Practical, appropriate, empirically-validated guidelines for designing educational games.">227. Practical, appropriate, empirically-validated guidelines for designing educational games.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979229">Paper Link</a>    Pages:1979-1988</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Linehan:Conor">Conor Linehan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kirman:Ben">Ben Kirman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lawson:Shaun_W=">Shaun W. Lawson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chan:Gail">Gail Chan</a></p>
<p>Abstract:
There has recently been a great deal of interest in the potential of computer games to function as innovative educational tools. However, there is very little evidence of games fulfilling that potential. Indeed, the process of merging the disparate goals of education and games design appears problematic, and there are currently no practical guidelines for how to do so in a coherent manner. In this paper, we describe the successful, empirically validated teaching methods developed by behavioural psychologists and point out how they are uniquely suited to take advantage of the benefits that games offer to education. We conclude by proposing some practical steps for designing educational games, based on the techniques of Applied Behaviour Analysis. It is intended that this paper can both focus educational games designers on the features of games that are genuinely useful for education, and also introduce a successful form of teaching that this audience may not yet be familiar with.</p>
<p>Keywords:
applied behaviour analysis; behavioural psychology; education; educational games; games design; psychology; serious games</p>
<h3 id="228. The mathematical imagery trainer: from embodied interaction to conceptual learning.">228. The mathematical imagery trainer: from embodied interaction to conceptual learning.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979230">Paper Link</a>    Pages:1989-1998</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Howison:Mark">Mark Howison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Trninic:Dragan">Dragan Trninic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reinholz:Daniel">Daniel Reinholz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Abrahamson:Dor">Dor Abrahamson</a></p>
<p>Abstract:
We introduce an embodied-interaction instructional design, the Mathematical Imagery Trainer (MIT), for helping young students develop grounded understanding of proportional equivalence (e.g., 2/3 = 4/6). Taking advantage of the low-cost availability of hand-motion tracking provided by the Nintendo Wii remote, the MIT applies cognitive-science findings that mathematical concepts are grounded in mental simulation of dynamic imagery, which is acquired through perceiving, planning, and performing actions with the body. We describe our rationale for and implementation of the MIT through a design-based research approach and report on clinical interviews with twenty-two 4th-6th grade students who engaged in problem-solving tasks with the MIT.</p>
<p>Keywords:
Wii remote; design-based research; educational technology; embodied cognition; mathematics education</p>
<h2 id="Time/animations    2">Time/animations    2</h2>
<h3 id="229. Kineticons: using iconographic motion in graphical user interface design.">229. Kineticons: using iconographic motion in graphical user interface design.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979232">Paper Link</a>    Pages:1999-2008</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Chris">Chris Harrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hsieh:Gary">Gary Hsieh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Willis:Karl_D=_D=">Karl D. D. Willis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hudson:Scott_E=">Scott E. Hudson</a></p>
<p>Abstract:
Icons in graphical user interfaces convey information in a mostly universal fashion that allows users to immediately interact with new applications, systems and devices. In this paper, we define Kineticons - an iconographic scheme based on motion. By motion, we mean geometric manipulations applied to a graphical element over time (e.g., scale, rotation, deformation). In contrast to static graphical icons and icons with animated graphics, kineticons do not alter the visual content or "pixel-space" of an element. Although kineticons are not new - indeed, they are seen in several popular systems - we formalize their scope and utility. One powerful quality is their ability to be applied to GUI elements of varying size and shape from a something as small as a close button, to something as large as dialog box or even the entire desktop. This allows a suite of system-wide kinetic behaviors to be reused for a variety of uses. Part of our contribution is an initial kineticon vocabulary, which we evaluated in a 200 participant study. We conclude with discussion of our results and design recommendations.</p>
<p>Keywords:
animation; gui; icons; kinetic; look and feel</p>
<h3 id="230. Temporal distortion for animated transitions.">230. Temporal distortion for animated transitions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979233">Paper Link</a>    Pages:2009-2018</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dragicevic:Pierre">Pierre Dragicevic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bezerianos:Anastasia">Anastasia Bezerianos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Javed:Waqas">Waqas Javed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Elmqvist:Niklas">Niklas Elmqvist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fekete:Jean=Daniel">Jean-Daniel Fekete</a></p>
<p>Abstract:
Animated transitions are popular in many visual applications but they can be difficult to follow, especially when many objects move at the same time. One informal design guideline for creating effective animated transitions has long been the use of slow-in/slow-out pacing, but no empirical data exist to support this practice. We remedy this by studying object tracking performance under different conditions of temporal distortion, i.e., constant speed transitions, slow-in/slow-out, fast-in/fast-out, and an adaptive technique that slows down the visually complex parts of the animation. Slow-in/slow-out outperformed other techniques, but we saw technique differences depending on the type of visual transition.</p>
<p>Keywords:
animated transitions; animation; information visualization</p>
<h2 id="Touch 1: tactile & haptics    6">Touch 1: tactile &amp; haptics    6</h2>
<h3 id="231. Tactile brush: drawing on skin with a tactile grid display.">231. Tactile brush: drawing on skin with a tactile grid display.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979235">Paper Link</a>    Pages:2019-2028</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/i/Israr:Ali">Ali Israr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Poupyrev:Ivan">Ivan Poupyrev</a></p>
<p>Abstract:
Tactile Brush is an algorithm that produces smooth, two-dimensional tactile moving strokes with varying frequency, intensity, velocity and direction of motion. The design of the algorithm is derived from the results of psychophysical investigations of two tactile illusions -- apparent tactile mo-tion and phantom sensations. Combined together they allow for the design of high-density two-dimensional tactile displays using sparse vibrotactile arrays. In a series of experiments and evaluations we demonstrate that Tactile Brush is robust and can reliably generate a wide variety of moving tactile sensations for a broad range of applications.</p>
<p>Keywords:
illusions; psychophysics; tactile displays; tactile feedback</p>
<h3 id="232. A comparative study of tactile representation techniques for landmarks on a wearable device.">232. A comparative study of tactile representation techniques for landmarks on a wearable device.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979236">Paper Link</a>    Pages:2029-2038</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Srikulwong:Mayuree">Mayuree Srikulwong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/O=Neill:Eamonn">Eamonn O'Neill</a></p>
<p>Abstract:
Wearable tactile navigation displays may provide an alternative or complement to mobile visual navigation displays. Landmark information may provide a useful complement to directional information for navigation, however, there has been no reported use of landmark information in tactile navigation displays. We report a study that compared two tactile display techniques for landmark representation using one or two actuators respectively. The single-actuator technique generated different vibration patterns on a single actuator to represent different landmarks. The dual-actuator technique generated a single vibration pattern using two simultaneous actuators and different pairs of actuators around the body represented different landmarks. We compared the two techniques on four measures: distinguishability, learnability, short term memorability and user preference. Results showed that users performed equally well when either technique was used to represent landmarks alone. However, when landmark representations were presented together with directional signals, performance with the single-actuator technique was significantly reduced while performance with the dual-actuator technique remained unchanged.</p>
<p>Keywords:
pedestrian navigation; tactile feedback; tactile interface; tactile representation of direction; tactile representation of landmarks; wearable interface</p>
<h3 id="233. Handscope: enabling blind people to experience statistical graphics on websites through haptics.">233. Handscope: enabling blind people to experience statistical graphics on websites through haptics.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979237">Paper Link</a>    Pages:2039-2042</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Da=jung">Da-jung Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lim:Youn=Kyung">Youn-Kyung Lim</a></p>
<p>Abstract:
Statistical graphics on the web such as a tag cloud visually represent statistical data which are generated by website users. While sighted people can scan the latest information through the dynamic changes of statistical graphics, blind people, who cannot perceive them, lose opportunities to keep up to date in this quickly-changing society. In order to enable blind people to experience socially-generated statistical graphics, we propose a new assistive device, namely, Handscope, which translates statistical graphics on websites into simple height changes of its haptic pole. We conducted a two-phase user study with blind people in order to test its usability and explore its effects on the quality of blind users' web experiences. The results show the meaningful contribution of Handscope in extending the area of blind people's web experiences.</p>
<p>Keywords:
blind users; haptic; statistical graphics; web accessibility</p>
<h3 id="234. Nenya: subtle and eyes-free mobile input with a magnetically-tracked finger ring.">234. Nenya: subtle and eyes-free mobile input with a magnetically-tracked finger ring.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979238">Paper Link</a>    Pages:2043-2046</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Ashbrook:Daniel">Daniel Ashbrook</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baudisch:Patrick">Patrick Baudisch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/White:Sean">Sean White</a></p>
<p>Abstract:
We present Nenya, a new input device in the shape of a finger ring. Nenya provides an input mechanism that is always available, fast to access, and allows analog input, while remaining socially acceptable by being embodied in commonly worn items. Users make selections by twisting the ring and "click" by sliding it along the finger. The ring - the size of a regular wedding band - is magnetic, and is tracked by a wrist-worn sensor. Nenya's tiny size, eyes-free usability, and physical form indistinguishable from a regular ring make its use subtle and socially acceptable. We present two user studies (one- and two-handed) in which we studied sighted and eyes-free use, finding that even with no visual feedback users were able to select from eight targets.</p>
<p>Keywords:
eyes-free; finger ring; jewelry; mobile; one-handed; screen-less; subtle; two-handed; wearable; wristwatch</p>
<h3 id="235. The haptic laser: multi-sensation tactile feedback for at-a-distance physical space perception and interaction.">235. The haptic laser: multi-sensation tactile feedback for at-a-distance physical space perception and interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979239">Paper Link</a>    Pages:2047-2050</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/i/Iannacci:Francis">Francis Iannacci</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Turnquist:Erik">Erik Turnquist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Avrahami:Daniel">Daniel Avrahami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Patel:Shwetak_N=">Shwetak N. Patel</a></p>
<p>Abstract:
We present the Haptic Laser, a system for providing a range of tactile sensations to represent a physical environment at-a-distance. The Haptic Laser is a handheld device that simulates interaction with physical surfaces as a user targets objects of interest (e.g., a light switch, TV, etc). Using simple computer vision techniques for scene analysis and laser range finding for calculating distance, the Haptic Laser extracts information about the physical environment and conveys it haptically through a collection of hardware actuators. Pointing the Haptic Laser around a room, for example, presents the user with information about the presence of objects, transitions, and edges through touch rather than, or in addition to, vision. The Haptic Laser extends current work on haptic touch screens and pens, and is designed to allow for haptic feedback from a distance using multiple feedback channels.</p>
<p>Keywords:
at-a-distance interaction; computer vision; haptic feedback; motor control; ubiquitous computing</p>
<h3 id="236. Interactive generator: a self-powered haptic feedback device.">236. Interactive generator: a self-powered haptic feedback device.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979240">Paper Link</a>    Pages:2051-2054</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Badshah:Akash">Akash Badshah</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gupta:Sidhant">Sidhant Gupta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cohn:Gabe">Gabe Cohn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Villar:Nicolas">Nicolas Villar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hodges:Steve">Steve Hodges</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Patel:Shwetak_N=">Shwetak N. Patel</a></p>
<p>Abstract:
We present Interactive Generator (InGen), a self-powered wireless rotary input device capable of generating haptic or force feedback without the need for any external power source. Our approach uses a modified servomotor to perform three functions: (1) generating power for wireless communication and embedded electronics, (2) sensing the direction and speed of rotation, and (3) providing force feedback during rotation. While InGen is rotating, the device is capable of providing the sensation of detents or bumps, changes in stiffness, and abrupt stops using only power that is harvested during interaction. We describe the device in detail, demonstrate an initial 'TV remote control' application, and end with a discussion of our experiences developing the prototype and application. To the best of our knowledge, InGen is the first self-powered device, which also provides haptic feedback during operation. More broadly, this work demonstrates a new class of input sys-tems that uses human-generated power to provide feedback to the user and wirelessly communicate sensed information.</p>
<p>Keywords:
force feedback; haptics; human-powered; remote control; self-powered; tactile feedback; user interface device</p>
<h2 id="Security (systems)    4">Security (systems)    4</h2>
<h3 id="237. Security through a different kind of obscurity: evaluating distortion in graphical authentication schemes.">237. Security through a different kind of obscurity: evaluating distortion in graphical authentication schemes.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979242">Paper Link</a>    Pages:2055-2064</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hayashi:Eiji">Eiji Hayashi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jason_I=">Jason I. Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Christin:Nicolas">Nicolas Christin</a></p>
<p>Abstract:
While a large body of research on image-based authentication has focused on memorability, comparatively less attention has been paid to the new security challenges these schemes may introduce. Because images can convey more information than text, image-based authentication may be more vulnerable to educated guess attacks than passwords. In this paper, we evaluate the resilience of a recognition-based graphical authentication scheme using distorted images against two types of educated guess attacks through two user studies. The first study, consisting of 30 participants, investigates whether distortion prevents educated guess attacks primarily based on information about individual users. The second study, using Amazon Mechanical Turk, investigates whether distortion mitigates the risk of educated guess attacks based on collective information about users. Our results show that authentication images without distortion are vulnerable to educated guess attacks, especially when information about the target is known, and that distortion makes authentication images more resilient against educated guess attacks.</p>
<p>Keywords:
educated guess attack; graphical authentication; user authentication</p>
<h3 id="238. More than skin deep: measuring effects of the underlying model on access-control system usability.">238. More than skin deep: measuring effects of the underlying model on access-control system usability.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979243">Paper Link</a>    Pages:2065-2074</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Reeder:Robert_W=">Robert W. Reeder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bauer:Lujo">Lujo Bauer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranor:Lorrie_Faith">Lorrie Faith Cranor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reiter:Michael_K=">Michael K. Reiter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vaniea:Kami">Kami Vaniea</a></p>
<p>Abstract:
In access-control systems, policy rules conflict when they prescribe different decisions (allow or deny) for the same access. We present the results of a user study that demonstrates the significant impact of conflict-resolution method on policy-authoring usability. In our study of 54 participants, varying the conflict-resolution method yielded statistically significant differences in accuracy in five of the six tasks we tested, including differences in accuracy rates of up to 78%. Our results suggest that a conflict-resolution method favoring rules of smaller scope over rules of larger scope is more usable than the Microsoft Windows operating system's method of favoring deny rules over allow rules. Perhaps more importantly, our results demonstrate that even seemingly small changes to a system's semantics can fundamentally affect the system's usability in ways that are beyond the power of user interfaces to correct.</p>
<p>Keywords:
access control; home computing; human factors; privacy; security</p>
<h3 id="239. Does domain highlighting help people identify phishing sites?">239. Does domain highlighting help people identify phishing sites?</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979244">Paper Link</a>    Pages:2075-2084</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lin:Eric">Eric Lin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Greenberg:Saul">Saul Greenberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Trotter:Eileah">Eileah Trotter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Ma:David">David Ma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aycock:John">John Aycock</a></p>
<p>Abstract:
Phishers are fraudsters that mimic legitimate websites to steal user's credenfitial information and exploit that information for identity theft and other criminal activities. Various anti-phishing techniques attempt to mitigate such attacks. Domain highlighting is one such approach recently incorporated by several popular web browsers. The idea is simple: the domain name of an address is highlighted in the address bar, so that users can inspect it to determine a web site's legitimacy. Our research asks a basic question: how well does domain highlighting work? To answer this, we showed 22 participants 16 web pages typical of those targeted for phishing attacks, where participants had to determine the page's legitimacy. In the first round, they judged the page's legitimacy by whatever means they chose. In the second round, they were directed specifically to look at the address bar. We found that participants fell into 3 types in terms of how they determined the legitimacy of a web page; while domain highlighting was somewhat effective for one user type, it was much less effective for others. We conclude that domain highlighting, while providing some benefit, cannot be relied upon as the sole method to prevent phishing attacks.</p>
<p>Keywords:
domain name highlighting; phishing; usable security</p>
<h3 id="240. Exploring reactive access control.">240. Exploring reactive access control.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979245">Paper Link</a>    Pages:2085-2094</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mazurek:Michelle_L=">Michelle L. Mazurek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Klemperer:Peter_F=">Peter F. Klemperer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shay:Richard">Richard Shay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Takabi:Hassan">Hassan Takabi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bauer:Lujo">Lujo Bauer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranor:Lorrie_Faith">Lorrie Faith Cranor</a></p>
<p>Abstract:
As users store and share more digital content at home, access control becomes increasingly important. One promising approach for helping non-expert users create accurate access policies is reactive policy creation, in which users can update their policy dynamically in response to access requests that would not otherwise succeed. An earlier study suggested reactive policy creation might be a good fit for file access control at home. To test this, we conducted an experience-sampling study in which participants used a simulated reactive access-control system for a week. Our results bolster the case for reactive policy creation as one mode by which home users specify access-control policy. We found both quantitative and qualitative evidence of dynamic, situational policies that are hard to implement using traditional models but that reactive policy creation can facilitate. While we found some clear disadvantages to the reactive model, they do not seem insurmountable.</p>
<p>Keywords:
access control; home computing; human factors; privacy</p>
<h2 id="Home automation    3">Home automation    3</h2>
<h3 id="241. Reflecting on pills and phone use: supporting awareness of functional abilities for older adults.">241. Reflecting on pills and phone use: supporting awareness of functional abilities for older adults.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979247">Paper Link</a>    Pages:2095-2104</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Matthew_L=">Matthew L. Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dey:Anind_K=">Anind K. Dey</a></p>
<p>Abstract:
Older adults often struggle with maintaining self-aware of their ability to carry out everyday activities important for independence. Unobtrusive sensors embedded in the home can monitor how older adults interact with objects around the home and can provide objective accounts of behaviors to support self-awareness. In this paper, we describe the design and four month deployment of a prototype sensing system that tracks medication taking and phone use in the homes of two older adults. We describe two case studies on 1) how they engaged with the data by looking for and explaining their own anomalous behaviors and 2) how they used the sensor data to reflect on their actions and their own self-awareness of their abilities to remain independent. Finally, we propose recommendations for the design of home sensing systems that support awareness of functional abilities for older adults using reflection.</p>
<p>Keywords:
aging-in-place; awareness; embedded assessment; functional ability; older adults; reflection</p>
<h3 id="242. User-centred multimodal reminders for assistive living.">242. User-centred multimodal reminders for assistive living.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979248">Paper Link</a>    Pages:2105-2114</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McGee=Lennon:Marilyn_Rose">Marilyn Rose McGee-Lennon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wolters:Maria_Klara">Maria Klara Wolters</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a></p>
<p>Abstract:
While there has been a lot of research on the usability of reminders and alarms in the work context, the home has been somewhat neglected despite the importance of reminder systems for telecare and assistive living systems. We conducted a comprehensive mixed-methods study into the requirements for useable and acceptable reminders in the home. The study consisted of a questionnaire (N=379), 6 focus groups, and 7 home tour interviews. Our results highlight the need for highly flexible and contextualized multimodal and multi-device reminder solutions that build on existing successful strategies for remembering in and around the home. We suggest that developers of home care reminder systems should design for diversity, context, priorities, autonomy, shared spaces, and optimal care.</p>
<p>Keywords:
assisted living; focus groups; home tours; multimodal interfaces; personalisation; reminder systems; surveys; telecare</p>
<h3 id="243. Home automation in the wild: challenges and opportunities.">243. Home automation in the wild: challenges and opportunities.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979249">Paper Link</a>    Pages:2115-2124</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brush:A=_J=_Bernheim">A. J. Bernheim Brush</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Bongshin">Bongshin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mahajan:Ratul">Ratul Mahajan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agarwal:Sharad">Sharad Agarwal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Saroiu:Stefan">Stefan Saroiu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dixon:Colin">Colin Dixon</a></p>
<p>Abstract:
Visions of smart homes have long caught the attention of researchers and considerable effort has been put toward enabling home automation. However, these technologies have not been widely adopted despite being available for over three decades. To gain insight into this state of affairs, we conducted semi-structured home visits to 14 households with home automation. The long term experience, both positive and negative, of the households we interviewed illustrates four barriers that need to be addressed before home automation becomes amenable to broader adoption. These barriers are high cost of ownership, inflexibility, poor manageability, and difficulty achieving security. Our findings also provide several directions for further research, which include eliminating the need for structural changes for installing home automation, providing users with simple security primitives that they can confidently configure, and enabling composition of home devices.</p>
<p>Keywords:
domestic technology; home automation; smart home</p>
<h2 id="Sustainability 1    4">Sustainability 1    4</h2>
<h3 id="244. Creek watch: pairing usefulness and usability for successful citizen science.">244. Creek watch: pairing usefulness and usability for successful citizen science.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979251">Paper Link</a>    Pages:2125-2134</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Sunyoung">Sunyoung Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Robson:Christine">Christine Robson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:Thomas">Thomas Zimmerman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pierce:Jeffrey_S=">Jeffrey S. Pierce</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haber:Eben_M=">Eben M. Haber</a></p>
<p>Abstract:
Citizen science projects can collect a wealth of scientific data, but that data is only helpful if it is actually used. While previous citizen science research has mostly focused on designing effective capture interfaces and incentive mechanisms, in this paper we explore the application of HCI methods to ensure that the data itself is useful. To provide a focus for this exploration we designed and implemented Creek Watch, an iPhone application and website that allow volunteers to report information about waterways in order to aid water management programs. Working with state and local officials and private groups involved in water monitoring, we conducted a series of contextual inquiries to uncover what data they wanted, what data they could immediately use, and how to most effectively deliver that data to them. We iteratively developed the Creek Watch application and website based on our findings and conducted evaluations of it with both contributors and consumers of water data, including scientists at the city water resources department. Our study reveals that the data collected is indeed useful for their existing practices and is already in use in water and trash management programs. Our results suggest the application of HCI methods to design the data for the end users is just as important as their use in designing the user interface.</p>
<p>Keywords:
citizen science; iphone; mobile; participatory sensing</p>
<h3 id="245. Designing eco-feedback systems for everyday life.">245. Designing eco-feedback systems for everyday life.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979252">Paper Link</a>    Pages:2135-2144</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Strengers:Yolande_A=_A=">Yolande A. A. Strengers</a></p>
<p>Abstract:
Eco-feedback systems currently frame householders as micro-resource managers, who weigh up the costs and benefits of their consumption, and make autonomous, rational and efficient decisions. Reporting on findings from a qualitative study of three Australian energy and water eco-feedback programs utilising an in-home display (IHD) system, this paper challenges this view. The research finds that householders consume energy and water to carry out everyday practices, such as showering, laundering and cooling, which are mediated by social, cultural, technical and institutional dynamics. The paper proposes an alternative design paradigm for eco-feedback systems premised on the realities of everyday life and identifies several design directions that emerge from this new starting point.</p>
<p>Keywords:
consumption; demand management; eco-feedback; energy; smart meters; sustainable hci; water</p>
<h3 id="246. BeeParking: feedback interfaces for collective behavior change.">246. BeeParking: feedback interfaces for collective behavior change.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979253">Paper Link</a>    Pages:2145-2148</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gabrielli:Silvia">Silvia Gabrielli</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sabatino:Alessandra">Alessandra Sabatino</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mu=ntilde=oz:Jes=uacute=s">Jess Muoz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marchesoni:Michele">Michele Marchesoni</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mayora:Oscar">Oscar Mayora</a></p>
<p>Abstract:
Recent years have seen a growing interest for the study of feedback interfaces to support behavior change in different research areas, from personal healthcare and wellbeing, to energy saving and proenvironmental sustainability. While HCI design has been primarily inspired by behavior change models that best fit individual change, less attention has been deserved to test their validity in the context of collective behavior change, where interdependencies between people's choices and behaviors matter, as in the shared use of limited resources or public goods. We discuss some relevant directions to fill this gap, based on the iterative design of BeeParking, a feedback display aimed to induce more cooperative use of a parking facility within a work environment.</p>
<p>Keywords:
behavior change; feedback interfaces; interaction design; persuasive computing</p>
<h3 id="247. GreenHat: exploring the natural environment through experts' perspectives.">247. GreenHat: exploring the natural environment through experts' perspectives.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979254">Paper Link</a>    Pages:2149-2152</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ryokai:Kimiko">Kimiko Ryokai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oehlberg:Lora">Lora Oehlberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Manoochehri:Michael">Michael Manoochehri</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agogino:Alice_M=">Alice M. Agogino</a></p>
<p>Abstract:
We present GreenHat, an interactive mobile learning application that helps students learn about biodiversity and sustainability issues in their surroundings from experts' points of view, before participating in unfamiliar debates about their familiar surroundings. Using the interactive location-sensitive map and video on a smart phone, GreenHat simulates how experts go about making observations in the field and encourages students to actively observe their environment. We present our design process, our initial prototype, report the results from our preliminary evaluation, and discuss ongoing work.</p>
<p>Keywords:
biodiversity; expert perspectives; location-based information; mobile learning; sustainability</p>
<h2 id="Mobile issues    3">Mobile issues    3</h2>
<h3 id="248. Telling calls: facilitating mobile phone conversation grounding and management.">248. Telling calls: facilitating mobile phone conversation grounding and management.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979256">Paper Link</a>    Pages:2153-2162</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Grandhi:Sukeshini_A=">Sukeshini A. Grandhi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schuler:Richard_P=">Richard P. Schuler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Quentin">Quentin Jones</a></p>
<p>Abstract:
Current cell phone designs are limited by the information a caller can provide to the receiver at the time of a call. As a result callers are handicapped in effectively negotiating interaction commitment from the receiver, and perhaps more importantly, receivers are unable to make informed call handling decisions. To examine the nature of this information gap we 1) developed Telling Calls, a mobile phone application which allows users to provide and receive information such as what the call is about and the circumstances of the caller under which it is being made, and 2) conducted a qualitative field study (36 users) and a quantitative field study (30 users) of Telling Calls use. Together these studies provide insights on how additional caller generated information shared at the time of call handling effectively improves the process of negotiating interaction commitment, and establishing common ground.</p>
<p>Keywords:
availability; cell phone; communication; design; grounding; interruption; management; outeraction; response</p>
<h3 id="249. Deep shot: a framework for migrating tasks across devices using mobile phone cameras.">249. Deep shot: a framework for migrating tasks across devices using mobile phone cameras.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979257">Paper Link</a>    Pages:2163-2172</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chang:Tsung=Hsiang">Tsung-Hsiang Chang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a></p>
<p>Abstract:
A user task often spans multiple heterogeneous devices, e.g., working on a PC in the office and continuing the work on a laptop or a mobile phone while commuting on a shuttle. However, there is a lack of support for users to easily migrate their tasks across devices. To address this problem, we created Deep Shot, a framework for capturing the user's work state that is needed for a task (e.g., the specific part of a webpage being viewed) and resuming it on a different device. In particular, Deep Shot supports two novel and intuitive interaction techniques, deep shooting and deep posting, for pulling and pushing work states, respectively, using a mobile phone camera. In addition, Deep Shot provides a concise API for developers to leverage its services and make their application states migratable. We demonstrated that Deep Shot can be used to support a range of everyday tasks migrating across devices. An evaluation consisting of a series of experiments showed that our framework and techniques are feasible.</p>
<p>Keywords:
camera; computer vision; mobile interaction; multi-device environment; task migration.</p>
<h3 id="250. Eyes-free multitasking: the effect of cognitive load on mobile spatial audio interfaces.">250. Eyes-free multitasking: the effect of cognitive load on mobile spatial audio interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979258">Paper Link</a>    Pages:2173-2176</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vazquez=Alvarez:Yolanda">Yolanda Vazquez-Alvarez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a></p>
<p>Abstract:
As mobile devices increase in functionality, users perform more tasks when on the move. Spatial audio interfaces offer a solution for eyes-free interaction. However, such interfaces face a number of challenges when supporting multiple and simultaneous tasks, namely: 1) interference amongst multiple audio streams, and 2) the constraints of cognitive load. We present a comparative study of spatial audio techniques evaluated in a divided- and selective-attention task. A podcast was used for high cognitive load (divided-attention) and classical music for low cognitive load (selective-attention), while interacting with an audio menu. Results showed that spatial audio techniques were preferred when cognitive load was kept low, while a baseline technique using an interruptible single audio stream was significantly less preferred. Conversely, when cognitive load was increased the preferences reversed. Thus, given an appropriate task structure, spatial techniques offer a means of designing effective audio interfaces to support eyes-free mobile multitasking.</p>
<p>Keywords:
audio interfaces; cognitive load; divided-attention task; eyes-free interaction; multitasking; selective-attention task</p>
<h2 id="Website & application design    5">Website &amp; application design    5</h2>
<h3 id="251. Feedlack detects missing feedback in web applications.">251. Feedlack detects missing feedback in web applications.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979260">Paper Link</a>    Pages:2177-2186</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Ko:Andrew_J=">Andrew J. Ko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Xing">Xing Zhang</a></p>
<p>Abstract:
While usability methods such as user studies and inspections can reveal a wide range of problems, they do so for only a subset of an application's features and states. We present FeedLack, a tool that explores the full range of web applications' behaviors for one class of usability problems, namely that of missing feedback. It does this by enumerating control flow paths originating from user input, identifying paths that lack output-affecting code. FeedLack was applied to 330 applications; of the 129 that contained input handlers and did not contain syntax errors, 115 were successfully analyzed, resulting in 647 warnings. Of these 36% were missing crucial feedback; 34% were executable and missing feedback, but followed conventions that made feedback inessential; 18% were scenarios that did produce feedback; 12% could not be executed. We end with a discussion of the viability of FeedLack as a usability testing tool.</p>
<p>Keywords:
feedback; javascript; program analysis; static analysis</p>
<h3 id="252. Entity-linking interfaces in user-contributed content: preference and performance.">252. Entity-linking interfaces in user-contributed content: preference and performance.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979261">Paper Link</a>    Pages:2187-2196</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dong:Xiao">Xiao Dong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harper:F=_Maxwell">F. Maxwell Harper</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Konstan:Joseph_A=">Joseph A. Konstan</a></p>
<p>Abstract:
The ability to embed links to other resources in user generated content can help authors create more useful and usable content. A variety of interfaces have emerged for entity-linking at popular online sites; such interfaces vary in the way that entity linking is initiated (in-band or out-of-band with respect to the message creation), the timing of entity resolution (interrupting or deferred), and the method of resolving the entity (auto-completion or search). Four interfaces mimicking popular entity linking websites were developed and tested. Results showed that out-of-band initiation (e.g., a link button) was faster to learn, but that in-band initiation performance improved with familiarity. Deferred search was disliked and led to worse performance. And auto-completion was generally preferred to search interfaces.</p>
<p>Keywords:
cross linking; entity reference; user generated content</p>
<h3 id="253. Bricolage: example-based retargeting for web design.">253. Bricolage: example-based retargeting for web design.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979262">Paper Link</a>    Pages:2197-2206</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kumar:Ranjitha">Ranjitha Kumar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Talton:Jerry_O=">Jerry O. Talton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ahmad:Salman">Salman Ahmad</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Klemmer:Scott_R=">Scott R. Klemmer</a></p>
<p>Abstract:
The Web provides a corpus of design examples unparalleled in human history. However, leveraging existing designs to produce new pages is often difficult. This paper introduces the Bricolage algorithm for transferring design and content between Web pages. Bricolage employs a novel, structured-prediction technique that learns to create coherent mappings between pages by training on human-generated exemplars. The produced mappings are then used to automatically transfer the content from one page into the style and layout of another. We show that Bricolage can learn to accurately reproduce human page mappings, and that it provides a general, efficient, and automatic technique for retargeting content between a variety of real Web pages.</p>
<p>Keywords:
examples; retargeting; structured prediction; web design</p>
<h3 id="254. HyperSource: bridging the gap between source and code-related web sites.">254. HyperSource: bridging the gap between source and code-related web sites.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979263">Paper Link</a>    Pages:2207-2210</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hartmann:Bj=ouml=rn">Bjrn Hartmann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dhillon:Mark">Mark Dhillon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chan:Matthew_K=">Matthew K. Chan</a></p>
<p>Abstract:
Programmers frequently use the Web while writing code: they search for libraries, code examples, tutorials, and documentation. This link between code and visited Web pages remains implicit today. Connecting source code and browsing histories might help programmers maintain con-text, reduce the cost of Web page re-retrieval, and enhance understanding when code is shared. This note introduces HyperSource, an IDE augmentation that associates browsing histories with source code edits. HyperSource comprises a browser extension that logs visited pages; an IDE that tracks user activity and maps pages to code edits; a source document model that tracks visited pages at a character level; and a user interface that enables interaction with these histories. We discuss relevance heuristics and privacy issues inherent in this approach. Informal log analyses and user feedback suggest that our annotation model is promising for code editing and might also apply to other document authoring tasks after refinement.</p>
<p>Keywords:
browsing history; code editors; edit wear</p>
<h3 id="255. Item sampling for information architecture.">255. Item sampling for information architecture.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979264">Paper Link</a>    Pages:2211-2214</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Craig_S=">Craig S. Miller</a></p>
<p>Abstract:
When creating a taxonomy for information architecture, practitioners or design participants typically work with a sample of content items to form categories that allow users to successfully navigate to desired information, commands, or items. In order to examine how sample selection affects the coverage of the desired taxonomy, computer simulations were conducted that models the process of sample selection. The simulations reveal how the number of categories, the distribution of items in the taxonomy and the method of selection affect the coverage of a sample at various sizes.</p>
<p>Keywords:
card sorting; information architecture</p>
<h2 id="New approaches to usability    5">New approaches to usability    5</h2>
<h3 id="256. When designing usability questionnaires, does it hurt to be positive?">256. When designing usability questionnaires, does it hurt to be positive?</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979266">Paper Link</a>    Pages:2215-2224</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sauro:Jeff">Jeff Sauro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lewis:James_R=">James R. Lewis</a></p>
<p>Abstract:
When designing questionnaires there is a tradition of including items with both positive and negative wording to minimize acquiescence and extreme response biases. Two disadvantages of this approach are respondents accidentally agreeing with negative items (mistakes) and researchers forgetting to reverse the scales (miscoding). The original System Usability Scale (SUS) and an all positively worded version were administered in two experiments (n=161 and n=213) across eleven websites. There was no evidence for differences in the response biases between the different versions. A review of 27 SUS datasets found 3 (11%) were miscoded by researchers and 21 out of 158 questionnaires (13%) contained mistakes from users. We found no evidence that the purported advantages of including negative and positive items in usability questionnaires outweigh the disadvantages of mistakes and miscoding. It is recommended that researchers using the standard SUS verify the proper coding of scores and include procedural steps to ensure error-free completion of the SUS by users. Researchers can use the all positive version with confidence because respondents are less likely to make mistakes when responding, researchers are less likely to make errors in coding, and the scores will be similar to the standard SUS.</p>
<p>Keywords:
acquiescent bias; satisfaction measures; standardized questionnaires; system usability scale (sus); usability evaluation</p>
<h3 id="257. Synchronous remote usability testing: a new approach facilitated by virtual worlds.">257. Synchronous remote usability testing: a new approach facilitated by virtual worlds.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979267">Paper Link</a>    Pages:2225-2234</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Madathil:Kapil_Chalil">Kapil Chalil Madathil</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Greenstein:Joel_S=">Joel S. Greenstein</a></p>
<p>Abstract:
This study proposes a new methodology for conducting synchronous remote usability studies using a three-dimensional virtual usability testing laboratory built using the Open Wonderland toolkit. This virtual laboratory method is then compared with two other commonly used synchronous usability test methods: the traditional lab approach and WebEx, a web-based conferencing and screen sharing approach. A study was conducted with 48 participants in total, 36 test participants and 12 test facilitators. The test participants completed 5 tasks on a simulated e-commerce website. The three methodologies were compared with respect to the following dependent variables: the time taken to complete the tasks; the usability defects identified; the severity of these usability defects; and the subjective ratings from NASA-TLX, presence and post-test subjective questionnaires. The three methodologies agreed closely in terms of the total number defects identified, number of high severity defects identified and the time taken to complete the tasks. However, there was a significant difference in the workload experienced by the test participants and facilitators, with the traditional lab condition imposing the least and the virtual lab and the WebEx conditions imposing similar levels. It was also found that the test participants experienced greater involvement and a more immersive experience in the virtual world condition than the WebEx condition. These ratings were not significantly different from those in the traditional lab condition. The results of this study suggest that participants were productive and enjoyed the virtual lab condition, indicating the potential of a virtual world based approach as an alternative to the conventional approaches for synchronous usability testing.</p>
<p>Keywords:
remote usability testing; synchronous remote usability testing; virtual worlds</p>
<h3 id="258. Representing users in accessibility research.">258. Representing users in accessibility research.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979268">Paper Link</a>    Pages:2235-2238</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sears:Andrew">Andrew Sears</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hanson:Vicki_L=">Vicki L. Hanson</a></p>
<p>Abstract:
The need to study representative users is widely accepted within the human-computer interaction (HCI) community. While exceptions exist, and alternative populations are sometimes studied, virtually any introduction to the process of designing user interfaces will discuss the importance of understanding the intended users as well as the significant impact individual differences can have on how effectively individuals can use various technologies. HCI researchers are expected to provide relevant demographics regarding study participants as well as information about experience using similar technologies. Yet, in the field of accessibility we continue to see studies that do not appropriately include representative users. Highlighting ways to remedy this multifaceted problem, we argue that expectations regarding how accessibility research is conducted and reported must be raised if this field is to have the desired impact with regard to inclusive design, the information technologies studied, and the lives of the individuals being studied.</p>
<p>Keywords:
accessibility; accessible computing; disabilities; inclusion; older adults; representative users</p>
<h3 id="259. Democratising technology: making transformation using designing, performance and props.">259. Democratising technology: making transformation using designing, performance and props.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979269">Paper Link</a>    Pages:2239-2242</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Light:Ann">Ann Light</a></p>
<p>Abstract:
This study of personal transformation is offered as HCI increasingly seeks to change behavior with persuasive products. Performance-derived improvisation methods were used to inspire a sense of agency with ICT in people marginalized from digital design. A case study of an older person's experience shows the techniques supporting her to reconceive her response to technology. In particular, we analyze how using a "prop" as a design artifact allows her to imagine new possibilities and take a more assertive role.</p>
<p>Keywords:
behavior change; confidence; older people; performance</p>
<h3 id="260. Post-deployment usability: a survey of current practices.">260. Post-deployment usability: a survey of current practices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979270">Paper Link</a>    Pages:2243-2246</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chilana:Parmit_K=">Parmit K. Chilana</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Ko:Andrew_J=">Andrew J. Ko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
Despite the growing research on usability in the pre-development phase, we know little about post-deployment usability activities. To characterize these activities, we surveyed 333 full-time usability professionals and consultants working in large and small corporations from a wide range of industries. Our results show that, as a whole, usability professionals are currently not playing a substantial role in the post-deployment phase compared to other phases of user-centered design, but when they do, practitioners find their interactions quite valuable. We highlight opportunities in HCI research and practice to bridge this gap by working more closely with software support and maintenance teams. We also raise the need to understand what might be called 'usability maintenance,' that is, the process and procedures, by which usability is maintained after deployment.</p>
<p>Keywords:
post-deployment usability; usability practices; usability professionals</p>
<h2 id="Design Methods    4">Design Methods    4</h2>
<h3 id="261. Collaboration personas: a new approach to designing workplace collaboration tools.">261. Collaboration personas: a new approach to designing workplace collaboration tools.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979272">Paper Link</a>    Pages:2247-2256</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Tara">Tara Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moran:Thomas_P=">Thomas P. Moran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yuen:Sandra">Sandra Yuen</a></p>
<p>Abstract:
The success of social computing has generated a host of workplace collaboration tools. However, adoption of these tools by entire groups is a major problem. One reason for the adoption problem is a lack of methods for considering collaborative groups in technology design. Even when designing collaboration tools, designers often employ methods that focus on individuals. This leads to tools that are not well targeted at the groups who will use them. To solve this problem, we propose the notion of collaboration personas, which are empirically derived descriptions of hypothetical groups, including details that inform the design of collaboration tools. Collaboration personas differ from individual personas in having (1) multiple, inter-related individuals playing specific roles; (2) a focus on collective goals and elaboration of individual goals that affect the collective goal; and (3) new attributes that characterize collaborative aspects of the group's work. We contrast collaboration personas with other design approaches and provide examples of how they can be used to design new collaborative tools that better meet the needs of typical groups.</p>
<p>Keywords:
collaboration; design tools; office; personas; workplace</p>
<h3 id="262. From garments to gardens: negotiating material relationships online and 'by hand'.">262. From garments to gardens: negotiating material relationships online and 'by hand'.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979273">Paper Link</a>    Pages:2257-2266</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Goodman:Elizabeth">Elizabeth Goodman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rosner:Daniela">Daniela Rosner</a></p>
<p>Abstract:
From home improvement to scrapbooking, leisure activities performed "by hand" increasingly involve digital tools. In turn, software and devices to support handwork are proliferating. We use data from an observational field study of gardening and knitting to examine relationships to information technology. Handwork experiences of patience, effort, sensation, and cleverness can shift with the introduction of new tools. Our participants' attachment to these experiences made them sensitive to the potential consequences of introducing new tools. Digital tools were sometimes rejected and other times woven into handwork activities. In response, we propose three metaphors for handwork practice - extending, interjecting, and segmenting - as a resource for moving beyond the binary opposition of digital and physical practices.</p>
<p>Keywords:
craft; design theory; gardening; handwork; knitting</p>
<h3 id="263. Persona cases: a technique for grounding personas.">263. Persona cases: a technique for grounding personas.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979274">Paper Link</a>    Pages:2267-2270</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Faily:Shamal">Shamal Faily</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Flechais:Ivan">Ivan Flechais</a></p>
<p>Abstract:
Personas are a popular technique in User-Centered Design, however their validity can be called into question. While the techniques used to developed personas and their integration with other design activities provide some measure of validity, a persona's legitimacy can be threatened by challenging its characteristics. This note presents Persona Cases: personas whose characteristics are both grounded in, and traceable to their originating source of empirical data. This approach builds on the premise that sense-making in qualitative data analysis is an argumentative activity, and aligns concepts associated with a Grounded Theory analysis with recent work on arguing the characteristics of personas. We illustrate this approach using a case study in the Critical Infrastructure Protection domain.</p>
<p>Keywords:
critical infrastructure protection; design rationale; grounded theory; personas</p>
<h3 id="264. When the implication is not to design (technology).">264. When the implication is not to design (technology).</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979275">Paper Link</a>    Pages:2271-2274</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Baumer:Eric_P=_S=">Eric P. S. Baumer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Silberman:M=_Six">M. Six Silberman</a></p>
<p>Abstract:
As HCI is applied in increasingly diverse contexts, it is important to consider situations in which computational or information technologies may be less appropriate. This paper presents a series of questions that can help researchers, designers, and practitioners articulate a technology's appropriateness or inappropriateness. Use of these questions is demonstrated via examples from the literature. The paper concludes with specific arguments for improving the conduct of HCI. This paper provides a means for understanding and articulating the limits of HCI technologies, an important but heretofore under-explored contribution to the field.</p>
<p>Keywords:
design; non-design; reflective hci; sustainability</p>
<h2 id="Decision making & the web    2">Decision making &amp; the web    2</h2>
<h3 id="265. Utility of human-computer interactions: toward a science of preference measurement.">265. Utility of human-computer interactions: toward a science of preference measurement.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979277">Paper Link</a>    Pages:2275-2284</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Toomim:Michael">Michael Toomim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kriplean:Travis">Travis Kriplean</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/P=ouml=rtner:Claus">Claus Prtner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Landay:James_A=">James A. Landay</a></p>
<p>Abstract:
The success of a computer system depends upon a user choosing it, but the field of Human-Computer Interaction has little ability to predict this user choice. We present a new method that measures user choice, and quantifies it as a measure of utility. Our method has two core features. First, it introduces an economic definition of utility, one that we can operationalize through economic experiments. Second, we employ a novel method of crowdsourcing that enables the collection of thousands of economic judgments from real users.</p>
<p>Keywords:
HCI; crowdsourcing; economics; evaluation; mechanical turk; user-interface; utility</p>
<h3 id="266. Informing decisions: how people use online rating information to make choices.">266. Informing decisions: how people use online rating information to make choices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979278">Paper Link</a>    Pages:2285-2294</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lelis:Stelios">Stelios Lelis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Howes:Andrew">Andrew Howes</a></p>
<p>Abstract:
In this paper we investigate how people use online rating information to inform decision making. We examine whether a theory of searching for information to discriminate between alternative choices can explain behavior, and we contrast it to the normative theory. Partly in accord with the theory, findings from a controlled experiment suggest that in an environment dominated by positive reviews, such as the World-Wide Web, people gather more information for the best alternative under consideration, and they take more time to inspect reviews of lower rating. We discuss the theoretical and experimental implications, and propose a bounded optimal account of the way in which people acquire information in service of decision making.</p>
<p>Keywords:
decision making; e-commerce; information search; online consumer reviews; user modeling</p>
<h2 id="Security (social)    4">Security (social)    4</h2>
<h3 id="267. Oops, I did it again: mitigating repeated access control errors on facebook.">267. Oops, I did it again: mitigating repeated access control errors on facebook.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979280">Paper Link</a>    Pages:2295-2304</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Egelman:Serge">Serge Egelman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oates:Andrew">Andrew Oates</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Krishnamurthi:Shriram">Shriram Krishnamurthi</a></p>
<p>Abstract:
We performed a study of Facebook users to examine how they coped with limitations of the Facebook privacy settings interface. Students graduating and joining the workforce create significant problems for all but the most basic privacy settings on social networking websites. We therefore created realistic scenarios exploiting work/play boundaries that required users to specify access control policies that were impossible due to various limitations. We examined whether users were aware of these problems without being prompted, and once given feedback, what their coping strategies were. Overall, we found that simply alerting participants to potential errors was ineffective, but when choices were also presented, participants introduced significantly fewer errors. Based on our findings, we designed a privacy settings interface based on Venn diagrams, which we validated with a usability study. We conclude that this interface may be more effective than the current privacy settings interface.</p>
<p>Keywords:
access control; facebook; policy authoring; privacy; social networks</p>
<h3 id="268. Integrating user feedback with heuristic security and privacy management systems.">268. Integrating user feedback with heuristic security and privacy management systems.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979281">Paper Link</a>    Pages:2305-2314</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Ayyavu:Prashanth">Prashanth Ayyavu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jensen:Carlos">Carlos Jensen</a></p>
<p>Abstract:
Tools aimed at helping users safely navigate the web and safeguard themselves against potential online predators have become reasonably common. Currently there are two families of tools; heuristics analysis tools that test websites directly using automated scripts and programs, and community based tools where users rate websites and write reviews for the benefit of others. In this paper we examine the relative strengths and weaknesses of each technique, whether these techniques are compatible, and how community feedback can be combined with heuristic-based evaluations. In order to do this we conduct a large-scale comparison of the ratings of heuristic and community based tools, and explore novel methods for abstracting key information from user comments, which could be used to add context and nuance to heuristic based ratings. We find that heuristic and community based ratings are highly complementary, and can be combined to potentially guide users to make more informed decisions.</p>
<p>Keywords:
safe surfing tools; social navigation; usable privacy; usable security; user comments; user feedback</p>
<h3 id="269. Pairing devices for social interactions: a comparative usability evaluation.">269. Pairing devices for social interactions: a comparative usability evaluation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979282">Paper Link</a>    Pages:2315-2324</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/u/Uzun:Ersin">Ersin Uzun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Saxena:Nitesh">Nitesh Saxena</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kumar:Arun">Arun Kumar</a></p>
<p>Abstract:
When users wish to establish wireless radio communication between/among their devices, the channel has to be bootstrapped first. The process of setting up a secure communication channel between two previously unassociated devices is referred to as "Secure Device Pairing". The focus of prior research on this topic has mostly been limited to "personal pairing" scenarios, whereby a single user controls both the devices. In this paper, we instead consider "social pairing" scenarios, whereby two different users establish pairing between their respective devices. We present a comprehensive study to identify methods suitable for social pairing, and comparatively evaluate the usability and security of these methods. Our results identify methods best-suited for users, in terms of efficiency, error-tolerance and of course, usability. Our work provides insights on the applicability and usability of methods for emerging social pairing scenarios, a topic largely ignored so far.</p>
<p>Keywords:
secure device pairing; social pairing; usability; usable security</p>
<h3 id="270. Experiencing security in interaction design.">270. Experiencing security in interaction design.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979283">Paper Link</a>    Pages:2325-2334</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mathiasen:Niels_Raabjerg">Niels Raabjerg Mathiasen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/B=oslash=dker:Susanne">Susanne Bdker</a></p>
<p>Abstract:
Security is experienced differently in different contexts. This paper argues that in everyday situations, users base their security decisions on a mix of prior experiences. When approaching security and interaction design from an experience approach, tools that help bring out such relevant experiences for design are needed. This paper reports on how Prompted exploration workshops and Acting out security were developed to target such experiences when iteratively designing a mobile digital signature solution in a participatory design process. We discuss how these tools helped the design process and illustrate how the tangibility of such tools matters. We further demonstrate how the approach grants access to non-trivial insights into people's security experience. We point out how the specific context is essential for exploring the space between experience and expectations, and we illustrate how people activate their collections of security experiences rather than deploying one security strategy in all situations.</p>
<p>Keywords:
acting out security; participatory design; prompted exploration workshops; security; tools</p>
<h2 id="Games    4">Games    4</h2>
<h3 id="271. Building sensitising terms to understand free-play in open-ended interactive art environments.">271. Building sensitising terms to understand free-play in open-ended interactive art environments.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979285">Paper Link</a>    Pages:2335-2344</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Morrison:Ann_Judith">Ann Judith Morrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Viller:Stephen">Stephen Viller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mitchell:Peta">Peta Mitchell</a></p>
<p>Abstract:
In this paper we introduce and discuss the nature of free-play in the context of three open-ended interactive art installation works. We observe the interaction work of situated free-play of the participants in these environments and, building on precedent work, devise a set of sensitising terms derived both from the literature and from what we observe from participants interacting there. These sensitising terms act as guides and are designed to be used by those who experience, evaluate or report on open-ended interactive art. That is, we propose these terms as a common-ground language to be used by participants communicating while in the art work to describe their experience, by researchers in the various stages of research process (observation, coding activity, analysis, reporting, and publication), and by inter-disciplinary researchers working across the fields of HCI and art. This work builds a foundation for understanding the relationship between free-play, open-ended environments, and interactive installations and contributes sensitising terms useful for the HCI community for discussion and analysis of open-ended interactive art works.</p>
<p>Keywords:
common-sense language; free-play; interactive art installation; open-ended; sensitising guides; sensitising terms</p>
<h3 id="272. Evaluating the benefits of 3d stereo in modern video games.">272. Evaluating the benefits of 3d stereo in modern video games.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979286">Paper Link</a>    Pages:2345-2354</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/LaViola_Jr=:Joseph_J=">Joseph J. LaViola Jr.</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Litwiller:Tad">Tad Litwiller</a></p>
<p>Abstract:
We present a study that investigates user performance benefits of 3D stereo in modern video games. Based on an analysis of several video games that are best suited for use with commercial 3D stereo drivers and vision systems, we chose five modern titles focusing on racing, first and third person shooter, and sports game genres. For each game, quantitative and qualitative measures were taken to determine if users performed better and learned faster in the experimental group (3D stereo display) than in the control group (2D display). A game experience pre-questionnaire was used to classify participants into beginner, intermediate, and advanced gameplay categories to ensure prior game experience did not bias the experiment. Our results indicate that although participants preferred playing in 3D stereo for the games we tested, it does not provide any significant advantage in overall user performance. In addition, users' learning rates were comparable in the 3D stereo display and 2D display cases.</p>
<p>Keywords:
3d stereo; evaluation; user performance and experience; video games</p>
<h3 id="273. Target assistance for subtly balancing competitive play.">273. Target assistance for subtly balancing competitive play.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979287">Paper Link</a>    Pages:2355-2364</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bateman:Scott">Scott Bateman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stach:Tadeusz">Tadeusz Stach</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a></p>
<p>Abstract:
In games where skills such as targeting are critical to winning, it is difficult for players with different skill levels to have a competitive and engaging experience. Although several mechanisms for accommodating different skill levels have been proposed, traditional approaches can be too obvious and can change the nature of the game. For games involving aiming, we propose the use of target assistance techniques (such as area cursors, target gravity, and sticky targets) to accommodate skill imbalances. We compared three techniques in a study, and found that area cursors and target gravity significantly reduced score differential in a shooting-gallery game. Further, less skilled players reported having more fun when the techniques helped them be more competitive, and even after they learned assistance was given, felt that this form of balancing was good for group gameplay. Our results show that target assistance techniques can make target-based games more competitive for shared play.</p>
<p>Keywords:
competition; game balance; game design; target assistance</p>
<h3 id="274. Data cracker: developing a visual game analytic tool for analyzing online gameplay.">274. Data cracker: developing a visual game analytic tool for analyzing online gameplay.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979288">Paper Link</a>    Pages:2365-2374</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Medler:Ben">Ben Medler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/John:Michael">Michael John</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lane:Jeff">Jeff Lane</a></p>
<p>Abstract:
Game analytics is a domain that focuses on the systems and methods used to analyze game-related data. In this paper we present how a visual game analytic tool can be developed to analyze player gameplay behavior. Our tool, Data Cracker, was built for monitoring gameplay in Dead Space 2, the latest game in the Dead Space franchise. We use Data Cracker as a case study to inform a larger discussion of designing a visual game analytic tool while working with a game team. Our design approach focuses on increasing the data literacy of a game team. This means getting an entire team interested and involved with game analytics. We found that building our tool during the early game development cycle, creating multiple early visual prototypes and branding the tool to the Dead Space team caused more team members to become interested in our tool. Increasing interest in analytics is also a means, we argue, for changing the common occurrence within the game industry to disband teams after a game is released. Instead, we promote the creation of "live" teams which stay attached to a game long after it is release in order to continue the analysis process. Additionally, we discuss the barriers one might face when developing game analytic tools, such as prejudice against analytics or the technical issues involved when collecting large data sets. All of these examples are presented as insights we gained while coupling analytic tool design to game development.</p>
<p>Keywords:
game analytics; game design; information visualization; player behavior; team communication; visual analytics</p>
<h2 id="Sustainability 2    4">Sustainability 2    4</h2>
<h3 id="275. Ceci n'est pas une pipe bombe: authoring urban landscapes with air quality sensors.">275. Ceci n'est pas une pipe bombe: authoring urban landscapes with air quality sensors.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979290">Paper Link</a>    Pages:2375-2384</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kuznetsov:Stacey">Stacey Kuznetsov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davis:George_Noel">George Noel Davis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cheung:Jian_Chiu">Jian Chiu Cheung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paulos:Eric">Eric Paulos</a></p>
<p>Abstract:
Our work explores the convergence between participatory sensing, political activism and public expressions. Unlike prior research, which focuses on personal sensing, we present low-cost, networked air quality sensors, designed to be repositioned across public landscapes by communities of citizen stakeholders. Our GPS-enabled sensors report dust, exhaust, or VOC's (volatile organic compounds), along with temperature, humidity and light levels to a website that visualizes this data in real time. The sensors can be attached to a variety of surfaces serving as research probes to demarcate ('tag') public spaces with environmental concerns. We deploy our fully functional system with four urban communities - parents, bicyclists, homeless and activists, positioning our system as a tool for studying and supporting community togetherness and public activism. Our findings highlight community sharing of the physical sensors and dialogues surrounding the collected data.</p>
<p>Keywords:
participatory sensing; political computing; urban computing</p>
<h3 id="276. Second-hand interactions: investigating reacquisition and dispossession practices around domestic objects.">276. Second-hand interactions: investigating reacquisition and dispossession practices around domestic objects.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979291">Paper Link</a>    Pages:2385-2394</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pierce:James">James Pierce</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paulos:Eric">Eric Paulos</a></p>
<p>Abstract:
We present a qualitative study of reacquisition-the acquisition of previously possessed goods-involving in-depth interviews with 18 reacquirers within or nearby Pittsburgh, PA, USA. Based on critiques of sustainable consumption and our findings, we reframe technology consumption as acquisition, possession, dispossession and reacquisition. We present four reacquisition orientations describing our participants' motivations and practices: casual, necessary, critical, and experiential. We then present a range of findings including issues with work, time and effort involved in reacquisition, and values and practices of care and patience associated with invested reacquirers. We conclude with implications for designing technologies to support current reacquisition practices, as well as broader opportunities for HCI and interaction design to incorporate non-mainstream reacquisition practices and values into more mainstream technologies.</p>
<p>Keywords:
consumption; design; reacquisition; second-hand; sustainability</p>
<h3 id="277. Practices in the creative reuse of e-waste.">277. Practices in the creative reuse of e-waste.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979292">Paper Link</a>    Pages:2395-2404</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Sunyoung">Sunyoung Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paulos:Eric">Eric Paulos</a></p>
<p>Abstract:
E-waste is a generic term embracing various forms of electric and electronic equipment that is loosely discarded, surplus, obsolete, or broken [27]. When e-waste is improperly discarded as trash, there are predictable negative impacts on the environment and human health. Existing e-waste solutions range from designing for reuse to fabricating with eco-friendly decomposable materials to more radical critiques of current practices surrounding capitalism and consumerism. Complementary to theses efforts, this paper presents an accessible reuse framework that encourages creativity while maintaining personal ownership of e-waste. Through a series of online surveys of existing personal e-waste stockpiling behaviors combined with observational studies of existing reuse practices, we developed a design reuse vocabulary: materials, shapes, and operations to enable wide ranging and creative reuse of obsolete electronics by everyday people. We operationalized this vocabulary and evaluated its legibility and usefulness. As a result, we derived a novel reuse composition framework: reuse as-is, remake, and remanufacture designed to be accessible and to have broader impact in encouraging creative reuse across a wide range of e-waste types beyond those specifically used in our study. We believe these frameworks will be a catalyst for the creative reuse of e-waste.</p>
<p>Keywords:
creativity; diy; e-waste; reuse; sustainability</p>
<h3 id="278. A phenomenology of human-electricity relations.">278. A phenomenology of human-electricity relations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979293">Paper Link</a>    Pages:2405-2408</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pierce:James">James Pierce</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paulos:Eric">Eric Paulos</a></p>
<p>Abstract:
This paper investigates the philosophical question of how we can experience energy with the aim of informing the design of future ways of experiencing energy by means of technology. Four human-technology relations formulated by philosopher of technology Don Ihde are presented. Each is then developed in the context of electrical interactive technologies. In conclusion these human-electricity and human-technology relations are employed in order to interpret current work related to energy and sustainability within HCI and point to future work in these areas.</p>
<p>Keywords:
design theory; energy; phenomenology; sustainability</p>
<h2 id="Location sharing    5">Location sharing    5</h2>
<h3 id="279. I'm the mayor of my house: examining why people use foursquare - a social-driven location sharing application.">279. I'm the mayor of my house: examining why people use foursquare - a social-driven location sharing application.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979295">Paper Link</a>    Pages:2409-2418</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lindqvist:Janne">Janne Lindqvist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranshaw:Justin">Justin Cranshaw</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wiese:Jason">Jason Wiese</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jason_I=">Jason I. Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a></p>
<p>Abstract:
There have been many location sharing systems developed over the past two decades, and only recently have they started to be adopted by consumers. In this paper, we present the results of three studies focusing on the foursquare check-in system. We conducted interviews and two surveys to understand, both qualitatively and quantitatively, how and why people use location sharing applications, as well as how they manage their privacy. We also document surprising uses of foursquare, and discuss implications for design of mobile social services.</p>
<p>Keywords:
check-in; foursquare; location based service; mobile computing; privacy; social computing; uses and gratifications</p>
<h3 id="280. In the best families: tracking and relationships.">280. In the best families: tracking and relationships.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979296">Paper Link</a>    Pages:2419-2428</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mancini:Clara">Clara Mancini</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Yvonne">Yvonne Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thomas:Keerthi">Keerthi Thomas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Joinson:Adam_N=">Adam N. Joinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Price:Blaine_A=">Blaine A. Price</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bandara:Arosha_K=">Arosha K. Bandara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jedrzejczyk:Lukasz">Lukasz Jedrzejczyk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nuseibeh:Bashar">Bashar Nuseibeh</a></p>
<p>Abstract:
A growing body of research has been exploring the use of control mechanisms to address the privacy concerns raised by location-tracking technology. We report on a qualitative study of two family groups who used a custom-built tracking application for an extended period of time. Akin to sociological breaching experiments, the study focuses on the interferences between location tracking and relationship management. We analyze the tensions that can arise between affordances of the technology and uses that the contracts between family members legitimize. We describe how, by fostering misperceptions and 'nudging' behaviors, location-tracking technology can generate anxieties and conflicts even in close relationships. We discuss their vulnerability to the overreaching effects of tracking, against which the use of mechanisms such as location-sharing preferences and feedback may not be socially viable.</p>
<p>Keywords:
family contract; family relationships; location tracking; location-based technology; privacy</p>
<h3 id="281. Opportunities exist: continuous discovery of places to perform activities.">281. Opportunities exist: continuous discovery of places to perform activities.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979297">Paper Link</a>    Pages:2429-2438</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dearman:David">David Dearman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sohn:Timothy">Timothy Sohn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Truong:Khai_N=">Khai N. Truong</a></p>
<p>Abstract:
A rich cognitive map of a space can enhance the individual's experience within the space. However, cognitive maps develop gradually through repeated experience; and because of this, on-demand mobile search services (e.g., Google Maps, Yelp) are often used to compensate for missing knowledge. In this work, we developed and evaluated a context-aware place discovery application called Opportunities Exist to assist in the acquisition of spatial knowledge and meaning. The application differs from traditional search in that places are discovered using an activity (e.g., drink coffee, sit in the sun) and the discovery process runs continuously, maintaining a history of places the user can perform her activities as she goes about her day. We conducted a 4-week deployment in two North American cities. The results show that users were able to discover new places to perform their activities in familiar spaces and learned to associate new activities with familiar places. In addition, participants leveraged the application to perform activities opportunistically, and used continuous place discovery as an opportunistic reminder of routines they wanted to break out of or resume.</p>
<p>Keywords:
activities; activity; continuous discovery; location-aware; mobile; opportunities exist; search</p>
<h3 id="282. Location visualization in social media applications.">282. Location visualization in social media applications.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979298">Paper Link</a>    Pages:2439-2448</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pakanen:Minna">Minna Pakanen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huhtala:Jussi">Jussi Huhtala</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=auml=kkil=auml=:Jonna">Jonna Hkkil</a></p>
<p>Abstract:
Location sharing applications are becoming increasingly popular in social media and for use on mobile devices, yet little research has focused on their user interface design. In this paper we describe our method of charting and creating comparable designs, and present a survey-based study of 106 social media users on their preferences regarding location indicators. Our paper contributes in proposing a methodology for visual element evaluation purposes, and reveals results, e.g., that users preferred simple indicators such as points or pins for their own location, and friend location indicators to include the corresponding name.</p>
<p>Keywords:
location sharing; social media; user interface design</p>
<h3 id="283. When are users comfortable sharing locations with advertisers?">283. When are users comfortable sharing locations with advertisers?</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979299">Paper Link</a>    Pages:2449-2452</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kelley:Patrick_Gage">Patrick Gage Kelley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benisch:Michael">Michael Benisch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranor:Lorrie_Faith">Lorrie Faith Cranor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sadeh:Norman_M=">Norman M. Sadeh</a></p>
<p>Abstract:
As smartphones and other mobile computing devices have increased in ubiquity, advertisers have begun to realize a more effective way of targeting users and a promising area for revenue growth: location-based advertising. This trend brings to bear new questions about whether or not users will adopt products involving this potentially invasive form of advertising and what sorts of protections they should be given. Our real-world user study of 27 participants echoes earlier findings that users have significant privacy concerns regarding sharing their locations with advertisers. However, we examine these concerns in more detail and find that they are complex (e.g., relating not only to the quantity of ads, but the locations and times at which they are received). With advanced privacy settings, users stated they would feel more comfortable and share more information than with a simple opt-in/opt-out mechanism.</p>
<p>Keywords:
advertising; expressiveness; location-based sharing; privacy</p>
<h2 id="Text entry & typing    4">Text entry &amp; typing    4</h2>
<h3 id="284. Typing on flat glass: examining ten-finger expert typing patterns on touch surfaces.">284. Typing on flat glass: examining ten-finger expert typing patterns on touch surfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979301">Paper Link</a>    Pages:2453-2462</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Findlater:Leah">Leah Findlater</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel">Daniel Wigdor</a></p>
<p>Abstract:
Touch screen surfaces large enough for ten-finger input have become increasingly popular, yet typing on touch screens pales in comparison to physical keyboards. We examine typing patterns that emerge when expert users of physical keyboards touch-type on a flat surface. Our aim is to inform future designs of touch screen keyboards, with the ultimate goal of supporting touch-typing with limited tactile feedback. To study the issues inherent to flat-glass typing, we asked 20 expert typists to enter text under three conditions: (1) with no visual keyboard and no feedback on input errors, then (2) with and (3) without a visual keyboard, but with some feedback. We analyzed touch contact points and hand contours, looking at attributes such as natural finger positioning, the spread of hits among individual keys, and the pattern of non-finger touches. We also show that expert typists exhibit spatially consistent key press distributions within an individual, which provides evidence that eyes-free touch-typing may be possible on touch surfaces and points to the role of personalization in such a solution. We conclude with implications for design.</p>
<p>Keywords:
multi-touch input; tabletop computing; touch-typing; user study</p>
<h3 id="285. CHANTI: predictive text entry using non-verbal vocal input.">285. CHANTI: predictive text entry using non-verbal vocal input.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979302">Paper Link</a>    Pages:2463-2472</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sporka:Adam_J=">Adam J. Sporka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Felzer:Torsten">Torsten Felzer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kurniawan:Sri_Hastuti">Sri Hastuti Kurniawan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pol=aacute=cek:Ondrej">Ondrej Polcek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haiduk:Paul">Paul Haiduk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacKenzie:I=_Scott">I. Scott MacKenzie</a></p>
<p>Abstract:
This paper introduces a text entry application for users with physical disabilities who cannot utilize a manual keyboard. The system allows the user to enter text hands-free, with the help of "Non-verbal Vocal Input" (e.g., humming or whistling). To keep the number of input sounds small, an ambiguous keyboard is used. As the user makes a sequence of sounds, each representing a subset of the alphabet, the program searches for matches in a dictionary. As a model for the system, the scanning-based application QANTI was redesigned and adapted to accept the alternative input signals. The usability of the software was investigated in an international longitudinal study done at locations in the Czech Republic, Germany, and the United States. Eight test users were recruited from the target community. The users differed in the level of speech impairment. Three users did not complete the study due to the severity of their impairment. By the end of the experiment, the users were able to enter text at rates between 10 and 15 characters per minute.</p>
<p>Keywords:
ambiguous keyboard; assistive technology; human-computer interaction; non-verbal voice input; predictive text entry; scanning; user study</p>
<h3 id="286. AirStroke: bringing unistroke text entry to freehand gesture interfaces.">286. AirStroke: bringing unistroke text entry to freehand gesture interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979303">Paper Link</a>    Pages:2473-2476</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Ni:Tao">Tao Ni</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bowman:Doug_A=">Doug A. Bowman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/North:Chris">Chris North</a></p>
<p>Abstract:
In this paper, we explore the opportunity of bringing unistroke text entry to freehand gesture interfaces. Using existing text entry methods directly in such interfaces is impractical because of the differences between freehand gestures and traditional forms of input. To address this problem, we consider the design constraints of text entry methods using freehand gestures, and present AirStroke, a new technique based on a reengineering of the well-known unistroke technique Graffiti. Using Graffiti's alphabet, AirStroke takes advantage of the richer input capabilities of two-handed freehand gestures by providing combined mode selection and character entry with one hand, as well as word completion with the other hand. A longitudinal study suggests that AirStroke has competitive speed and accuracy to unistroke methods based on stylus input.</p>
<p>Keywords:
freehand gesture input; graffiti; text entry; unistroke</p>
<h3 id="287. Sampling representative phrase sets for text entry experiments: a procedure and public resource.">287. Sampling representative phrase sets for text entry experiments: a procedure and public resource.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979304">Paper Link</a>    Pages:2477-2480</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Paek:Tim">Tim Paek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hsu:Bo=June_Paul">Bo-June Paul Hsu</a></p>
<p>Abstract:
Text entry experiments evaluating the effectiveness of various input techniques often employ a procedure whereby users are prompted with natural language phrases which they are instructed to enter as stimuli. For experimental validity, it is desirable to control the stimuli and present text that is representative of a target task, domain or language. MacKenzie and Soukoreff (2001) manually selected a set of 500 phrases for text entry experiments. To demonstrate representativeness, they correlated the distribution of single letters in their phrase set to a relatively small (by current standards) corpus of English prior to 1966, which may not reflect the style of text input today. In this paper, we ground the notion of representativeness in terms of information theory and propose a procedure for sampling representative phrases from any large corpus so that researchers can curate their own stimuli. We then describe the characteristics of phrase sets we generated using the procedure for email and social media (Facebook and Twitter). The phrase sets and code for the procedure are publicly available for download.</p>
<p>Keywords:
experiment; relative entropy; sampling; text entry</p>
<h2 id="Touch 2: tactile & targets    4">Touch 2: tactile &amp; targets    4</h2>
<h3 id="288. Enhancing physicality in touch interaction with programmable friction.">288. Enhancing physicality in touch interaction with programmable friction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979306">Paper Link</a>    Pages:2481-2490</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/L=eacute=vesque:Vincent">Vincent Lvesque</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oram:Louise">Louise Oram</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacLean:Karon_E=">Karon E. MacLean</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marchuk:Nicholas_D=">Nicholas D. Marchuk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Johnson:Dan">Dan Johnson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Colgate:J=_Edward">J. Edward Colgate</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Peshkin:Michael_A=">Michael A. Peshkin</a></p>
<p>Abstract:
Touch interactions have refreshed some of the 'glowing enthusiasm' of thirty years ago for direct manipulation interfaces. However, today's touch technologies, whose interactions are supported by graphics, sounds or crude clicks, have a tactile sameness and gaps in usability. We use a Large Area Tactile Pattern Display (LATPaD) to examine design possibilities and outcomes when touch interactions are enhanced with variable surface friction. In a series of four studies, we first confirm that variable friction gives significant performance advantages in low-level targeting activities. We then explore the design space of variable friction interface controls and assess user reactions. Most importantly, we demonstrate that variable friction can have a positive impact on the enjoyment, engagement and sense of realism experienced by users of touch interfaces.</p>
<p>Keywords:
Fitts Law; design space; haptics; programmable friction; tactile feedback; target acquisition; touch interaction; touch interface; touch screen; touchscreen; variable friction</p>
<h3 id="289. Surfpad: riding towards targets on a squeeze film effect.">289. Surfpad: riding towards targets on a squeeze film effect.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979307">Paper Link</a>    Pages:2491-2500</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Casiez:G=eacute=ry">Gry Casiez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roussel:Nicolas">Nicolas Roussel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vanbelleghem:Romuald">Romuald Vanbelleghem</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Giraud:Fr=eacute=d=eacute=ric">Frdric Giraud</a></p>
<p>Abstract:
We present Surfpad, a pointing facilitation technique that does not decrease target distance or increase target width in either control or display space. This new technique operates instead in the tactile domain by taking advantage of the ability to alter a touchpad's coefficient of friction by means of a squeeze film effect. We report on three experiments comparing Surfpad to the Semantic Pointing technique and constant control-display gain with and without distractor targets. Our results clearly show the limits of traditional target-aware control-display gain adaptation in the latter case, and the benefits of our tactile approach in both cases. Surfpad leads to a performance improvement close to 9% compared to unassisted pointing at small targets with no distractor. It is also robust to high distractor densities, keeping an average performance improvement of nearly 10% while Semantic Pointing can degrade up to 100%. Our results also suggest the performance improvement is caused by tactile information feedback rather than mechanical causes, and that the feedback is more effective when friction is increased on targets using a simple step function.</p>
<p>Keywords:
control-display gain adaptation; pointing facilitation; squeeze film effect; target-aware</p>
<h3 id="290. Understanding touch.">290. Understanding touch.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979308">Paper Link</a>    Pages:2501-2510</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Holz:Christian">Christian Holz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baudisch:Patrick">Patrick Baudisch</a></p>
<p>Abstract:
Current touch devices, such as capacitive touchscreens are based on the implicit assumption that users acquire targets with the center of the contact area between finger and device. Findings from our previous work indicate, however, that such devices are subject to systematic error offsets. This suggests that the underlying assumption is most likely wrong. In this paper, we therefore revisit this assumption. In a series of three user studies, we find evidence that the features that users align with the target are visual features. These features are located on the top of the user's fingers, not at the bottom, as assumed by traditional devices. We present the projected center model, under which error offsets drop to 1.6mm, compared to 4mm for the traditional model. This suggests that the new model is indeed a good approximation of how users conceptualize touch input. The primary contribution of this paper is to help understand touch-one of the key input technologies in human-computer interaction. At the same time, our findings inform the design of future touch input technology. They explain the inaccuracy of traditional touch devices as a -Sparallax- artifact between user control based on the top of the finger and sensing based on the bottom side of the finger. We conclude that certain camera-based sensing technologies can inherently be more accurate than contact area-based sensing.</p>
<p>Keywords:
experiment; generalized perceived input point model; targeting; touch input</p>
<h3 id="291. Magic desk: bringing multi-touch surfaces into desktop work.">291. Magic desk: bringing multi-touch surfaces into desktop work.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979309">Paper Link</a>    Pages:2511-2520</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bi:Xiaojun">Xiaojun Bi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matejka:Justin">Justin Matejka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
Despite the prominence of multi-touch technologies, there has been little work investigating its integration into the desktop environment. Bringing multi-touch into desktop computing would give users an additional input channel to leverage, enriching the current interaction paradigm dominated by a mouse and keyboard. We provide two main contributions in this domain. First, we describe the results from a study we performed, which systematically evaluates the various potential regions within the traditional desktop configuration that could become multi-touch enabled. The study sheds light on good or bad regions for multi-touch, and also the type of input most appropriate for each of these regions. Second, guided by the results from our study, we explore the design space of multi-touch-integrated desktop experiences. A set of new interaction techniques are coherently integrated into a desktop prototype, called Magic Desk, demonstrating potential uses for multi-touch enabled desktop configurations.</p>
<p>Keywords:
desktop work; multi-touch; tabletop</p>
<h2 id="Methods to aid & structure design    4">Methods to aid &amp; structure design    4</h2>
<h3 id="292. Benefits of matching domain structure for planning software: the right stuff.">292. Benefits of matching domain structure for planning software: the right stuff.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979311">Paper Link</a>    Pages:2521-2530</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Billman:Dorrit">Dorrit Billman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Arsintescucu:Lucia">Lucia Arsintescucu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Feary:Michael">Michael Feary</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Jessica">Jessica Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Asha">Asha Smith</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tiwary:Rachna">Rachna Tiwary</a></p>
<p>Abstract:
We investigated the role of domain structure, in designing for software usefulness and usability. We ran through the whole application development cycle, in miniature, from needs analysis through design, implementation, and evaluation, for planning needs of one NASA Mission Control group. Based on our needs analysis, we developed prototype software that matched domain structure better than did the legacy system. We compared our new prototype to the legacy application in a laboratory, high-fidelity analog of the natural planning work. We found large performance differences favoring the prototype, which better captured domain structure. Our research illustrates the importance of needs analysis (particularly Domain Structure Analysis), and the viability of the design process that we are exploring.</p>
<p>Keywords:
aeroastronautics; complex work domains; planning</p>
<h3 id="293. Developmentally situated design (DSD): making theoretical knowledge accessible to designers of children's technology.">293. Developmentally situated design (DSD): making theoretical knowledge accessible to designers of children's technology.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979312">Paper Link</a>    Pages:2531-2540</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bekker:Tilde">Tilde Bekker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Antle:Alissa_Nicole">Alissa Nicole Antle</a></p>
<p>Abstract:
There is a wealth of theoretical knowledge about the developmental abilities and skills of children. However, this knowledge is not readily accessible to designers of interactive products. In this paper, we present the requirements, design and evaluation of developmentally situated design (DSD) cards. DSD cards are a design tool that makes age specific information about children's developing cognitive, physical, social, and emotional abilities readily accessible for designers. Initial requirements were elicited through interviews with design practitioners and students. The cards were evaluated through a design-in-use study in which design students used the cards to address three different design problems. Our analysis of observational notes and post-design interviews revealed how the cards' characteristics enabled different kinds of uses including framing, orienting, inspiring, informing, integrating and constraining. We conclude with a discussion of possible refinements and an analysis of the strengths and weaknesses of our approach.</p>
<p>Keywords:
child development; child-computer interaction; design cards; design methods; design tools; interaction design</p>
<h3 id="294. A spreadsheet-based user interface for managing plural relationships in structured data.">294. A spreadsheet-based user interface for managing plural relationships in structured data.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979313">Paper Link</a>    Pages:2541-2550</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bakke:Eirik">Eirik Bakke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karger:David_R=">David R. Karger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Rob">Rob Miller</a></p>
<p>Abstract:
A key feature of relational database applications is managing \emph{plural} relationships---one-to-many and many-to-many---between entities. However, since it is often infeasible to adopt or develop a new database application for any given schema at hand, information workers instead turn to spreadsheets, which lend themselves poorly to schemas requiring multiple related entity sets. In this paper, we propose to reduce the cost-usability gap between spreadsheets and tailor-made relational database applications by extending the spreadsheet paradigm to let the user establish relationships between rows in related worksheets as well as view and navigate the hierarchical cell structure that arises as a result. We present Related Worksheets, a spreadsheet-like prototype application, and evaluate it with a screencast-based user study on 36 Mechanical Turk workers. First-time users of our software were able to solve lookup-type query tasks with the same or higher accuracy as subjects using Microsoft Excel, in one case 40% faster on average.</p>
<p>Keywords:
databases; foreign key relationships; hierarchical views; one-to-many relationships; spreadsheets</p>
<h3 id="295. Variation in importance of time-on-task with familiarity with mobile phone models.">295. Variation in importance of time-on-task with familiarity with mobile phone models.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979314">Paper Link</a>    Pages:2551-2554</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Suzuki:Shunsuke">Shunsuke Suzuki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bellotti:Victoria">Victoria Bellotti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yee:Nick">Nick Yee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/John:Bonnie_E=">Bonnie E. John</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nakao:Yusuke">Yusuke Nakao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Asahi:Toshiyuki">Toshiyuki Asahi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fukuzumi:Shin=ichi">Shin'ichi Fukuzumi</a></p>
<p>Abstract:
We studied the extent to which time-on-task is correlated with perception of usability for people who are familiar with a phone model and for those who are not. Our controlled experiment, conducted in Japan, correlated subjective usability assessments with time-on-task for expert and novice users on three different mobile phone models. We found that the correlation between perceived usability and time-on-task is stronger when participants are more familiar with the phone model. While not significant when initially inspecting a new phone model, a negative correlation between time-on-task and perceived usability becomes significant with as little as an hour's time doing tasks on the unfamiliar phone. This suggests that designing the UI to make time-on-task as short as possible may not have much effect on the purchase decision, but as experience increases, it may increase the loyalty of existing users.</p>
<p>Keywords:
expertise; mobile phone; time on task; usability metrics</p>
<h2 id="Touch 3: sensing    4">Touch 3: sensing    4</h2>
<h3 id="296. Some like it hot: thermal feedback for mobile devices.">296. Some like it hot: thermal feedback for mobile devices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979316">Paper Link</a>    Pages:2555-2564</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wilson:Graham_A=">Graham A. Wilson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Halvey:Martin">Martin Halvey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hughes:Stephen_A=">Stephen A. Hughes</a></p>
<p>Abstract:
Thermal stimulation is a rich, emotive and salient feedback channel that is well suited to HCI, but one that is yet to be fully investigated. Thermal feedback may be suited to environments that are too loud for audio or too bumpy for vibrotactile feedback. This paper presents two studies into how well users could detect hot and cold stimuli presented to the fingertips, the palm, the dorsal surface of the forearm and the dorsal surface of the upper arm. Evaluations were carried out in static and mobile settings. Results showed that the palm is most sensitive, cold is more perceivable and comfortable than warm and that stronger and faster-changing stimuli are more detectable but less comfortable. Guidelines for the design of thermal feedback are outlined, with attention paid to perceptual and hedonic factors.</p>
<p>Keywords:
mobile interaction; non-visual feedback; thermal feedback</p>
<h3 id="297. HeatWave: thermal imaging for surface user interaction.">297. HeatWave: thermal imaging for surface user interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979317">Paper Link</a>    Pages:2565-2574</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Larson:Eric_C=">Eric C. Larson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cohn:Gabe">Gabe Cohn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gupta:Sidhant">Sidhant Gupta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ren:Xiaofeng">Xiaofeng Ren</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Beverly_L=">Beverly L. Harrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fox:Dieter">Dieter Fox</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Patel:Shwetak">Shwetak Patel</a></p>
<p>Abstract:
We present HeatWave, a system that uses digital thermal imaging cameras to detect, track, and support user interaction on arbitrary surfaces. Thermal sensing has had limited examination in the HCI research community and is generally under-explored outside of law enforcement and energy auditing applications. We examine the role of thermal imaging as a new sensing solution for enhancing user surface interaction. In particular, we demonstrate how thermal imaging in combination with existing computer vision techniques can make segmentation and detection of routine interaction techniques possible in real-time, and can be used to complement or simplify algorithms for traditional RGB and depth cameras. Example interactions include (1) distinguishing hovering above a surface from touch events, (2) shape-based gestures similar to ink strokes, (3) pressure based gestures, and (4) multi-finger gestures. We close by discussing the practicality of thermal sensing for naturalistic user interaction and opportunities for future work.</p>
<p>Keywords:
cameras; computer vision; gestures; surface interaction; thermal imaging; user interfaces</p>
<h3 id="298. AnglePose: robust, precise capacitive touch tracking via 3d orientation estimation.">298. AnglePose: robust, precise capacitive touch tracking via 3d orientation estimation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979318">Paper Link</a>    Pages:2575-2584</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Simon">Simon Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williamson:John">John Williamson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stewart:Craig_D=">Craig D. Stewart</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Murray=Smith:Roderick">Roderick Murray-Smith</a></p>
<p>Abstract:
We present a finger-tracking system for touch-based interaction which can track 3D finger angle in addition to position, using low-resolution conventional capacitive sensors, therefore compensating for the inaccuracy due to pose variation in conventional touch systems. Probabilistic inference about the pose of the finger is carried out in real-time using a particle filter; this results in an efficient and robust pose estimator which also gives appropriate uncertainty estimates. We show empirically that tracking the full pose of the finger results in greater accuracy in pointing tasks with small targets than competitive techniques. Our model can detect and cope with different finger sizes and the use of either fingers or thumbs, bringing a significant potential for improvement in one-handed interaction with touch devices. In addition to the gain in accuracy we also give examples of how this technique could open up the space of novel interactions.</p>
<p>Keywords:
capacitive; mobile; particle filter; probabilistic; touch</p>
<h3 id="299. TouchCuts and TouchZoom: enhanced target selection for touch displays using finger proximity sensing.">299. TouchCuts and TouchZoom: enhanced target selection for touch displays using finger proximity sensing.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979319">Paper Link</a>    Pages:2585-2594</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Xing=Dong">Xing-Dong Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Irani:Pourang">Pourang Irani</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
Although touch-screen laptops are increasing in popularity, users still do not comfortably rely on touch in these environments, as current software interfaces were not designed for being used by the finger. In this paper, we first demonstrate the benefits of using touch as a complementary input modality along with the keyboard and mouse or touchpad in a laptop setting. To alleviate the frustration users experience with touch, we then design two techniques, TouchCuts, a single target expansion technique, and ,i&gt;TouchZoom,/i&gt;, a multiple target expansion technique. Both techniques facilitate the selection of small icons, by detecting the finger proximity above the display surface, and expanding the target as the finger approaches. In a controlled evaluation, we show that our techniques improve performance in comparison to both the computer mouse and a baseline touch-based target acquisition technique. We conclude by discussing other application scenarios that our techniques support.</p>
<p>Keywords:
target expansion; touch input</p>
<h2 id="Authentication    6">Authentication    6</h2>
<h3 id="300. Of passwords and people: measuring the effect of password-composition policies.">300. Of passwords and people: measuring the effect of password-composition policies.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979321">Paper Link</a>    Pages:2595-2604</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Komanduri:Saranga">Saranga Komanduri</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shay:Richard">Richard Shay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kelley:Patrick_Gage">Patrick Gage Kelley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mazurek:Michelle_L=">Michelle L. Mazurek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bauer:Lujo">Lujo Bauer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Christin:Nicolas">Nicolas Christin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranor:Lorrie_Faith">Lorrie Faith Cranor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Egelman:Serge">Serge Egelman</a></p>
<p>Abstract:
Text-based passwords are the most common mechanism for authenticating humans to computer systems. To prevent users from picking passwords that are too easy for an adversary to guess, system administrators adopt password-composition policies (e.g., requiring passwords to contain symbols and numbers). Unfortunately, little is known about the relationship between password-composition policies and the strength of the resulting passwords, or about the behavior of users (e.g., writing down passwords) in response to different policies. We present a large-scale study that investigates password strength, user behavior, and user sentiment across four password-composition policies. We characterize the predictability of passwords by calculating their entropy, and find that a number of commonly held beliefs about password composition and strength are inaccurate. We correlate our results with user behavior and sentiment to produce several recommendations for password-composition policies that result in strong passwords without unduly burdening users.</p>
<p>Keywords:
passwords; policy; security; usability</p>
<h3 id="301. MARASIM: a novel jigsaw based authentication scheme using tagging.">301. MARASIM: a novel jigsaw based authentication scheme using tagging.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979322">Paper Link</a>    Pages:2605-2614</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Khot:Rohit_Ashok">Rohit Ashok Khot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Srinathan:Kannan">Kannan Srinathan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kumaraguru:Ponnurangam">Ponnurangam Kumaraguru</a></p>
<p>Abstract:
In this paper we propose and evaluate Marasim, a novel Jigsaw based graphical authentication mechanism using tagging. Marasim is aimed at achieving the security of random images with the memorability of personal images. Our scheme relies on the human ability to remember a personal image and later recognize the alternate visual representations (images) of the concepts occurred in the image. These concepts are retrieved from the tags assigned to the image. We illustrate how a Jigsaw based approach helps to create a portfolio of system-chosen random images to be used for authentication. The paper describes the complete design of Marasim along with the empirical studies of Marasim that provide evidences of increased memorability. Results show that 93% of all participants succeeded in the authentication tests using Marasim after three months while 71% succeeded in authentication tests using Marasim after nine months. Our findings indicate that Marasim has potential applications, especially where text input is hard (e.g., PDAs or ATMs), or in situations where passwords are infrequently used (e.g., web site passwords).</p>
<p>Keywords:
graphical passwords; jigsaw; tagging; user authentication</p>
<h3 id="302. Exploring implicit memory for painless password recovery.">302. Exploring implicit memory for painless password recovery.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979323">Paper Link</a>    Pages:2615-2618</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Denning:Tamara">Tamara Denning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bowers:Kevin_D=">Kevin D. Bowers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dijk:Marten_van">Marten van Dijk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Juels:Ari">Ari Juels</a></p>
<p>Abstract:
Knowledge-based authentication systems generally rely upon users' explicit recollection of passwords, facts, or personal preferences. These systems impose a cognitive burden that often results in forgotten secrets or secrets with poor entropy. We propose an authentication system that instead draws on implicit memory - that is, the unconscious encoding and usage of information. In such a system, a user is initially presented with images of common objects in a casual familiarization task. When the user later authenticates, she is asked to perform a task involving a set of degraded images, some of which are based upon the images in the familiarization task. The prior exposure to those images influences the user's responses in the task, thereby eliciting authentication information. We ran a user study to investigate the plausibility of our system design. Our results suggest that implicit memory has potential as a basis for low-cognitive-overhead, high-stability, knowledge-based authentication.</p>
<p>Keywords:
authentication; implicit memory; password recovery; priming; security</p>
<h3 id="303. Self-reported password sharing strategies.">303. Self-reported password sharing strategies.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979324">Paper Link</a>    Pages:2619-2622</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kaye:Joseph">Joseph Kaye</a></p>
<p>Abstract:
This paper contributes to the growing body of literature on privacy and security by looking at self-reported password sharing practices. 62 men and 60 women recruited through a combination of snowball sampling and small ads answered a series of open-ended questions about their password sharing strategies. One third of respondants shared their personal email password, and a quarter shared their Facebook password, both primarily with partners and close friends. Approximately 20% of people who had work email passwords reported sharing them with colleagues. These results support understanding password sharing not as a deviant practice to be stamped out, but rather a nuanced practice engaged in with thought and care.</p>
<p>Keywords:
passwords; security; sharing</p>
<h3 id="304. On the necessity of user-friendly CAPTCHA.">304. On the necessity of user-friendly CAPTCHA.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979325">Paper Link</a>    Pages:2623-2626</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fidas:Christos">Christos Fidas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Voyiatzis:Artemios_G=">Artemios G. Voyiatzis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Avouris:Nikolaos_M=">Nikolaos M. Avouris</a></p>
<p>Abstract:
A "Completely Automated Public Turing test to tell Computers and Humans Apart" (CAPTCHA) is a mechanism widely used nowadays for protection of web applications, interfaces, and services from malicious users. A questionnaire-based survey combined with a real usage scenario of a native-language CAPTCHA mechanism was conducted in order to investigate several aspects that affect end-user perceptions related to the quality of CAPTCHA. A total of 210 participants of age between 19 and 64 participated during May and July 2010. The survey results validate the common belief that CAPTCHAs are still difficult for humans to solve. They also provide insights that can be applied to improve users' experience on interacting with CAPTCHA systems.</p>
<p>Keywords:
CAPTCHA; native language CAPTCHA; security; usability; usable security; user perceptions</p>
<h3 id="305. A diary study of password usage in daily life.">305. A diary study of password usage in daily life.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979326">Paper Link</a>    Pages:2627-2630</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hayashi:Eiji">Eiji Hayashi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jason_I=">Jason I. Hong</a></p>
<p>Abstract:
While past work has examined password usage on a specific computer, web site, or organization, there is little work examining overall password usage in daily life. Through a diary study, we examine all usage of passwords, and offer some new findings based on quantitative analyses regarding how often people log in, where they log in, and how frequently people use foreign computers. Our analysis also confirms or updates existing statistics about password usage patterns. We also discuss some implications for design as well as security education.</p>
<p>Keywords:
diary study; password; user authentication</p>
<h2 id="Cats, dogs, sports, games & books    5">Cats, dogs, sports, games &amp; books    5</h2>
<h3 id="306. Understanding people and animals: the use of a positioning system in ordinary human-canine interaction.">306. Understanding people and animals: the use of a positioning system in ordinary human-canine interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979328">Paper Link</a>    Pages:2631-2640</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Weilenmann:Alexandra">Alexandra Weilenmann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Juhlin:Oskar">Oskar Juhlin</a></p>
<p>Abstract:
Animals are increasingly integrated in interactive contexts depending on digital technologies. The current and future use of such technologies is a relevant topic for HCI research. However, the field is struggling with the inherent problem of 'nteraction' in understanding interaction with animals. We argue for a way forward based on an ethnomethodological perspective on anthropomorphism, with a focus on manifest interaction. Drawing upon a field study of hunters' use of a GPS dog tracking-device, we discuss how interaction between dogs and humans is affected when new technology is introduced. The GPS data is situated and interpreted by the dog handler, and supports the hunter's work of dealing with the dogs' intentions. This opens up for new forms of interactions with the dog. When studying and designing for interaction between humans and animals we should move beyond merely looking at dyadic relationships, and also consider the social organization of the interaction.</p>
<p>Keywords:
anthropomorphism; dogs; ethnomethodology; gps; human-canine interaction; mobile technology; mobility; social organization</p>
<h3 id="307. Communication technology for human-dog interaction: exploration of dog owners' experiences and expectations.">307. Communication technology for human-dog interaction: exploration of dog owners' experiences and expectations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979329">Paper Link</a>    Pages:2641-2650</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Paldanius:Mikko">Mikko Paldanius</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/K=auml=rkk=auml=inen:Tuula">Tuula Krkkinen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/V=auml==auml=n=auml=nen=Vainio=Mattila:Kaisa">Kaisa Vnnen-Vainio-Mattila</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Juhlin:Oskar">Oskar Juhlin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=auml=kkil=auml=:Jonna">Jonna Hkkil</a></p>
<p>Abstract:
Whereas communication technology to connect people has long been an integral part of our everyday lives, it has only recently expanded to offer applications for dogs and dog-owners. In this paper, we present two explorative studies to understand the experiences and expectations of dog owners for communication technology to support their interaction with dogs. These studies look at two different user groups, hunters and pet owners, charting the lessons learnt from the current technology and exploring the aspects that should be taken into account when designing future applications and services. Our findings reveal that usability problems are still the dominant issue with current applications. We also suggest key design implications which can be utilized in the development of future human-dog interaction systems.</p>
<p>Keywords:
communication technology; dogs; user experience</p>
<h3 id="308. Designing sports: a framework for exertion games.">308. Designing sports: a framework for exertion games.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979330">Paper Link</a>    Pages:2651-2660</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mueller_0001:Florian">Florian Mueller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edge:Darren">Darren Edge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vetere:Frank">Frank Vetere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gibbs:Martin_R=">Martin R. Gibbs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agamanolis:Stefan">Stefan Agamanolis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bongers:Bert">Bert Bongers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sheridan:Jennifer_G=">Jennifer G. Sheridan</a></p>
<p>Abstract:
Exertion games require investing physical effort. The fact that such games can support physical health is tempered by our limited understanding of how to design for engaging exertion experiences. This paper introduces the Exertion Framework as a way to think and talk about Exertion Games, both for their formative design and summative analysis. Our Exertion Framework is based on the ways in which we can conceive of the body investing in game-directed exertion, supported by four perspectives on the body (the Responding Body, Moving Body, Sensing Body and Relating Body) and three perspectives on gaming (rules, play and context). The paper illustrates how this framework was derived from prior systems and theory, and presents a case study of how it has been used to inspire novel exertion interactions.</p>
<p>Keywords:
bodily interaction; exergame; exergaming; exertion interface; kinesthetic; sports; whole-body interaction</p>
<h3 id="309. Cat cat revolution: an interspecies gaming experience.">309. Cat cat revolution: an interspecies gaming experience.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979331">Paper Link</a>    Pages:2661-2664</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Noz:Frank">Frank Noz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/An:Jinsoo">Jinsoo An</a></p>
<p>Abstract:
Despite owners' desires to include pets in their everyday activities, pets have yet to be included in the digital gaming experience. The Cat Cat Revolution (CCR) is a digital game of cat and mouse that allows cats to participate in play through a species-appropriate interface. The game applies Human-Computer Interaction (HCI) principles to pets and casts pets as participants in the gaming experience. During the pilot study, pet owners characterized CCR as a mutually positive experience, describing the game as a fun way to play. CCR explores the effects of including pets in the digital gaming experience.</p>
<p>Keywords:
HCI interactions; cats; designing for emergence; designing for interspecies interaction; emergent intelligence; human-pet gaming; human-pet interaction; non-human interaction</p>
<h3 id="310. Antiquarian answers: book restoration as a resource for design.">310. Antiquarian answers: book restoration as a resource for design.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979332">Paper Link</a>    Pages:2665-2668</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rosner:Daniela_K=">Daniela K. Rosner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Alex_S=">Alex S. Taylor</a></p>
<p>Abstract:
As technologies age, they experience wear and degradation, sometimes resulting in loss of functionality. In response, parts are replaced and software is updated. Yet restoration - the process of returning something to a previous condition, often regardless of its instrumental value -"is a relatively rare practice with computational technologies. The aim of this paper is to enrich HCI design practices by considering the material qualities of restoration. We consider what makes a technology worth restoring and what constitutes the process of restoration by examining data collected from a three-month apprenticeship-based qualitative study of bookbinding. Building on relevant literatures, we offer antiquarian books -"long-established information technologies - as a lens onto the ways values are enacted through material engagements. We conclude with a discussion of restoration's role in HCI.</p>
<p>Keywords:
binding; books; handcraft; handwork; material; skill; tool</p>
<h2 id="User experience    5">User experience    5</h2>
<h3 id="311. Which version is this?: improving the desktop experience within a copy-aware computing ecosystem.">311. Which version is this?: improving the desktop experience within a copy-aware computing ecosystem.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979334">Paper Link</a>    Pages:2669-2678</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Karlson:Amy_K=">Amy K. Karlson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Greg">Greg Smith</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Bongshin">Bongshin Lee</a></p>
<p>Abstract:
Computers today make it easy for people to scatter copies and versions of digital items across their file systems, but do little to help people manage the resulting mess. In this paper, we introduce the concept of a copy-aware computing ecosystem, inspired by a vision of computing when systems track and surface copy relationships between files. Based on two deployments of a copy-aware software prototype and in-depth interviews with individuals in collaborative relationships, we present our findings on the origins of copies and the barriers to eliminating them, but offer a promising solution based on the set of files that together represent a user's conceptual view of a document - the versionset. We show that the versionset is viable to infer, and we draw upon user activity logs and feedback on personalized views of versionsets to distill guidelines for the factors that define a versionset. We conclude by enumerating the many PIM user experiences that could be transformed as a result.</p>
<p>Keywords:
PIM; copy-aware computing; file management; versioning</p>
<h3 id="312. Enticing consumers via incomplete product experience: an investigation of online product interactivity designs.">312. Enticing consumers via incomplete product experience: an investigation of online product interactivity designs.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979335">Paper Link</a>    Pages:2679-2688</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yi:Cheng">Cheng Yi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jiang:Zhenhui">Zhenhui Jiang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benbasat:Izak">Izak Benbasat</a></p>
<p>Abstract:
This paper reports on two studies that investigate the design of online product interactivity. The first study compares three different presentation formats: a video presentation and two Virtual Product Experience (VPE) presentations, namely, triggered interaction and full interaction. The findings suggest that triggered interaction VPE is more effective in enticing users to attend to and further explore the featured products than both the non-interactive video presentation and the full interaction VPE. The second study builds upon the first and focuses on two specific VPE design factors. In particular, it investigates interaction constraint (high versus low constraint) in addition to the activation mode of interaction (process-based interaction versus event-based interaction). The results reveal interesting interaction patterns between the two design factors, i.e., providing less constrained interaction performs better when process-based interaction design is adopted, but performs worse when event-based interaction is employed.</p>
<p>Keywords:
full interaction; interaction constraint; online product presentation; product seductiveness; triggered interaction; virtual product experience (vpe)</p>
<h3 id="313. Old wine in new bottles or novel challenges: a critical analysis of empirical studies of user experience.">313. Old wine in new bottles or novel challenges: a critical analysis of empirical studies of user experience.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979336">Paper Link</a>    Pages:2689-2698</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bargas=Avila:Javier_A=">Javier A. Bargas-Avila</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
This paper reviews how empirical research on User Experience (UX) is conducted. It integrates products, dimensions of experience, and methodologies across a systematically selected sample of 51 publications from 2005-2009, reporting a total of 66 empirical studies. Results show a shift in the products and use contexts that are studied, from work towards leisure, from controlled tasks towards open use situations, and from desktop computing towards consumer products and art. Context of use and anticipated use, often named key factors of UX, are rarely researched. Emotions, enjoyment and aesthetics are the most frequently assessed dimensions. The methodologies used are mostly qualitative, and known from traditional usability studies, though constructive methods with unclear validity are being developed and used. Many studies use self-developed questionnaires without providing items or statistical validations. We discuss underexplored research questions and potential improvements of UX research.</p>
<p>Keywords:
meta-analysis; review; usability; user experience; ux</p>
<h3 id="314. Perceptual analysis of talking avatar head movements: a quantitative perspective.">314. Perceptual analysis of talking avatar head movements: a quantitative perspective.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979337">Paper Link</a>    Pages:2699-2702</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Ma:Xiaohan">Xiaohan Ma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Le:Binh_Huy">Binh Huy Le</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Deng:Zhigang">Zhigang Deng</a></p>
<p>Abstract:
Lifelike interface agents (e.g. talking avatars) have been increasingly used in human-computer interaction applications. In this work, we quantitatively analyze how human perception is affected by audio-head motion characteristics of talking avatars. Specifically, we quantify the correlation between perceptual user ratings (obtained via user study) and joint audio-head motion features as well as head motion patterns in the frequency-domain. Our quantitative analysis results clearly show that the correlation coefficient between the pitch of speech signals (but not the RMS energy of speech signals) and head motions is approximately linearly proportional to the perceptual user rating, and a larger proportion of high frequency signals in talking avatar head movements tends to degrade the user perception in terms of naturalness.</p>
<p>Keywords:
and audio-head motion features; head motion; perceptual modeling; quantitative analysis</p>
<h3 id="315. Diminishing returns?: revisiting perception of computing performance.">315. Diminishing returns?: revisiting perception of computing performance.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979338">Paper Link</a>    Pages:2703-2706</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Anderson:Glen_J=">Glen J. Anderson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Doherty:Rina">Rina Doherty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baugh:Eric">Eric Baugh</a></p>
<p>Abstract:
The computing performance literature offers guidelines and frameworks, but data on the limits of user appreciation for performance are scarce. This paper presents a study of user satisfaction with different levels of computing performance. Thirty-five participants performed common computing tasks such as creating email and Web surfing. They rated computing performance for specific task elements - such as application launching and menu responsiveness - that occurred during those tasks. They repeated the tasks under varying levels of computer performance. Results include user ratings as a function of computing performance for each of the task elements. The results have implications for system designers who create products that must meet user expectations for performance.</p>
<p>Keywords:
performance perception; time perception; usability</p>
<h2 id="Interaction on mobile devices    7">Interaction on mobile devices    7</h2>
<h3 id="316. ShadowPuppets: supporting collocated interaction with mobile projector phones using hand shadows.">316. ShadowPuppets: supporting collocated interaction with mobile projector phones using hand shadows.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979340">Paper Link</a>    Pages:2707-2716</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cowan:Lisa_G=">Lisa G. Cowan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Kevin_A=">Kevin A. Li</a></p>
<p>Abstract:
Pico projectors attached to mobile phones allow users to view phone content using a large display. However, to provide input to projector phones, users have to look at the device, diverting their attention from the projected image. Additionally, other collocated users have no way of interacting with the device. We present ShadowPuppets, a system that supports collocated interaction with mobile projector phones. ShadowPuppets allows users to cast hand shadows as input to mobile projector phones. Most people understand how to cast hand shadows, which provide an easy input modality. Additionally, they implicitly support collocated usage, as nearby users can cast shadows as input and one user can see and understand another user's hand shadows. We describe the results of three user studies. The first study examines what hand shadows users expect will cause various effects. The second study looks at how users perceive hand shadows, examining what effects they think various hand shadows will cause. Finally, we present qualitative results from a study with our functional prototype and discuss design implications for systems using shadows as input. Our findings suggest that shadow input can provide a natural and intuitive way of interacting with projected interfaces and can support collocated collaboration.</p>
<p>Keywords:
gesture; interaction technique; mobile projector phone; projector-camera system; shadow</p>
<h3 id="317. DoubleFlip: a motion gesture delimiter for mobile interaction.">317. DoubleFlip: a motion gesture delimiter for mobile interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979341">Paper Link</a>    Pages:2717-2720</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ruiz:Jaime">Jaime Ruiz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a></p>
<p>Abstract:
To make motion gestures more widely adopted on mobile devices it is important that devices be able to distinguish between motion intended for mobile interaction and every-day motion. In this paper, we present DoubleFlip, a unique motion gesture designed as an input delimiter for mobile motion-based interaction. The DoubleFlip gesture is distinct from regular motion of a mobile device. Based on a collection of 2,100 hours of motion data captured from 99 users, we found that our DoubleFlip recognizer is extremely resistant to false positive conditions, while still achieving a high recognition rate. Since DoubleFlip is easy to perform and unlikely to be accidentally invoked, it provides an always-active input event for mobile interaction.</p>
<p>Keywords:
mobile interaction; motion gestures; sensors</p>
<h3 id="318. Multi-user interaction on media facades through live video on mobile devices.">318. Multi-user interaction on media facades through live video on mobile devices.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979342">Paper Link</a>    Pages:2721-2724</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Boring:Sebastian">Sebastian Boring</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gehring:Sven">Sven Gehring</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wiethoff:Alexander">Alexander Wiethoff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bl=ouml=ckner:Anna_Magdalena">Anna Magdalena Blckner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sch=ouml=ning:Johannes">Johannes Schning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Butz:Andreas">Andreas Butz</a></p>
<p>Abstract:
The increasing number of media facades in urban spaces offers great potential for new forms of interaction especially for collaborative multi-user scenarios. In this paper, we present a way to directly interact with them through live video on mobile devices. We extend the Touch Projector interface to accommodate multiple users by showing individual content on the mobile display that would otherwise clutter the facade's canvas or distract other users. To demonstrate our concept, we built two collaborative multi-user applications: (1) painting on the facade and (2) solving a 15-puzzle. We gathered informal feedback during the ARS Electronica Festival in Linz, Austria and found that our interaction technique is (1) considered easy-to-learn, but (2) may leave users unaware of the actions of others.</p>
<p>Keywords:
augmented reality; input device; interaction techniques; interface distribution; media facades; mobile device; multi-user interaction</p>
<h3 id="319. Interaction with magic lenses: real-world validation of a Fitts' Law model.">319. Interaction with magic lenses: real-world validation of a Fitts' Law model.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979343">Paper Link</a>    Pages:2725-2728</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rohs:Michael">Michael Rohs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Suomalainen:Tiia">Tiia Suomalainen</a></p>
<p>Abstract:
Rohs and Oulasvirta (2008) proposed a two-component Fitts' law model for target acquisition with magic lenses in mobile augmented reality (AR) with 1) a physical pointing phase, in which the target can be directly observed on the background surface, and 2) a virtual pointing phase, in which the target can only be observed through the device display. The model provides a good fit (R2=0.88) with laboratory data, but it is not known if it generalizes to real-world AR tasks. In the present outdoor study, subjects (N=12) did building-selection tasks in an urban area. The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context. Nevertheless, the model yielded an R2 of 0.80, and when using effective target width an R2 of 0.88 was achieved.</p>
<p>Keywords:
Fitt's Law; augmented reality; field experiment; human-performance modeling; magic lens pointing; target acquisition</p>
<h3 id="320. Xpaaand: interaction techniques for rollable displays.">320. Xpaaand: interaction techniques for rollable displays.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979344">Paper Link</a>    Pages:2729-2732</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Khalilbeigi:Mohammadreza">Mohammadreza Khalilbeigi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lissermann:Roman">Roman Lissermann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=hlh=auml=user:Max">Max Mhlhuser</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steimle:J=uuml=rgen">Jrgen Steimle</a></p>
<p>Abstract:
We present a device concept and a prototype of a future mobile device. By featuring a rollable display, its display size and its form factor can be dynamically changed. Moreover, we investigate how physical resizing of the display can be used as an input technique for interacting with digital contents and present a set of novel interaction techniques. Evaluation results show that physical resizing of the display can improve the way we interact with digital contents on mobile devices.</p>
<p>Keywords:
input technique.; mobile device; resizing; rollable display; screen; scroll; tangible interaction</p>
<h3 id="321. TapBack: towards richer mobile interfaces in impoverished contexts.">321. TapBack: towards richer mobile interfaces in impoverished contexts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979345">Paper Link</a>    Pages:2733-2736</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Robinson:Simon">Simon Robinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rajput:Nitendra">Nitendra Rajput</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Matt">Matt Jones</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jain:Anupam">Anupam Jain</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sahay:Shrey">Shrey Sahay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nanavati:Amit_Anil">Amit Anil Nanavati</a></p>
<p>Abstract:
Much of the mobile work by HCI researchers explores a future world populated by high-end devices and relatively affluent users. This paper turns to consider the hundreds of millions of people for whom such sophistication will not be realised for many years to come. In developing world contexts, people will continue to rely on voice-primary interactions due to both literacy and economic reasons. Here, we motivate research into how to accommodate advanced mobile interface techniques while overcoming the handset, data-connection and user limitations. As a first step we introduce TapBack: back-of-device taps to control a dialled-up, telephone-network-based voice service. We show how these audio gestures might be recognised over a standard telephone connection, via users' existing low-end devices. Further, in a longitudinal deployment, the techniques were made available on a live voice service used by rural Indian farmers. Data from the study illustrates the desire by users to adopt the approach and its potential extensions.</p>
<p>Keywords:
audio gestures; back-of-device interaction; developing regions; mobile hci; spoken web</p>
<h3 id="322. "ClearPlate" for capturing printed information: a scanner and viewfinder in one optical unit.">322. "ClearPlate" for capturing printed information: a scanner and viewfinder in one optical unit.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979346">Paper Link</a>    Pages:2737-2740</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Maeda:Atsuhiko">Atsuhiko Maeda</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hara:Kenji">Kenji Hara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kobayashi:Minoru">Minoru Kobayashi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Abe:Masanobu">Masanobu Abe</a></p>
<p>Abstract:
As it is becoming more common for various handheld devices to be equipped with a camera, applications that use image recognition are increasing. Therefore, improving the usability of these devices by enhancing their image capture characteristics is becoming more important. We present ClearPlate - a new optical unit for image capture. It has a physically transparent viewfinder through which the user can observe the target directly without offset; the framed image is captured by the built-in camera. We also present a user study that evaluates ClearPlate performance in the 2D barcode acquisition task. Results show that ClearPlate significantly outperforms the camera-phone-based approach with regard to 2D barcode acquisition.</p>
<p>Keywords:
2d barcode; camera; image recognition; paper interface; see-through interface; target acquisition</p>
<h2 id="Shortcuts commands & expertise    4">Shortcuts commands &amp; expertise    4</h2>
<h3 id="323. Dips and ceilings: understanding and supporting transitions to expertise in user interfaces.">323. Dips and ceilings: understanding and supporting transitions to expertise in user interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979348">Paper Link</a>    Pages:2741-2750</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Scarr:Joey">Joey Scarr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/q/Quinn:Philip">Philip Quinn</a></p>
<p>Abstract:
Interface guidelines encourage designers to include shortcut mechanisms that enable high levels of expert performance, but prior research has demonstrated that few users switch to using them. To help understand how interfaces can better support a transition to expert performance we develop a framework of the interface and human factors influencing expertise development. We then present a system called Blur that addresses three main problems in promoting the transition: prompting an initial switch to expert techniques, minimising the performance dip arising from the switch, and enabling a high performance ceiling. Blur observes the user's interaction with unaltered desktop applications and uses calm notification to support learning and promote awareness of an alternative hot command interface. An empirical study validates Blur's design, showing that users make an early and sustained switch to hot commands, and that doing so improves their performance and satisfaction.</p>
<p>Keywords:
command line interfaces.; expertise development; novice-to-expert transition</p>
<h3 id="324. Ambient help.">324. Ambient help.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979349">Paper Link</a>    Pages:2751-2760</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Matejka:Justin">Justin Matejka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
In this paper we present Ambient Help, a system that supports opportunistic learning by providing automatic, context-sensitive learning resources while a user works. Multiple videos and textual help resources are presented ambiently on a secondary display. We define and examine a collection of design consideration for this type of interface. After describing our implementation details, we report on an experiment which shows that Ambient Help supports finding more helpful information, while not having a negative impact on the user's productivity, as compared to a traditional help condition.</p>
<p>Keywords:
ambient system; help; learnability; understanding</p>
<h3 id="325. Parameter selection in keyboard-based dialog boxes.">325. Parameter selection in keyboard-based dialog boxes.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979350">Paper Link</a>    Pages:2761-2764</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hendy:Jeff_C=">Jeff C. Hendy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Link:Juliette">Juliette Link</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Booth:Kellogg_S=">Kellogg S. Booth</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McGrenere:Joanna">Joanna McGrenere</a></p>
<p>Abstract:
Recent keyboard-based alternatives to WIMP interfaces do not have good support for commands that require multiple parameters. We remedy this by extending a previous design and mimicking dialog boxes to provide good visual feedback while still keeping the advantages of keyboard input. A laboratory study showed the new technique to be competitive with dialog boxes on speed and error rate, but strongly preferred over dialog boxes by experienced command line users. This is a marked improvement over the previous design, which was also preferred by the target user group but did not compete with dialog boxes in terms of performance.</p>
<p>Keywords:
command-line interfaces; dialog boxes; wimp</p>
<h3 id="326. Categorization costs for hierarchical keyboard commands.">326. Categorization costs for hierarchical keyboard commands.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979351">Paper Link</a>    Pages:2765-2768</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Craig_S=">Craig S. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Denkov:Svetlin">Svetlin Denkov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Omanson:Richard_C=">Richard C. Omanson</a></p>
<p>Abstract:
Previous research comparing methods of issuing commands found that selecting a toolbar item is faster than selecting an item from two menus with either a mouse or keyboard shortcut. Over the course of 90 trials, however, the keyboard method showed the most improvement, nearing the toolbar response time. The study presented in this paper compared the response time of the keyboard method across 240 trials when items were drawn from a single versus two menus. Throughout the trials, the 1-menu condition produced selection times that were on average 600 ms to 800 ms faster than the 2-menu condition suggesting users in the 2-menu condition were not able to bypass the menu decision by chunking the 3-key sequence into one cognitive unit. Models are presented to describe performance at various stages of learning. Practical implications are that hierarchical, category-based keyboard commands do not provide a clear advantage to toolbar-based selection and that theory-based evaluation methods may need to reflect this result.</p>
<p>Keywords:
command entry; effects; keyboard shortcuts; performance models; practice; toolbar</p>
<h2 id="Sound interactions    5">Sound interactions    5</h2>
<h3 id="327. Sasayaki: augmented voice web browsing experience.">327. Sasayaki: augmented voice web browsing experience.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979353">Paper Link</a>    Pages:2769-2778</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sato:Daisuke">Daisuke Sato</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhu:Shaojian">Shaojian Zhu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kobayashi:Masatomo">Masatomo Kobayashi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Takagi:Hironobu">Hironobu Takagi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Asakawa:Chieko">Chieko Asakawa</a></p>
<p>Abstract:
Auditory user interfaces have great Web-access potential for billions of people with visual impairments, with limited literacy, who are driving, or who are otherwise unable to use a visual interface. However a sequential speech-based representation can only convey a limited amount of information. In addition, typical auditory user interfaces lose the visual cues such as text styles and page structures, and lack effective feedback about the current focus. To address these limitations, we created Sasayaki (from whisper in Japanese), which augments the primary voice output with a secondary whisper of contextually relevant information, automatically or in response to user requests. It also offers new ways to jump to semantically meaningful locations. A prototype was implemented as a plug-in for an auditory Web browser. Our experimental results show that the Sasayaki can reduce the task completion times for finding elements in webpages and increase satisfaction and confidence.</p>
<p>Keywords:
Sasayaki; auditory interface; multiple voices; voice augmented browsing; web accessibility</p>
<h3 id="328. On the audio representation of radial direction.">328. On the audio representation of radial direction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979354">Paper Link</a>    Pages:2779-2788</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harada:Susumu">Susumu Harada</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Takagi:Hironobu">Hironobu Takagi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Asakawa:Chieko">Chieko Asakawa</a></p>
<p>Abstract:
We present and evaluate an approach towards eyes-free auditory display of spatial information that considers radial direction as a fundamental type of value primitive. There are many benefits to being able to sonify radial directions, such as indicating the heading towards a point of interest in a direct and dynamic manner, rendering a path or shape outline by sonifying a continual sequence of tangent directions as the path is traced, and providing direct feedback of the direction of motion of the user in a physical space or a pointer in a virtual space. We propose a concrete mapping of vowel-like sounds to radial directions as one potential method to enable sonification of such information. We conducted a longitudinal study with five sighted and two blind participants to evaluate the learnability and effectiveness of this method. Results suggest that our directional sound mapping can be learned within a few hours and be used to aurally perceive spatial information such as shape outlines and path contours.</p>
<p>Keywords:
audio display; navigation; non-speech; non-verbal; radial direction; sonification; visual impairment</p>
<h3 id="329. Multidimensional gesture sensing at the piano keyboard.">329. Multidimensional gesture sensing at the piano keyboard.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979355">Paper Link</a>    Pages:2789-2798</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McPherson:Andrew_P=">Andrew P. McPherson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Youngmoo_E=">Youngmoo E. Kim</a></p>
<p>Abstract:
In this paper we present a new keyboard interface for computer music applications. Where traditional keyboard controllers report the velocity of each key-press, our interface senses up to five separate dimensions: velocity, percussiveness, rigidity, weight, and depth. These dimensions, which we identified based on the pedagogical piano literature and pilot studies with professional pianists, together present a rich picture of physical gestures at the keyboard, including information on the performer's motion before, during, and after a note is played. User studies confirm that the sensed dimensions are intuitive and controllable and that mappings between gesture and sound produce novel, playable musical instruments, even for users without prior keyboard experience. The multidimensional sensing capability demonstrated in this paper is also potentially applicable to button interfaces outside the musical domain.</p>
<p>Keywords:
gesture sensing; keyboard; multidimensional input; musical interfaces; piano</p>
<h3 id="330. Spatialized sound enhances biomechanically-induced self-motion illusion (vection).">330. Spatialized sound enhances biomechanically-induced self-motion illusion (vection).</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979356">Paper Link</a>    Pages:2799-2802</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Riecke:Bernhard_E=">Bernhard E. Riecke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Feuereissen:Daniel">Daniel Feuereissen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rieser:John_J=">John J. Rieser</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McNamara:Timothy_P=">Timothy P. McNamara</a></p>
<p>Abstract:
The use of vection, the illusion of self-movement, has recently been explored as a novel way to immerse observers in mediated environments through illusory yet compelling self-motion without physically moving. This provides advantages over existing systems that employ costly, cumbersome, and potentially hazardous motion platforms, which are often surprisingly inadequate to provide life-like motion experiences. This study investigates whether spatialized sound rotating around the stationary, blindfolded listener can facilitate biomechanical vection, the illusion of self-rotation induced by stepping along a rotating floor plate. For the first time, integrating simple auditory and biomechanical cues for turning in place evoked convincing circular vection. In an auditory baseline condition, participants experienced only spatialized auditory cues. In a purely biomechanical condition, seated participants stepped along sideways on a rotating plate while listening to mono masking sounds. Scores of the bi-modal condition (binaural+biomechanical cues) exceeded the sum of both single cue conditions, which may imply super-additive or synergistic effects.</p>
<p>Keywords:
bio-mechanical and auditory circular vection; cognitive science; cue-integration; human factors; psychology; self-motion illusions; self-motion perception; virtual reality</p>
<h3 id="331. Name that tune: musicons as reminders in the home.">331. Name that tune: musicons as reminders in the home.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979357">Paper Link</a>    Pages:2803-2806</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McGee=Lennon:Marilyn_Rose">Marilyn Rose McGee-Lennon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wolters:Maria_K=">Maria K. Wolters</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McLachlan:Ross">Ross McLachlan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hall:Cordelia_V=">Cordelia V. Hall</a></p>
<p>Abstract:
In this paper we argue that Musicons, short samples from pieces of music are a useful way to present private but memorable reminder messages. We investigated accuracy, memorability and response times for short, medium, and long Musicons. User performance on the Musicons was also compared to short spoken reminders. The study consisted of two sessions a week apart. Quantitative measures were augmented with qualitative questions about associations and memories. Overall, participants achieved a high level of accuracy (89%) on the Musicons. Recognition was stable at 90% or better across sessions for users who were able to construct meaningful links between Musicons and the associated tasks. Optimal response times were achieved for medium-length 0.5 sec. Musicons. We conclude that Musicons are a viable option for alarms and notifications that combine the high learnability of Auditory Icons with the more private nature of Earcons.</p>
<p>Keywords:
auditory reminders; earcons; memory; musicons</p>
<h2 id="Innovation & design    1">Innovation &amp; design    1</h2>
<h3 id="332. Prototyping dynamics: sharing multiple designs improves exploration, group rapport, and results.">332. Prototyping dynamics: sharing multiple designs improves exploration, group rapport, and results.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979359">Paper Link</a>    Pages:2807-2816</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dow:Steven">Steven Dow</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fortuna:Julie">Julie Fortuna</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwartz:Dan">Dan Schwartz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Altringer:Beth">Beth Altringer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwartz:Daniel_L=">Daniel L. Schwartz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Klemmer:Scott_R=">Scott R. Klemmer</a></p>
<p>Abstract:
Prototypes ground group communication and facilitate decision making. However, overly investing in a single design idea can lead to fixation and impede the collaborative process. Does sharing multiple designs improve collaboration? In a study, participants created advertisements individually and then met with a partner. In the Share Multiple condition, participants designed and shared three ads. In the Share Best condition, participants designed three ads and selected one to share. In the Share One condition, participants designed and shared one ad. Sharing multiple designs improved outcome, exploration, sharing, and group rapport. These participants integrated more of their partner's ideas into their own subsequent designs, explored a more divergent set of ideas, and provided more productive critiques of their partner's designs. Furthermore, their ads were rated more highly and garnered a higher click-through rate when hosted online.</p>
<p>Keywords:
creativity; critique; design teams; exploration; prototyping</p>
<h2 id="Tabletop synchronous collaboration    2">Tabletop synchronous collaboration    2</h2>
<h3 id="333. Enhancing genomic learning through tabletop interaction.">333. Enhancing genomic learning through tabletop interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979361">Paper Link</a>    Pages:2817-2826</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shaer:Orit">Orit Shaer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Strait:Megan">Megan Strait</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Valdes:Consuelo">Consuelo Valdes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Feng:Taili">Taili Feng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lintz:Michael">Michael Lintz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Heidi">Heidi Wang</a></p>
<p>Abstract:
We present G-nome Surfer 2.0, a tabletop interface for fostering inquiry-based learning of genomics. We conducted an experimental study with 48 participants that compared students' learning of genomic concepts using existing bioinformatics tools and using two alternative implementations of G-nome Surfer: a collaborative multi-mouse GUI and a tabletop interface. Our findings indicate that G-nome Surfer improves students' performance, reduces workload, and increases enjoyment. The comparison of tabletop and multi-mouse implementations further shows that the tabletop condition results in four educational benefits: 1) increasing physical participation, 2) encouraging reflection, 3) fostering effective collaboration, and 4) facilitating more intuitive interaction.</p>
<p>Keywords:
collaborative learning; multi-touch; tabletop interaction</p>
<h3 id="334. Supporting fluid tabletop collaboration across distances.">334. Supporting fluid tabletop collaboration across distances.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979362">Paper Link</a>    Pages:2827-2836</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yamashita:Naomi">Naomi Yamashita</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kuzuoka:Hideaki">Hideaki Kuzuoka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hirata:Keiji">Keiji Hirata</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aoyagi:Shigemi">Shigemi Aoyagi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shirai:Yoshinari">Yoshinari Shirai</a></p>
<p>Abstract:
In this study, we examine how remote collaborators' upper body view affects collaboration when people engage in multiparty fluid tabletop activities across distances. We experimentally investigated the effects of upper body view on four-person group tabletop collaboration, two-by-two at identical locations: shared tabletop vs. shared tabletop plus upper body view. Although previous research has often failed to illustrate the advantages of showing remote participants' upper body view, our study showed that task performance was significantly higher in conditions with upper body view. Furthermore, participants with upper body view tended to take a step away from their remote partners to effectively glance at them while taking a comparable perspective of the tabletop objects. Detailed analysis of the video recordings revealed that upper body view was effective for fluid tabletop collaboration because it helped achieve joint perspective and helped estimate the timing and rough location of subsequent tabletop activity.</p>
<p>Keywords:
group-to-group collaboration; remote gesture; shared tabletop; upper body view; video-mediated communication</p>
<h2 id="Social Q & A    3">Social Q &amp; A    3</h2>
<h3 id="335. Effects of community size and contact rate in synchronous social q&a.">335. Effects of community size and contact rate in synchronous social q&amp;a.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979364">Paper Link</a>    Pages:2837-2846</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/White:Ryen_W=">Ryen W. White</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Richardson:Matthew">Matthew Richardson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Yandong">Yandong Liu</a></p>
<p>Abstract:
Social question-and-answer (Q&amp;A) involves the location of answers to questions through communication with people. Social Q&amp;A systems, such as mailing lists and Web forums are popular, but their asynchronous nature can lead to high answer latency. Synchronous Q&amp;A systems facilitate real-time dialog, usually via instant messaging, but face challenges with interruption costs and the availability of knowledgeable answerers at question time. We ran a longitudinal study of a synchronous social Q&amp;A system to investigate the effects of the rate with which potential answerers were contacted (trading off time-to-answer against interruption cost) and community size (varying total number of members). We found important differences in subjective and objective measures of system performance with these variations. Our findings help us understand the costs and benefits of varying contact rate and community size in synchronous social Q&amp;A, and inform system design for social Q&amp;A.</p>
<p>Keywords:
community size; contact rate; synchronous social q&amp;a</p>
<h3 id="336. Redesign as an act of violence: disrupted interaction patterns and the fragmenting of a social Q&A community.">336. Redesign as an act of violence: disrupted interaction patterns and the fragmenting of a social Q&amp;A community.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979365">Paper Link</a>    Pages:2847-2856</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gazan:Rich">Rich Gazan</a></p>
<p>Abstract:
The worst-case scenario for the redesign of an established online community is a subsequent mass migration of its core members to other sites. Using data from transaction logs, content analysis and participant observation, this paper presents a descriptive analysis of the fragmentation of a social question answering (Q&amp;A) community in the immediate aftermath of a fundamental redesign, where site-based communication mechanisms no longer functioned. The ways in which the community and its diaspora reacted, reconnected and resettled on other sites provides empirical data to support recent research on the life cycle of online communities. The results suggest that many of the same processes that help social Q&amp;A sites generate content and motivate participation can work to dismantle an established community if communications between members are even temporarily disrupted. Modeling a redesign as an attack on a community can help future designers anticipate alternative paths of communication and information flows.</p>
<p>Keywords:
online communities; question answering; social q&amp;a</p>
<h3 id="337. Design lessons from the fastest q&a site in the west.">337. Design lessons from the fastest q&amp;a site in the west.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979366">Paper Link</a>    Pages:2857-2866</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mamykina:Lena">Lena Mamykina</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Manoim:Bella">Bella Manoim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mittal:Manas">Manas Mittal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hripcsak:George">George Hripcsak</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hartmann:Bj=ouml=rn">Bjrn Hartmann</a></p>
<p>Abstract:
This paper analyzes a Question &amp; Answer site for programmers, Stack Overflow, that dramatically improves on the utility and performance of Q&amp;A systems for technical domains. Over 92% of Stack Overflow questions about expert topics are answered - in a median time of 11 minutes. Using a mixed methods approach that combines statistical data analysis with user interviews, we seek to understand this success. We argue that it is not primarily due to an a priori superior technical design, but also to the high visibility and daily involvement of the design team within the community they serve. This model of continued community leadership presents challenges to both CSCW systems research as well as to attempts to apply the Stack Overflow model to other specialized knowledge domains.</p>
<p>Keywords:
mixed methods analysis; q&amp;a</p>
<h2 id="Empowering users in developing regions    1">Empowering users in developing regions    1</h2>
<h3 id="338. Towards a design model for women's empowerment in the developing world.">338. Towards a design model for women's empowerment in the developing world.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979368">Paper Link</a>    Pages:2867-2876</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shroff:Geeta">Geeta Shroff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kam:Matthew">Matthew Kam</a></p>
<p>Abstract:
Pulitzer Prize-winning journalist Nicholas Kristof argues that in this century the paramount moral challenge will be the struggle for gender equality around the world. In this paper, we present a design model for empowering low-income women in the developing world, in ways that cut across individual application areas. Specifically, this model characterizes a possible trajectory for NGOs and women to engage with each other and among themselves potentially augmented by technology to help women escape from poverty. The fieldwork components in this study took place over 15 weeks in three phases, with a total of 47 NGO staff members and 35 socio-economically challenged women in rural and urban India. Interviews and co-design sessions with seven proof-of-concept prototypes showed that women appeared to belong to five distinct stages of growth in striving towards independence. We report the technology design lessons from our co-design sessions to illustrate how user readiness, relationship building at the community and family levels, and integration with state, national and international level programs, should be taken into account in the broader context of intervention design.</p>
<p>Keywords:
HCI4D; ICT4D; ICTD; design for inclusion; developing countries; development; digital divide; feminist interaction; gender; women empowerment</p>
<h2 id="Organizations & distributed work    3">Organizations &amp; distributed work    3</h2>
<h3 id="339. Reuse in the wild: an empirical and ethnographic study of organizational content reuse.">339. Reuse in the wild: an empirical and ethnographic study of organizational content reuse.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979370">Paper Link</a>    Pages:2877-2886</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mejova:Yelena">Yelena Mejova</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schepper:Klaar_De">Klaar De Schepper</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bergman:Lawrence">Lawrence Bergman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lu:Jie">Jie Lu</a></p>
<p>Abstract:
We present a large-scale study of content reuse networks in a large and highly hierarchical organization. In our study, we combine analysis of a collection of presentations produced by employees with interviews conducted throughout the organization and a survey to study presentation content reuse. Study results show a variety of information needs and behaviors related to content reuse as well as a need for a personalized and socially-integrated networking tool for enabling easy access to previously generated presentation material. In this paper we describe our findings and outline a set of requirements for an effective content reuse facility.</p>
<p>Keywords:
content reuse; data diffusion; social network; user study</p>
<h3 id="340. Do you know dis?: a user study of a knowledge discovery tool for organizations.">340. Do you know dis?: a user study of a knowledge discovery tool for organizations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979371">Paper Link</a>    Pages:2887-2896</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Laqua:Sven">Sven Laqua</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sasse:Martina_Angela">Martina Angela Sasse</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Greenspan:Steven">Steven Greenspan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gates:Carrie">Carrie Gates</a></p>
<p>Abstract:
Organisations today have no reliable way of ensuring that all employees are aware of information that may be relevant to their work. In this paper we report on a 2-year project in which we have iteratively designed, developed and tested a knowledge discovery system (KnowDis) for organizations. Early stages of our study revealed that, employees do not know what is available on the corporate intranet, or files and messages they have stored. KnowDis proactively fetches relevant information and displays it in an unobtrusive form; this increases employee awareness without disrupting their tasks. We discuss and characterize knowledge workers' email usage behavior. Our main study with 28 users of KnowDis-enhanced email showed it can improve the user experience and performance on information retrieval tasks for knowledge workers.</p>
<p>Keywords:
contextual user interfaces; contextualization; information discovery; knowledge management; personal information management; sensemaking</p>
<h3 id="341. What's in a move?: normal disruption and a design challenge.">341. What's in a move?: normal disruption and a design challenge.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979372">Paper Link</a>    Pages:2897-2906</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zadeh:Reza">Reza Zadeh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Balakrishnan:Aruna_D=">Aruna D. Balakrishnan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kiesler:Sara_B=">Sara B. Kiesler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cummings:Jonathon_N=">Jonathon N. Cummings</a></p>
<p>Abstract:
The CHI community has led efforts to support teamwork, but has neglected team disruption, as may occur if team members relocate to another institution. We studied moves in 548 interdisciplinary research projects with 2691 researchers (PIs). Moves, and thus disruptions, were not rare, especially in large distributed projects. Overall, one-third of all projects experienced at least one member relocating but most moves reflected churn across high-ranking institutions. When collaborators moved, the project was disrupted. Our data suggest that moves exemplify normal disruptions. A design challenge is to help projects adapt to disruption.</p>
<p>Keywords:
coordination; disruption; distributed work; interdisciplinary teams; moving; r &amp; d; relocation; turnover; virtual organization</p>
<h2 id="Reading & writing    3">Reading &amp; writing    3</h2>
<h3 id="342. Finders/keepers: a longitudinal study of people managing information scraps in a micro-note tool.">342. Finders/keepers: a longitudinal study of people managing information scraps in a micro-note tool.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979374">Paper Link</a>    Pages:2907-2916</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kleek:Max_Van">Max Van Kleek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Styke:Wolfe">Wolfe Styke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/schraefel:m=_c=">m. c. schraefel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karger:David_R=">David R. Karger</a></p>
<p>Abstract:
Mainstream PIM tools capture only a portion of the information that people need to manage. Many information scraps seem to exist that don't make their way into these tools, instead being relegated to sticky notes, text files, and other makeshift storage, or simply being lost. In an effort to understand the role of these information scraps, the underlying needs they reflect, and the way PIM tools must be modified to support those needs, we created List-it, a micronote tool for quick and simple capture of information scraps. In this article, we analyze the notes and interaction logs of 420 volunteer users of List-it over a two-year period of study (August 2008-August 2010). We contextualize our analysis with results of two surveys and an e-mail interview we conducted in October 2009. We find that people are drawn to List-it by the ease and speed of note capture and by the ability to record scraps with arbitrary content that blends or completely escapes the types and roles imposed by our rigid PIM tools. Notes are taken to serve a variety of needs -- reminding, reference, journaling/activity logging, brainstorming, and to indefinitely archive information of sentimental or personal value. Finally, while people differ considerably in the ways they keep information, our findings suggest such differences can be described as a combination of four distinct strategies, enriching the Filer/Piler distinction identified for classic document management.</p>
<p>Keywords:
information scraps; longitudinal study; note taking; personal information management; personal organization</p>
<h3 id="343. The imposition and superimposition of digital reading technology: the academic potential of e-readers.">343. The imposition and superimposition of digital reading technology: the academic potential of e-readers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979375">Paper Link</a>    Pages:2917-2926</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Thayer:Alexander">Alexander Thayer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Charlotte_P=">Charlotte P. Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hwang:Linda_H=">Linda H. Hwang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sales:Heidi">Heidi Sales</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sen:Pausali">Pausali Sen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dalal:Ninad">Ninad Dalal</a></p>
<p>Abstract:
While rapid growth in e-reader use is receiving much attention in industry and academia, the use of e-readers for academic reading remains understudied. This qualitative study investigates how graduate students accomplish their academic reading and integrate an e-reader into their reading practices. Our work represents the first long-term study of e-reading on a production device (the Amazon Kindle DX). In this paper we contribute new knowledge to the discussion of the academic potential of e-readers by analyzing the meta-level relationship between reading tasks and associated reading techniques, students' compensation for the limitations of e-readers, and the hindrance of the human ability to construct cognitive maps of texts when using e-readers.</p>
<p>Keywords:
academic reading practice; design; e-book; e-reader</p>
<h3 id="344. Active reading and its discontents: the situations, problems and ideas of readers.">344. Active reading and its discontents: the situations, problems and ideas of readers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979376">Paper Link</a>    Pages:2927-2936</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tashman:Craig_S=">Craig S. Tashman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edwards:W=_Keith">W. Keith Edwards</a></p>
<p>Abstract:
The increasing popularity of personal reading devices raises the question of how best to support so-called active reading, which involves acts like annotation, note taking, etc. Prior research addressed this question by observing the active reading process, and identifying disparities between computers and paper as a reading medium. We extend this research by 1) investigating the problems that readers experience in their real world tasks, 2) inquiring about their requirements for an ideal reading technology, and 3) updating earlier studies of naturalistic reading behavior, which are several years old now. We present here the results of our investigation, which included a diary study, interviews, and participatory design workshops.</p>
<p>Keywords:
active reading; diary studies; participatory design</p>
<h2 id="Engaging youth    5">Engaging youth    5</h2>
<h3 id="345. Exploratory evaluations of a computer game supporting cognitive behavioural therapy for adolescents.">345. Exploratory evaluations of a computer game supporting cognitive behavioural therapy for adolescents.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979378">Paper Link</a>    Pages:2937-2946</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Coyle:David">David Coyle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McGlade:Nicola">Nicola McGlade</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Doherty:Gavin">Gavin Doherty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/O=Reilly:Gary">Gary O'Reilly</a></p>
<p>Abstract:
The need to provide effective mental health treatments for adolescents has been described as a global public health challenge [27]. In this paper we discuss the exploratory evaluations of the first adolescent intervention to fully integrate a computer game implementing Cognitive Behavioural Therapy. Three distinct studies are presented: a detailed evaluation in which therapists independent of the design team used the game with 6 adolescents experiencing clinical anxiety disorders; a study in which a member of the design team used the game with 15 adolescents; and finally a study assessing the acceptability of the game and intervention with 216 practicing therapists. Findings are presented within the context of a framework for the design and evaluation of complex health interventions. The paper provides an in-depth insight into the use of therapeutic games to support adolescent interventions and provides stronger evidence than previously available for both their effectiveness and acceptability to stakeholders.</p>
<p>Keywords:
adolescent mental health; cognitive behavioural therapy; complex health interventions; computer games; evaluations</p>
<h3 id="346. In the mood: engaging teenagers in psychotherapy using mobile phones.">346. In the mood: engaging teenagers in psychotherapy using mobile phones.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979379">Paper Link</a>    Pages:2947-2956</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Mark">Mark Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Doherty:Gavin">Gavin Doherty</a></p>
<p>Abstract:
Mental illness is a significant and growing problem throughout the world. Many mental health problems have their root in childhood, and early intervention is recommended. Engaging young people in psychotherapeutic activities is challenging, and treatment adherence is often poor. This paper presents a series of studies carried out as part of the development of a mobile and online symptom tracking tool for adolescents with mental health problems. Teenagers use the system to record symptoms on their mobile phones and can view this information in a clinical setting with a therapist. We focus on a clinical pilot of the system with ten users in public mental health clinics. As well as indicating that the mobile diary tool can increase client adherence to therapeutic activities, the study yields insight into the factors influencing the success of the design and informs the design of other systems to be used as adjuncts to therapy.</p>
<p>Keywords:
clinical evaluation; mental health; mobile applications</p>
<h3 id="347. Breaking boundaries: strategies for mentoring through textile computing workshops.">347. Breaking boundaries: strategies for mentoring through textile computing workshops.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979380">Paper Link</a>    Pages:2957-2966</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kuznetsov:Stacey">Stacey Kuznetsov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Trutoiu:Laura_C=">Laura C. Trutoiu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kute:Casey">Casey Kute</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Howley:Iris">Iris Howley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paulos:Eric">Eric Paulos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Siewiorek:Daniel_P=">Daniel P. Siewiorek</a></p>
<p>Abstract:
With over 13.3 million children living below poverty line in the United States, there is a pressing need for engaging HCI research with children at the socio-economic margins. Drawing from design studio culture and art therapy literature, we explore wearable computing as a creative and tangible medium (similar to markers, paints, clays, etc.) for motivating 'at-risk' children in hands-on making and expressive instantiation of ideas. Working with a local outreach organization for 'at-risk' middle school girls, we conducted five weekly workshops during which participants ideated, designed and implemented personal wearable computing projects. These sessions inspired participants (age 10-12) who tend to be uninterested and uncooperative in educational activities to complete interactive projects and engage with workshop volunteers as mentors and peers. We present the challenges, merits and outcomes of our approach, proposing wearable computing as a healing outlet and a mentoring strategy for at-risk children.</p>
<p>Keywords:
at-risk children; design studio culture; wearable computing</p>
<h3 id="348. African American men constructing computing identity.">348. African American men constructing computing identity.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979381">Paper Link</a>    Pages:2967-2970</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/DiSalvo:Betsy_James">Betsy James DiSalvo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yardi:Sarita">Sarita Yardi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guzdial:Mark">Mark Guzdial</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McKlin:Tom">Tom McKlin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Meadows:Charles">Charles Meadows</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perry:Kenneth">Kenneth Perry</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bruckman:Amy">Amy Bruckman</a></p>
<p>Abstract:
Many young African American males have a passion for video games, but they don't often translate that passion into learning about computing. Part of the problem is that they do not identify with computing as a social norm within their peer group. This disidentification with computing can negatively impact academic performance and limit opportunities for upward mobility. We developed a job training program called Glitch Game Testers in which young African American men are trained to 'Sbreak open the black box' of their game consoles to learn about computing. Perceptions of peers' technical competency were measured before and after the summer 2010 program. Results showed that participants were more likely to view their peers as technical resources and their overall access to technical resources increased. Broader implications for motivating technology adoption in HCI are discussed.</p>
<p>Keywords:
African American culture; broadening participation in computing; group identity; masculinity; video games</p>
<h3 id="349. Brick by brick: iterating interventions to bridge the achievement gap with virtual peers.">349. Brick by brick: iterating interventions to bridge the achievement gap with virtual peers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979382">Paper Link</a>    Pages:2971-2974</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rader:Emilee_J=">Emilee J. Rader</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Echelbarger:Margaret">Margaret Echelbarger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cassell:Justine">Justine Cassell</a></p>
<p>Abstract:
We lay out one strand of a continuing investigation into the development of a virtual peer to help children learn to use "school English" and "school-ratified science talk". In this paper we describe a detailed analysis of a corpus of child-child language use, and report our findings on the ways children shift dialects and ways of discussing science depending on the social context and task. We discuss the implications of these results for the redesign of a virtual peer that can evoke language behaviors associated with student achievement. Furthermore, our results allow us to describe the ways in which this virtual agent can tailor its level of interaction based on a child's current aptitude in this area.</p>
<p>Keywords:
african american english; dialect; embodied conversational agent; quantitative methods; virtual peer</p>
<h2 id="Tangibles    5">Tangibles    5</h2>
<h3 id="350. Tangible bots: interaction with active tangibles in tabletop interfaces.">350. Tangible bots: interaction with active tangibles in tabletop interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979384">Paper Link</a>    Pages:2975-2984</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pedersen:Esben_Warming">Esben Warming Pedersen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
We present interaction techniques for tangible tabletop interfaces that use active, motorized tangibles, what we call Tangible Bots. Tangible Bots can reflect changes in the digital model and assist users by haptic feedback, by correcting errors, by multi-touch control, and by allowing efficient interaction with multiple tangibles. A first study shows that Tangible Bots are usable for fine-grained manipulation (e.g., rotating tangibles to a particular orientation); for coarse movements, Tangible Bots become useful only when several tangibles are controlled simultaneously. Participants prefer Tangible Bots and find them less taxing than passive, non-motorized tangibles. A second study focuses on usefulness by studying how electronic musicians use Tangible Bots to create music with a tangible tabletop application. We conclude by discussing the further potential of active tangibles, and their relative benefits over passive tangibles and multi-touch.</p>
<p>Keywords:
active tangibles; bidirectional interfaces; tangible user interfaces; user evaluation</p>
<h3 id="351. Geckos: combining magnets and pressure images to enable new tangible-object design and interaction.">351. Geckos: combining magnets and pressure images to enable new tangible-object design and interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979385">Paper Link</a>    Pages:2985-2994</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Leitner:Jakob">Jakob Leitner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haller:Michael">Michael Haller</a></p>
<p>Abstract:
In this paper we present Geckos, a new type of tangible objects which are tracked using a Force-Sensitive Resistance sensor. Geckos are based on low-cost permanent magnets and can also be used on non-horizontal surfaces. Unique pressure footprints are used to identify each tangible Gecko. Two types of tangible object designs are presented: Using a single magnet in combination with felt pads provides new pressure-based interaction modalities. Using multiple separate magnets it is possible to change the marker footprint dynamically and create new haptic experiences. The tangible object design and interaction are illustrated with example applications. We also give details on the feasibility and benefits of our tracking approach and show compatibility with other tracking technologies.</p>
<p>Keywords:
force-sensitive resistance; physical marker; pressure image; tangible; vertical display</p>
<h3 id="352. TUIC: enabling tangible interaction on capacitive multi-touch displays.">352. TUIC: enabling tangible interaction on capacitive multi-touch displays.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979386">Paper Link</a>    Pages:2995-3004</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yu:Neng=Hao">Neng-Hao Yu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chan:Li=Wei">Li-Wei Chan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lau:Seng=Yong">Seng-Yong Lau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tsai:Sung=Sheng">Sung-Sheng Tsai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hsiao:I=Chun">I-Chun Hsiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tsai:Dian=Je">Dian-Je Tsai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hsiao:Fang=I">Fang-I Hsiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cheng:Lung=Pan">Lung-Pan Cheng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Mike_Y=">Mike Y. Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Polly">Polly Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hung:Yi=Ping">Yi-Ping Hung</a></p>
<p>Abstract:
We present TUIC, a technology that enables tangible interaction on capacitive multi-touch devices, such as iPad, iPhone, and 3M's multi-touch displays, without requiring any hardware modifications. TUIC simulates finger touches on capacitive displays using passive materials and active modulation circuits embedded inside tangible objects, and can be used with multi-touch gestures simultaneously. TUIC consists of three approaches to sense and track objects: spatial, frequency, and hybrid (spatial plus frequency). The spatial approach, also known as 2D markers, uses geometric, multi-point touch patterns to encode object IDs. Spatial tags are straightforward to construct and are easily tracked when moved, but require sufficient spacing between the multiple touch points. The frequency approach uses modulation circuits to generate high-frequency touches to encode object IDs in the time domain. It requires fewer touch points and allows smaller tags to be built. The hybrid approach combines both spatial and frequency tags to construct small tags that can be reliably tracked when moved and rotated. We show three applications demonstrating the above approaches on iPads and 3M's multi-touch displays.</p>
<p>Keywords:
2d marker; frequency tag; interactive surface; multi-touch; physical interaction; tags; tangible; tui</p>
<h3 id="353. tBox: a 3d transformation widget designed for touch-screens.">353. tBox: a 3d transformation widget designed for touch-screens.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979387">Paper Link</a>    Pages:3005-3008</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Coh=eacute=:Aur=eacute=lie">Aurlie Coh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Decle:Fabrice">Fabrice Decle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hachet:Martin">Martin Hachet</a></p>
<p>Abstract:
3D transformation widgets are commonly used in many 3D applications operated from mice and keyboards. These user interfaces allow independent control of translations, rotations, and scaling for manipulation of 3D objects. In this paper, we study how these widgets can be adapted to the tactile paradigm. We have explored an approach where users apply rotations by means of physically plausible gestures, and we have extended successful 2D tactile principles to the context of 3D interaction. These investigations led to the design of a new 3D transformation widget, tBox, that can been operated easily and efficiently from gestures on touch-screens.</p>
<p>Keywords:
3d transformation widget; 3d user interfaces; multi-touch</p>
<h3 id="354. Rendering physical effects in tabletop controls.">354. Rendering physical effects in tabletop controls.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979388">Paper Link</a>    Pages:3009-3012</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Weiss:Malte">Malte Weiss</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Remy_0001:Christian">Christian Remy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borchers:Jan_O=">Jan O. Borchers</a></p>
<p>Abstract:
We introduce dynamic physical properties as an additional degree of freedom for passive tabletop controls. Using electromagnetic actuation, we manipulate attributes of tangibles on the fly, such as perceived weight, spring resistance, friction, and latching. We describe our actuation concepts, prototypes, and measurements showing that magnetic fields can change physical effects in a linear way. Controlled experiments reveal that participants can tactually distinguish four rendered resistance levels of a button prototype and easily detect dynamic detents in a continuous slider. Finally, we describe how adjustable physical properties in tangibles can enhance tabletop interaction.</p>
<p>Keywords:
actuation; haptics; interactive tabletops; physical properties; tangible user interfaces</p>
<h2 id="Groups around the table    4">Groups around the table    4</h2>
<h3 id="355. Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops.">355. Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979390">Paper Link</a>    Pages:3013-3022</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jetter:Hans=Christian">Hans-Christian Jetter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gerken:Jens">Jens Gerken</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Z=ouml=llner:Michael">Michael Zllner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reiterer:Harald">Harald Reiterer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Milic=Frayling:Natasa">Natasa Milic-Frayling</a></p>
<p>Abstract:
We introduce "Facet-Streams", a hybrid interactive surface for co-located collaborative product search on a tabletop. Facet-Streams combines techniques of information visualization with tangible and multi-touch interaction to materialize collaborative search on a tabletop. It harnesses the expressive power of facets and Boolean logic without exposing users to complex formal notations. Two user studies reveal how Facet-Streams unifies visual and tangible expressivity with simplicity in interaction, supports different strategies and collaboration styles, and turns product search into a fun and social experience.</p>
<p>Keywords:
collaborative search; tabletop; tangible user interfaces</p>
<h3 id="356. Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits.">356. Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979391">Paper Link</a>    Pages:3023-3032</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hinrichs:Uta">Uta Hinrichs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carpendale:M=_Sheelagh_T=">M. Sheelagh T. Carpendale</a></p>
<p>Abstract:
In this paper we describe our findings from a field study that was conducted at the Vancouver Aquarium to investigate how visitors interact with a large interactive table exhibit using multi-touch gestures. Our findings show that the choice and use of multi-touch gestures are influenced not only by general preferences for certain gestures but also by the interaction context and social context they occur in. We found that gestures are not executed in isolation but linked into sequences where previous gestures influence the formation of subsequent gestures. Furthermore, gestures were used beyond the manipulation of media items to support social encounters around the tabletop exhibit. Our findings indicate the importance of versatile many-to-one mappings between gestures and their actions that, other than one-to-one mappings, can support fluid transitions between gestures as part of sequences and facilitate social information exploration.</p>
<p>Keywords:
direct-touch interaction; field study; multi-touch gestures; public displays; tabletop displays</p>
<h3 id="357. Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop interface.">357. Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop interface.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979392">Paper Link</a>    Pages:3033-3042</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Paul">Paul Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Richard">Richard Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Yvonne">Yvonne Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kreitmayer:Stefan">Stefan Kreitmayer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davies:Matt">Matt Davies</a></p>
<p>Abstract:
Multi-touch tabletops have been much heralded as an innovative technology that can facilitate new ways of group working. However, there is little evidence of these materialising outside of research lab settings. We present the findings of a 5-week in-the-wild study examining how a shared planning application - designed to run on a walk-up-and-use tabletop - was used when placed in a tourist information centre. We describe how groups approached, congregated and interacted with it and the social interactions that took place - noting how they were quite different from research findings describing the ways groups work around a tabletop in lab settings. We discuss the implications of such situated group work for designing collaborative tabletop applications for use in public settings.</p>
<p>Keywords:
in situ; in-the-wild; public; tabletop; walk-up-and-use</p>
<h3 id="358. The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables.">358. The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979393">Paper Link</a>    Pages:3043-3052</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jamil:Izdihar">Izdihar Jamil</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/O=Hara:Kenton">Kenton O'Hara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perry:Mark_J=">Mark J. Perry</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karnik:Abhijit">Abhijit Karnik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a></p>
<p>Abstract:
This paper presents the findings of a user study investigating conversational patterns across three conditions of table-based interaction (direct touch interactive table, pantograph interactive table and non-digital table) for different types of educational activities. Findings demonstrate that communication style is significantly affected by interaction techniques. The direct touch technique stimulated conversations based around the topic and pedagogical method. The pantograph technique promoted playfulness and had a higher number of directive utterances between participants, with fewer task-based, group-oriented utterances. The non-digital table promoted reflective forms of task-orientated utterance, encouraged group communication and fostered more equitable participation between members. The findings provide insights into the design of interactive tables to support particular forms of social interaction.</p>
<p>Keywords:
children; collaborative learning; communication; interaction techniques; tabletop</p>
<h2 id="Rehabilitation    4">Rehabilitation    4</h2>
<h3 id="359. Opportunities for computing technologies to support healthy sleep behaviors.">359. Opportunities for computing technologies to support healthy sleep behaviors.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979395">Paper Link</a>    Pages:3053-3062</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Choe:Eun_Kyoung">Eun Kyoung Choe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Consolvo:Sunny">Sunny Consolvo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Watson:Nathaniel_F=">Nathaniel F. Watson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kientz:Julie_A=">Julie A. Kientz</a></p>
<p>Abstract:
Getting the right amount of quality sleep is a key aspect of good health, along with a healthy diet and regular exercise. Human-computer interaction (HCI) researchers have recently designed systems to support diet and exercise, but sleep has been relatively under-studied in the HCI community. We conducted a literature review and formative study aimed at uncovering opportunities for computing to support the important area of promoting healthy sleep. We present results from interviews with sleep experts, as well as a survey (N = 230) and interviews with potential users (N = 16) to indicate what people would find practical and useful for sleep. Based on these results, we identify a number of design considerations, challenges, and opportunities for using computing to support healthy sleep behaviors, as well as a design framework for mapping the design space of technologies for sleep.</p>
<p>Keywords:
design; health; health informatics; persuasive technology; qualitative study; sleep; wellness</p>
<h3 id="360. How to evaluate technologies for health behavior change in HCI research.">360. How to evaluate technologies for health behavior change in HCI research.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979396">Paper Link</a>    Pages:3063-3072</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Klasnja:Predrag_V=">Predrag V. Klasnja</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Consolvo:Sunny">Sunny Consolvo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pratt:Wanda">Wanda Pratt</a></p>
<p>Abstract:
New technologies for encouraging physical activity, healthy diet, and other types of health behavior change now frequently appear in the HCI literature. Yet, how such technologies should be evaluated within the context of HCI research remains unclear. In this paper, we argue that the obvious answer to this question - that evaluations should assess whether a technology brought about the intended change in behavior - is too limited. We propose that demonstrating behavior change is often infeasible as well as unnecessary for a meaningful contribution to HCI research, especially when in the early stages of design or when evaluating novel technologies. As an alternative, we suggest that HCI contributions should focus on efficacy evaluations that are tailored to the specific behavior-change intervention strategies (e.g., self-monitoring, conditioning) embodied in the system and studies that help gain a deep understanding of people's experiences with the technology.</p>
<p>Keywords:
behavior change; evaluation methods; health informatics; user studies</p>
<h3 id="361. Motivating mobility: designing for lived motivation in stroke rehabilitation.">361. Motivating mobility: designing for lived motivation in stroke rehabilitation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979397">Paper Link</a>    Pages:3073-3082</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Balaam:Madeline">Madeline Balaam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Egglestone:Stefan_Rennick">Stefan Rennick Egglestone</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzpatrick:Geraldine">Geraldine Fitzpatrick</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rodden:Tom">Tom Rodden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hughes:Ann=Marie">Ann-Marie Hughes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wilkinson:Anna">Anna Wilkinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nind:Thomas">Thomas Nind</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Axelrod:Lesley">Lesley Axelrod</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harris:Eric_Charles">Eric Charles Harris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ricketts:Ian">Ian Ricketts</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mawson:Susan">Susan Mawson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Burridge:Jane_H=">Jane H. Burridge</a></p>
<p>Abstract:
How to motivate and support behaviour change through design is becoming of increasing interest to the CHI community. In this paper, we present our experiences of building systems that motivate people to engage in upper limb rehabilitation exercise after stroke. We report on participatory design work with four stroke survivors to develop a holistic understanding of their motivation and rehabilitation needs, and to construct and deploy engaging interactive systems that satisfy these. We reflect on the limits of motivational theories in trying to design for the lived experience of motivation and highlight lessons learnt around: helping people articulate what motivates them; balancing work, duty, fun; supporting motivation over time; and understanding the wider social context. From these we identify design guidelines that can inform a toolkit approach to support both scalability and personalisability.</p>
<p>Keywords:
behaviour change; home; motivation; rehabilitation; stroke</p>
<h3 id="362. Group pulmonary rehabilitation delivered to the home via the internet: feasibility and patient perception.">362. Group pulmonary rehabilitation delivered to the home via the internet: feasibility and patient perception.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979398">Paper Link</a>    Pages:3083-3092</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Andrea">Andrea Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aitken:Angus">Angus Aitken</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Godden:David">David Godden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Colligan:Judith">Judith Colligan</a></p>
<p>Abstract:
Chronic Obstructive Pulmonary Disease (COPD) is a common and debilitating lung condition. Pulmonary rehabilitation is effective in treating COPD. Rehabilitation, combining physical exercise with education, is usually undertaken in hospital or clinic-based groups led by a clinician. The support of the group is important. However, distance of travel, and mobility and transport problems can mean that patients are unable to participate. This paper describes a feasibility study to deliver a program to a group of patients in their own homes, improving accessibility. A novel videoconferencing system was installed in four patient's homes, connected to their TV and the Internet. A physiotherapist delivered a pulmonary rehabilitation program, involving twice-weekly exercise sessions for eight weeks. All were visible and audible to maintain the group-based approach of the conventional program. The technology performed well, satisfaction was high, and clinical improvements occurred in all patients, comparable to a conventional program. Larger studies are warranted.</p>
<p>Keywords:
chronic obstructive pulmonary disease (copd); healthcare; internet; lung disease; physical exercise; pulmonary rehabilitation; rehabilitation; videoconferencing</p>
<h2 id="Software development & product support    1">Software development &amp; product support    1</h2>
<h3 id="363. Modern software product support processes and the usage of multimedia formats.">363. Modern software product support processes and the usage of multimedia formats.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979400">Paper Link</a>    Pages:3093-3102</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chilana:Parmit_K=">Parmit K. Chilana</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
Despite being an important channel for end-user assistance, few studies have directly investigated the interactions that occur in modern-day practice of software product support. We present results from a multi-dimensional analysis of product support activities at a leading design software company. We carried out a quantitative analysis of existing support requests, a survey with product support specialists, and follow-up interviews to understand the current practices in product support. In particular, we investigated the utility of different multimedia formats that modern web-based support systems enable. Our results showed that despite the value that these formats bring to support tasks, support specialists still face bottlenecks in remotely resolving software problems. We conclude by highlighting several opportunities in HCI for improving diagnosis and resolution of software issues over the web.</p>
<p>Keywords:
issue diagnosis; issue resolution; product support; support tools</p>
<h2 id="Multitasking & interruption    4">Multitasking &amp; interruption    4</h2>
<h3 id="364. Ease of juggling: studying the effects of manual multitasking.">364. Ease of juggling: studying the effects of manual multitasking.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979402">Paper Link</a>    Pages:3103-3112</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bergstrom=Lehtovirta:Joanna">Joanna Bergstrom-Lehtovirta</a></p>
<p>Abstract:
Everyday activities often involve using an interactive device while one is handling various other physical objects (wallets, bags, doors, pens, mugs, etc.). This paper presents the Manual Multitasking Test, a test with 12 conditions emulating manual demands of everyday multitasking situations. It allows experimenters to expose the effects of design on "manual flexibility": users' ability to reconfigure the sensorimotor control of arms, hands, and fingers in order to regain the high performance levels they experience when using the device on its own. The test was deployed for pointing devices on laptops and Qwerty keyboards of mobile devices. In these studies, we identified facilitative design features whose absence explains, for example, why the mouse and stylus function poorly in multi-object performance. The issue deserves more attention, because interfaces that are nominally similar (e.g., "one-handed input") can vary dramatically in terms of "ease of juggling".</p>
<p>Keywords:
evaluation; human-computer interaction; interface design; multi-object manual performance; multitasking; usability</p>
<h3 id="365. Designing of multimodal feedback for enhanced multitasking performance.">365. Designing of multimodal feedback for enhanced multitasking performance.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979403">Paper Link</a>    Pages:3113-3122</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Gerard">Gerard Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Hyeong_Cheol">Hyeong Cheol Kim</a></p>
<p>Abstract:
In this paper, we explore the possibility of applying multimodal feedback to improve multitasking performance. For this purpose, we have devised a general multitasking test application, called the MSP-Blocks, which includes many basic elements of multitasking and can be used to carry out a variety of multimodal multitasking experiments. An experiment was run to study the effects of two factors (the number of jobs and types of multimodal feedback) to user task performance, specifically, interaction effort, concurrency, fairness and output quality. The results indicated that multimodal feedback did influence multitasking performance, and moreover, non-redundant multimodal feedback was more effective than no multimodality or redundant multimodality for tasks with reasonable difficulty, e.g. when the number of jobs was more than four.</p>
<p>Keywords:
Concurrency; experiment; multimodal interfaces; multitasking; task performance</p>
<h3 id="366. The effects of time constraints on user behavior for deferrable interruptions.">366. The effects of time constraints on user behavior for deferrable interruptions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979404">Paper Link</a>    Pages:3123-3126</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bogunovich:Peter">Peter Bogunovich</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Salvucci:Dario_D=">Dario D. Salvucci</a></p>
<p>Abstract:
Previous studies of multitasking have highlighted the importance of cognitive load in interruptibility by showing that forced interruptions are least disruptive when cognitive load is low, and also that users prefer to address interruptions at low-load points when given a choice. We present an empirical study that uses a ringing-phone scenario to examine how users manage deferrable interruptions in the presence of varying time constraints. We found that while cognitive load did influence multitasking as expected, the time constraints placed on the user also had a significant impact. In particular, we observed three distinct strategies for addressing interruption: the expected strategy of switching at low-load points, but also two other strategies of continuing on after a low-load point or giving up at a high-load point. The presence of the latter two strategies strongly suggests that users can adapt their multitasking behavior with respect to the time constraints of the interrupting task.</p>
<p>Keywords:
attention; interruption; multitasking; workload</p>
<h3 id="367. Why do i keep interrupting myself?: environment, habit and self-interruption.">367. Why do i keep interrupting myself?: environment, habit and self-interruption.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979405">Paper Link</a>    Pages:3127-3130</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dabbish:Laura">Laura Dabbish</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mark:Gloria">Gloria Mark</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gonz=aacute=lez:V=iacute=ctor_M=">Vctor M. Gonzlez</a></p>
<p>Abstract:
Self-interruptions account for a significant portion of task switching in information-centric work contexts. However, most of the research to date has focused on understanding, analyzing and designing for external interruptions. The causes of self-interruptions are not well understood. In this paper we present an analysis of 889 hours of observed task switching behavior from 36 individuals across three high-technology information work organizations. Our analysis suggests that self-interruption is a function of organizational environment and individual differences, but also external interruptions experienced. We find that people in open office environments interrupt themselves at a higher rate. We also find that people are significantly more likely to interrupt themselves to return to solitary work associated with central working spheres, suggesting that self-interruption occurs largely as a function of prospective memory events. The research presented contributes substantially to our understanding of attention and multitasking in context.</p>
<p>Keywords:
interruption; multitasking; self-interruption; task switching</p>
<h2 id="Organizations & enterprise    5">Organizations &amp; enterprise    5</h2>
<h3 id="368. CommentSpace: structured support for collaborative visual analysis.">368. CommentSpace: structured support for collaborative visual analysis.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979407">Paper Link</a>    Pages:3131-3140</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Willett:Wesley">Wesley Willett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heer:Jeffrey">Jeffrey Heer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hellerstein:Joseph_M=">Joseph M. Hellerstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agrawala:Maneesh">Maneesh Agrawala</a></p>
<p>Abstract:
Collaborative visual analysis tools can enhance sensemaking by facilitating social interpretation and parallelization of effort. These systems enable distributed exploration and evidence gathering, allowing many users to pool their effort as they discuss and analyze the data. We explore how adding lightweight tag and link structure to comments can aid this analysis process. We present CommentSpace, a collaborative system in which analysts comment on visualizations and websites and then use tags and links to organize findings and identify others'" contributions. In a pair of studies comparing CommentSpace to a system without support for tags and links, we find that a small, fixed vocabulary of tags (question, hypothesis, to-do) and links (evidence-for, evidence-against) helps analysts more consistently and accurately classify evidence and establish common ground. We also find that managing and incentivizing participation is important for analysts to progress from exploratory analysis to deeper analytical tasks. Finally, we demonstrate that tags and links can help teams complete evidence gathering and synthesis tasks and that organizing comments using tags and links improves analytic results.</p>
<p>Keywords:
asynchronous collaboration; information visualization; social data analysis; tagging</p>
<h3 id="369. Supporting collaborative help for individualized use.">369. Supporting collaborative help for individualized use.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979408">Paper Link</a>    Pages:3141-3150</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huh:Jina">Jina Huh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Newman:Mark_W=">Mark W. Newman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ackerman:Mark_S=">Mark S. Ackerman</a></p>
<p>Abstract:
In this paper, we seek to advance the research around utilizing collaborative help for supporting individualized use of technologies. We do this by shedding light on the ways that users of MythTV, a highly flexible open-source software system for home entertainment enthusiasts, collaboratively help one another in maintaining their individualized MythTV systems. By analyzing the MythTV user community's mailing list archive, documentation, and wiki, coupled with user interviews we discuss how the community utilizes configuration artifacts as proxies to easily mobilize and exchange knowledge. While exchanging concrete artifacts such as scripts and configuration files was seen to sometimes increase the efficiency of knowledge transfer, it also presented several challenges. Negotiating the transparency of configuration artifacts, navigating the customization and appropriation gulfs, and aligning usage trajectories all emerged as problematic areas. We discuss design implications that address these challenges. Our findings provide a crucial understanding for how to support users in their individualized use of systems.</p>
<p>Keywords:
appropriation; collaborative help; configuration; individualized use; mythtv; pervasive systems; tailorability</p>
<h3 id="370. The scale and evolution of coordination needs in large-scale distributed projects: implications for the future generation of collaborative tools.">370. The scale and evolution of coordination needs in large-scale distributed projects: implications for the future generation of collaborative tools.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979409">Paper Link</a>    Pages:3151-3160</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Costa:Jean_Marcel_dos_Reis">Jean Marcel dos Reis Costa</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cataldo:Marcelo">Marcelo Cataldo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Souza:Cleidson_R=_B=_de">Cleidson R. B. de Souza</a></p>
<p>Abstract:
The past decade has witnessed the development of a new class of coordination tools that focus on automatically providing individuals a rich context for facilitating the coordination of their work. Despite their valuable contributions, current coordination tools have mostly been designed without taking into account scalability aspects beyond the small-group level. The increasing pervasiveness of large-scale projects suggests that those mechanisms need to scale dramatically to adequately support such work settings. In this paper, we used data from five distinct large-scale projects from three different companies to study the scale, range, and volatility of the coordination requirements that emerged over time within those projects. Our results showed that coordination requirements tend to be quite volatile, vary significantly in their magnitude across project members and a significant proportion of the coordination requirements cut across organizational and geographical boundaries. Furthermore, new coordination requirements represent, on average, a third of the coordination requirements faced by a project member on a monthly basis. The implications of these results for the design of collaborative tools are discussed.</p>
<p>Keywords:
awareness; collaboration tools; coordination; scalability</p>
<h3 id="371. Topika: integrating collaborative sharing with email.">371. Topika: integrating collaborative sharing with email.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979410">Paper Link</a>    Pages:3161-3164</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mahmud:Jalal">Jalal Mahmud</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Tara">Tara Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moran:Tom">Tom Moran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lau:Tessa">Tessa Lau</a></p>
<p>Abstract:
New enterprise tools (wikis, team spaces, social tags) offer potential benefits for enterprise collaboration, providing shared resources to organize work. However, a vast amount of collaboration still takes place by email. But email is problematic for collaboration because information may be distributed across multiple messages in an overloaded inbox. Email also increases workload as each individual has to manage their own versions of collaborative materials. We present a novel system, Topika that integrates email with collaboration tools. It allows users to continue to use email while also enjoying the benefits of these dedicated tools. When a user composes an email Topika analyzes the message and suggests relevant shared spaces (e.g., wiki pages) within the user's collaboration tools. This allows her to post the email to those spaces. An evaluation of Topika's suggestion algorithm shows that it performs well at accurately suggesting shared spaces.</p>
<p>Keywords:
CSCW; office; social computing; workplace.</p>
<h3 id="372. Raconteur: integrating authored and real-time social media.">372. Raconteur: integrating authored and real-time social media.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979411">Paper Link</a>    Pages:3165-3168</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chi:Pei=Yu">Pei-Yu Chi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lieberman:Henry">Henry Lieberman</a></p>
<p>Abstract:
Social media enables people to share personal experiences, often through real-time media such as chat. People also record their life experiences in media collections, with photos and video. However, today's social media force a choice between real-time communication, and authoring a coherent story illustrated with digital media. There is simply not enough time in real-time communication to select and compose coherent multimedia stories. We present Raconteur, which introduces a new style of social media combining aspects of the real-time and authored styles of communication. It is structured around a text chat, augmented by an agent that continuously interprets the chat text to suggest appropriate media elements to illustrate the story. A small experiment shows that storytellers find Raconteur's suggestions helpful in presenting their experiences, and audiences find the interaction engaging.</p>
<p>Keywords:
chat; commonsense computing; conversation; life stories; social media; storytelling</p>
<h2 id="Books & language    5">Books &amp; language    5</h2>
<h3 id="373. MicroMandarin: mobile language learning in context.">373. MicroMandarin: mobile language learning in context.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979413">Paper Link</a>    Pages:3169-3178</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Edge:Darren">Darren Edge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Searle:Elly">Elly Searle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chiu:Kevin">Kevin Chiu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Jing">Jing Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Landay:James_A=">James A. Landay</a></p>
<p>Abstract:
Learning a new language is hard, but learning to use it confidently in conversations with native speakers is even harder. From our field research with language learners, with support from Cognitive Psychology and Second Language Acquisition, we argue for the value of contextual microlearning in the many breaks spread across different places and throughout the day. We present a mobile application that supports such microlearning by leveraging the location-based service Foursquare to automatically provide contextually relevant content in the world's major cities. In an evaluation of Mandarin Chinese learning, a four-week, 23-user study spanning Beijing and Shanghai compared this contextual system to a system based on word frequency. Study sessions with the contextual version lasted half as long but occurred in twice as many places as sessions with the frequency version, suggesting a complementary relationship between the two approaches.</p>
<p>Keywords:
context-aware; language learning; microlearning; mobile</p>
<h3 id="374. Augmenting the web for second language vocabulary learning.">374. Augmenting the web for second language vocabulary learning.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979414">Paper Link</a>    Pages:3179-3188</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Trusty:Andrew">Andrew Trusty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Truong:Khai_N=">Khai N. Truong</a></p>
<p>Abstract:
The busyness of everyday life means that those with casual interest in additional learning opportunities are often unable to schedule regular time and effort for studying. In this paper, we explore how to augment information technologies that people use on a daily basis to create micro-learning opportunities. In particular, we examine how a person's existing Web browsing experience-with first language Web pages-can be augmented to teach them second language vocabulary. We present a prototype, ALOE, which runs inside the Firefox Web browser and dynamically augments Web pages by replacing a selected set of English words with their foreign translations. The foreign translations are embedded in the rich context of a Web page's existing English text to promote incidental learning and guessing from context of the translated words. Through a two month user evaluation of ALOE, we found that most participants were able to learn an average of 50 new French vocabulary words.</p>
<p>Keywords:
aloe; computer assisted language learning; user interface; web</p>
<h3 id="375. Document area identification for extending books without markers.">375. Document area identification for extending books without markers.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979415">Paper Link</a>    Pages:3189-3198</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Miyata:Akihiro">Akihiro Miyata</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fujimura:Ko">Ko Fujimura</a></p>
<p>Abstract:
We present a method of document area identification that utilizes consecutive characters in the non-reading direction as search keys. We use this method to develop a prototype system called Kappan. It enables service providers and users to create hyperlinks in books without markers. Existing techniques generally require markers to be printed on the page if a hyperlink is to be created. We consider that utilizing the concept of the search index makes markers unnecessary. Kappan associates indexed text areas in a large number of books with supporting digital contents. The indexed text areas, freely defined by service providers or users, are identified by subjecting images of small areas of the printed page to OCR (Optical Character Recognition) and extracting from the text so recognized highly specific and efficient search keys. Traditional text indexing methods must extract long character sequences from the partial image in order to identify the area exactly given the sheer number of book pages. However, considering that the average OCR error rate is more than 20 percent if the partial image is captured by a camera-equipped cellular phone, it is highly probable that many characters would be misrecognized and area identification would thus fail. In contrast, our indexing method can extract area-specific clues using fewer characters that can identify the area exactly even when the partial image is small and the extracted text contains misrecognized characters. An experiment proves that our method can identify the exact area from more than one million areas with the high accuracy rates of 99 percent and 96 percent for OCR error rates of 0 percent and 22 percent, respectively.</p>
<p>Keywords:
cellular phone; cross media; digital media; document area identification; paper media</p>
<h3 id="376. The reading desk: applying physical interactions to digital documents.">376. The reading desk: applying physical interactions to digital documents.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979416">Paper Link</a>    Pages:3199-3202</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pearson:Jennifer_S=">Jennifer S. Pearson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Buchanan:George">George Buchanan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thimbleby:Harold_W=">Harold W. Thimbleby</a></p>
<p>Abstract:
Reading is increasingly being performed interactively on-screen; for instance, new novels are now routinely released in electronic format for viewing on PCs and mobile devices. Unfortunately, on-screen reading loses many of the natural features of conventional physical media, such as the ability to annotate, slip in bookmarks, turn page corners, and so on. How best should these features be represented electronically? Can computerized representations give benefits that excel the conventional benefits of paper? We describe the design and implementation of a novel reading system that mimics key properties of paper and surpasses them by incorporating digital techniques. A comparative user study evaluating the system confirmed the effectiveness of the features and the value of the system as a whole.</p>
<p>Keywords:
annotation; bookmarking; documents; note taking</p>
<h3 id="377. ReadN'Karaoke: visualizing prosody in children's books for expressive oral reading.">377. ReadN'Karaoke: visualizing prosody in children's books for expressive oral reading.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979417">Paper Link</a>    Pages:3203-3206</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Patel:Rupal">Rupal Patel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Furr:William">William Furr</a></p>
<p>Abstract:
We present a method for displaying prosody, the melody of speech, to aid beginning readers with fluent oral reading. We build on proven auditory techniques by manipulating and augmenting text in children's stories. The acoustic properties of a fluent recording are used to construct visualizations of pitch, loudness and length variations in read samples aligned with text. Our initial approach was to directly manipulate text, which was tested on ten children who showed significant increases in pitch modulation with manipulated text but reported difficulty with word recognition. This motivated designing the augmented text renderings, which display prosodic cues layered with text. Manipulated and augmented texts were compared with two beginning readers. Children showed similar prosodic gains with both versions and reported greater satisfaction with augmented pitch cues. Visual prosodic cues show promise for improving reading fluency in early readers and may have applications for disability education and second language learning.</p>
<p>Keywords:
children; prosody; reading; visualization</p>
<h2 id="Privacy    4">Privacy    4</h2>
<h3 id="378. Situating the concern for information privacy through an empirical study of responses to video recording.">378. Situating the concern for information privacy through an empirical study of responses to video recording.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979419">Paper Link</a>    Pages:3207-3216</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nguyen:David_H=">David H. Nguyen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bedford:Aurora">Aurora Bedford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bretana:Alexander_Gerard">Alexander Gerard Bretana</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hayes:Gillian_R=">Gillian R. Hayes</a></p>
<p>Abstract:
In this paper, we present the results of an empirical study of perceptions towards pervasive video recording. We describe a commonly used model for understanding information privacy, the Concern for Information Privacy (CFIP) model, and present the ways that this model and its associated questionnaire can shed light on information privacy concerns about pervasive and ubiquitous computing technologies. Specifically, the CFIP model encourages analysis of data across four facets of experience: the collection of personal data, the risk of improper access, the potential for unauthorized secondary use, and the challenge of preventing or correcting errors in the data. We further identify areas not well handled by this model of information privacy and suggest avenues for future work, including research on how and when to notify people about recording technologies, awareness of data provenance and leakage, and understanding of and access to the data assemblage being created about individuals.</p>
<p>Keywords:
CCTV; CFIP; information privacy; video recording</p>
<h3 id="379. We're in it together: interpersonal management of disclosure in social network services.">379. We're in it together: interpersonal management of disclosure in social network services.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979420">Paper Link</a>    Pages:3217-3226</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lampinen:Airi">Airi Lampinen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lehtinen:Vilma">Vilma Lehtinen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lehmuskallio:Asko">Asko Lehmuskallio</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tamminen:Sakari">Sakari Tamminen</a></p>
<p>Abstract:
The workload needed for managing privacy and publicness in current social network services (SNSs) is placed on individuals, yet people have few means to control what others disclose about them. This paper considers SNS-users' concerns in relation to online disclosure and the ways in which they cope with these both individually and collaboratively. While previous work has focused mainly on individual coping strategies, our findings from a qualitative study with 27 participants suggest that collaborative strategies in boundary regulation are of additional importance. We present a framework of strategies for boundary regulation that informs both theoretical work and design practice related to management of disclosure in SNSs. The framework considers disclosure as an interpersonal process of boundary regulation, in which people are dependent on what others choose to disclose about them. The paper concludes by proposing design solutions supportive of collaborative and preventive strategies in boundary regulation that facilitate the management of disclosure online.</p>
<p>Keywords:
boundary regulation; disclosure; privacy; social network service</p>
<h3 id="380. Privacy dictionary: a linguistic taxonomy of privacy for content analysis.">380. Privacy dictionary: a linguistic taxonomy of privacy for content analysis.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979421">Paper Link</a>    Pages:3227-3236</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gill:Alastair_J=">Alastair J. Gill</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vasalou:Asimina">Asimina Vasalou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Papoutsi:Chrysanthi">Chrysanthi Papoutsi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Joinson:Adam_N=">Adam N. Joinson</a></p>
<p>Abstract:
Privacy is frequently a key concern relating to technology and central to HCI research, yet it is notoriously difficult to study in a naturalistic way. In this paper we describe and evaluate a dictionary of privacy designed for content analysis, derived using prototype theory and informed by traditional theoretical approaches to privacy. We evaluate our dictionary categories alongside privacy-related categories from an existing content analysis tool, LIWC, using verbal discussions of privacy issues from a variety of technology and non-technology contexts. We find that our privacy dictionary is better able to distinguish between privacy and non-privacy language, and is less context-dependent than LIWC. However, the more general LIWC categories are able to describe a greater amount of variation in our data. We discuss possible improvements to the privacy dictionary and note future work.</p>
<p>Keywords:
content analysis; language; privacy; privacy dictionary</p>
<h3 id="381. Social and technical challenges in parenting teens' social media use.">381. Social and technical challenges in parenting teens' social media use.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979422">Paper Link</a>    Pages:3237-3246</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yardi:Sarita">Sarita Yardi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bruckman:Amy">Amy Bruckman</a></p>
<p>Abstract:
With millions of teenagers on the Internet, millions of parents are trying to understand what their teens are doing and why. Understanding how technology use impacts teens' learning, growth, and social development is critical for their health and wellbeing and for the welfare of the family. Yet, balancing parent authority with teen privacy and autonomy is difficult. We conducted an interview study with 16 parents to examine challenges in "technoparenting" - parenting teens' technology use. Parents said they wanted more transparency in their teens' use of cell phones and the Internet and they struggled with their own unfamiliarity with technology. Technoparenting is a distributed problem and, surprisingly, parents wanted support and collaboration from the broader community. We conclude with design implications for a socially translucent "digital window".</p>
<p>Keywords:
internet; parents; social computing; teens; texting</p>
<h2 id="Tactile interaction    5">Tactile interaction    5</h2>
<h3 id="382. Enhancing independence and safety for blind and deaf-blind public transit riders.">382. Enhancing independence and safety for blind and deaf-blind public transit riders.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979424">Paper Link</a>    Pages:3247-3256</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Azenkot:Shiri">Shiri Azenkot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Prasain:Sanjana">Sanjana Prasain</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borning:Alan">Alan Borning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fortuna:Emily">Emily Fortuna</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Ladner:Richard_E=">Richard E. Ladner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a></p>
<p>Abstract:
Blind and deaf-blind people often rely on public transit for everyday mobility, but using transit can be challenging for them. We conducted semi-structured interviews with 13 blind and deaf-blind people to understand how they use public transit and what human values were important to them in this domain. Two key values were identified: independence and safety. We developed GoBraille, two related Braille-based applications that provide information about buses and bus stops while supporting the key values. GoBraille is built on MoBraille, a novel framework that enables a Braille display to benefit from many features in a smartphone without knowledge of proprietary, device-specific protocols. Finally, we conducted user studies with blind people to demonstrate that GoBraille enables people to travel more independently and safely. We also conducted co-design with a deaf-blind person, finding that a minimalist interface, with short input and output messages, was most effective for this population.</p>
<p>Keywords:
accessibility; autonomy; blind; deaf-blind; public transit usability; safety; value sensitive design</p>
<h3 id="383. A haptic wristwatch for eyes-free interactions.">383. A haptic wristwatch for eyes-free interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979425">Paper Link</a>    Pages:3257-3266</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pasquero:J=eacute=r=ocirc=me">Jrme Pasquero</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stobbe:Scott_J=">Scott J. Stobbe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stonehouse:Noel">Noel Stonehouse</a></p>
<p>Abstract:
We present a haptic wristwatch prototype that makes it possible to acquire information from a companion mobile device through simple eyes-free gestures. The wristwatch we have built uses a custom-made piezoelectric actuator combined with sensors to create a natural, inconspicuous, gesture-based interface. Feedback is returned to the user in the form of haptic stimuli that are delivered to the wrist. We evaluated the capabilities and limitations of our prototype through two user experiments. One experiment verified that the apparatus could be used as a tactile notification mechanism. The other experiment assessed the feasibility of using a cover-and-hold gesture on the wristwatch to obtain numerical data tactually. Results from the numerosity experiment and feedback from participants prompted us to redesign the cover-and-hold gesture to provide users with additional control over the interaction. We qualitatively evaluated the redesigned interaction by handing the prototype to users so that they could use it in a realistic work environment. Taken together, results from the experiments and the validation process indicate that a wrist accessory can be effectively used to perform discreet, closed-loop, eyes-free interactions with a mobile device.</p>
<p>Keywords:
eyes-free interaction; haptic interface; non-visual gestures; wearable computing</p>
<h3 id="384. Detecting vibrations across the body in mobile contexts.">384. Detecting vibrations across the body in mobile contexts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979426">Paper Link</a>    Pages:3267-3276</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Karuei:Idin">Idin Karuei</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacLean:Karon_E=">Karon E. MacLean</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Foley=Fisher:Zoltan">Zoltan Foley-Fisher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacKenzie:Russell">Russell MacKenzie</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Koch:Sebastian">Sebastian Koch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/El=Zohairy:Mohamed">Mohamed El-Zohairy</a></p>
<p>Abstract:
In this paper we explore the potential and limitations of vibrotactile displays in practical wearable applications, by comparing users' detection rate and response time to stimuli applied across the body in varied conditions. We examined which body locations are more sensitive to vibrations and more affected by movement; whether visual workload, expectation of location, or gender impact performance; and if users have subjective preferences to any of these conditions. In two experiments we compared these factors using five vibration intensities on up to 13 body locations. Our contributions are comparisons of tactile detection performance under conditions typifying mobile use, an experiment design that supports further investigation in vibrotactile communication, and guidelines for optimal display location given intended use.</p>
<p>Keywords:
mobile applications; vibrotactile display; wearable haptics</p>
<h3 id="385. Tactile feedback can assist vision during mobile interactions.">385. Tactile feedback can assist vision during mobile interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979427">Paper Link</a>    Pages:3277-3280</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pasquero:J=eacute=r=ocirc=me">Jrme Pasquero</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hayward:Vincent">Vincent Hayward</a></p>
<p>Abstract:
We evaluated the use of rich tactile feedback in the task of scrolling through a long list of items. We used a hand-held device having a tactile transducer that could provide sensations with temporal and spatial content. These capabilities were put to use in an interaction metaphor where input and tactile feedback were tightly coupled. We measured time- to-target and error rates, but also measured the time spent by participants to look at the screen. We found a 28% decrease of reliance on vision when tactile feedback was enabled.</p>
<p>Keywords:
mobile interaction; tactile feedback</p>
<h3 id="386. Designing tactile feedback for piezo buttons.">386. Designing tactile feedback for piezo buttons.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979428">Paper Link</a>    Pages:3281-3284</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lylykangas:Jani">Jani Lylykangas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Surakka:Veikko">Veikko Surakka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Salminen:Katri">Katri Salminen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Raisamo:Jukka">Jukka Raisamo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Laitinen:Pauli">Pauli Laitinen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/R=ouml=nning:Kasper">Kasper Rnning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Raisamo:Roope">Roope Raisamo</a></p>
<p>Abstract:
The present aim was to study the preference of tactile feedback stimulations given by non-physical (i.e., solid) piezo-actuated buttons. Participants (n=16) ranked 16 different tactile feedback stimuli varied by 4 output delays and 4 vibration durations. The results showed that the mean ranks of the stimuli differed significantly from each other. The timing parameters of delay and duration interacted with each other, for example, so that preference of certain vibration duration fluctuated in response to different output delays. Using a very short time window (i.e., 10-453 ms) combining both delay and duration parameters of the feedback could result either in favorable or significantly less favorable subjective experience. The results suggest that a preferred perception of tactile feedback from non-physical buttons requires careful design and controlling of the timing parameters.</p>
<p>Keywords:
delay; haptics; interaction design; lag; non-physical buttons; piezo-electric; tactile feedback</p>
<h2 id="Tabletop & wall displays    5">Tabletop &amp; wall displays    5</h2>
<h3 id="387. LiquidText: a flexible, multitouch environment to support active reading.">387. LiquidText: a flexible, multitouch environment to support active reading.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979430">Paper Link</a>    Pages:3285-3294</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tashman:Craig_S=">Craig S. Tashman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edwards:W=_Keith">W. Keith Edwards</a></p>
<p>Abstract:
Active reading, involving acts such as highlighting, writing notes, etc., is an important part of knowledge workers' activities. Most computer-based active reading support seeks to replicate the affordances of paper, but paper has limitations, being in many ways inflexible. In this paper we introduce LiquidText, a computer-based active reading system that takes a fundamentally different approach, offering a flexible, fluid document representation built on multitouch input, with a range of interaction techniques designed to facilitate the activities of active reading. We report here on our design for LiquidText, its interactions and gesture vocabulary, and our design process, including formative user evaluations which helped shape the final system.</p>
<p>Keywords:
active reading; multitouch input; visualization</p>
<h3 id="388. Dimensions of collaboration on a tabletop interface for children with autism spectrum disorder.">388. Dimensions of collaboration on a tabletop interface for children with autism spectrum disorder.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979431">Paper Link</a>    Pages:3295-3304</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Giusti:Leonardo">Leonardo Giusti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zancanaro:Massimo">Massimo Zancanaro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gal:Eynat">Eynat Gal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weiss:Patrice_L=_=Tamar=">Patrice L. (Tamar) Weiss</a></p>
<p>Abstract:
In this paper we describe a co-located suite of games on a tabletop device to support social competence training for children with Autism Spectrum Disorder. This suite has been designed to use patterns of collaboration to support therapists in their use of Cognitive-Behavioral Therapy (CBT). In this paper, we discuss the observations collected during a field study where two therapists used the system for social competence training sessions with 8 children. We conclude with lessons learned from meshing software enhanced collaboration within the CBT model.</p>
<p>Keywords:
asd; cbt; cognitive-behavioral therapy; collaborative games; multi-user interfaces</p>
<h3 id="389. MemTable: an integrated system for capture and recall of shared histories in group workspaces.">389. MemTable: an integrated system for capture and recall of shared histories in group workspaces.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979432">Paper Link</a>    Pages:3305-3314</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hunter:Seth_E=">Seth E. Hunter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Maes:Pattie">Pattie Maes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Scott:Stacey_D=">Stacey D. Scott</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kaufman:Henry">Henry Kaufman</a></p>
<p>Abstract:
This paper presents the design, implementation, and evaluation of an interactive tabletop system that supports co-located meeting capture and asynchronous search and review of past meetings. The goal of the project is to evaluate the design of a conference table that augments the everyday work patterns of small collaborative groups by incorporating an integrated annotation system. We present a holistic design that values hardware ergonomics, supports heterogeneous input modalities, generates a memory of all user interactions, and provides access to historical data on and off the table. We present a user evaluation that assesses the usefulness of the input modalities and software features, and validates the effectiveness of the MemTable system as a tool for assisting memory recall.</p>
<p>Keywords:
capture and recall; ergonomics; history; meeting support; memory; memtable; surface computing</p>
<h3 id="390. Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation.">390. Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979433">Paper Link</a>    Pages:3315-3318</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hutama:William">William Hutama</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Song:Peng">Peng Song</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fu:Chi=Wing">Chi-Wing Fu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Goh:Wooi=Boon">Wooi-Boon Goh</a></p>
<p>Abstract:
While very large collaborative surfaces are already being widely employed to facilitate concurrent interactions with multiple users, they involve no personalization in the touch interactions. Augmenting them to identify the touch interactions with multiple smart-phones can enable interesting co-located communal applications with context-based personalized interactions and information exchange amongst users' portable devices and the shared wall display. This paper proposes a novel matching technique, called tilt correlation, which employs the built-in tilt sensor to identify smart-phones that make concurrent two-point contacts on a common multi-touch wall display. Experimental investigations suggest that the resultant error rate is relatively low; in addition, we also propose a quantitative measure, called the Bourne Identity Index to allow application designers to determine the reliability of each device identification.</p>
<p>Keywords:
collaborative interactions; multi-touch interaction; personal handheld device</p>
<h3 id="391. Through the troll forest: exploring tabletop interaction design for children with special cognitive needs.">391. Through the troll forest: exploring tabletop interaction design for children with special cognitive needs.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979434">Paper Link</a>    Pages:3319-3322</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zarin:Ru">Ru Zarin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fallman:Daniel">Daniel Fallman</a></p>
<p>Abstract:
We describe the interaction design process of conceiving, designing, implementing, and testing Trollskogen, a purpose-built tabletop multitouch system featuring a range of small software applications, termed 'micro applications'. Each micro application is devised as a tool intended to improve or allow for exercise of social communication skills. Throughout the project, we have worked closely with a group of six children diagnosed with Autism Spectrum Disorder (ASD) or Down's syndrome, all in the age range of 5-8. The system has been designed together with the users, their teachers, and various experts as a complement to the current curricula. In this paper, the three main phases of our design process are described and we conclude the paper by reporting on and discussing some preliminary findings and observations from a small user study.</p>
<p>Keywords:
children; interaction design; learning; multitouch; social skills; special cognitive needs; tabletop</p>
<h2 id="Doctor-patient care    4">Doctor-patient care    4</h2>
<h3 id="392. Exploring the potential for touchless interaction in image-guided interventional radiology.">392. Exploring the potential for touchless interaction in image-guided interventional radiology.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979436">Paper Link</a>    Pages:3323-3332</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Johnson:Rose">Rose Johnson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/O=Hara:Kenton">Kenton O'Hara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sellen:Abigail">Abigail Sellen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cousins:Claire">Claire Cousins</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Criminisi:Antonio">Antonio Criminisi</a></p>
<p>Abstract:
The growth of image-guided procedures in surgical settings has led to an increased need to interact with digital images under sterile conditions. Traditional touch-based interaction techniques present challenges for managing asepsis in these environments leading to suggestions that new touchless interaction techniques may provide a compelling set of alternatives. In this paper we explore the potential for touchless interaction in image-guided Interventional Radiology (IR) through an ethnographic study. The findings highlight how the distribution of labour and spatial practices of this work are organised with respect to concerns about asepsis and radiation exposure, the physical and cognitive demands of artefact manipulation, patient management, and the construction of "professional vision". We discuss the implications of these key features of the work for touchless interaction technologies within IR and suggest that such issues will be of central importance in considering new input techniques in other medical settings.</p>
<p>Keywords:
ethnography; fieldwork; gesture input; image use; medical practice; touchless interaction</p>
<h3 id="393. AnatOnMe: facilitating doctor-patient communication using a projection-based handheld device.">393. AnatOnMe: facilitating doctor-patient communication using a projection-based handheld device.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979437">Paper Link</a>    Pages:3333-3342</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Ni:Tao">Tao Ni</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karlson:Amy_K=">Amy K. Karlson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel">Daniel Wigdor</a></p>
<p>Abstract:
In this paper, we explore the use of a projection-based handheld device to facilitate in-clinic doctor-patient communication. We present the user-centered design process used to understand the workflow of medical professionals and to identify challenges they currently face in communicating information to patients. Based on the lessons learned, we developed AnatOnMe, a prototype projection-based hand-held system for enhancing information exchange in the current practice of one medical sub-specialty, physical therapy. We then present the results of a controlled experiment to understand the desirability and learning tradeoffs of using AnatOnMe to teach medical concepts on three potential projection surfaces - wall, model, and patient body. Finally, we present results of two expert reviews of the system.</p>
<p>Keywords:
doctor-patient communication; handheld device; healthcare; physical therapy; pico-projector</p>
<h3 id="394. Unpacking exam-room computing: negotiating computer-use in patient-physician interactions.">394. Unpacking exam-room computing: negotiating computer-use in patient-physician interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979438">Paper Link</a>    Pages:3343-3352</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Yunan">Yunan Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Ngo:Victor">Victor Ngo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Sidney">Sidney Harrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Duong:Victoria">Victoria Duong</a></p>
<p>Abstract:
The presence of computers - especially desktops - takes significant time and attention away from patients during medical visits. As a result, patients may feel disengaged and disregarded. In this study, we examined the impact of using "Computer-on-Wheels" (COWs) in exam-rooms. We found physicians constantly reorienting and resituating exam-room computers to different positions during the three stages of a medical visit: communication-intensive phase, lecturing phase and ordering phase. We refer to this behavior as micro-negotiation of computer-use. Analysis of its usage patterns, as well as physician and patient perceptions, show that micro-negotiations facilitate eye contact expression and encourage patient participation in medical visits. In addition, we identify two tensions and two unintended benefits resulting from micro-negotiations. These findings lead us to consider new modes of negotiation in the exam-room that could alleviate the tensions identified while enabling physicians to continue enjoying micro-negotiation benefits in their work practice.</p>
<p>Keywords:
electronic medical record (emr); exam-room computing; eye contact; micro-negotiation; patient-physician interactions</p>
<h3 id="395. CPOE workarounds, boundary objects, and assemblages.">395. CPOE workarounds, boundary objects, and assemblages.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979439">Paper Link</a>    Pages:3353-3362</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhou:Xiaomu">Xiaomu Zhou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ackerman:Mark_S=">Mark S. Ackerman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zheng:Kai">Kai Zheng</a></p>
<p>Abstract:
We conducted an ethnographically based study at a large teaching hospital to examine clinician workarounds engendered by the adoption of a Computerized Prescribe Order Entry (CPOE) system. Specifically, we investigated how adoption of computerized systems may alter medical practice, order management in particular, as manifested through the working-around behavior developed by doctors and nurses to accommodate the changes in their day-to-day work environment. In this paper, we focus on clinicians' workarounds, including those workarounds that gradually disappeared and those that have become routinized. Further, we extend the CSCW concept of boundary object (to "assemblage") in order to understand the workarounds created with CPOE system use and the changing nature of clinical practices that are increasingly computerized.</p>
<p>Keywords:
assemblage; boundary object; cpoe; cscw; ehr; electronic patient records; health informatics; medical orders</p>
<h2 id="Developers & end-user programmers    5">Developers &amp; end-user programmers    5</h2>
<h3 id="396. Wrangler: interactive visual specification of data transformation scripts.">396. Wrangler: interactive visual specification of data transformation scripts.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979444">Paper Link</a>    Pages:3363-3372</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kandel:Sean">Sean Kandel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paepcke:Andreas">Andreas Paepcke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hellerstein:Joseph_M=">Joseph M. Hellerstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heer:Jeffrey">Jeffrey Heer</a></p>
<p>Abstract:
Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manipulating data and assessing data quality issues. Such "data wrangling" regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrating multiple data sources. These transforms are often difficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler, an interactive system for creating data transformations. Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing.</p>
<p>Keywords:
data analysis; data cleaning; transformation; visualization; wrangler</p>
<h3 id="397. The concept maps method as a tool to evaluate the usability of APIs.">397. The concept maps method as a tool to evaluate the usability of APIs.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979445">Paper Link</a>    Pages:3373-3382</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gerken:Jens">Jens Gerken</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jetter:Hans=Christian">Hans-Christian Jetter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Z=ouml=llner:Michael">Michael Zllner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mader:Martin">Martin Mader</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reiterer:Harald">Harald Reiterer</a></p>
<p>Abstract:
Application programming interfaces (APIs) are the interfaces to existing code structures, such as widgets, frameworks, or toolkits. Therefore, they very much do have an impact on the quality of the resulting system. So, ensuring that developers can make the most out of them is an important challenge. However standard usability evaluation methods as known from HCI have limitations in grasping the interaction between developer and API as most IDEs (essentially the GUI) capture only part of it. In this paper we present the Concept Map method to study the usability of an API over time. This allows us to elicit the mental model of a programmer when using an API and thereby identify usability issues and learning barriers and their development over time.</p>
<p>Keywords:
API usability; concept maps; evaluation method; longitudinal</p>
<h3 id="398. Shared substance: developing flexible multi-surface applications.">398. Shared substance: developing flexible multi-surface applications.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979446">Paper Link</a>    Pages:3383-3392</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gjerlufsen:Tony">Tony Gjerlufsen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Klokmose:Clemens_Nylandsted">Clemens Nylandsted Klokmose</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Eagan:James">James Eagan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pillias:Cl=eacute=ment">Clment Pillias</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Beaudouin=Lafon:Michel">Michel Beaudouin-Lafon</a></p>
<p>Abstract:
This paper presents a novel middleware for developing flexible interactive multi-surface applications. Using a scenario-based approach, we identify the requirements for this type of applications. We then introduce Substance, a data-oriented framework that decouples functionality from data, and Shared Substance, a middleware implemented in Substance that provides powerful sharing abstractions. We describe our implementation of two applications with Shared Substance and discuss the insights gained from these experiments. Our finding is that the combination of a data-oriented programming model with middleware support for sharing data and functionality provides a flexible, robust solution with low viscosity at both design-time and run-time.</p>
<p>Keywords:
data-oriented model; middleware; multi-surface interaction</p>
<h3 id="399. OldGen: mobile phone personalization for older adults.">399. OldGen: mobile phone personalization for older adults.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979447">Paper Link</a>    Pages:3393-3396</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Olwal:Alex">Alex Olwal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lachanas:Dimitris">Dimitris Lachanas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zacharouli:Ermioni">Ermioni Zacharouli</a></p>
<p>Abstract:
Mobile devices are currently difficult to customize for the usability needs of elderly users. The elderly are instead referred to specially designed "senior phones" or software add-ons. These tend to compromise in functionality as they attempt to solve many disabilities in a single solution. We present OldGen, a prototype framework where a novel concept enables accessibility features on generic mobile devices, by decoupling the software user interface from the phone's physical form factor. This opens up for better customization of the user interface, its functionality and behavior, and makes it possible to adapt it to the specific needs of each individual. OldGen makes the user interface portable, such that it could be moved between different phone hardware, regardless of model and brand. Preliminary observations and evaluations with elderly users indicate that this concept could address individual user interface related accessibility issues on general-purpose devices.</p>
<p>Keywords:
accessibility; elderly; mobile; older users; user interfaces</p>
<h3 id="400. Dinah: an interface to assist non-programmers with selecting program code causing graphical output.">400. Dinah: an interface to assist non-programmers with selecting program code causing graphical output.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979448">Paper Link</a>    Pages:3397-3400</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gross:Paul_A=">Paul A. Gross</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Jennifer">Jennifer Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kelleher:Caitlin">Caitlin Kelleher</a></p>
<p>Abstract:
The web holds an abundance of source code examples with the potential to become learning resources for any end-user. However, for some end-users these examples may be unusable. An example is unusable if a user cannot select the code in the example that corresponds to their interests. Research suggests that non-programmers struggle to correctly select the code responsible for interesting output functionality. In this paper we present Dinah: an interface to support non-programmers with selecting code causing graphical output. Dinah assists non-programmers by providing concurrency support and in-context affordances for statement replay and temporally based navigation.</p>
<p>Keywords:
Dinah; end-user; localization; looking glass; navigation; non-programmer; search; selection; storytelling alice</p>
<h2 id="Incentives & user generated content    5">Incentives &amp; user generated content    5</h2>
<h3 id="401. Normative influences on thoughtful online participation.">401. Normative influences on thoughtful online participation.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979450">Paper Link</a>    Pages:3401-3410</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sukumaran:Abhay">Abhay Sukumaran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vezich:Stephanie">Stephanie Vezich</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McHugh:Melanie">Melanie McHugh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nass:Clifford">Clifford Nass</a></p>
<p>Abstract:
We describe two experiments on whether individual thoughtful effort during online commenting is shaped by situational norms derived from the behavior of social others and the design of the environment, respectively. By measuring the length of participants' comments on a news website, the time taken to write them, and the number of issue-relevant thoughts they contain, we demonstrate that participants conform to high vs. low norms of thoughtfulness manifested through either the apparent behavior of other users or through visual, textual and interactional design features conceptually associated with thoughtfulness. Theoretical and applied insights for designing online participatory environments are discussed.</p>
<p>Keywords:
environmental norms; online comments; social norms; thoughtfulness; user-generated content</p>
<h3 id="402. My kind of people?: perceptions about wikipedia contributors and their motivations.">402. My kind of people?: perceptions about wikipedia contributors and their motivations.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979451">Paper Link</a>    Pages:3411-3420</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Antin:Judd">Judd Antin</a></p>
<p>Abstract:
Perceptions of information products such as Wikipedia can depend on assumptions and stereotypes about the people who create them. As new Wikipedians consider contributing they are likely to apply such assumptions and ask themselves: "Are Wikipedia contributors my kind of people? Is this a group I'd like to belong to?" In this qualitative study I address the potential challenge of these questions by exploring readers and infrequent editors' perceptions of Wikipedia contributors and their motivations. Through analysis of twenty semi-structured interviews, I find evidence of strong negative perceptions as well as positive ones which nonetheless prevent users from identifying with active Wikipedia contributors. I argue that these perceptions present a barrier to the progression of participation over time. I conclude by discussing the practical challenges of my findings for Wikipedia and other online collaborative systems.</p>
<p>Keywords:
community; participation; wikipedia</p>
<h3 id="403. Computers can't give credit: how automatic attribution falls short in an online remixing community.">403. Computers can't give credit: how automatic attribution falls short in an online remixing community.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979452">Paper Link</a>    Pages:3421-3430</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Monroy=Hern=aacute=ndez:Andr=eacute=s">Andrs Monroy-Hernndez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hill:Benjamin_Mako">Benjamin Mako Hill</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gonzalez=Rivero:Jazmin">Jazmin Gonzalez-Rivero</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Boyd:Danah">Danah Boyd</a></p>
<p>Abstract:
In this paper, we explore the role that attribution plays in shaping user reactions to content reuse, or remixing, in a large user-generated content community. We present two studies using data from the Scratch online community - a social media platform where hundreds of thousands of young people share and remix animations and video games. First, we present a quantitative analysis that examines the effects of a technological design intervention introducing automated attribution of remixes on users' reactions to being remixed. We compare this analysis to a parallel examination of "manual" credit-giving. Second, we present a qualitative analysis of twelve in-depth, semi-structured, interviews with Scratch participants on the subject of remixing and attribution. Results from both studies suggest that automatic attribution done by technological systems (i.e., the listing of names of contributors) plays a role that is distinct from, and less valuable than, credit which may superficially involve identical information but takes on new meaning when it is given by a human remixer. We discuss the implications of these findings for the designers of online communities and social media platforms.</p>
<p>Keywords:
attribution; credit-giving; online communities; remixing; user-generated content</p>
<h3 id="404. Identifying shared leadership in Wikipedia.">404. Identifying shared leadership in Wikipedia.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979453">Paper Link</a>    Pages:3431-3434</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhu:Haiyi">Haiyi Zhu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Yi=Chia">Yi-Chia Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a></p>
<p>Abstract:
In this paper, we introduce a method to measure shared leadership in Wikipedia as a step in developing a new model of online leadership. We show that editors with varying degrees of engagement and from peripheral as well as central roles all act like leaders, but that core and peripheral editors show different profiles of leadership behavior. Specifically, we developed machine learning models to automatically identify four types of leadership behaviors from 4 million messages sent between Wikipedia editors. We found strong evidence of shared leadership in Wikipedia, with editors in peripheral roles producing a large proportion of leadership behaviors.</p>
<p>Keywords:
applied machine learning; shared leadership; wikipedia</p>
<h3 id="405. Donate for credibility: how contribution incentives can improve credibility.">405. Donate for credibility: how contribution incentives can improve credibility.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979454">Paper Link</a>    Pages:3435-3438</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hsieh:Gary">Gary Hsieh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hudson:Scott_E=">Scott E. Hudson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a></p>
<p>Abstract:
This study explores whether certain contribution incentives for online user-generated content can undermine or enhance contributor's credibility. In an online experiment, we found that contributors who are rewarded with donations made in their names are perceived to be more credible than contributors who are financially compensated through revenue-sharing or contribute voluntarily. In addition, disclosing the chosen charity for donation can also impact credibility. Content viewer's self-identification with charity and the congruency between charity and content topic are both factors that may enhance credibility. Our findings lead to practical implications on when and how to use contribution incentives to enhance credibility.</p>
<p>Keywords:
credibility; incentive; user-generated content</p>
<h2 id="Courriel    4">Courriel    4</h2>
<h3 id="406. Should I open this email?: inbox-level cues, curiosity and attention to email.">406. Should I open this email?: inbox-level cues, curiosity and attention to email.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979456">Paper Link</a>    Pages:3439-3448</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wainer:Jaclyn">Jaclyn Wainer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dabbish:Laura">Laura Dabbish</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a></p>
<p>Abstract:
The quantity of email people receive each day can be overwhelming. Previous research suggests that when handling email, individuals prioritize certain messages for attention over others. Since people generally make this decision about which message to read before opening the email, the question largely unanswered in the email literature is: what surface features of an email draw attention to it? In this research, we examined how top-level cues about an email's content influence attention to email. We describe results from a think-aloud study examining people's stated rationale for prioritizing certain emails over others. Based on these results and theory on curiosity, we conducted an experiment examining how message importance, subject line specificity, workload and personal utility influence attention to email. Results suggest that uncertainty about message content at the inbox level increases the likelihood of attention to a message. The influence of uncertainty diminishes, however, in the face of enhanced task and personal utility cues and increased demand, suggesting that curiosity operates in an intrinsic way in the email context. Our results have implications for intelligent email system design, email client interfaces, and reducing email strain.</p>
<p>Keywords:
attention; computer-mediated communication; curiosity; electronic mail; email; information gap; prioritization</p>
<h3 id="407. Am I wasting my time organizing email?: a study of email refinding.">407. Am I wasting my time organizing email?: a study of email refinding.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979457">Paper Link</a>    Pages:3449-3458</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Tara">Tara Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cerruti:Julian_A=">Julian A. Cerruti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Badenes:Hernan">Hernan Badenes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tang:John_C=">John C. Tang</a></p>
<p>Abstract:
We all spend time every day looking for information in our email, yet we know little about this refinding process. Some users expend considerable preparatory effort creating complex folder structures to promote effective refinding. However modern email clients provide alternative opportunistic methods for access, such as search and threading, that promise to reduce the need to manually prepare. To compare these different refinding strategies, we instrumented a modern email client that supports search, folders, tagging and threading. We carried out a field study of 345 long-term users who conducted over 85,000 refinding actions. Our data support opportunistic access. People who create complex folders indeed rely on these for retrieval, but these preparatory behaviors are inefficient and do not improve retrieval success. In contrast, both search and threading promote more effective finding. We present design implications: current search-based clients ignore scrolling, the most prevalent refinding behavior, and threading approaches need to be extended.</p>
<p>Keywords:
PIM; conversation threading; email; field study; folders; management strategy; refinding; search; usage logging</p>
<h3 id="408. Using email to facilitate wiki-based coordinated, collaborative authoring.">408. Using email to facilitate wiki-based coordinated, collaborative authoring.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979458">Paper Link</a>    Pages:3459-3468</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chi:Chang_Yan">Chang Yan Chi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhou:Michelle_X=">Michelle X. Zhou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/x/Xiao:Wenpeng">Wenpeng Xiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Min">Min Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wilcox:Eric">Eric Wilcox</a></p>
<p>Abstract:
Dandelion is a wiki-based tool that supports coordinated, collaborative authoring. In this paper, we present an ex-tended version of Dandelion, which provides an email inter-face for users to accomplish their tasks by email in a coordinated, collaborative authoring process. Specifically, Dandelion employs a semi-structured, template-based approach that allows users to use templates to specify their requests in email. These emailed requests can be interpreted by Dandelion and are then used to automatically drive the collaboration flow. As part of its actions, Dandelion automatically creates a wiki page and dynamically updates it to record co-authoring tasks and collate co-authored content. As a result, users can use their familiar tool (email) to accomplish their tasks in a co-authoring process, while leveraging a wiki for additional benefits (e.g., obtaining collaboration awareness and formatting the text). Our preliminary study with two groups of users shows the usefulness of both Dandelion email and wiki features and their impact on collaboration effectiveness.</p>
<p>Keywords:
co-authoring; collaboration; coordination; email; wiki</p>
<h3 id="409. F for fake: four studies on how we fall for phish.">409. F for fake: four studies on how we fall for phish.</h3>
<p><a href="http://doi.acm.org/10.1145/1978942.1979459">Paper Link</a>    Pages:3469-3478</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Blythe:Mark">Mark Blythe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Petrie:Helen">Helen Petrie</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Clark:John_A=">John A. Clark</a></p>
<p>Abstract:
This paper reports findings from a multi-method set of four studies that investigate why we continue to fall for phish. Current security advice suggests poor spelling and grammar in emails can be signs of phish. But a content analysis of a phishing archive indicates that many such emails contain no obvious spelling or grammar mistakes and often use convincing logos and letterheads. An online survey of 224 people finds that although phish are detected approximately 80% of the time, those with logos are significantly harder to detect. A qualitative interview study was undertaken to better understand the strategies used to identify phish. Blind users were selected because it was thought they may be more vulnerable to phishing attacks, however they demonstrated robust strategies for identifying phish based on careful reading of emails. Finally an analysis was undertaken of phish as a literary form. This identifies the main literary device employed as pastiche and draws on critical theory to consider why security based pastiche may be currently very persuasive.</p>
<p>Keywords:
critical theory; human factors; persuasion; phish detection; visually impaired users</p>
 

<div class="home">
<i title='' onclick="location.href='../index.html'"><i class="fa fa-home fa-lg"></i></i>
</div>

<div class="toc">
<i id="showLeftPush" title=''><i class="fa fa-list fa-lg"></i></i>
</div>

<!-- Classie - class helper functions by @desandro https://github.com/desandro/classie -->
<script>
	var menuLeft = document.getElementById( 'menu-s1' ),
		showLeftPush = document.getElementById( 'showLeftPush' ),
		body = document.body;

	showLeftPush.onclick = function() {
		classie.toggle( this, 'active' );
		classie.toggle( body, 'cbp-spmenu-push-toright' );
		classie.toggle( menuLeft, 'cbp-spmenu-open' );
		disableOther( 'showLeftPush' );
	};
</script>

<div class="go-top" >
<i title='' onclick="window.scrollTo('0', '0')"><i class="fa fa-angle-double-up fa-2x"></i></i>
</div>

<div class="theme" >
<i title='' onclick="change_css()"><i class="fa fa-adjust fa-lg"></i></i>
</div>

<div id="footer">

  <p> <i class="fa fa-envelope-o fa-1x"></i>:&nbsp huntercmd@163.com &nbsp Published under<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh"> (CC) BY-NC-SA 3.0</a></p>

  <p>&copy; 2013 HunterCmd &nbsp <a href="https://github.com/huntercmd/ccf"><i class="fa fa-github fa-1x"></i>
  </p>
</div>

</body>
