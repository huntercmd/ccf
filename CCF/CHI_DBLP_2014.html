 
<head>
<meta name="HunterCmd" charset="utf-8">

<link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
<link id="cssfile" rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/huntercmd/blog/master/config/css/light.css">
<script src="https://cdn.rawgit.com/huntercmd/blog/master/config/css/skin.js"></script>
<script src="https://cdn.rawgit.com/huntercmd/blog/master/config/css/classie.js"></script>

<!-- This is for Mathjax -->

<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'], ["$","$"] ],
			displayMath: [ ['$$','$$'], ["$$","$$"] ],
			processEscapes: true
			},
		TeX: {equationNumbers: {autoNumber: ["AMS"], useLabelIds: true}},
		"HTML-CSS": {linebreaks: {automatic: true}},
		SVG: {linebreaks: {automatic: true}}
	});
</script>

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<title>HunterCmd</title>
</head>

<body class="cbp-spmenu-push">

<nav class="cbp-spmenu cbp-spmenu-vertical cbp-spmenu-left" id="menu-s1" style="width: 320px;overflow: auto;
">

<h1>Table of contents</h1>
<ul>
<li><a href="#CHI 2014:Toronto, ON, Canada">CHI 2014:Toronto, ON, Canada</a><ul>
<li><a href="#Paper Num: 465 || Session Num: 114">Paper Num: 465 || Session Num: 114</a></li>
<li><a href="#Visualization and aesthetics    4">Visualization and aesthetics    4</a><ul>
<li><a href="#1. Metaphone: machine aesthetics meets interaction design.">1. Metaphone: machine aesthetics meets interaction design.</a></li>
<li><a href="#2. Quantifying visual preferences around the world.">2. Quantifying visual preferences around the world.</a></li>
<li><a href="#3. The influence of aesthetics in usability testing: the case of dual-domain products.">3. The influence of aesthetics in usability testing: the case of dual-domain products.</a></li>
<li><a href="#4. Extracting references between text and charts via crowdsourcing.">4. Extracting references between text and charts via crowdsourcing.</a></li>
</ul>
</li>
<li><a href="#Stress    4">Stress    4</a><ul>
<li><a href="#5. Stress and multitasking in everyday college life: an empirical study of online activity.">5. Stress and multitasking in everyday college life: an empirical study of online activity.</a></li>
<li><a href="#6. Under pressure: sensing stress of computer users.">6. Under pressure: sensing stress of computer users.</a></li>
<li><a href="#7. MouStress: detecting stress from mouse motion.">7. MouStress: detecting stress from mouse motion.</a></li>
<li><a href="#8. Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration.">8. Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration.</a></li>
</ul>
</li>
<li><a href="#Social local mobile    5">Social local mobile    5</a><ul>
<li><a href="#9. Let's do it at my place instead?: attitudinal and behavioral study of privacy in client-side personalization.">9. Let's do it at my place instead?: attitudinal and behavioral study of privacy in client-side personalization.</a></li>
<li><a href="#10. The effect of developer-specified explanations for permission requests on smartphone user behavior.">10. The effect of developer-specified explanations for permission requests on smartphone user behavior.</a></li>
<li><a href="#11. Reflection or action?: how feedback and control affect location sharing decisions.">11. Reflection or action?: how feedback and control affect location sharing decisions.</a></li>
<li><a href="#12. Effects of security warnings and instant gratification cues on attitudes toward mobile websites.">12. Effects of security warnings and instant gratification cues on attitudes toward mobile websites.</a></li>
<li><a href="#13. Social media participation and performance at work: a longitudinal study.">13. Social media participation and performance at work: a longitudinal study.</a></li>
</ul>
</li>
<li><a href="#Coordination and collaboration    4">Coordination and collaboration    4</a><ul>
<li><a href="#14. The doing of doing stuff: understanding the coordination of social group-activities.">14. The doing of doing stuff: understanding the coordination of social group-activities.</a></li>
<li><a href="#15. Effects of implicit sharing in collaborative analysis.">15. Effects of implicit sharing in collaborative analysis.</a></li>
<li><a href="#16. Effects of simultaneous and sequential work structures on distributed collaborative interdependent tasks.">16. Effects of simultaneous and sequential work structures on distributed collaborative interdependent tasks.</a></li>
<li><a href="#17. Necessary, unpleasant, and disempowering: reputation management in the internet age.">17. Necessary, unpleasant, and disempowering: reputation management in the internet age.</a></li>
</ul>
</li>
<li><a href="#Watches and small devices    5">Watches and small devices    5</a><ul>
<li><a href="#18. Duet: exploring joint interactions on a smart phone and a smart watch.">18. Duet: exploring joint interactions on a smart phone and a smart watch.</a></li>
<li><a href="#19. Interaction on the edge: offset sensing for small devices.">19. Interaction on the edge: offset sensing for small devices.</a></li>
<li><a href="#20. More than touch: understanding how people use skin as an input surface for mobile computing.">20. More than touch: understanding how people use skin as an input surface for mobile computing.</a></li>
<li><a href="#21. TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads.">21. TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads.</a></li>
<li><a href="#22. Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click.">22. Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click.</a></li>
</ul>
</li>
<li><a href="#The third dimension    4">The third dimension    4</a><ul>
<li><a href="#23. The use of surrounding visual context in handheld AR: device vs. user perspective rendering.">23. The use of surrounding visual context in handheld AR: device vs. user perspective rendering.</a></li>
<li><a href="#24. Altering gameplay behavior using stereoscopic 3D vision-based video game design.">24. Altering gameplay behavior using stereoscopic 3D vision-based video game design.</a></li>
<li><a href="#25. Depth perception with gaze-contingent depth of field.">25. Depth perception with gaze-contingent depth of field.</a></li>
<li><a href="#26. Imperceptible depth shifts for touch interaction with stereoscopic objects.">26. Imperceptible depth shifts for touch interaction with stereoscopic objects.</a></li>
</ul>
</li>
<li><a href="#Audio interaction    4">Audio interaction    4</a><ul>
<li><a href="#27. SonicExplorer: fluid exploration of audio parameters.">27. SonicExplorer: fluid exploration of audio parameters.</a></li>
<li><a href="#28. The boomRoom: mid-air direct interaction with virtual sound sources.">28. The boomRoom: mid-air direct interaction with virtual sound sources.</a></li>
<li><a href="#29. ISSE: an interactive source separation editor.">29. ISSE: an interactive source separation editor.</a></li>
<li><a href="#30. Evaluation of hear-through sound localization.">30. Evaluation of hear-through sound localization.</a></li>
</ul>
</li>
<li><a href="#Sustainability and everyday practices    1">Sustainability and everyday practices    1</a><ul>
<li><a href="#31. Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends.">31. Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends.</a></li>
</ul>
</li>
<li><a href="#Studying online communities    4">Studying online communities    4</a><ul>
<li><a href="#32. The impact of membership overlap on the survival of online communities.">32. The impact of membership overlap on the survival of online communities.</a></li>
<li><a href="#33. Goals and perceived success of online enterprise communities: what is important to leaders & members?">33. Goals and perceived success of online enterprise communities: what is important to leaders &amp; members?</a></li>
<li><a href="#34. Selecting an effective niche: an ecological view of the success of online communities.">34. Selecting an effective niche: an ecological view of the success of online communities.</a></li>
<li><a href="#35. Snuggle: designing for efficient socialization and ideological critique.">35. Snuggle: designing for efficient socialization and ideological critique.</a></li>
</ul>
</li>
<li><a href="#Image and animation authoring    4">Image and animation authoring    4</a><ul>
<li><a href="#36. Offline painted media for digital animation authoring.">36. Offline painted media for digital animation authoring.</a></li>
<li><a href="#37. Supporting informal design with interactive whiteboards.">37. Supporting informal design with interactive whiteboards.</a></li>
<li><a href="#38. Juxtapoze: supporting serendipity and creative expression in clipart compositions.">38. Juxtapoze: supporting serendipity and creative expression in clipart compositions.</a></li>
<li><a href="#39. Draco: bringing life to illustrations with kinetic textures.">39. Draco: bringing life to illustrations with kinetic textures.</a></li>
</ul>
</li>
<li><a href="#Studying and designing gameplay    4">Studying and designing gameplay    4</a><ul>
<li><a href="#40. A user study of different gameplay visualizations.">40. A user study of different gameplay visualizations.</a></li>
<li><a href="#41. The influence of controllers on immersion in mobile games.">41. The influence of controllers on immersion in mobile games.</a></li>
<li><a href="#42. Combining think-aloud and physiological data to understand video game experiences.">42. Combining think-aloud and physiological data to understand video game experiences.</a></li>
<li><a href="#43. The MOY framework for collaborative play design in integrated shared and private interactive spaces.">43. The MOY framework for collaborative play design in integrated shared and private interactive spaces.</a></li>
</ul>
</li>
<li><a href="#Force input and haptic feedback    5">Force input and haptic feedback    5</a><ul>
<li><a href="#44. Transient and transitional states: pressure as an auxiliary input modality for bimanual interaction.">44. Transient and transitional states: pressure as an auxiliary input modality for bimanual interaction.</a></li>
<li><a href="#45. VacuumTouch: attractive force feedback interface for haptic interactive surface using air suction.">45. VacuumTouch: attractive force feedback interface for haptic interactive surface using air suction.</a></li>
<li><a href="#46. Expressive touch: studying tapping force on tabletops.">46. Expressive touch: studying tapping force on tabletops.</a></li>
<li><a href="#47. Presstures: exploring pressure-sensitive multi-touch gestures on trackpads.">47. Presstures: exploring pressure-sensitive multi-touch gestures on trackpads.</a></li>
<li><a href="#48. Gaze gestures and haptic feedback in mobile devices.">48. Gaze gestures and haptic feedback in mobile devices.</a></li>
</ul>
</li>
<li><a href="#Hackerspaces, making and breaking    5">Hackerspaces, making and breaking    5</a><ul>
<li><a href="#49. Emerging sites of HCI innovation: hackerspaces, hardware startups & incubators.">49. Emerging sites of HCI innovation: hackerspaces, hardware startups &amp; incubators.</a></li>
<li><a href="#50. Breakdown, obsolescence and reuse: HCI and the art of repair.">50. Breakdown, obsolescence and reuse: HCI and the art of repair.</a></li>
<li><a href="#51. Printing teddy bears: a technique for 3D printing of soft interactive objects.">51. Printing teddy bears: a technique for 3D printing of soft interactive objects.</a></li>
<li><a href="#52. Taking things apart: reaching common ground and shared material understanding.">52. Taking things apart: reaching common ground and shared material understanding.</a></li>
<li><a href="#53. "now that's definitely a proper hack": self-made tools in hackerspaces.">53. "now that's definitely a proper hack": self-made tools in hackerspaces.</a></li>
</ul>
</li>
<li><a href="#Activity recognition    3">Activity recognition    3</a><ul>
<li><a href="#54. Toss 'n' turn: smartphone as sleep and sleep quality detector.">54. Toss 'n' turn: smartphone as sleep and sleep quality detector.</a></li>
<li><a href="#55. Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness.">55. Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness.</a></li>
<li><a href="#56. Predictors of life satisfaction based on daily activities from mobile sensor data.">56. Predictors of life satisfaction based on daily activities from mobile sensor data.</a></li>
</ul>
</li>
<li><a href="#Managing income    4">Managing income    4</a><ul>
<li><a href="#57. Pay or delay: the role of technology when managing a low income.">57. Pay or delay: the role of technology when managing a low income.</a></li>
<li><a href="#58. Poverty on the cheap: estimating poverty maps using aggregated mobile communication networks.">58. Poverty on the cheap: estimating poverty maps using aggregated mobile communication networks.</a></li>
<li><a href="#59. Money talks: tracking personal finances.">59. Money talks: tracking personal finances.</a></li>
<li><a href="#60. Fostering social capital in economically distressed communities.">60. Fostering social capital in economically distressed communities.</a></li>
</ul>
</li>
<li><a href="#Designing and understanding visualizations    4">Designing and understanding visualizations    4</a><ul>
<li><a href="#61. Automatic generation of semantic icon encodings for visualizations.">61. Automatic generation of semantic icon encodings for visualizations.</a></li>
<li><a href="#62. Task-driven evaluation of aggregation in time series visualization.">62. Task-driven evaluation of aggregation in time series visualization.</a></li>
<li><a href="#63. Dive in!: enabling progressive loading for real-time navigation of data visualizations.">63. Dive in!: enabling progressive loading for real-time navigation of data visualizations.</a></li>
<li><a href="#64. Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions.">64. Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions.</a></li>
</ul>
</li>
<li><a href="#Crowdfunding and crowd storage    3">Crowdfunding and crowd storage    3</a><ul>
<li><a href="#65. Learning to fail: experiencing public failure online through crowdfunding.">65. Learning to fail: experiencing public failure online through crowdfunding.</a></li>
<li><a href="#66. Show me the money!: an analysis of project updates during crowdfunding campaigns.">66. Show me the money!: an analysis of project updates during crowdfunding campaigns.</a></li>
<li><a href="#67. Crowd storage: storing information on existing memories.">67. Crowd storage: storing information on existing memories.</a></li>
</ul>
</li>
<li><a href="#Novel approaches to navigation    5">Novel approaches to navigation    5</a><ul>
<li><a href="#68. Walk this way: musically guided walking experiences.">68. Walk this way: musically guided walking experiences.</a></li>
<li><a href="#69. Simplifying orientation measurement for mobile audio augmented reality applications.">69. Simplifying orientation measurement for mobile audio augmented reality applications.</a></li>
<li><a href="#70. Gifting personal interpretations in galleries.">70. Gifting personal interpretations in galleries.</a></li>
<li><a href="#71. Visual recognition in museum guide apps: do visitors want it?">71. Visual recognition in museum guide apps: do visitors want it?</a></li>
<li><a href="#72. A billion signposts: repurposing barcodes for indoor navigation.">72. A billion signposts: repurposing barcodes for indoor navigation.</a></li>
</ul>
</li>
<li><a href="#Interfaces for care and support    4">Interfaces for care and support    4</a><ul>
<li><a href="#73. Taking part: role-play in the design of therapeutic systems.">73. Taking part: role-play in the design of therapeutic systems.</a></li>
<li><a href="#74. Staccato social support in mobile health applications.">74. Staccato social support in mobile health applications.</a></li>
<li><a href="#75. My journey compass: a preliminary investigation of a mobile tool for cancer patients.">75. My journey compass: a preliminary investigation of a mobile tool for cancer patients.</a></li>
<li><a href="#76. An assistive robotic table for older and post-stroke adults: results from participatory design and evaluation activities with clinical staff.">76. An assistive robotic table for older and post-stroke adults: results from participatory design and evaluation activities with clinical staff.</a></li>
</ul>
</li>
<li><a href="#Research through design    4">Research through design    4</a><ul>
<li><a href="#77. Experience design theatre: exploring the role of live theatre in scaffolding design dialogues.">77. Experience design theatre: exploring the role of live theatre in scaffolding design dialogues.</a></li>
<li><a href="#78. Non-finito products: a new design space of user creativity for personal user experience.">78. Non-finito products: a new design space of user creativity for personal user experience.</a></li>
<li><a href="#79. Research through design fiction: narrative in real and imaginary abstracts.">79. Research through design fiction: narrative in real and imaginary abstracts.</a></li>
<li><a href="#80. Research on research: design research at the margins: academia, industry and end-users.">80. Research on research: design research at the margins: academia, industry and end-users.</a></li>
</ul>
</li>
<li><a href="#Pointing and cursors    4">Pointing and cursors    4</a><ul>
<li><a href="#81. Impact of form factors and input conditions on absolute indirect-touch pointing tasks.">81. Impact of form factors and input conditions on absolute indirect-touch pointing tasks.</a></li>
<li><a href="#82. Beating the bubble: using kinematic triggering in the bubble lens for acquiring small, dense targets.">82. Beating the bubble: using kinematic triggering in the bubble lens for acquiring small, dense targets.</a></li>
<li><a href="#83. Mouse pointing endpoint prediction using kinematic template matching.">83. Mouse pointing endpoint prediction using kinematic template matching.</a></li>
<li><a href="#84. The implicit fan cursor: a velocity dependent area cursor.">84. The implicit fan cursor: a velocity dependent area cursor.</a></li>
</ul>
</li>
<li><a href="#Always connected: email and social media    4">Always connected: email and social media    4</a><ul>
<li><a href="#85. The product of availability: understanding the economic underpinnings of constant connectivity.">85. The product of availability: understanding the economic underpinnings of constant connectivity.</a></li>
<li><a href="#86. Giving up Twitter for Lent: how and why we take breaks from social media.">86. Giving up Twitter for Lent: how and why we take breaks from social media.</a></li>
<li><a href="#87. MinEMail: SMS alert system for managing critical emails.">87. MinEMail: SMS alert system for managing critical emails.</a></li>
<li><a href="#88. Overload is overloaded: email in the age of Gmail.">88. Overload is overloaded: email in the age of Gmail.</a></li>
</ul>
</li>
<li><a href="#Smart homes and sustainability    3">Smart homes and sustainability    3</a><ul>
<li><a href="#89. Practical trigger-action programming in the smart home.">89. Practical trigger-action programming in the smart home.</a></li>
<li><a href="#90. Doing the laundry with agents: a field trial of a future smart energy system in the home.">90. Doing the laundry with agents: a field trial of a future smart energy system in the home.</a></li>
<li><a href="#91. Making sustainability sustainable: challenges in the design of eco-interaction technologies.">91. Making sustainability sustainable: challenges in the design of eco-interaction technologies.</a></li>
</ul>
</li>
<li><a href="#Multilingual communication    4">Multilingual communication    4</a><ul>
<li><a href="#92. Global connectivity and multilinguals in the Twitter network.">92. Global connectivity and multilinguals in the Twitter network.</a></li>
<li><a href="#93. Effects of public vs. private automated transcripts on multiparty communication between native and non-native english speakers.">93. Effects of public vs. private automated transcripts on multiparty communication between native and non-native english speakers.</a></li>
<li><a href="#94. Smart subtitles for vocabulary learning.">94. Smart subtitles for vocabulary learning.</a></li>
<li><a href="#95. Using annotations in online group chats.">95. Using annotations in online group chats.</a></li>
</ul>
</li>
<li><a href="#Interactive visualization and visual elements    4">Interactive visualization and visual elements    4</a><ul>
<li><a href="#96. Visualizing dynamic networks with matrix cubes.">96. Visualizing dynamic networks with matrix cubes.</a></li>
<li><a href="#97. A table!: improving temporal navigation in soccer ranking tables.">97. A table!: improving temporal navigation in soccer ranking tables.</a></li>
<li><a href="#98. Kinetica: naturalistic multi-touch data visualization.">98. Kinetica: naturalistic multi-touch data visualization.</a></li>
<li><a href="#99. Traffigram: distortion for clarification via isochronal cartography.">99. Traffigram: distortion for clarification via isochronal cartography.</a></li>
</ul>
</li>
<li><a href="#Understanding and designing games    5">Understanding and designing games    5</a><ul>
<li><a href="#100. Understanding procedural content generation: a design-centric analysis of the role of PCG in games.">100. Understanding procedural content generation: a design-centric analysis of the role of PCG in games.</a></li>
<li><a href="#101. A systematic review of quantitative studies on the enjoyment of digital entertainment games.">101. A systematic review of quantitative studies on the enjoyment of digital entertainment games.</a></li>
<li><a href="#102. The effectiveness (or lack thereof">102. The effectiveness (or lack thereof) of aim-assist techniques in first-person shooter games.</a> of aim-assist techniques in first-person shooter games.)</li>
<li><a href="#103. Design tactics for authentic interactive fiction: insights from alternate reality game designers.">103. Design tactics for authentic interactive fiction: insights from alternate reality game designers.</a></li>
<li><a href="#104. Jump and shoot!: prioritizing primary and alternative body gestures for intense gameplay.">104. Jump and shoot!: prioritizing primary and alternative body gestures for intense gameplay.</a></li>
</ul>
</li>
<li><a href="#Personal values and preferences    6">Personal values and preferences    6</a><ul>
<li><a href="#105. KnowMe and ShareMe: understanding automatically discovered personality traits from social media and user sharing preferences.">105. KnowMe and ShareMe: understanding automatically discovered personality traits from social media and user sharing preferences.</a></li>
<li><a href="#106. Faces engage us: photos with faces attract more likes and comments on Instagram.">106. Faces engage us: photos with faces attract more likes and comments on Instagram.</a></li>
<li><a href="#107. Photo sharing of the subject, by the owner, for the viewer: examining the subject's preference.">107. Photo sharing of the subject, by the owner, for the viewer: examining the subject's preference.</a></li>
<li><a href="#108. Does content determine information popularity in social media?: a case study of youtube videos' content and their popularity.">108. Does content determine information popularity in social media?: a case study of youtube videos' content and their popularity.</a></li>
<li><a href="#109. You read what you value: understanding personal values and reading interests.">109. You read what you value: understanding personal values and reading interests.</a></li>
<li><a href="#110. Gaining empathy for non-routine mobile device use through autoethnography.">110. Gaining empathy for non-routine mobile device use through autoethnography.</a></li>
</ul>
</li>
<li><a href="#Enabling interactive performances    5">Enabling interactive performances    5</a><ul>
<li><a href="#111. Designing for movement: evaluating computational models using LMA effort qualities.">111. Designing for movement: evaluating computational models using LMA effort qualities.</a></li>
<li><a href="#112. The vocal chorder: empowering opera singers with a large interactive instrument.">112. The vocal chorder: empowering opera singers with a large interactive instrument.</a></li>
<li><a href="#113. Let me catch this!: experiencing interactive 3D cinema through collecting content with a mobile phone.">113. Let me catch this!: experiencing interactive 3D cinema through collecting content with a mobile phone.</a></li>
<li><a href="#114. Coding livecoding.">114. Coding livecoding.</a></li>
<li><a href="#115. Exploring percussive gesture on iPads with ensemble metatone.">115. Exploring percussive gesture on iPads with ensemble metatone.</a></li>
</ul>
</li>
<li><a href="#Battery life and energy harvesting    4">Battery life and energy harvesting    4</a><ul>
<li><a href="#116. How carat affects user behavior: implications for mobile battery awareness applications.">116. How carat affects user behavior: implications for mobile battery awareness applications.</a></li>
<li><a href="#117. EnergyBugs: energy harvesting wearables for children.">117. EnergyBugs: energy harvesting wearables for children.</a></li>
<li><a href="#118. OJAS: open source bi-directional inductive power link.">118. OJAS: open source bi-directional inductive power link.</a></li>
<li><a href="#119. Using asymmetric cores to reduce power consumption for interactive devices with bi-stable displays.">119. Using asymmetric cores to reduce power consumption for interactive devices with bi-stable displays.</a></li>
</ul>
</li>
<li><a href="#Mid-air gestures    4">Mid-air gestures    4</a><ul>
<li><a href="#120. Consumed endurance: a metric to quantify arm fatigue of mid-air interactions.">120. Consumed endurance: a metric to quantify arm fatigue of mid-air interactions.</a></li>
<li><a href="#121. Vulture: a mid-air word-gesture keyboard.">121. Vulture: a mid-air word-gesture keyboard.</a></li>
<li><a href="#122. Understanding finger input above desktop devices.">122. Understanding finger input above desktop devices.</a></li>
<li><a href="#123. Exploring the usefulness of finger-based 3D gesture menu selection.">123. Exploring the usefulness of finger-based 3D gesture menu selection.</a></li>
</ul>
</li>
<li><a href="#Touch and stylus interaction    4">Touch and stylus interaction    4</a><ul>
<li><a href="#124. In the blink of an eye: investigating latency perception during stylus interaction.">124. In the blink of an eye: investigating latency perception during stylus interaction.</a></li>
<li><a href="#125. Pinch-drag-flick vs. spatial input: rethinking zoom & pan on mobile displays.">125. Pinch-drag-flick vs. spatial input: rethinking zoom &amp; pan on mobile displays.</a></li>
<li><a href="#126. InkAnchor: enhancing informal ink-based note taking on touchscreen mobile phones.">126. InkAnchor: enhancing informal ink-based note taking on touchscreen mobile phones.</a></li>
<li><a href="#127. Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion.">127. Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion.</a></li>
</ul>
</li>
<li><a href="#Quantified self    3">Quantified self    3</a><ul>
<li><a href="#128. Understanding quantified-selfers' practices in collecting and exploring personal data.">128. Understanding quantified-selfers' practices in collecting and exploring personal data.</a></li>
<li><a href="#129. BodyDiagrams: improving communication of pain symptoms through drawing.">129. BodyDiagrams: improving communication of pain symptoms through drawing.</a></li>
<li><a href="#130. Personal tracking as lived informatics.">130. Personal tracking as lived informatics.</a></li>
</ul>
</li>
<li><a href="#Sustainability perspectives    2">Sustainability perspectives    2</a><ul>
<li><a href="#131. Towards an holistic view of the energy and environmental impacts of domestic media and IT.">131. Towards an holistic view of the energy and environmental impacts of domestic media and IT.</a></li>
<li><a href="#132. Beyond ethnography: engagement and reciprocity as foundations for design research out here.">132. Beyond ethnography: engagement and reciprocity as foundations for design research out here.</a></li>
</ul>
</li>
<li><a href="#Navigating video    5">Navigating video    5</a><ul>
<li><a href="#133. Visualization of personal history for video navigation.">133. Visualization of personal history for video navigation.</a></li>
<li><a href="#134. WaaZam!: supporting creative play at a distance in customized video environments.">134. WaaZam!: supporting creative play at a distance in customized video environments.</a></li>
<li><a href="#135. LACES: live authoring through compositing and editing of streaming video.">135. LACES: live authoring through compositing and editing of streaming video.</a></li>
<li><a href="#136. ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging.">136. ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging.</a></li>
<li><a href="#137. Panopticon as an eLearning support search tool.">137. Panopticon as an eLearning support search tool.</a></li>
</ul>
</li>
<li><a href="#Crowds and creativity    4">Crowds and creativity    4</a><ul>
<li><a href="#138. Searching for analogical ideas with crowds.">138. Searching for analogical ideas with crowds.</a></li>
<li><a href="#139. skWiki: a multimedia sketching system for collaborative creativity.">139. skWiki: a multimedia sketching system for collaborative creativity.</a></li>
<li><a href="#140. Distributed analogical idea generation: inventing with crowds.">140. Distributed analogical idea generation: inventing with crowds.</a></li>
<li><a href="#141. Frenzy: collaborative data organization for creating conference sessions.">141. Frenzy: collaborative data organization for creating conference sessions.</a></li>
</ul>
</li>
<li><a href="#Interacting with the web    3">Interacting with the web    3</a><ul>
<li><a href="#142. End-users publishing structured information on the web: an observational study of what, why, and how.">142. End-users publishing structured information on the web: an observational study of what, why, and how.</a></li>
<li><a href="#143. Designing usable web forms: empirical evaluation of web form improvement guidelines.">143. Designing usable web forms: empirical evaluation of web form improvement guidelines.</a></li>
<li><a href="#144. Choice overload in search engine use?">144. Choice overload in search engine use?</a></li>
</ul>
</li>
<li><a href="#Music, dance, and television    4">Music, dance, and television    4</a><ul>
<li><a href="#145. Coming in from the margins: amateur musicians in the online age.">145. Coming in from the margins: amateur musicians in the online age.</a></li>
<li><a href="#146. Watching the footwork: second screen interaction at a dance and music performance.">146. Watching the footwork: second screen interaction at a dance and music performance.</a></li>
<li><a href="#147. Streaming on twitch: fostering participatory communities of play within live mixed media.">147. Streaming on twitch: fostering participatory communities of play within live mixed media.</a></li>
<li><a href="#148. Long tail TV revisited: from ordinary camera phone use to pro-am video production.">148. Long tail TV revisited: from ordinary camera phone use to pro-am video production.</a></li>
</ul>
</li>
<li><a href="#Social media and health    4">Social media and health    4</a><ul>
<li><a href="#149. Estimating county health statistics with twitter.">149. Estimating county health statistics with twitter.</a></li>
<li><a href="#150. Unraveling abstinence and relapse: smoking cessation reflected in social media.">150. Unraveling abstinence and relapse: smoking cessation reflected in social media.</a></li>
<li><a href="#151. Weaving clinical expertise in online health communities.">151. Weaving clinical expertise in online health communities.</a></li>
<li><a href="#152. Seeking and sharing health information online: comparing search engines and social media.">152. Seeking and sharing health information online: comparing search engines and social media.</a></li>
</ul>
</li>
<li><a href="#On and above the surface    5">On and above the surface    5</a><ul>
<li><a href="#153. RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces.">153. RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces.</a></li>
<li><a href="#154. SurfaceLink: using inertial and acoustic sensing to enable multi-device interaction on a surface.">154. SurfaceLink: using inertial and acoustic sensing to enable multi-device interaction on a surface.</a></li>
<li><a href="#155. Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction.">155. Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction.</a></li>
<li><a href="#156. PrintSense: a versatile sensing technique to support multimodal flexible surface interaction.">156. PrintSense: a versatile sensing technique to support multimodal flexible surface interaction.</a></li>
<li><a href="#157. Let's kick it: how to stop wasting the bottom third of your large screen display.">157. Let's kick it: how to stop wasting the bottom third of your large screen display.</a></li>
</ul>
</li>
<li><a href="#Interactive whiteboards and public displays    3">Interactive whiteboards and public displays    3</a><ul>
<li><a href="#158. Communiplay: a field study of a public display mediaspace.">158. Communiplay: a field study of a public display mediaspace.</a></li>
<li><a href="#159. Posting for community and culture: considerations for the design of interactive digital bulletin boards.">159. Posting for community and culture: considerations for the design of interactive digital bulletin boards.</a></li>
<li><a href="#160. I can wait a minute: uncovering the optimal delay time for pre-moderated user-generated content on public displays.">160. I can wait a minute: uncovering the optimal delay time for pre-moderated user-generated content on public displays.</a></li>
</ul>
</li>
<li><a href="#Human-robot interaction    5">Human-robot interaction    5</a><ul>
<li><a href="#161. Design patterns for exploring and prototyping human-robot interactions.">161. Design patterns for exploring and prototyping human-robot interactions.</a></li>
<li><a href="#162. Improving social presence in human-agent interaction.">162. Improving social presence in human-agent interaction.</a></li>
<li><a href="#163. Robot gestures make difficult tasks easier: the impact of gestures on perceived workload and task performance.">163. Robot gestures make difficult tasks easier: the impact of gestures on perceived workload and task performance.</a></li>
<li><a href="#164. Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces.">164. Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces.</a></li>
<li><a href="#165. Stay on the boundary: artifact analysis exploring researcher and user framing of robot design.">165. Stay on the boundary: artifact analysis exploring researcher and user framing of robot design.</a></li>
</ul>
</li>
<li><a href="#Emergency response    4">Emergency response    4</a><ul>
<li><a href="#166. Help beacons: design and evaluation of an ad-hoc lightweight s.o.s. system for smartphones.">166. Help beacons: design and evaluation of an ad-hoc lightweight s.o.s. system for smartphones.</a></li>
<li><a href="#167. Upvoting hurricane Sandy: event-based news production processes on a social news site.">167. Upvoting hurricane Sandy: event-based news production processes on a social news site.</a></li>
<li><a href="#168. Online public communications by police & fire services during the 2012 Hurricane Sandy.">168. Online public communications by police &amp; fire services during the 2012 Hurricane Sandy.</a></li>
<li><a href="#169. EmergencyMessenger: a text based communication concept for indoor firefighting.">169. EmergencyMessenger: a text based communication concept for indoor firefighting.</a></li>
</ul>
</li>
<li><a href="#Sensemaking and information in use    5">Sensemaking and information in use    5</a><ul>
<li><a href="#170. Odin: contextual document opinions on the go.">170. Odin: contextual document opinions on the go.</a></li>
<li><a href="#171. Monadic exploration: seeing the whole through its parts.">171. Monadic exploration: seeing the whole through its parts.</a></li>
<li><a href="#172. Photographing information needs: the role of photos in experience sampling method-style research.">172. Photographing information needs: the role of photos in experience sampling method-style research.</a></li>
<li><a href="#173. Design insights for the next wave ontology authoring tools.">173. Design insights for the next wave ontology authoring tools.</a></li>
<li><a href="#174. The role of interactive biclusters in sensemaking.">174. The role of interactive biclusters in sensemaking.</a></li>
</ul>
</li>
<li><a href="#Presentation technologies    4">Presentation technologies    4</a><ul>
<li><a href="#175. SmartVoice: a presentation support system for overcoming the language barrier.">175. SmartVoice: a presentation support system for overcoming the language barrier.</a></li>
<li><a href="#176. PitchPerfect: integrated rehearsal environment for structured presentation preparation.">176. PitchPerfect: integrated rehearsal environment for structured presentation preparation.</a></li>
<li><a href="#177. DemoWiz: re-performing software demonstrations for a live presentation.">177. DemoWiz: re-performing software demonstrations for a live presentation.</a></li>
<li><a href="#178. TurningPoint: narrative-driven presentation planning.">178. TurningPoint: narrative-driven presentation planning.</a></li>
</ul>
</li>
<li><a href="#Personal health and wellbeing    4">Personal health and wellbeing    4</a><ul>
<li><a href="#179. Supporting treatment of people living with HIV / AIDS in resource limited settings with IVRs.">179. Supporting treatment of people living with HIV / AIDS in resource limited settings with IVRs.</a></li>
<li><a href="#180. Reflection through design: immigrant women's self-reflection on managing health and wellness.">180. Reflection through design: immigrant women's self-reflection on managing health and wellness.</a></li>
<li><a href="#181. DDFSeeks same: sexual health-related language in online personal ads for men who have sex with men.">181. DDFSeeks same: sexual health-related language in online personal ads for men who have sex with men.</a></li>
<li><a href="#182. Support matching and satisfaction in an online breast cancer support community.">182. Support matching and satisfaction in an online breast cancer support community.</a></li>
</ul>
</li>
<li><a href="#Design theory    4">Design theory    4</a><ul>
<li><a href="#183. Between theory and practice: bridging concepts in HCI research.">183. Between theory and practice: bridging concepts in HCI research.</a></li>
<li><a href="#184. Evolution of design competence in UX practice.">184. Evolution of design competence in UX practice.</a></li>
<li><a href="#185. Causal interactions.">185. Causal interactions.</a></li>
<li><a href="#186. Personas is applicable: a study on the use of personas in Denmark.">186. Personas is applicable: a study on the use of personas in Denmark.</a></li>
</ul>
</li>
<li><a href="#Novel keyboards    5">Novel keyboards    5</a><ul>
<li><a href="#187. GestKeyboard: enabling gesture-based interaction on ordinary physical keyboard.">187. GestKeyboard: enabling gesture-based interaction on ordinary physical keyboard.</a></li>
<li><a href="#188. Gesture script: recognizing gestures and their structure using rendering scripts and interactively trained parts.">188. Gesture script: recognizing gestures and their structure using rendering scripts and interactively trained parts.</a></li>
<li><a href="#189. Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.">189. Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.</a></li>
<li><a href="#190. B#: chord-based correction for multitouch braille input.">190. B#: chord-based correction for multitouch braille input.</a></li>
<li><a href="#191. Representatively memorable: sampling the right phrase set to get the text entry experiment right.">191. Representatively memorable: sampling the right phrase set to get the text entry experiment right.</a></li>
</ul>
</li>
<li><a href="#DIY and hacking    4">DIY and hacking    4</a><ul>
<li><a href="#192. Sketching in circuits: designing and building electronics on paper.">192. Sketching in circuits: designing and building electronics on paper.</a></li>
<li><a href="#193. Do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy.">193. Do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy.</a></li>
<li><a href="#194. 3D printed interactive speakers.">194. 3D printed interactive speakers.</a></li>
<li><a href="#195. Circuit stickers: peel-and-stick construction of interactive electronic prototypes.">195. Circuit stickers: peel-and-stick construction of interactive electronic prototypes.</a></li>
</ul>
</li>
<li><a href="#User models and prediction    4">User models and prediction    4</a><ul>
<li><a href="#196. Modeling the perception of user performance.">196. Modeling the perception of user performance.</a></li>
<li><a href="#197. Edit distance modulo bisimulation: a quantitative measure to study evolution of user models.">197. Edit distance modulo bisimulation: a quantitative measure to study evolution of user models.</a></li>
<li><a href="#198. The law of unintended consequences: the case of external subgoal support.">198. The law of unintended consequences: the case of external subgoal support.</a></li>
<li><a href="#199. Causality: a conceptual model of interaction history.">199. Causality: a conceptual model of interaction history.</a></li>
</ul>
</li>
<li><a href="#Engage and educate children    5">Engage and educate children    5</a><ul>
<li><a href="#200. Conversing with children: cartoon and video people elicit similar conversational behaviors.">200. Conversing with children: cartoon and video people elicit similar conversational behaviors.</a></li>
<li><a href="#201. Involving children in content control: a collaborative and education-oriented content filtering approach.">201. Involving children in content control: a collaborative and education-oriented content filtering approach.</a></li>
<li><a href="#202. What did spot hide?: a question-answering game for preschool children.">202. What did spot hide?: a question-answering game for preschool children.</a></li>
<li><a href="#203. Rafigh: a living media interface for speech intervention.">203. Rafigh: a living media interface for speech intervention.</a></li>
<li><a href="#204. A comparative study about children's and adults' perception of targeted web search engines.">204. A comparative study about children's and adults' perception of targeted web search engines.</a></li>
</ul>
</li>
<li><a href="#Studying visualization    2">Studying visualization    2</a><ul>
<li><a href="#205. Structuring the space: a study on enriching node-link diagrams with visual references.">205. Structuring the space: a study on enriching node-link diagrams with visual references.</a></li>
<li><a href="#206. Highlighting interventions and user differences: informing adaptive information visualization support.">206. Highlighting interventions and user differences: informing adaptive information visualization support.</a></li>
</ul>
</li>
<li><a href="#Exploring exergames    4">Exploring exergames    4</a><ul>
<li><a href="#207. Exertion in the small: improving differentiation and expressiveness in sports games with physical controls.">207. Exertion in the small: improving differentiation and expressiveness in sports games with physical controls.</a></li>
<li><a href="#208. "healthifying" exergames: improving health outcomes through intentional priming.">208. "healthifying" exergames: improving health outcomes through intentional priming.</a></li>
<li><a href="#209. Human factors of speed-based exergame controllers.">209. Human factors of speed-based exergame controllers.</a></li>
<li><a href="#210. Establishing design guidelines in interactive exercise gaming: preliminary data from two posing studies.">210. Establishing design guidelines in interactive exercise gaming: preliminary data from two posing studies.</a></li>
</ul>
</li>
<li><a href="#Narratives and storytelling    4">Narratives and storytelling    4</a><ul>
<li><a href="#211. The dept. of hidden stories: playful digital storytelling for children in a public library.">211. The dept. of hidden stories: playful digital storytelling for children in a public library.</a></li>
<li><a href="#212. Visualizing interactive narratives: employing a branching comic to tell a story and show its readings.">212. Visualizing interactive narratives: employing a branching comic to tell a story and show its readings.</a></li>
<li><a href="#213. FOCUS: enhancing children's engagement in reading by using contextual BCI training sessions.">213. FOCUS: enhancing children's engagement in reading by using contextual BCI training sessions.</a></li>
<li><a href="#214. Sensing a live audience.">214. Sensing a live audience.</a></li>
</ul>
</li>
<li><a href="#Designing for older adults and demographic change    4">Designing for older adults and demographic change    4</a><ul>
<li><a href="#215. Interface design for older adults with varying cultural attitudes toward uncertainty.">215. Interface design for older adults with varying cultural attitudes toward uncertainty.</a></li>
<li><a href="#216. Social dependency and mobile autonomy: supporting older adults' mobility with ridesharing ict.">216. Social dependency and mobile autonomy: supporting older adults' mobility with ridesharing ict.</a></li>
<li><a href="#217. From checking on to checking in: designing for low socio-economic status older adults.">217. From checking on to checking in: designing for low socio-economic status older adults.</a></li>
<li><a href="#218. Invisible connections: investigating older people's emotions and social relations around objects.">218. Invisible connections: investigating older people's emotions and social relations around objects.</a></li>
</ul>
</li>
<li><a href="#Critical design    4">Critical design    4</a><ul>
<li><a href="#219. Always somewhere, never there: using critical design to understand database interactions.">219. Always somewhere, never there: using critical design to understand database interactions.</a></li>
<li><a href="#220. Reading critical designs: supporting reasoned interpretations of critical design.">220. Reading critical designs: supporting reasoned interpretations of critical design.</a></li>
<li><a href="#221. Designing for slowness, anticipation and re-visitation: a long term field study of the photobox.">221. Designing for slowness, anticipation and re-visitation: a long term field study of the photobox.</a></li>
<li><a href="#222. Generating implications for design through design research.">222. Generating implications for design through design research.</a></li>
</ul>
</li>
<li><a href="#Understanding and modeling touch    6">Understanding and modeling touch    6</a><ul>
<li><a href="#223. Investigating the effects of encumbrance on one- and two- handed interactions with mobile devices.">223. Investigating the effects of encumbrance on one- and two- handed interactions with mobile devices.</a></li>
<li><a href="#224. Modeling the functional area of the thumb on mobile touchscreen surfaces.">224. Modeling the functional area of the thumb on mobile touchscreen surfaces.</a></li>
<li><a href="#225. Coordination of tilt and touch in one- and two-handed use.">225. Coordination of tilt and touch in one- and two-handed use.</a></li>
<li><a href="#226. 28 frames later: predicting screen touches from back-of-device grip changes.">226. 28 frames later: predicting screen touches from back-of-device grip changes.</a></li>
<li><a href="#227. Probabilistic palm rejection using spatiotemporal touch features and iterative classification.">227. Probabilistic palm rejection using spatiotemporal touch features and iterative classification.</a></li>
<li><a href="#228. Orientation matters: efficiency of translation-rotation multitouch tasks.">228. Orientation matters: efficiency of translation-rotation multitouch tasks.</a></li>
</ul>
</li>
<li><a href="#3D interaction: modeling and prototyping    5">3D interaction: modeling and prototyping    5</a><ul>
<li><a href="#229. MotionMontage: a system to annotate and combine motion takes for 3D animations.">229. MotionMontage: a system to annotate and combine motion takes for 3D animations.</a></li>
<li><a href="#230. History assisted view authoring for 3D models.">230. History assisted view authoring for 3D models.</a></li>
<li><a href="#231. FrameBox and MirrorBox: tools and guidelines to support designers in prototyping interfaces for 3D displays.">231. FrameBox and MirrorBox: tools and guidelines to support designers in prototyping interfaces for 3D displays.</a></li>
<li><a href="#232. Direct drawing on 3D shapes with automated camera control.">232. Direct drawing on 3D shapes with automated camera control.</a></li>
<li><a href="#233. Interactively stylizing camera motion.">233. Interactively stylizing camera motion.</a></li>
</ul>
</li>
<li><a href="#The eyes have it    4">The eyes have it    4</a><ul>
<li><a href="#234. Stimulating a blink: reduction of eye fatigue with visual stimulus.">234. Stimulating a blink: reduction of eye fatigue with visual stimulus.</a></li>
<li><a href="#235. Smart photo selection: interpret gaze as personal interest.">235. Smart photo selection: interpret gaze as personal interest.</a></li>
<li><a href="#236. Pupil responses during discrete goal-directed movements.">236. Pupil responses during discrete goal-directed movements.</a></li>
<li><a href="#237. Collocating interface objects: zooming into maps.">237. Collocating interface objects: zooming into maps.</a></li>
</ul>
</li>
<li><a href="#Learning and education    4">Learning and education    4</a><ul>
<li><a href="#238. Showing face in video instruction: effects on information retention, visual attention, and affect.">238. Showing face in video instruction: effects on information retention, visual attention, and affect.</a></li>
<li><a href="#239. Supporting learners in collecting and exploring data from immersive simulations in collective inquiry.">239. Supporting learners in collecting and exploring data from immersive simulations in collective inquiry.</a></li>
<li><a href="#240. Learning to see the body: supporting instructional practices in laparoscopic surgical procedures.">240. Learning to see the body: supporting instructional practices in laparoscopic surgical procedures.</a></li>
<li><a href="#241. Information-building applications: designing for data exploration and analysis by elementary school students.">241. Information-building applications: designing for data exploration and analysis by elementary school students.</a></li>
</ul>
</li>
<li><a href="#Telepresence and connecting over video    5">Telepresence and connecting over video    5</a><ul>
<li><a href="#242. Remote handshaking: touch enhances video-mediated social telepresence.">242. Remote handshaking: touch enhances video-mediated social telepresence.</a></li>
<li><a href="#243. Bodies in motion: mobility, presence, and task awareness in telepresence.">243. Bodies in motion: mobility, presence, and task awareness in telepresence.</a></li>
<li><a href="#244. Exploring video streaming in public settings: shared geocaching over distance using mobile video chat.">244. Exploring video streaming in public settings: shared geocaching over distance using mobile video chat.</a></li>
<li><a href="#245. A gaze-preserving situated multiview telepresence system.">245. A gaze-preserving situated multiview telepresence system.</a></li>
<li><a href="#246. OneSpace: shared visual scenes for active freeplay.">246. OneSpace: shared visual scenes for active freeplay.</a></li>
</ul>
</li>
<li><a href="#Exergame design    4">Exergame design    4</a><ul>
<li><a href="#247. i-dentity: innominate movement representation as engaging game element.">247. i-dentity: innominate movement representation as engaging game element.</a></li>
<li><a href="#248. Movement-based game guidelines.">248. Movement-based game guidelines.</a></li>
<li><a href="#249. Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames.">249. Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames.</a></li>
<li><a href="#250. Supporting the creative game design process with exertion cards.">250. Supporting the creative game design process with exertion cards.</a></li>
</ul>
</li>
<li><a href="#Designing and modeling GUIs    5">Designing and modeling GUIs    5</a><ul>
<li><a href="#251. WADE: simplified GUI add-on development for third-party software.">251. WADE: simplified GUI add-on development for third-party software.</a></li>
<li><a href="#252. Pixel-based methods for widget state and style in a runtime implementation of sliding widgets.">252. Pixel-based methods for widget state and style in a runtime implementation of sliding widgets.</a></li>
<li><a href="#253. The usability of CommandMaps in realistic tasks.">253. The usability of CommandMaps in realistic tasks.</a></li>
<li><a href="#254. Novice use of a predictive human performance modeling tool to produce UI recommendations.">254. Novice use of a predictive human performance modeling tool to produce UI recommendations.</a></li>
<li><a href="#255. On the selection of 2D objects using external labeling.">255. On the selection of 2D objects using external labeling.</a></li>
</ul>
</li>
<li><a href="#Health and everyday life    5">Health and everyday life    5</a><ul>
<li><a href="#256. Real-time feedback for improving medication taking.">256. Real-time feedback for improving medication taking.</a></li>
<li><a href="#257. Don't forget your pill!: designing effective medication reminder apps that support users' daily routines.">257. Don't forget your pill!: designing effective medication reminder apps that support users' daily routines.</a></li>
<li><a href="#258. @BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones.">258. @BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones.</a></li>
<li><a href="#259. DoDo game, a color vision deficiency screening test for young children.">259. DoDo game, a color vision deficiency screening test for young children.</a></li>
<li><a href="#260. The influence of emotion on number entry errors.">260. The influence of emotion on number entry errors.</a></li>
</ul>
</li>
<li><a href="#Text entry and evaluation    2">Text entry and evaluation    2</a><ul>
<li><a href="#261. Both complete and correct?: multi-objective optimization of touchscreen keyboard.">261. Both complete and correct?: multi-objective optimization of touchscreen keyboard.</a></li>
<li><a href="#262. Uncertain text entry on mobile devices.">262. Uncertain text entry on mobile devices.</a></li>
</ul>
</li>
<li><a href="#Emotions and mobiles    3">Emotions and mobiles    3</a><ul>
<li><a href="#263. Mobile attachment causes and consequences for emotional bonding with mobile phones.">263. Mobile attachment causes and consequences for emotional bonding with mobile phones.</a></li>
<li><a href="#264. Hooked on smartphones: an exploratory study on smartphone overuse among college students.">264. Hooked on smartphones: an exploratory study on smartphone overuse among college students.</a></li>
<li><a href="#265. Broken display = broken interface': the impact of display damage on smartphone interaction.">265. Broken display = broken interface': the impact of display damage on smartphone interaction.</a></li>
</ul>
</li>
<li><a href="#Privacy    4">Privacy    4</a><ul>
<li><a href="#266. Leakiness and creepiness in app space: perceptions of privacy and mobile app use.">266. Leakiness and creepiness in app space: perceptions of privacy and mobile app use.</a></li>
<li><a href="#267. Personalisation and privacy in future pervasive display networks.">267. Personalisation and privacy in future pervasive display networks.</a></li>
<li><a href="#268. A field trial of privacy nudges for facebook.">268. A field trial of privacy nudges for facebook.</a></li>
<li><a href="#269. In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies.">269. In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies.</a></li>
</ul>
</li>
<li><a href="#Issues that matter    3">Issues that matter    3</a><ul>
<li><a href="#270. Listening to the forest and its curators: lessons learnt from a bioacoustic smartphone application deployment.">270. Listening to the forest and its curators: lessons learnt from a bioacoustic smartphone application deployment.</a></li>
<li><a href="#271. Making public things: how HCI design can express matters of concern.">271. Making public things: how HCI design can express matters of concern.</a></li>
<li><a href="#272. Just awful enough: the functional dysfunction of the something awful forums.">272. Just awful enough: the functional dysfunction of the something awful forums.</a></li>
</ul>
</li>
<li><a href="#Understanding and using social media    4">Understanding and using social media    4</a><ul>
<li><a href="#273. Everyday ideation: all of my ideas are on pinterest.">273. Everyday ideation: all of my ideas are on pinterest.</a></li>
<li><a href="#274. Understanding user adaptation strategies for the launching of facebook timeline.">274. Understanding user adaptation strategies for the launching of facebook timeline.</a></li>
<li><a href="#275. Curation through use: understanding the personal value of social media.">275. Curation through use: understanding the personal value of social media.</a></li>
<li><a href="#276. Together alone: motivations for live-tweeting a television series.">276. Together alone: motivations for live-tweeting a television series.</a></li>
</ul>
</li>
<li><a href="#Working together    3">Working together    3</a><ul>
<li><a href="#277. Documentscape: intertextuality, sequentiality, & autonomy at work.">277. Documentscape: intertextuality, sequentiality, &amp; autonomy at work.</a></li>
<li><a href="#278. Cloudy forecast: an exploration of the factors underlying shared repository use.">278. Cloudy forecast: an exploration of the factors underlying shared repository use.</a></li>
<li><a href="#279. Designing information savvy societies: an introduction to assessability.">279. Designing information savvy societies: an introduction to assessability.</a></li>
</ul>
</li>
<li><a href="#Programming and development tools    4">Programming and development tools    4</a><ul>
<li><a href="#280. Addressing misconceptions about code with always-on programming visualizations.">280. Addressing misconceptions about code with always-on programming visualizations.</a></li>
<li><a href="#281. Emergent, crowd-scale programming practice in the IDE.">281. Emergent, crowd-scale programming practice in the IDE.</a></li>
<li><a href="#282. Design considerations for parallel performance tools.">282. Design considerations for parallel performance tools.</a></li>
<li><a href="#283. The patchworks code editor: toward faster navigation with less code arranging and fewer navigation mistakes.">283. The patchworks code editor: toward faster navigation with less code arranging and fewer navigation mistakes.</a></li>
</ul>
</li>
<li><a href="#Interactive technologies for rehabilitation    5">Interactive technologies for rehabilitation    5</a><ul>
<li><a href="#284. A novel knee rehabilitation system for the home.">284. A novel knee rehabilitation system for the home.</a></li>
<li><a href="#285. GaitAssist: a daily-life support and training system for parkinson's disease patients with freezing of gait.">285. GaitAssist: a daily-life support and training system for parkinson's disease patients with freezing of gait.</a></li>
<li><a href="#286. A technology probe of wearable in-home computer-assisted physical therapy.">286. A technology probe of wearable in-home computer-assisted physical therapy.</a></li>
<li><a href="#287. Exploring the acceptability of google glass as an everyday assistive device for people with parkinson's.">287. Exploring the acceptability of google glass as an everyday assistive device for people with parkinson's.</a></li>
<li><a href="#288. Non-intrusive tongue machine interface.">288. Non-intrusive tongue machine interface.</a></li>
</ul>
</li>
<li><a href="#Shape-changing interfaces    5">Shape-changing interfaces    5</a><ul>
<li><a href="#289. Causing commotion with a shape-changing bench: experiencing shape-changing interfaces in use.">289. Causing commotion with a shape-changing bench: experiencing shape-changing interfaces in use.</a></li>
<li><a href="#290. Paddle: highly deformable mobile devices with physical controls.">290. Paddle: highly deformable mobile devices with physical controls.</a></li>
<li><a href="#291. Is my phone alive?: a large-scale study of shape change in handheld devices using videos.">291. Is my phone alive?: a large-scale study of shape change in handheld devices using videos.</a></li>
<li><a href="#292. Evaluating the effectiveness of physical shape-change for in-pocket mobile device notifications.">292. Evaluating the effectiveness of physical shape-change for in-pocket mobile device notifications.</a></li>
<li><a href="#293. Changibles: analyzing and designing shape changing constructive assembly.">293. Changibles: analyzing and designing shape changing constructive assembly.</a></li>
</ul>
</li>
<li><a href="#Touch input    4">Touch input    4</a><ul>
<li><a href="#294. Expanding touch input vocabulary by using consecutive distant taps.">294. Expanding touch input vocabulary by using consecutive distant taps.</a></li>
<li><a href="#295. LinearDragger: a linear selector for target acquisition on touch screens.">295. LinearDragger: a linear selector for target acquisition on touch screens.</a></li>
<li><a href="#296. Faster command selection on tablets with FastTap.">296. Faster command selection on tablets with FastTap.</a></li>
<li><a href="#297. Crossing-based selection with direct touch input.">297. Crossing-based selection with direct touch input.</a></li>
</ul>
</li>
<li><a href="#Risks and security    5">Risks and security    5</a><ul>
<li><a href="#298. Easy does it: more usable CAPTCHAs.">298. Easy does it: more usable CAPTCHAs.</a></li>
<li><a href="#299. Using personal examples to improve risk communication for security & privacy decisions.">299. Using personal examples to improve risk communication for security &amp; privacy decisions.</a></li>
<li><a href="#300. "My religious aunt asked why i was trying to sell her viagra": experiences with account hijacking.">300. "My religious aunt asked why i was trying to sell her viagra": experiences with account hijacking.</a></li>
<li><a href="#301. Experimenting at scale with google chrome's SSL warning.">301. Experimenting at scale with google chrome's SSL warning.</a></li>
<li><a href="#302. Betrayed by updates: how negative experiences affect future security.">302. Betrayed by updates: how negative experiences affect future security.</a></li>
</ul>
</li>
<li><a href="#CHI for social development    4">CHI for social development    4</a><ul>
<li><a href="#303. Understanding sustained community engagement: a case study in heritage preservation in rural argentina.">303. Understanding sustained community engagement: a case study in heritage preservation in rural argentina.</a></li>
<li><a href="#304. Human values in curating a human rights media archive.">304. Human values in curating a human rights media archive.</a></li>
<li><a href="#305. Protibadi: a platform for fighting sexual harassment in urban bangladesh.">305. Protibadi: a platform for fighting sexual harassment in urban bangladesh.</a></li>
<li><a href="#306. How technology supports family communication in rural, suburban, and urban kenya.">306. How technology supports family communication in rural, suburban, and urban kenya.</a></li>
</ul>
</li>
<li><a href="#Question and answer systems    5">Question and answer systems    5</a><ul>
<li><a href="#307. Towards crowd-based customer service: a mixed-initiative tool for managing Q&A sites.">307. Towards crowd-based customer service: a mixed-initiative tool for managing Q&amp;A sites.</a></li>
<li><a href="#308. Estimating the social costs of friendsourcing.">308. Estimating the social costs of friendsourcing.</a></li>
<li><a href="#309. Expert voices in echo chambers: effects of source expertise indicators on exposure to diverse opinions.">309. Expert voices in echo chambers: effects of source expertise indicators on exposure to diverse opinions.</a></li>
<li><a href="#310. Is anyone out there?: unpacking Q&A hashtags on twitter.">310. Is anyone out there?: unpacking Q&amp;A hashtags on twitter.</a></li>
<li><a href="#311. What if we ask a different question?: social inferences create product ratings faster.">311. What if we ask a different question?: social inferences create product ratings faster.</a></li>
</ul>
</li>
<li><a href="#Cross-device interaction    4">Cross-device interaction    4</a><ul>
<li><a href="#312. Smarties: an input system for wall display development.">312. Smarties: an input system for wall display development.</a></li>
<li><a href="#313. Conductor: enabling and understanding cross-device interaction.">313. Conductor: enabling and understanding cross-device interaction.</a></li>
<li><a href="#314. Panelrama: enabling easy specification of cross-device web applications.">314. Panelrama: enabling easy specification of cross-device web applications.</a></li>
<li><a href="#315. Interactive development of cross-device user interfaces.">315. Interactive development of cross-device user interfaces.</a></li>
</ul>
</li>
<li><a href="#Exergaming for health and fitness    4">Exergaming for health and fitness    4</a><ul>
<li><a href="#316. Motivating people with chronic pain to do physical activity: opportunities for technology design.">316. Motivating people with chronic pain to do physical activity: opportunities for technology design.</a></li>
<li><a href="#317. Investigating the long-term use of exergames in the home with elderly fallers.">317. Investigating the long-term use of exergames in the home with elderly fallers.</a></li>
<li><a href="#318. StepStream: a school-based pervasive social fitness system for everyday adolescent health.">318. StepStream: a school-based pervasive social fitness system for everyday adolescent health.</a></li>
<li><a href="#319. Social fabric fitness: the design and evaluation of wearable E-textile displays to support group running.">319. Social fabric fitness: the design and evaluation of wearable E-textile displays to support group running.</a></li>
</ul>
</li>
<li><a href="#Sensory experiences: smell and taste    4">Sensory experiences: smell and taste    4</a><ul>
<li><a href="#320. Opportunities for odor: experiences with smell and implications for technology.">320. Opportunities for odor: experiences with smell and implications for technology.</a></li>
<li><a href="#321. Temporal, affective, and embodied characteristics of taste experiences: a framework for design.">321. Temporal, affective, and embodied characteristics of taste experiences: a framework for design.</a></li>
<li><a href="#322. SensaBubble: a chrono-sensory mid-air display of sight and smell.">322. SensaBubble: a chrono-sensory mid-air display of sight and smell.</a></li>
<li><a href="#323. Food messaging: using edible medium for social messaging.">323. Food messaging: using edible medium for social messaging.</a></li>
</ul>
</li>
<li><a href="#Multitouch interaction    4">Multitouch interaction    4</a><ul>
<li><a href="#324. Multi-finger chords for hand-held tablets: recognizable and memorable.">324. Multi-finger chords for hand-held tablets: recognizable and memorable.</a></li>
<li><a href="#325. Prospective motor control on tabletops: planning grasp for multitouch interaction.">325. Prospective motor control on tabletops: planning grasp for multitouch interaction.</a></li>
<li><a href="#326. Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects.">326. Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects.</a></li>
<li><a href="#327. TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction.">327. TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction.</a></li>
</ul>
</li>
<li><a href="#Authentication and passwords    5">Authentication and passwords    5</a><ul>
<li><a href="#328. Passhint: memorable and secure authentication.">328. Passhint: memorable and secure authentication.</a></li>
<li><a href="#329. Can long passwords be secure and usable?">329. Can long passwords be secure and usable?</a></li>
<li><a href="#330. Now you see me, now you don't: protecting smartphone authentication from shoulder surfers.">330. Now you see me, now you don't: protecting smartphone authentication from shoulder surfers.</a></li>
<li><a href="#331. The presentation effect on graphical passwords.">331. The presentation effect on graphical passwords.</a></li>
<li><a href="#332. An implicit author verification system for text messages based on gesture typing biometrics.">332. An implicit author verification system for text messages based on gesture typing biometrics.</a></li>
</ul>
</li>
<li><a href="#Policies and practice: doing the right thing    3">Policies and practice: doing the right thing    3</a><ul>
<li><a href="#333. HCI as a means to prosociality in the economy.">333. HCI as a means to prosociality in the economy.</a></li>
<li><a href="#334. Towards a closer dialogue between policy and practice: responsible design in HCI.">334. Towards a closer dialogue between policy and practice: responsible design in HCI.</a></li>
<li><a href="#335. Towards community-centered support for peer-to-peer service exchange: rethinking the timebanking metaphor.">335. Towards community-centered support for peer-to-peer service exchange: rethinking the timebanking metaphor.</a></li>
</ul>
</li>
<li><a href="#Journalism and social news    4">Journalism and social news    4</a><ul>
<li><a href="#336. Designing for dabblers and deterring drop-outs in citizen science.">336. Designing for dabblers and deterring drop-outs in citizen science.</a></li>
<li><a href="#337. Utilising insight journalism for community technology design.">337. Utilising insight journalism for community technology design.</a></li>
<li><a href="#338. NewsViews: an automated pipeline for creating custom geovisualizations for news.">338. NewsViews: an automated pipeline for creating custom geovisualizations for news.</a></li>
<li><a href="#339. Finding "real people": trust and diversity in the interface between professional and citizen journalists.">339. Finding "real people": trust and diversity in the interface between professional and citizen journalists.</a></li>
</ul>
</li>
<li><a href="#Interruptions and distractions    4">Interruptions and distractions    4</a><ul>
<li><a href="#340. Bored mondays and focused afternoons: the rhythm of attention and online activity in the workplace.">340. Bored mondays and focused afternoons: the rhythm of attention and online activity in the workplace.</a></li>
<li><a href="#341. CRISP: an interruption management algorithm based on collaborative filtering.">341. CRISP: an interruption management algorithm based on collaborative filtering.</a></li>
<li><a href="#342. Interrupted by a phone call: exploring designs for lowering the impact of call notifications for smartphone users.">342. Interrupted by a phone call: exploring designs for lowering the impact of call notifications for smartphone users.</a></li>
<li><a href="#343. Large-scale assessment of mobile notifications.">343. Large-scale assessment of mobile notifications.</a></li>
</ul>
</li>
<li><a href="#Decisions, recommendations, and machine learning    5">Decisions, recommendations, and machine learning    5</a><ul>
<li><a href="#344. Customization bias in decision support systems.">344. Customization bias in decision support systems.</a></li>
<li><a href="#345. Structured labeling for facilitating concept evolution in machine learning.">345. Structured labeling for facilitating concept evolution in machine learning.</a></li>
<li><a href="#346. Choice-based preference elicitation for collaborative filtering recommender systems.">346. Choice-based preference elicitation for collaborative filtering recommender systems.</a></li>
<li><a href="#347. Finding dependencies between actions using the crowd.">347. Finding dependencies between actions using the crowd.</a></li>
<li><a href="#348. Scalable multi-label annotation.">348. Scalable multi-label annotation.</a></li>
</ul>
</li>
<li><a href="#Accessibility    4">Accessibility    4</a><ul>
<li><a href="#349. Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users.">349. Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users.</a></li>
<li><a href="#350. The last meter: blind visual guidance to a target.">350. The last meter: blind visual guidance to a target.</a></li>
<li><a href="#351. Current and future mobile and wearable device use by people with visual impairments.">351. Current and future mobile and wearable device use by people with visual impairments.</a></li>
<li><a href="#352. Visually impaired users on an online social network.">352. Visually impaired users on an online social network.</a></li>
</ul>
</li>
<li><a href="#Tangible interactions and technologies    4">Tangible interactions and technologies    4</a><ul>
<li><a href="#353. Kickables: tangibles for feet.">353. Kickables: tangibles for feet.</a></li>
<li><a href="#354. GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays.">354. GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays.</a></li>
<li><a href="#355. Designing tangible video games: lessons learned from the sifteo cubes.">355. Designing tangible video games: lessons learned from the sifteo cubes.</a></li>
<li><a href="#356. A low-cost transparent electric field sensor for 3d interaction on mobile devices.">356. A low-cost transparent electric field sensor for 3d interaction on mobile devices.</a></li>
</ul>
</li>
<li><a href="#Head-worn displays    4">Head-worn displays    4</a><ul>
<li><a href="#357. The personal cockpit: a spatial interface for effective task switching on head-worn displays.">357. The personal cockpit: a spatial interface for effective task switching on head-worn displays.</a></li>
<li><a href="#358. Exploring the use of hand-to-face input for interacting with head-worn displays.">358. Exploring the use of hand-to-face input for interacting with head-worn displays.</a></li>
<li><a href="#359. Permulin: mixed-focus collaboration on multi-view tabletops.">359. Permulin: mixed-focus collaboration on multi-view tabletops.</a></li>
<li><a href="#360. In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time.">360. In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time.</a></li>
</ul>
</li>
<li><a href="#Applications of body sensing    4">Applications of body sensing    4</a><ul>
<li><a href="#361. Kinect-taped communication: using motion sensing to study gesture use and similarity in face-to-face and computer-mediated brainstorming.">361. Kinect-taped communication: using motion sensing to study gesture use and similarity in face-to-face and computer-mediated brainstorming.</a></li>
<li><a href="#362. Is motion capture-based biomechanical simulation valid for HCI studies?: study and implications.">362. Is motion capture-based biomechanical simulation valid for HCI studies?: study and implications.</a></li>
<li><a href="#363. RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises.">363. RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises.</a></li>
<li><a href="#364. Improving automatic speech recognition through head pose driven visual grounding.">364. Improving automatic speech recognition through head pose driven visual grounding.</a></li>
</ul>
</li>
<li><a href="#Urban communities and social media    4">Urban communities and social media    4</a><ul>
<li><a href="#365. Tensions in scaling-up community social media: a multi-neighborhood study of nextdoor.">365. Tensions in scaling-up community social media: a multi-neighborhood study of nextdoor.</a></li>
<li><a href="#366. Curated city: capturing individual city guides through social curation.">366. Curated city: capturing individual city guides through social curation.</a></li>
<li><a href="#367. ZWERM: a modular component network approach for an urban participation game.">367. ZWERM: a modular component network approach for an urban participation game.</a></li>
<li><a href="#368. Studying digital graffiti as a location-based social network.">368. Studying digital graffiti as a location-based social network.</a></li>
</ul>
</li>
<li><a href="#Social media usage    4">Social media usage    4</a><ul>
<li><a href="#369. Social epistemic cognition in online interactions.">369. Social epistemic cognition in online interactions.</a></li>
<li><a href="#370. Share your view: impact of co-navigation support and status composition in collaborative online shopping.">370. Share your view: impact of co-navigation support and status composition in collaborative online shopping.</a></li>
<li><a href="#371. Nutriflect: reflecting collective shopping behavior and nutrition.">371. Nutriflect: reflecting collective shopping behavior and nutrition.</a></li>
<li><a href="#372. Didn't you see my message?: predicting attentiveness to mobile instant messages.">372. Didn't you see my message?: predicting attentiveness to mobile instant messages.</a></li>
</ul>
</li>
<li><a href="#Games and education    4">Games and education    4</a><ul>
<li><a href="#373. Using extracted features to inform alignment-driven design ideas in an educational game.">373. Using extracted features to inform alignment-driven design ideas in an educational game.</a></li>
<li><a href="#374. Brain points: a growth mindset incentive structure boosts persistence in an educational game.">374. Brain points: a growth mindset incentive structure boosts persistence in an educational game.</a></li>
<li><a href="#375. Towards automatic experimentation of educational knowledge.">375. Towards automatic experimentation of educational knowledge.</a></li>
<li><a href="#376. Spending real money: purchasing patterns of virtual goods in an online social game.">376. Spending real money: purchasing patterns of virtual goods in an online social game.</a></li>
</ul>
</li>
<li><a href="#Learning and games    4">Learning and games    4</a><ul>
<li><a href="#377. CADament: a gamified multiplayer software tutorial system.">377. CADament: a gamified multiplayer software tutorial system.</a></li>
<li><a href="#378. Combining crowdsourcing and learning to improve engagement and performance.">378. Combining crowdsourcing and learning to improve engagement and performance.</a></li>
<li><a href="#379. A game-based learning approach to road safety: the code of everand.">379. A game-based learning approach to road safety: the code of everand.</a></li>
<li><a href="#380. L.IVE: an integrated interactive video-based learning environment.">380. L.IVE: an integrated interactive video-based learning environment.</a></li>
</ul>
</li>
<li><a href="#Persuasive technologies and applications    4">Persuasive technologies and applications    4</a><ul>
<li><a href="#381. Persuasive technology for overcoming food cravings and improving snack choices.">381. Persuasive technology for overcoming food cravings and improving snack choices.</a></li>
<li><a href="#382. The effects of embodied persuasive games on player attitudes toward people using wheelchairs.">382. The effects of embodied persuasive games on player attitudes toward people using wheelchairs.</a></li>
<li><a href="#383. Spent: changing students' affective learning toward homelessness through persuasive video game play.">383. Spent: changing students' affective learning toward homelessness through persuasive video game play.</a></li>
<li><a href="#384. Incentives to participate in online research: an experimental examination of "surprise" incentives.">384. Incentives to participate in online research: an experimental examination of "surprise" incentives.</a></li>
</ul>
</li>
<li><a href="#Whole body sensing and interaction    4">Whole body sensing and interaction    4</a><ul>
<li><a href="#385. Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces.">385. Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces.</a></li>
<li><a href="#386. Wave to me: user identification using body lengths and natural gestures.">386. Wave to me: user identification using body lengths and natural gestures.</a></li>
<li><a href="#387. Haptic turk: a motion platform based on people.">387. Haptic turk: a motion platform based on people.</a></li>
<li><a href="#388. Audience experience in social videogaming: effects of turn expectation and game physicality.">388. Audience experience in social videogaming: effects of turn expectation and game physicality.</a></li>
</ul>
</li>
<li><a href="#Novel mobile displays and devices    4">Novel mobile displays and devices    4</a><ul>
<li><a href="#389. Exploiting thermal reflection for interactive systems.">389. Exploiting thermal reflection for interactive systems.</a></li>
<li><a href="#390. MisTable: reach-through personal screens for tabletops.">390. MisTable: reach-through personal screens for tabletops.</a></li>
<li><a href="#391. What is a device bend gesture really good for?">391. What is a device bend gesture really good for?</a></li>
<li><a href="#392. SurfacePhone: a mobile projection device for single- and multiuser everywhere tabletop interaction.">392. SurfacePhone: a mobile projection device for single- and multiuser everywhere tabletop interaction.</a></li>
</ul>
</li>
<li><a href="#HCI paradigms: past, present and future    4">HCI paradigms: past, present and future    4</a><ul>
<li><a href="#393. Is once enough?: on the extent and content of replications in human-computer interaction.">393. Is once enough?: on the extent and content of replications in human-computer interaction.</a></li>
<li><a href="#394. Binding the material and the discursive with a relational approach of affordances.">394. Binding the material and the discursive with a relational approach of affordances.</a></li>
<li><a href="#395. The turn to practice in HCI: towards a research agenda.">395. The turn to practice in HCI: towards a research agenda.</a></li>
<li><a href="#396. CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis.">396. CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis.</a></li>
</ul>
</li>
<li><a href="#PolitiCHI    4">PolitiCHI    4</a><ul>
<li><a href="#397. "Narco" emotions: affect and desensitization in social media during the mexican drug war.">397. "Narco" emotions: affect and desensitization in social media during the mexican drug war.</a></li>
<li><a href="#398. A pool of dreams: facebook, politics and the emergence of a social movement.">398. A pool of dreams: facebook, politics and the emergence of a social movement.</a></li>
<li><a href="#399. Shared values/conflicting logics: working around e-government systems.">399. Shared values/conflicting logics: working around e-government systems.</a></li>
<li><a href="#400. Rethinking plan A for sustainable HCI.">400. Rethinking plan A for sustainable HCI.</a></li>
</ul>
</li>
<li><a href="#Location-based services and navigation    5">Location-based services and navigation    5</a><ul>
<li><a href="#401. HaptiMoto: turn-by-turn haptic route guidance interface for motorcyclists.">401. HaptiMoto: turn-by-turn haptic route guidance interface for motorcyclists.</a></li>
<li><a href="#402. Experimental evaluation of user interfaces for visual indoor navigation.">402. Experimental evaluation of user interfaces for visual indoor navigation.</a></li>
<li><a href="#403. Digitally driven: how location based services impact the work practices of London bus drivers.">403. Digitally driven: how location based services impact the work practices of London bus drivers.</a></li>
<li><a href="#404. Smart flashlight: map navigation using a bike-mounted projector.">404. Smart flashlight: map navigation using a bike-mounted projector.</a></li>
<li><a href="#405. Partially intelligent automobiles and driving experience at the moment of system transition.">405. Partially intelligent automobiles and driving experience at the moment of system transition.</a></li>
</ul>
</li>
<li><a href="#Crowdsourcing    4">Crowdsourcing    4</a><ul>
<li><a href="#406. Slide to X: unlocking the potential of smartphone unlocking.">406. Slide to X: unlocking the potential of smartphone unlocking.</a></li>
<li><a href="#407. Twitch crowdsourcing: crowd contributions in short bursts of time.">407. Twitch crowdsourcing: crowd contributions in short bursts of time.</a></li>
<li><a href="#408. Crowdsourcing the future: predictions made with a social network.">408. Crowdsourcing the future: predictions made with a social network.</a></li>
<li><a href="#409. Cognitively inspired task design to improve user performance on crowdsourcing platforms.">409. Cognitively inspired task design to improve user performance on crowdsourcing platforms.</a></li>
</ul>
</li>
<li><a href="#Desktop search and history    4">Desktop search and history    4</a><ul>
<li><a href="#410. Searching for myself: motivations and strategies for self-search.">410. Searching for myself: motivations and strategies for self-search.</a></li>
<li><a href="#411. Finder highlights: field evaluation and design of an augmented file browser.">411. Finder highlights: field evaluation and design of an augmented file browser.</a></li>
<li><a href="#412. PIM and personality: what do our personal file systems say about us?">412. PIM and personality: what do our personal file systems say about us?</a></li>
<li><a href="#413. Show me the invisible: visualizing hidden content.">413. Show me the invisible: visualizing hidden content.</a></li>
</ul>
</li>
<li><a href="#Lost and found in translation    5">Lost and found in translation    5</a><ul>
<li><a href="#414. "Maybe it was a joke": emotion detection in text-only communication by non-native english speakers.">414. "Maybe it was a joke": emotion detection in text-only communication by non-native english speakers.</a></li>
<li><a href="#415. TransPhoner: automated mnemonic keyword generation.">415. TransPhoner: automated mnemonic keyword generation.</a></li>
<li><a href="#416. AudioCanvas: internet-free interactive audio photos.">416. AudioCanvas: internet-free interactive audio photos.</a></li>
<li><a href="#417. The impact of visual contextualization on UI localization.">417. The impact of visual contextualization on UI localization.</a></li>
<li><a href="#418. Improving machine translation by showing two outputs.">418. Improving machine translation by showing two outputs.</a></li>
</ul>
</li>
<li><a href="#Participatory design    4">Participatory design    4</a><ul>
<li><a href="#419. Diversity for design: a framework for involving neurodiverse children in the technology design process.">419. Diversity for design: a framework for involving neurodiverse children in the technology design process.</a></li>
<li><a href="#420. Canine-centered interface design: supporting the work of diabetes alert dogs.">420. Canine-centered interface design: supporting the work of diabetes alert dogs.</a></li>
<li><a href="#421. Co-constructing child personas for health-promoting services with vulnerable children.">421. Co-constructing child personas for health-promoting services with vulnerable children.</a></li>
<li><a href="#422. Balancing design tensions: iterative display design to support ad hoc and multidisciplinary medical teamwork.">422. Balancing design tensions: iterative display design to support ad hoc and multidisciplinary medical teamwork.</a></li>
</ul>
</li>
<li><a href="#Brain computer interfaces    4">Brain computer interfaces    4</a><ul>
<li><a href="#423. Error related negativity in observing interactive tasks.">423. Error related negativity in observing interactive tasks.</a></li>
<li><a href="#424. Dynamic difficulty using brain metrics of workload.">424. Dynamic difficulty using brain metrics of workload.</a></li>
<li><a href="#425. Measuring the effect of think aloud protocols on workload using fNIRS.">425. Measuring the effect of think aloud protocols on workload using fNIRS.</a></li>
<li><a href="#426. An EEG-based approach for evaluating audio notifications under ambient sounds.">426. An EEG-based approach for evaluating audio notifications under ambient sounds.</a></li>
</ul>
</li>
<li><a href="#3D printing and fabrication    4">3D printing and fabrication    4</a><ul>
<li><a href="#427. faBrickation: fast 3D printing of functional objects by integrating construction kit building blocks.">427. faBrickation: fast 3D printing of functional objects by integrating construction kit building blocks.</a></li>
<li><a href="#428. Understanding physical activity through 3D printed material artifacts.">428. Understanding physical activity through 3D printed material artifacts.</a></li>
<li><a href="#429. Supporting the design and fabrication of physical visualizations.">429. Supporting the design and fabrication of physical visualizations.</a></li>
<li><a href="#430. MixFab: a mixed-reality environment for personal fabrication.">430. MixFab: a mixed-reality environment for personal fabrication.</a></li>
</ul>
</li>
<li><a href="#Modeling users and interaction    5">Modeling users and interaction    5</a><ul>
<li><a href="#431. Model of visual search and selection time in linear menus.">431. Model of visual search and selection time in linear menus.</a></li>
<li><a href="#432. Towards accurate and practical predictive models of active-vision-based visual search.">432. Towards accurate and practical predictive models of active-vision-based visual search.</a></li>
<li><a href="#433. Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling.">433. Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling.</a></li>
<li><a href="#434. How does knowing what you are looking for change visual search behavior?">434. How does knowing what you are looking for change visual search behavior?</a></li>
<li><a href="#435. Automated nonlinear regression modeling for HCI.">435. Automated nonlinear regression modeling for HCI.</a></li>
</ul>
</li>
<li><a href="#Engaging older adults through technology    4">Engaging older adults through technology    4</a><ul>
<li><a href="#436. Understanding digital and material social communications for older adults.">436. Understanding digital and material social communications for older adults.</a></li>
<li><a href="#437. Never too old: engaging retired people inventing the future with MaKey MaKey.">437. Never too old: engaging retired people inventing the future with MaKey MaKey.</a></li>
<li><a href="#438. What's on your mind?: investigating recommendations for inclusive social networking and older adults.">438. What's on your mind?: investigating recommendations for inclusive social networking and older adults.</a></li>
<li><a href="#439. Being senior and ICT: a study of seniors using ICT in China.">439. Being senior and ICT: a study of seniors using ICT in China.</a></li>
</ul>
</li>
<li><a href="#Computer mediated intimacy and romance    4">Computer mediated intimacy and romance    4</a><ul>
<li><a href="#440. The lonely raccoon at the ball: designing for intimacy, sociability, and selfhood.">440. The lonely raccoon at the ball: designing for intimacy, sociability, and selfhood.</a></li>
<li><a href="#441. Room for interpretation: the role of self-esteem and CMC in romantic couple conflict.">441. Room for interpretation: the role of self-esteem and CMC in romantic couple conflict.</a></li>
<li><a href="#442. Exploring affective communication through variable-friction surface haptics.">442. Exploring affective communication through variable-friction surface haptics.</a></li>
<li><a href="#443. Wrigglo: shape-changing peripheral for interpersonal mobile communication.">443. Wrigglo: shape-changing peripheral for interpersonal mobile communication.</a></li>
</ul>
</li>
<li><a href="#Network of care    3">Network of care    3</a><ul>
<li><a href="#444. Recreating living experiences from past memories through virtual worlds for people with dementia.">444. Recreating living experiences from past memories through virtual worlds for people with dementia.</a></li>
<li><a href="#445. Addressing the subtleties in dementia care: pre-study & evaluation of a GPS monitoring system.">445. Addressing the subtleties in dementia care: pre-study &amp; evaluation of a GPS monitoring system.</a></li>
<li><a href="#446. Sweet Home: understanding diabetes management via a chinese online community.">446. Sweet Home: understanding diabetes management via a chinese online community.</a></li>
</ul>
</li>
<li><a href="#Tutorials    4">Tutorials    4</a><ul>
<li><a href="#447. Investigating the feasibility of extracting tool demonstrations from in-situ video content.">447. Investigating the feasibility of extracting tool demonstrations from in-situ video content.</a></li>
<li><a href="#448. Crowdsourcing step-by-step information extraction to enhance existing how-to videos.">448. Crowdsourcing step-by-step information extraction to enhance existing how-to videos.</a></li>
<li><a href="#449. EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration.">449. EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration.</a></li>
<li><a href="#450. TaggedComments: promoting and integrating user comments in online application tutorials.">450. TaggedComments: promoting and integrating user comments in online application tutorials.</a></li>
</ul>
</li>
<li><a href="#Driving interfaces and evaluations    3">Driving interfaces and evaluations    3</a><ul>
<li><a href="#451. A smartphone-based sensing platform to model aggressive driving behaviors.">451. A smartphone-based sensing platform to model aggressive driving behaviors.</a></li>
<li><a href="#452. Classifying driver workload using physiological and driving performance data: two field studies.">452. Classifying driver workload using physiological and driving performance data: two field studies.</a></li>
<li><a href="#453. Evaluating multimodal driver displays under varying situational urgency.">453. Evaluating multimodal driver displays under varying situational urgency.</a></li>
</ul>
</li>
<li><a href="#Gesture-based interaction    4">Gesture-based interaction    4</a><ul>
<li><a href="#454. Multi-viewer gesture-based interaction for omni-directional video.">454. Multi-viewer gesture-based interaction for omni-directional video.</a></li>
<li><a href="#455. Making big gestures: effects of gesture size on observability and identification for co-located group awareness.">455. Making big gestures: effects of gesture size on observability and identification for co-located group awareness.</a></li>
<li><a href="#456. A chair as ubiquitous input device: exploring semaphoric chair gestures for focused and peripheral interaction.">456. A chair as ubiquitous input device: exploring semaphoric chair gestures for focused and peripheral interaction.</a></li>
<li><a href="#457. Exploring the design space of gestural interaction with active tokens through user-defined gestures.">457. Exploring the design space of gestural interaction with active tokens through user-defined gestures.</a></li>
</ul>
</li>
<li><a href="#Interactive surfaces and pervasive displays    4">Interactive surfaces and pervasive displays    4</a><ul>
<li><a href="#458. Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D">458. Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D).</a>.)</li>
<li><a href="#459. Bigger is not always better: display size, performance, and task load during peephole map navigation.">459. Bigger is not always better: display size, performance, and task load during peephole map navigation.</a></li>
<li><a href="#460. Mechanical force redistribution: enabling seamless, large-format, high-accuracy surface interaction.">460. Mechanical force redistribution: enabling seamless, large-format, high-accuracy surface interaction.</a></li>
<li><a href="#461. Effects of display size and navigation type on a classification task.">461. Effects of display size and navigation type on a classification task.</a></li>
</ul>
</li>
<li><a href="#Social Media for Relationships    4">Social Media for Relationships    4</a><ul>
<li><a href="#462. Stewarding a legacy: responsibilities and relationships in the management of post-mortem data.">462. Stewarding a legacy: responsibilities and relationships in the management of post-mortem data.</a></li>
<li><a href="#463. Captioned photographs in psychosocial aged care: relationship building and boundary work.">463. Captioned photographs in psychosocial aged care: relationship building and boundary work.</a></li>
<li><a href="#464. The routines and needs of grandparents and parents for grandparent-grandchild conversations over distance.">464. The routines and needs of grandparents and parents for grandparent-grandchild conversations over distance.</a></li>
<li><a href="#465. Growing closer on facebook: changes in tie strength through social network site use.">465. Growing closer on facebook: changes in tie strength through social network site use.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav><h1 id="CHI 2014:Toronto, ON, Canada">CHI 2014:Toronto, ON, Canada</h1>
<p><a href="http://dl.acm.org/citation.cfm?id=2556288">CHI Conference on Human Factors in Computing Systems, CHI'14, Toronto, ON, Canada - April 26 - May 01, 2014.</a> ACM
<a href="http://dblp.uni-trier.de/db/conf/chi/chi2014.html">DBLP Link</a></p>
<h2 id="Paper Num: 465 || Session Num: 114">Paper Num: 465 || Session Num: 114</h2>
<ul>
<li><a href="#3D interaction: modeling and prototyping    5">3D interaction: modeling and prototyping    5</a></li>
<li><a href="#3D printing and fabrication    4">3D printing and fabrication    4</a></li>
<li><a href="#Accessibility    4">Accessibility    4</a></li>
<li><a href="#Activity recognition    3">Activity recognition    3</a></li>
<li><a href="#Always connected: email and social media    4">Always connected: email and social media    4</a></li>
<li><a href="#Applications of body sensing    4">Applications of body sensing    4</a></li>
<li><a href="#Audio interaction    4">Audio interaction    4</a></li>
<li><a href="#Authentication and passwords    5">Authentication and passwords    5</a></li>
<li><a href="#Battery life and energy harvesting    4">Battery life and energy harvesting    4</a></li>
<li><a href="#Brain computer interfaces    4">Brain computer interfaces    4</a></li>
<li><a href="#CHI for social development    4">CHI for social development    4</a></li>
<li><a href="#Computer mediated intimacy and romance    4">Computer mediated intimacy and romance    4</a></li>
<li><a href="#Coordination and collaboration    4">Coordination and collaboration    4</a></li>
<li><a href="#Critical design    4">Critical design    4</a></li>
<li><a href="#Cross-device interaction    4">Cross-device interaction    4</a></li>
<li><a href="#Crowdfunding and crowd storage    3">Crowdfunding and crowd storage    3</a></li>
<li><a href="#Crowds and creativity    4">Crowds and creativity    4</a></li>
<li><a href="#Crowdsourcing    4">Crowdsourcing    4</a></li>
<li><a href="#DIY and hacking    4">DIY and hacking    4</a></li>
<li><a href="#Decisions, recommendations, and machine learning    5">Decisions, recommendations, and machine learning    5</a></li>
<li><a href="#Design theory    4">Design theory    4</a></li>
<li><a href="#Designing and modeling GUIs    5">Designing and modeling GUIs    5</a></li>
<li><a href="#Designing and understanding visualizations    4">Designing and understanding visualizations    4</a></li>
<li><a href="#Designing for older adults and demographic change    4">Designing for older adults and demographic change    4</a></li>
<li><a href="#Desktop search and history    4">Desktop search and history    4</a></li>
<li><a href="#Driving interfaces and evaluations    3">Driving interfaces and evaluations    3</a></li>
<li><a href="#Emergency response    4">Emergency response    4</a></li>
<li><a href="#Emotions and mobiles    3">Emotions and mobiles    3</a></li>
<li><a href="#Enabling interactive performances    5">Enabling interactive performances    5</a></li>
<li><a href="#Engage and educate children    5">Engage and educate children    5</a></li>
<li><a href="#Engaging older adults through technology    4">Engaging older adults through technology    4</a></li>
<li><a href="#Exergame design    4">Exergame design    4</a></li>
<li><a href="#Exergaming for health and fitness    4">Exergaming for health and fitness    4</a></li>
<li><a href="#Exploring exergames    4">Exploring exergames    4</a></li>
<li><a href="#Force input and haptic feedback    5">Force input and haptic feedback    5</a></li>
<li><a href="#Games and education    4">Games and education    4</a></li>
<li><a href="#Gesture-based interaction    4">Gesture-based interaction    4</a></li>
<li><a href="#HCI paradigms: past, present and future    4">HCI paradigms: past, present and future    4</a></li>
<li><a href="#Hackerspaces, making and breaking    5">Hackerspaces, making and breaking    5</a></li>
<li><a href="#Head-worn displays    4">Head-worn displays    4</a></li>
<li><a href="#Health and everyday life    5">Health and everyday life    5</a></li>
<li><a href="#Human-robot interaction    5">Human-robot interaction    5</a></li>
<li><a href="#Image and animation authoring    4">Image and animation authoring    4</a></li>
<li><a href="#Interacting with the web    3">Interacting with the web    3</a></li>
<li><a href="#Interactive surfaces and pervasive displays    4">Interactive surfaces and pervasive displays    4</a></li>
<li><a href="#Interactive technologies for rehabilitation    5">Interactive technologies for rehabilitation    5</a></li>
<li><a href="#Interactive visualization and visual elements    4">Interactive visualization and visual elements    4</a></li>
<li><a href="#Interactive whiteboards and public displays    3">Interactive whiteboards and public displays    3</a></li>
<li><a href="#Interfaces for care and support    4">Interfaces for care and support    4</a></li>
<li><a href="#Interruptions and distractions    4">Interruptions and distractions    4</a></li>
<li><a href="#Issues that matter    3">Issues that matter    3</a></li>
<li><a href="#Journalism and social news    4">Journalism and social news    4</a></li>
<li><a href="#Learning and education    4">Learning and education    4</a></li>
<li><a href="#Learning and games    4">Learning and games    4</a></li>
<li><a href="#Location-based services and navigation    5">Location-based services and navigation    5</a></li>
<li><a href="#Lost and found in translation    5">Lost and found in translation    5</a></li>
<li><a href="#Managing income    4">Managing income    4</a></li>
<li><a href="#Mid-air gestures    4">Mid-air gestures    4</a></li>
<li><a href="#Modeling users and interaction    5">Modeling users and interaction    5</a></li>
<li><a href="#Multilingual communication    4">Multilingual communication    4</a></li>
<li><a href="#Multitouch interaction    4">Multitouch interaction    4</a></li>
<li><a href="#Music, dance, and television    4">Music, dance, and television    4</a></li>
<li><a href="#Narratives and storytelling    4">Narratives and storytelling    4</a></li>
<li><a href="#Navigating video    5">Navigating video    5</a></li>
<li><a href="#Network of care    3">Network of care    3</a></li>
<li><a href="#Novel approaches to navigation    5">Novel approaches to navigation    5</a></li>
<li><a href="#Novel keyboards    5">Novel keyboards    5</a></li>
<li><a href="#Novel mobile displays and devices    4">Novel mobile displays and devices    4</a></li>
<li><a href="#On and above the surface    5">On and above the surface    5</a></li>
<li><a href="#Participatory design    4">Participatory design    4</a></li>
<li><a href="#Personal health and wellbeing    4">Personal health and wellbeing    4</a></li>
<li><a href="#Personal values and preferences    6">Personal values and preferences    6</a></li>
<li><a href="#Persuasive technologies and applications    4">Persuasive technologies and applications    4</a></li>
<li><a href="#Pointing and cursors    4">Pointing and cursors    4</a></li>
<li><a href="#Policies and practice: doing the right thing    3">Policies and practice: doing the right thing    3</a></li>
<li><a href="#PolitiCHI    4">PolitiCHI    4</a></li>
<li><a href="#Presentation technologies    4">Presentation technologies    4</a></li>
<li><a href="#Privacy    4">Privacy    4</a></li>
<li><a href="#Programming and development tools    4">Programming and development tools    4</a></li>
<li><a href="#Quantified self    3">Quantified self    3</a></li>
<li><a href="#Question and answer systems    5">Question and answer systems    5</a></li>
<li><a href="#Research through design    4">Research through design    4</a></li>
<li><a href="#Risks and security    5">Risks and security    5</a></li>
<li><a href="#Sensemaking and information in use    5">Sensemaking and information in use    5</a></li>
<li><a href="#Sensory experiences: smell and taste    4">Sensory experiences: smell and taste    4</a></li>
<li><a href="#Shape-changing interfaces    5">Shape-changing interfaces    5</a></li>
<li><a href="#Smart homes and sustainability    3">Smart homes and sustainability    3</a></li>
<li><a href="#Social Media for Relationships    4">Social Media for Relationships    4</a></li>
<li><a href="#Social local mobile    5">Social local mobile    5</a></li>
<li><a href="#Social media and health    4">Social media and health    4</a></li>
<li><a href="#Social media usage    4">Social media usage    4</a></li>
<li><a href="#Stress    4">Stress    4</a></li>
<li><a href="#Studying and designing gameplay    4">Studying and designing gameplay    4</a></li>
<li><a href="#Studying online communities    4">Studying online communities    4</a></li>
<li><a href="#Studying visualization    2">Studying visualization    2</a></li>
<li><a href="#Sustainability and everyday practices    1">Sustainability and everyday practices    1</a></li>
<li><a href="#Sustainability perspectives    2">Sustainability perspectives    2</a></li>
<li><a href="#Tangible interactions and technologies    4">Tangible interactions and technologies    4</a></li>
<li><a href="#Telepresence and connecting over video    5">Telepresence and connecting over video    5</a></li>
<li><a href="#Text entry and evaluation    2">Text entry and evaluation    2</a></li>
<li><a href="#The eyes have it    4">The eyes have it    4</a></li>
<li><a href="#The third dimension    4">The third dimension    4</a></li>
<li><a href="#Touch and stylus interaction    4">Touch and stylus interaction    4</a></li>
<li><a href="#Touch input    4">Touch input    4</a></li>
<li><a href="#Tutorials    4">Tutorials    4</a></li>
<li><a href="#Understanding and designing games    5">Understanding and designing games    5</a></li>
<li><a href="#Understanding and modeling touch    6">Understanding and modeling touch    6</a></li>
<li><a href="#Understanding and using social media    4">Understanding and using social media    4</a></li>
<li><a href="#Urban communities and social media    4">Urban communities and social media    4</a></li>
<li><a href="#User models and prediction    4">User models and prediction    4</a></li>
<li><a href="#Visualization and aesthetics    4">Visualization and aesthetics    4</a></li>
<li><a href="#Watches and small devices    5">Watches and small devices    5</a></li>
<li><a href="#Whole body sensing and interaction    4">Whole body sensing and interaction    4</a></li>
<li><a href="#Working together    3">Working together    3</a></li>
</ul>
<h2 id="Visualization and aesthetics    4">Visualization and aesthetics    4</h2>
<h3 id="1. Metaphone: machine aesthetics meets interaction design.">1. Metaphone: machine aesthetics meets interaction design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557152">Paper Link</a>    Pages:1-10</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Simbelis:Vygandas">Vygandas Simbelis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lundstr=ouml=m:Anders">Anders Lundstrm</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=ouml==ouml=k:Kristina">Kristina Hk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Solsona:Jordi">Jordi Solsona</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lewandowski:Vincent">Vincent Lewandowski</a></p>
<p>Abstract:
Through our art project, Metaphone, we explored a particular form of aesthetics referred to in the arts tradition as machine aesthetics. The Metaphone machine collects the participant's bio-data, Galvanic Skin Response (GSR) and Heart Rate (HR), creating a process of movement, painting and sound. The machine behaves in machine-like, aesthetically evocative ways: a shaft on two large wheels rotates on the floor, carrying paint that is dripped onto a large sheet of aquarelle paper on the floor according to bio-sensor data. A soundscape rhythmically follows the bio-sensor data, but also has its own machine-like sounds. Six commentators were invited to interact with the machine. They reported a strangely relaxing atmosphere induced by the machine. Based on these experiences we discuss how different art styles can help to describe aesthetics in interaction design generally, and how machine aesthetics in particular can be used to create interesting, sustained, stylistically coherent interactions.</p>
<p>Keywords:
affective computing; bodily interaction; interaction design; interactive arts; machine aesthetics; media arts</p>
<h3 id="2. Quantifying visual preferences around the world.">2. Quantifying visual preferences around the world.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557052">Paper Link</a>    Pages:11-20</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Reinecke:Katharina">Katharina Reinecke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gajos:Krzysztof_Z=">Krzysztof Z. Gajos</a></p>
<p>Abstract:
Website aesthetics have been recognized as an influential moderator of people's behavior and perception. However, what users perceive as "good design" is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups.</p>
<p>Keywords:
adaptation; colorfulness; complexity; modeling; personalization; website aesthetics</p>
<h3 id="3. The influence of aesthetics in usability testing: the case of dual-domain products.">3. The influence of aesthetics in usability testing: the case of dual-domain products.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557419">Paper Link</a>    Pages:21-30</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sonderegger:Andreas">Andreas Sonderegger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/u/Uebelbacher:Andreas">Andreas Uebelbacher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pugliese:Manuela">Manuela Pugliese</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sauer:J=uuml=rgen_S=">Jrgen S. Sauer</a></p>
<p>Abstract:
An experimental study examined whether the effects of aesthetic appeal on usability test outcomes are moderated by usage domain. The aesthetic appeal of a cell phone was experimentally manipulated in both home- and work-based usage domains. The two usage domains were modeled in a usability laboratory. 60 participants completed a series of typical cell phone user tasks. Dependent measures such as performance, perceived usability, and emotion were taken. The results showed that aesthetic appeal had a positive effect on perceived usability but a negative effect on performance. The effects of aesthetic appeal on usability test outcomes were not moderated by usage domain. The results of this study imply that it may be sufficient to test dual-domain products in only one of their usage domains.</p>
<p>Keywords:
perceived usability; product aesthetics; usability test; usage domain; user performance</p>
<h3 id="4. Extracting references between text and charts via crowdsourcing.">4. Extracting references between text and charts via crowdsourcing.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557241">Paper Link</a>    Pages:31-40</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kong:Nicholas">Nicholas Kong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hearst:Marti_A=">Marti A. Hearst</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agrawala:Maneesh">Maneesh Agrawala</a></p>
<p>Abstract:
News articles, reports, blog posts and academic papers often include graphical charts that serve to visually reinforce arguments presented in the text. To help readers better understand the relation between the text and the chart, we present a crowdsourcing pipeline to extract the references between them. Specifically, we give crowd workers paragraph-chart pairs and ask them to select text phrases as well as the corresponding visual marks in the chart. We then apply automated clustering and merging techniques to unify the references generated by multiple workers into a single set. Comparing the crowdsourced references to a set of gold standard references using a distance measure based on the F1 score, we find that the average distance between the raw set of references produced by a single worker and the gold standard is 0.54 (out of a max of 1.0). When we apply clustering and merging techniques the average distance between the unified set of references and the gold standard reduces to 0.39; an improvement of 27%. We conclude with an interactive document viewing application that uses the extracted references; readers can select phrases in the text and the system highlights the related marks in the chart.</p>
<p>Keywords:
crowdsourcing; interactive documents; visualization</p>
<h2 id="Stress    4">Stress    4</h2>
<h3 id="5. Stress and multitasking in everyday college life: an empirical study of online activity.">5. Stress and multitasking in everyday college life: an empirical study of online activity.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557361">Paper Link</a>    Pages:41-50</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mark:Gloria">Gloria Mark</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Yiran">Yiran Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Niiya:Melissa">Melissa Niiya</a></p>
<p>Abstract:
While HCI has focused on multitasking with information workers, we report on multitasking among Millennials who grew up with digital media - focusing on college students. We logged computer activity and used biosensors to measure stress of 48 students for 7 days for all waking hours, in their in situ environments. We found a significant positive relationship with stress and daily time spent on computers. Stress is positively associated with the amount of multitasking. Conversely, stress is negatively associated with Facebook and social media use. Heavy multitaskers use significantly more social media and report lower positive affect than light multitaskers. Night habits affect multitasking the following day: late-nighters show longer duration of computer use and those ending their activities earlier in the day multitask less. Our study shows that college students multitask at double the frequency compared to studies of information workers. These results can inform designs for stress management of college students.</p>
<p>Keywords:
biosensors; computer logging; in situ study; millennial generation; multitasking; social media; stress</p>
<h3 id="6. Under pressure: sensing stress of computer users.">6. Under pressure: sensing stress of computer users.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557165">Paper Link</a>    Pages:51-60</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hernandez:Javier">Javier Hernandez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paredes:Pablo">Pablo Paredes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roseway:Asta">Asta Roseway</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Czerwinski:Mary">Mary Czerwinski</a></p>
<p>Abstract:
Recognizing when computer users are stressed can help reduce their frustration and prevent a large variety of negative health conditions associated with chronic stress. However, measuring stress non-invasively and continuously at work remains an open challenge. This work explores the possibility of using a pressure-sensitive keyboard and a capacitive mouse to discriminate between stressful and relaxed conditions in a laboratory study. During a 30 minute session, 24 participants performed several computerized tasks consisting of expressive writing, text transcription, and mouse clicking. During the stressful conditions, the large majority of the participants showed significantly increased typing pressure (&gt;79% of the participants) and more contact with the surface of the mouse (75% of the participants). We discuss the potential implications of this work and provide recommendations for future work.</p>
<p>Keywords:
affective computing; capacitive mouse; pressure-sensitive keyboard; stress measurement</p>
<h3 id="7. MouStress: detecting stress from mouse motion.">7. MouStress: detecting stress from mouse motion.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557243">Paper Link</a>    Pages:61-70</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sun:David">David Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paredes:Pablo">Pablo Paredes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Canny:John">John Canny</a></p>
<p>Abstract:
Stress causes and exacerbates many physiological and mental health problems. Routine and unobtrusive monitoring of stress would enable a variety of treatments, from break-taking to calming exercises. It may also be a valuable tool for assessing effects (frustration, difficulty) of using interfaces or applications. Custom sensing hardware is a poor option, because of the need to buy/wear/use it continuously, even before stress-related problems are evident. Here we explore stress measurement from common computer mouse operations. We use a simple model of arm-hand dynamics that captures muscle stiffness during mouse movement. We show that the within-subject mouse-derived stress measure is quite strong, even compared to concurrent physiological sensor measurements. While our study used fixed mouse tasks, the stress signal was still strong even when averaged across widely varying task geometries. We argue that mouse sensing "in the wild" may be feasible, by analyzing frequently-performed operations of particular geometries.</p>
<p>Keywords:
affective interfaces; mouse interaction; stress modeling</p>
<h3 id="8. Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration.">8. Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557038">Paper Link</a>    Pages:71-80</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tan:Chiew_Seng_Sean">Chiew Seng Sean Tan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sch=ouml=ning:Johannes">Johannes Schning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Luyten:Kris">Kris Luyten</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Coninx:Karin">Karin Coninx</a></p>
<p>Abstract:
During remote video-mediated assistance, instructors often guide workers through problems and instruct them to perform unfamiliar or complex operations. However, the workers' performance might deteriorate due to stress. We argue that informing biofeedback to the instructor, can improve communication and lead to lower stress. This paper presents a thorough investigation on mental workload and stress perceived by twenty participants, paired up in an instructor-worker scenario, performing remote video-mediated tasks. The interface conditions differ in task, facial and biofeedback communication. Two self-report measures are used to assess mental workload and stress. Results show that pairs reported lower mental workload and stress when instructors are using the biofeedback as compared to using interfaces with facial view. Significant correlations were found on task performance with reducing stress (i.e. increased task engagement and decreased worry) for instructors and declining mental workload (i.e. increased performance) for workers. Our findings provide insights to advance video-mediated interfaces for remote collaborative work.</p>
<p>Keywords:
biofeedback; cscw; stress; video-mediated collaboration</p>
<h2 id="Social local mobile    5">Social local mobile    5</h2>
<h3 id="9. Let's do it at my place instead?: attitudinal and behavioral study of privacy in client-side personalization.">9. Let's do it at my place instead?: attitudinal and behavioral study of privacy in client-side personalization.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557102">Paper Link</a>    Pages:81-90</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kobsa:Alfred">Alfred Kobsa</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Knijnenburg:Bart_P=">Bart P. Knijnenburg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Livshits:Benjamin">Benjamin Livshits</a></p>
<p>Abstract:
Many users welcome personalized services, but are reluctant to provide the information about themselves that personalization requires. Performing personalization exclusively at the client side (e.g., on one's smartphone) may conceptually increase privacy, because no data is sent to a remote provider. But does client-side personalization (CSP) also increase users' perception of privacy? We developed a causal model of privacy attitudes and behavior in personalization, and validated it in an experiment that contrasted CSP with personalization at three remote providers: Amazon, a fictitious company, and the "Cloud". Participants gave roughly the same amount of personal data and tracking permissions in all four conditions. A structural equation modeling analysis reveals the reasons: CSP raises the fewest privacy concerns, but does not lead in terms of perceived protection nor in resulting self-anticipated satisfaction and thus privacy-related behavior. Encouragingly, we found that adding certain security features to CSP is likely to raise its perceived protection significantly. Our model predicts that CSP will then also sharply improve on all other privacy measures.</p>
<p>Keywords:
attitudes; behaviors; client-side; personalization; privacy; structural equation modeling (sem)</p>
<h3 id="10. The effect of developer-specified explanations for permission requests on smartphone user behavior.">10. The effect of developer-specified explanations for permission requests on smartphone user behavior.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557400">Paper Link</a>    Pages:91-100</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tan_0002:Joshua">Joshua Tan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nguyen:Khanh">Khanh Nguyen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Theodorides:Michael">Michael Theodorides</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Negr=oacute=n=Arroyo:Heidi">Heidi Negrn-Arroyo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thompson:Christopher">Christopher Thompson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Egelman:Serge">Serge Egelman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wagner:David">David Wagner</a></p>
<p>Abstract:
In Apple's iOS 6, when an app requires access to a protected resource (e.g., location or photos), the user is prompted with a permission request that she can allow or deny. These permission request dialogs include space for developers to optionally include strings of text to explain to the user why access to the resource is needed. We examine how app developers are using this mechanism and the effect that it has on user behavior. Through an online survey of 772 smartphone users, we show that permission requests that include explanations are significantly more likely to be approved. At the same time, our analysis of 4,400 iOS apps shows that the adoption rate of this feature by developers is relatively small: around 19% of permission requests include developer-specified explanations. Finally, we surveyed 30 iOS developers to better understand why they do or do not use this feature.</p>
<p>Keywords:
access control; privacy; smartphones; usability</p>
<h3 id="11. Reflection or action?: how feedback and control affect location sharing decisions.">11. Reflection or action?: how feedback and control affect location sharing decisions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557121">Paper Link</a>    Pages:101-110</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Patil:Sameer">Sameer Patil</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schlegel:Roman">Roman Schlegel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kapadia:Apu">Apu Kapadia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Adam_J=">Adam J. Lee</a></p>
<p>Abstract:
Owing to the ever-expanding size of social and professional networks, it is becoming cumbersome for individuals to configure information disclosure settings. We used location sharing systems to unpack the nature of discrepancies between a person's disclosure settings and contextual choices. We conducted an experience sampling study (N = 35) to examine various factors contributing to such divergence. We found that immediate feedback about disclosures without any ability to control the disclosures evoked feelings of oversharing. Moreover, deviation from specified settings did not always signal privacy violation; it was just as likely that settings prevented information disclosure considered permissible in situ. We suggest making feedback more actionable or delaying it sufficiently to avoid a knee-jerk reaction. Our findings also make the case for proactive techniques for detecting potential mismatches and recommending adjustments to disclosure settings, as well as selective control when sharing location with socially distant recipients and visiting atypical locations.</p>
<p>Keywords:</p>
<h3 id="12. Effects of security warnings and instant gratification cues on attitudes toward mobile websites.">12. Effects of security warnings and instant gratification cues on attitudes toward mobile websites.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557347">Paper Link</a>    Pages:111-114</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Bo">Bo Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wu:Mu">Mu Wu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kang:Hyunjin">Hyunjin Kang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Go:Eun">Eun Go</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sundar:S=_Shyam">S. Shyam Sundar</a></p>
<p>Abstract:
In order to address the increased privacy and security concerns raised by mobile communications, designers of mobile applications and websites have come up with a variety of warnings and appeals. While some interstitials warn about potential risk to personal information due to an untrusted security certificate, others attempt to take users' minds away from privacy concerns by making tempting, time-sensitive offers. How effective are they? We conducted an online experiment (N = 220) to find out. Our data show that both these strategies raise red flags for users - appeals to instant gratification make users more leery of the site and warnings make them perceive greater threat to personal data. Yet, users tend to reveal more information about their social media accounts when warned about an insecure site. This is probably because users process these interstitials based on cognitive heuristics triggered by them. These findings hold important implications for the design of cues in mobile interfaces.</p>
<p>Keywords:
information disclosure; mobile interface; online privacy; security; trust</p>
<h3 id="13. Social media participation and performance at work: a longitudinal study.">13. Social media participation and performance at work: a longitudinal study.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557417">Paper Link</a>    Pages:115-118</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shami:N=_Sadat">N. Sadat Shami</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nichols:Jeffrey">Jeffrey Nichols</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Jilin">Jilin Chen</a></p>
<p>Abstract:
The use of social media at work is gaining traction, and there is evidence to suggest that various benefits accrue from its use. Yet the relationship between using social media at work and employee performance is not clear. Through a study of 75,747 employees of a large global company over the course of 3 years, we find that some social media usage (number of forum posts, forum post length, and status update length) was positively associated with performance ratings. This study is one of the first to show the relationship among different forms of social media use and employee performance ratings.</p>
<p>Keywords:
performance; social media; social software; work</p>
<h2 id="Coordination and collaboration    4">Coordination and collaboration    4</h2>
<h3 id="14. The doing of doing stuff: understanding the coordination of social group-activities.">14. The doing of doing stuff: understanding the coordination of social group-activities.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557388">Paper Link</a>    Pages:119-128</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schuler:Richard_P=">Richard P. Schuler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grandhi:Sukeshini_A=">Sukeshini A. Grandhi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mayer:Julia_M=">Julia M. Mayer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ricken:Stephen_T=">Stephen T. Ricken</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Quentin">Quentin Jones</a></p>
<p>Abstract:
This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.</p>
<p>Keywords:
common ground; communication; conversation; coordination theory; diary study; language action theory; mobile coordination; qualitative research; social group-activity</p>
<h3 id="15. Effects of implicit sharing in collaborative analysis.">15. Effects of implicit sharing in collaborative analysis.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557229">Paper Link</a>    Pages:129-138</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Goyal:Nitesh">Nitesh Goyal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Leshed:Gilly">Gilly Leshed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cosley:Dan">Dan Cosley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fussell:Susan_R=">Susan R. Fussell</a></p>
<p>Abstract:
When crime analysts collaborate to solve crime cases, they need to share insights in order to connect the clues, identify a pattern, and attribute the crime to the right culprit. We designed a collaborative analysis tool to explore the value of implicitly sharing insights and notes, without requiring analysts to explicitly push information or request it from each other. In an experiment, pairs of remote individuals played the role of crime analysts solving a set of serial killer crimes with both partners having some, but not all, relevant clues. When implicit sharing of notes was available, participants remembered more clues related to detecting the serial killer, and they perceived the tool as more useful compared to when implicit sharing was not available.</p>
<p>Keywords:
collaborative analysis; implicit sharing; sensemaking</p>
<h3 id="16. Effects of simultaneous and sequential work structures on distributed collaborative interdependent tasks.">16. Effects of simultaneous and sequential work structures on distributed collaborative interdependent tasks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557158">Paper Link</a>    Pages:139-148</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Andr=eacute=:Paul">Paul Andr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a></p>
<p>Abstract:
Distributed online groups have great potential for generating interdependent and complex products like encyclopedia articles or product design. However, coordinating multiple group members to work together effectively while minimizing process losses remains an open challenge. We conducted an experiment comparing the effectiveness of two coordination strategies (simultaneous vs. sequential work) on a complex creative task as the number of group members increased. Our results indicate that, contrary to prior work, a sequential work structure was more effective than a simultaneous work structure as the size of the group increased. A mediation analysis suggests that social processes such as territoriality partially accounts for these results. A follow up experiment giving workers specific roles mitigated the detrimental effects of the simultaneous work structure. These results have implications for small group theory and crowdsourcing research.</p>
<p>Keywords:
coordination; group size; interdependence; small groups</p>
<h3 id="17. Necessary, unpleasant, and disempowering: reputation management in the internet age.">17. Necessary, unpleasant, and disempowering: reputation management in the internet age.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557126">Paper Link</a>    Pages:149-158</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Woodruff:Allison">Allison Woodruff</a></p>
<p>Abstract:
In this paper, we report on a qualitative study of how users manage their reputation online. We focus particularly on people who are bothered by content online about themselves and how they manage reputation damage and repair. We describe how users view reputation management chores as necessary but unpleasant, and how they feel disempowered to repair their online reputation. Participants were unable to identify feasible repair mechanisms and ultimately failed to resolve their problems. Given the current state of dysfunction indicated by our findings, we advocate for increased HCI research attention to this area.</p>
<p>Keywords:
online reputation; privacy; reputation management</p>
<h2 id="Watches and small devices    5">Watches and small devices    5</h2>
<h3 id="18. Duet: exploring joint interactions on a smart phone and a smart watch.">18. Duet: exploring joint interactions on a smart phone and a smart watch.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556955">Paper Link</a>    Pages:159-168</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Xiang_=Anthony=">Xiang 'Anthony' Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel_J=">Daniel J. Wigdor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices. In this paper, we present Duet -- an interactive system that explores a design space of interactions between a smart phone and a smart watch. Based on the devices' spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another. This transforms the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques. A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on Duet provides insights, observations, and guidance for future work.</p>
<p>Keywords:
duet; joint interaction; smart phone; smart watch.</p>
<h3 id="19. Interaction on the edge: offset sensing for small devices.">19. Interaction on the edge: offset sensing for small devices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557138">Paper Link</a>    Pages:169-178</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Oakley:Ian">Ian Oakley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Doyoung">Doyoung Lee</a></p>
<p>Abstract:
The touch screen interaction paradigm, currently dominant in mobile devices, begins to fail when very small systems are considered. Specifically, "fat fingers", a term referring to the fact that users' extremities physically obstruct their view of screen content and feedback, become particularly problematic. This paper presents a novel solution for this issue based on sensing touches to the perpendicular edges of a device featuring a front-mounted screen. The use of such offset contact points ensures that both a user's fingers and the device screen remain clearly in view throughout a targeting operation. The configuration also supports a range of novel interaction scenarios based on the touch, grip and grasp patterns it affords. To explore the viability of this concept, this paper describes EdgeTouch, a small (6 cm) hardware prototype instantiating this multi-touch functionality. User studies characterizing targeting performance, typical user grasps and exploring input affordances are presented. The results show that targets of 7.5-22.5 degrees in angular size are acquired in 1.25-1.75 seconds and with accuracy rates of 3%-18%, promising results considering the small form factor of the device. Furthermore, grasps made with between two and five fingers are robustly identifiable. Finally, we characterize the types of input users envisage performing with EdgeTouch, and report occurrence rates for key interactions such as taps, holds, strokes and multi-touch and compound input. The paper concludes with a discussion of the interaction scenarios enabled by offset sensing.</p>
<p>Keywords:
edge-of-device input; mobile devices; pointing; touch</p>
<h3 id="20. More than touch: understanding how people use skin as an input surface for mobile computing.">20. More than touch: understanding how people use skin as an input surface for mobile computing.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557239">Paper Link</a>    Pages:179-188</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Weigel:Martin">Martin Weigel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mehta:Vikram">Vikram Mehta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steimle:J=uuml=rgen">Jrgen Steimle</a></p>
<p>Abstract:
This paper contributes results from an empirical study of on-skin input, an emerging technique for controlling mobile devices. Skin is fundamentally different from off-body touch surfaces, opening up a new and largely unexplored interaction space. We investigate characteristics of the various skin-specific input modalities, analyze what kinds of gestures are performed on skin, and study what are preferred input locations. Our main findings show that (1) users intuitively leverage the properties of skin for a wide range of more expressive commands than on conventional touch surfaces; (2) established multi-touch gestures can be transferred to on-skin input; (3) physically uncomfortable modalities are deliberately used for irreversible commands and expressing negative emotions; and (4) the forearm and the hand are the most preferred locations on the upper limb for on-skin input. We detail on users' mental models and contribute a first consolidated set of on-skin gestures. Our findings provide guidance for developers of future sensors as well as for designers of future applications of on-skin input.</p>
<p>Keywords:
deformable surface; elicitation study; mobile computing; on-skin input; skin gestures; touch input</p>
<h3 id="21. TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads.">21. TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557258">Paper Link</a>    Pages:189-192</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Da=Yuan">Da-Yuan Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tsai:Ming=Chang">Ming-Chang Tsai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tung:Ying=Chao">Ying-Chao Tung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tsai:Min=Lun">Min-Lun Tsai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yeh:Yen=Ting">Yen-Ting Yeh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chan:Li=Wei">Li-Wei Chan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hung:Yi=Ping">Yi-Ping Hung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Mike_Y=">Mike Y. Chen</a></p>
<p>Abstract:
We present TouchSense, which provides additional touchscreen input vocabulary by distinguishing the areas of users' finger pads contacting the touchscreen. It requires minimal touch input area and minimal movement, making it especially ideal for wearable devices such as smart watches and smart glasses. For example, users of a calculator application on a smart watch could tap normally to enter numbers, and tap with the right side of their fingers to enter the operators (e.g. , -, =). Results from two human-factor studies showed that users could tap a touchscreen with five or more distinct areas of their finger pads. Also, they were able to tap with more distinct areas closer to their fingertips. We developed a TouchSense smart watch prototype using inertial measurement sensors, and developed two example applications: a calculator and a text editor. We also collected user feedback via an explorative study.</p>
<p>Keywords:
augmented finger input; input modality; single-tap mode switching; small-screen devices; smart watch</p>
<h3 id="22. Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click.">22. Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557017">Paper Link</a>    Pages:193-196</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/x/Xiao:Robert">Robert Xiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Laput:Gierad">Gierad Laput</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Chris">Chris Harrison</a></p>
<p>Abstract:
Smartwatches promise to bring enhanced convenience to common communication, creation and information retrieval tasks. Due to their prominent placement on the wrist, they must be small and otherwise unobtrusive, which limits the sophistication of interactions we can perform. This problem is particularly acute if the smartwatch relies on a touchscreen for input, as the display is small and our fingers are relatively large. In this work, we propose a complementary input approach: using the watch face as a multi-degree-of-freedom, mechanical interface. We developed a proof of concept smartwatch that supports continuous 2D panning and twist, as well as binary tilt and click. To illustrate the potential of our approach, we developed a series of example applications, many of which are cumbersome -- or even impossible -- on today's smartwatch devices.</p>
<p>Keywords:
buttons; on-body interfaces; smart clothing; touchscreens; watch; wearable computing</p>
<h2 id="The third dimension    4">The third dimension    4</h2>
<h3 id="23. The use of surrounding visual context in handheld AR: device vs. user perspective rendering.">23. The use of surrounding visual context in handheld AR: device vs. user perspective rendering.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557125">Paper Link</a>    Pages:197-206</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pucihar:Klen_Copic">Klen Copic Pucihar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Coulton:Paul">Paul Coulton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alexander:Jason">Jason Alexander</a></p>
<p>Abstract:
The magic lens paradigm, a commonly used descriptor for handheld Augmented Reality (AR), presents the user with dual views: the augmented view (magic lens) that appears on the device, and the real view of the surroundings (what the user can see around the perimeter of the device). The augmented view is typically implemented by rendering the video captured by the rear-facing camera directly onto the device's screen. This results in dual perspectives - the real world being captured from the device's perspective rather than the user's perspective (what an observer would see looking through a transparent glass pane). These differences manifest themselves in misaligned and/or incorrectly scaled transparency resulting in the dual-view problem. This paper presents two user studies comparing (a) device-perspective and (b) fixed Point-of-View (POV) user-perspective magic lenses to analyze the effect of the dual-view problem on the use of the surrounding visual context. The results confirm that the dual-view problem, a result of dual perspective, has a significant effect on the use of information from the surrounding visual context. The study also highlights that magnification and not the dual-view problem is the key factor explaining the correlation between magic lens size and the increased intensity of the magic lens type effect. From the results, we derive design guidelines for future magic lenses.</p>
<p>Keywords:
ar; dual views; dual-view; magic lens; user-perspective</p>
<h3 id="24. Altering gameplay behavior using stereoscopic 3D vision-based video game design.">24. Altering gameplay behavior using stereoscopic 3D vision-based video game design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557283">Paper Link</a>    Pages:207-216</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schild:Jonas">Jonas Schild</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/LaViola_Jr=:Joseph_J=">Joseph J. LaViola Jr.</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Masuch:Maic">Maic Masuch</a></p>
<p>Abstract:
We explore the potential of stereoscopic 3D (S3D) vision in offering distinct gameplay using an S3D-specific game called Deepress3D. Our game utilizes established S3D design principles for optimizing GUI design, visual comfort and game mechanics which rely on depth perception in time-pressured spatial conflicts. The game collects detailed S3D player metrics and allows players to choose between different, evenly matched strategies. We conducted a between subjects study comparing S3D and monoscopic versions of Deepress3D that examined player behavior and performance and measured user-reported data on presence, simulator sickness, and game experience. Confirming previous results, stereo users reported higher spatial presence. More importantly, for the first time, our game metrics indicate that S3D vision can measurably change player behavior depending on actual game content and level design, without necessarily affecting performance or emotional experience. These findings indicate the potential for optimizing applications for stereo users distinguishing them as a distinct group in HCI research.</p>
<p>Keywords:
game design; gameplay metrics; player behavior; simulator sickness; spatial presence; stereoscopic 3d; user experience</p>
<h3 id="25. Depth perception with gaze-contingent depth of field.">25. Depth perception with gaze-contingent depth of field.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557089">Paper Link</a>    Pages:217-226</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mauderer:Michael">Michael Mauderer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Conte:Simone">Simone Conte</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nacenta:Miguel_A=">Miguel A. Nacenta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vishwanath:Dhanraj">Dhanraj Vishwanath</a></p>
<p>Abstract:
Blur in images can create the sensation of depth because it emulates an optical property of the eye; namely, the limited depth of field created by the eye's lens. When the human eye looks at an object, this object appears sharp on the retina, but objects at different distances appear blurred. Advances in gaze-tracking technologies enable us to reproduce dynamic depth of field in regular displays, providing an alternative way of conveying depth. In this paper we investigate gaze-contingent depth of field as a method to produce realistic 3D images, and analyze how effectively people can use it to perceive depth. We found that GC DOF increases subjective perceived realism and depth and can contribute to the perception of ordinal depth and distance between objects, but it is limited in its accuracy.</p>
<p>Keywords:
blur; depth cues; depth perception; depth-of-field; eye tracking; gaze-contingent display; three-dimensional graphics and realism</p>
<h3 id="26. Imperceptible depth shifts for touch interaction with stereoscopic objects.">26. Imperceptible depth shifts for touch interaction with stereoscopic objects.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557134">Paper Link</a>    Pages:227-236</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Valkov:Dimitar">Dimitar Valkov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Giesler:Alexander">Alexander Giesler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hinrichs:Klaus_H=">Klaus H. Hinrichs</a></p>
<p>Abstract:
While touch technology has proven its usability for 2D interaction and has already become a standard input modality for many devices, the challenges to exploit its applicability with stereoscopically rendered content have barely been studied. In this paper we exploit the properties of the visual perception to allow users to touch stereoscopically displayed objects when the input is constrained to a 2D surface. Therefore, we have extended and generalized recent evaluations on the user's ability to discriminate small induced object shifts while reaching out to touch a virtual object, and we propose a practical interaction technique, the attracting shift technique, suitable for numerous application scenarios where shallow depth interaction is sufficient. In addition, our results indicate that slight object shifts during touch interaction make the virtual scene appear perceptually more stable compared to a static scene. As a consequence, applications have to manipulate the virtual objects to make them appear static for the user.</p>
<p>Keywords:
experimentation; human factors</p>
<h2 id="Audio interaction    4">Audio interaction    4</h2>
<h3 id="27. SonicExplorer: fluid exploration of audio parameters.">27. SonicExplorer: fluid exploration of audio parameters.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557206">Paper Link</a>    Pages:237-246</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Adams:Alexander_Travis">Alexander Travis Adams</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gonzalez:Berto">Berto Gonzalez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Latulipe:Celine">Celine Latulipe</a></p>
<p>Abstract:
In digital music production, the phrase "in the box" refers to the increasing replacement of extraneous hardware devices with compatible software components. As controls move from hard to soft, we have seen an increase in usability issues for musicians and sound engineers dealing with a large number of temporal inputs and both continuous and discrete controls. We present the SonicExplorer application, which we developed to give users a new interface for exploring and manipulating audio. SonicExplorer leverages users' spatial and color perception to enhance exploration by visualizing the parameter space and providing implicit memory cues. The application also leverages bimanual input to aid in fluid exploration of multidimensional audio parameter spaces, and to minimize the need for switching between parameters.</p>
<p>Keywords:
audio; bimanual interaction; color memory cues; parameter exploration; spatial memory cues</p>
<h3 id="28. The boomRoom: mid-air direct interaction with virtual sound sources.">28. The boomRoom: mid-air direct interaction with virtual sound sources.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557000">Paper Link</a>    Pages:247-256</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller_0001:J=ouml=rg">Jrg Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Geier:Matthias">Matthias Geier</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dicke:Christina">Christina Dicke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Spors:Sascha">Sascha Spors</a></p>
<p>Abstract:
In this paper we present a system that allows to "touch", grab and manipulate sounds in mid-air. Further, arbitrary objects can seem to emit sound. We use spatial sound reproduction for sound rendering and computer vision for tracking. Using our approach, sounds can be heard from anywhere in the room and always appear to originate from the same (possibly moving) position, regardless of the listener's position. We demonstrate that direct "touch" interaction with sound is an interesting alternative to indirect interaction mediated through controllers or visual interfaces. We show that sound localization is surprisingly accurate (11.5 cm), even in the presence of distractors. We propose to leverage the ventriloquist effect to further increase localization accuracy. Finally, we demonstrate how affordances of real objects can create synergies of auditory and visual feedback. As an application of the system, we built a spatial music mixing room.</p>
<p>Keywords:
gestural interaction; mid-air; spatial sound reproduction</p>
<h3 id="29. ISSE: an interactive source separation editor.">29. ISSE: an interactive source separation editor.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557253">Paper Link</a>    Pages:257-266</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bryan:Nicholas_J=">Nicholas J. Bryan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mysore:Gautham_J=">Gautham J. Mysore</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Ge">Ge Wang</a></p>
<p>Abstract:
Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.). Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source, freely available, and cross-platform audio editing tool that enables a user to perform source separation by painting on time-frequency visualizations of sound, resulting in an interactive machine learning system. The system brings to life our previously proposed interaction paradigm and separation algorithm that learns from user-feedback to perform separation. For evaluation, we conducted user studies and compared results between inexperienced and expert users. For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality.</p>
<p>Keywords:
audio interface; intelligent user interface; interactive machine learning; source separation</p>
<h3 id="30. Evaluation of hear-through sound localization.">30. Evaluation of hear-through sound localization.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557168">Paper Link</a>    Pages:267-270</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marentakis:Georgios">Georgios Marentakis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liepins:Rudolfs">Rudolfs Liepins</a></p>
<p>Abstract:
Listening and interacting with audio commonly relies on using earphones which limit the ability of users to perceive their auditory environment. Earphone sets that integrate miniature microphones on their exterior can, however, be used to hear-through the auditory environment. We present an evaluation study in which sound localization when wearing such a hear-through system is compared to normal earphones, open headphones and unblocked ears. Although localization performance is improved compared to open headphones, we find that it is compromised in comparison to listening without earphones because confusions of sound direction increase and localization judgment distributions are more dispersed and show a weaker correlation to the test directions. The implications of the results to human computer interaction and possible improvements to hear-through system design are discussed.</p>
<p>Keywords:
auditory augmented reality; hear-through systems</p>
<h2 id="Sustainability and everyday practices    1">Sustainability and everyday practices    1</h2>
<h3 id="31. Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends.">31. Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557318">Paper Link</a>    Pages:271-280</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Normark:Maria">Maria Normark</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tholander:Jakob">Jakob Tholander</a></p>
<p>Abstract:
The EcoFriends application was developed as an attempt to support grocery shopping adjusted to vegetables? seasonality through a performative approach to interaction and interactive applications. The design aimed at critical reflection and inspiration among users, rather than achieving a certain kind of persuasion. This guided the practical design to be modelled around open-endedness and social voices to challenge ideas and points of view. We argue that research addressing design for interactions about value-laden concepts such as sustainable action need to find ways of supporting various knowledge discourses, by distinguishing between performative and representational technologies. The approach allowed us to identify a number of design challenges regarding interactive technology and interaction design in relation to aspects of knowledge and truth, trust, negotiation and responsibility.</p>
<p>Keywords:
mobile interaction; performative design; sustainable interaction</p>
<h2 id="Studying online communities    4">Studying online communities    4</h2>
<h3 id="32. The impact of membership overlap on the survival of online communities.">32. The impact of membership overlap on the survival of online communities.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557213">Paper Link</a>    Pages:281-290</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhu:Haiyi">Haiyi Zhu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a></p>
<p>Abstract:
If the people belong to multiple online communities, their joint membership can influence the survival of each of the communities to which they belong. Communities with many joint memberships may struggle to get enough of their members' time and attention, but find it easy to import best practices from other communities. In this paper, we study the effects of membership overlap on the survival of online communities. By analyzing the historical data of 5673 Wikia communities, we find that higher levels of membership overlap are positively associated with higher survival rates of online communities. Furthermore, we find that it is beneficial for young communities to have shared members who play a central role in other mature communities. Our contributions are two-fold. Theoretically, by examining the impact of membership overlap on the survival of online communities we identified an important mechanism underlying the success of online communities. Practically, our findings may guide community creators on how to effectively manage their members, and tool designers on how to support this task.</p>
<p>Keywords:
membership overlap; online communities; survival analysis</p>
<h3 id="33. Goals and perceived success of online enterprise communities: what is important to leaders & members?">33. Goals and perceived success of online enterprise communities: what is important to leaders &amp; members?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557201">Paper Link</a>    Pages:291-300</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Tara">Tara Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Jilin">Jilin Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pal:Aditya">Aditya Pal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhu:Haiyi">Haiyi Zhu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Badenes:Hernan">Hernan Badenes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Barton_A=">Barton A. Smith</a></p>
<p>Abstract:
Online communities are successful only if they achieve their goals, but there has been little direct study of goals. We analyze novel data characterizing the goals of enterprise online communities, assessing the importance of goals for leaders, how goals influence member perceptions of community value, and how goals relate to success measures proposed in the literature. We find that most communities have multiple goals and common goals are learning, reuse of resources, collaboration, networking, influencing change, and innovation. Leaders and members agree that all of these goals are important, but their perceptions of success on goals do not align with each other, or with commonly used behavioral success measures. We conclude that simple behavioral measures and leader perceptions are not good success metrics, and propose alternatives based on specific goals members and leaders judge most important.</p>
<p>Keywords:
enterprise; goals; metrics; online communities; workplace</p>
<h3 id="34. Selecting an effective niche: an ecological view of the success of online communities.">34. Selecting an effective niche: an ecological view of the success of online communities.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557348">Paper Link</a>    Pages:301-310</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhu:Haiyi">Haiyi Zhu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Jilin">Jilin Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Tara">Tara Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pal:Aditya">Aditya Pal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Badenes:Hernan">Hernan Badenes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a></p>
<p>Abstract:
Online communities serve various important functions, but many fail to thrive. Research on community success has traditionally focused on internal factors. In contrast, we take an ecological view to understand how the success of a community is influenced by other communities. We measured a community's relationship with other communities - its "niche" - through four dimensions: topic overlap, shared members, content linking, and shared offline organizational affiliation. We used a mixed-method approach, combining the quantitative analysis of 9495 online enterprise communities and interviews with community members. Our results show that too little or too much overlap in topic with other communities causes a community's activity to suffer. We also show that this main result is moderated in predictable ways by whether the community shares members with, links to content in, or shares an organizational affiliation with other communities. These findings provide new insight on community success, guiding online community designers on how to effectively position their community in relation to others.</p>
<p>Keywords:
online communities; success; topic overlap; workplace</p>
<h3 id="35. Snuggle: designing for efficient socialization and ideological critique.">35. Snuggle: designing for efficient socialization and ideological critique.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557313">Paper Link</a>    Pages:311-320</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Halfaker:Aaron">Aaron Halfaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Geiger:R=_Stuart">R. Stuart Geiger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Terveen:Loren_G=">Loren G. Terveen</a></p>
<p>Abstract:
Wikipedia, the encyclopedia "anyone can edit", has become increasingly less so. Recent academic research and popular discourse illustrates the often aggressive ways newcomers are treated by veteran Wikipedians. These are complex sociotechnical issues, bound up in infrastructures based on problematic ideologies. In response, we worked with a coalition of Wikipedians to design, develop, and deploy Snuggle, a new user interface that served two critical functions: making the work of newcomer socialization more effective, and bringing visibility to instances in which Wikipedians? current practice of gatekeeping socialization breaks down. Snuggle supports positive socialization by helping mentors quickly find newcomers whose good-faith mistakes were reverted as damage. Snuggle also supports ideological critique and reflection by bringing visibility to the consequences of viewing newcomers through a lens of suspiciousness.</p>
<p>Keywords:
activism; algorithms; critique; design; wikipedia</p>
<h2 id="Image and animation authoring    4">Image and animation authoring    4</h2>
<h3 id="36. Offline painted media for digital animation authoring.">36. Offline painted media for digital animation authoring.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557062">Paper Link</a>    Pages:321-330</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nakajima:Makoto">Makoto Nakajima</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sakamoto:Daisuke">Daisuke Sakamoto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Igarashi:Takeo">Takeo Igarashi</a></p>
<p>Abstract:
We present an animation creation workflow for integrating offline physical, painted media into the digital authoring of Flash-style animations. Generally, animators create animations with standardized digital authoring software. However, the results tend to lack the individualism or atmosphere of physical media. In contrast, illustrators have skills in painting physical media but have limited experience in animation. To incorporate their skills, we present a workflow that integrates the offline painting and digital animation creation processes in a labor-saving manner. First, a user makes a rough sketch of the visual elements and defines their movements using our digital authoring software with a sketch interface. Then these images are exported to printed pages, and users can paint using offline physical media. Finally, the work is scanned and imported back into the digital content, forming a composite animation that combines digital and physical media. We present an implementation of this system to demonstrate its workflow. We also discuss the advantages of using physical media in digital animations through design evaluations.</p>
<p>Keywords:
animation authoring; creativity support tool; offline painted media; workflow</p>
<h3 id="37. Supporting informal design with interactive whiteboards.">37. Supporting informal design with interactive whiteboards.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557411">Paper Link</a>    Pages:331-340</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mangano:Nicolas">Nicolas Mangano</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/LaToza:Thomas_D=">Thomas D. LaToza</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Petre:Marian">Marian Petre</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hoek:Andr=eacute=_van_der">Andr van der Hoek</a></p>
<p>Abstract:
Whiteboards serve an important role in supporting informal design, providing a fluid and flexible medium for collaborative design. Interactive whiteboards offer the potential for enhanced support for manipulating content, managing sketches, and distributed work, but little is known about how this support affects the practice of informal design. To understand the opportunities and challenges, we first conducted a literature review, identifying 14 behaviors that occur during informal design. We then designed an interactive whiteboard system to support all of these behaviors and deployed the system to three groups of designers. Through usage logs and interviews, we examined the effects of interactivity on whiteboard use across a wide spectrum of design behaviors, identifying ways in which interactive whiteboards support the practices used in physical whiteboards and where they enable designers to work more effectively.</p>
<p>Keywords:
design; informal design; interactive whiteboard; sketching</p>
<h3 id="38. Juxtapoze: supporting serendipity and creative expression in clipart compositions.">38. Juxtapoze: supporting serendipity and creative expression in clipart compositions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557327">Paper Link</a>    Pages:341-350</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Benjamin:William">William Benjamin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chandrasegaran:Senthil_K=">Senthil K. Chandrasegaran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramanujan:Devarajan">Devarajan Ramanujan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Elmqvist:Niklas">Niklas Elmqvist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vishwanathan:S=_V=_N=">S. V. N. Vishwanathan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramani:Karthik">Karthik Ramani</a></p>
<p>Abstract:
Juxtapoze is a clipart composition workflow that supports creative expression and serendipitous discoveries in the shape domain. We achieve creative expression by supporting a workflow of searching, editing, and composing: the user queries the shape database using strokes, selects the desired search result, and finally modifies the selected image before composing it into the overall drawing. Serendipitous discovery of shapes is facilitated by allowing multiple exploration channels, such as doodles, shape filtering, and relaxed search. Results from a qualitative evaluation show that Juxtapoze makes the process of creating image compositions enjoyable and supports creative expression and serendipity.</p>
<p>Keywords:
clipart composition; creative expression; serendipity; shape search; sketching</p>
<h3 id="39. Draco: bringing life to illustrations with kinetic textures.">39. Draco: bringing life to illustrations with kinetic textures.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556987">Paper Link</a>    Pages:351-360</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kazi:Rubaiat_Habib">Rubaiat Habib Kazi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chevalier:Fanny">Fanny Chevalier</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
We present Draco, a sketch-based interface that allows artists and casual users alike to add a rich set of animation effects to their drawings, seemingly bringing illustrations to life. While previous systems have introduced sketch-based animations for individual objects, our contribution is a unified framework of motion controls that allows users to seamlessly add coordinated motions to object collections. We propose a framework built around kinetic textures, which provide continuous animation effects while preserving the unique timeless nature of still illustrations. This enables many dynamic effects difficult or not possible with previous sketch-based tools, such as a school of fish swimming, tree leaves blowing in the wind, or water rippling in a pond. We describe our implementation and illustrate the repertoire of animation effects it supports. A user study with professional animators and casual users demonstrates the variety of animations, applications and creative possibilities our tool provides.</p>
<p>Keywords:
animation; direct manipulation; kinetic textures; sketching</p>
<h2 id="Studying and designing gameplay    4">Studying and designing gameplay    4</h2>
<h3 id="40. A user study of different gameplay visualizations.">40. A user study of different gameplay visualizations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557317">Paper Link</a>    Pages:361-370</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kriglstein:Simone">Simone Kriglstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wallner:G=uuml=nter">Gnter Wallner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pohl:Margit">Margit Pohl</a></p>
<p>Abstract:
With the rising interest in multiplayer gaming, gameplay statistics have become an increasingly important aspect of the overall game experience for many players. As a part of this trend, visualizations have gained great popularity among players, in particular heatmaps since they allow them to reenact the course of a game and to develop new strategies. In this paper we report results of a user study conducted with 29 players (i) to investigate how players use heatmaps and two further graphical representations that use clustering algorithms to interpret gameplay and (ii) to assess the three representations in regard to time efficiency, correctness, suitability, and player preference. Our results show that heatmaps were mainly used to detect hot spots while the cluster representations proved useful to compare variables, allowing the players to uncover relationships between them and in turn allowing a deeper insight into the gameplay data.</p>
<p>Keywords:
clustering; evaluation; games; heatmap; visualization</p>
<h3 id="41. The influence of controllers on immersion in mobile games.">41. The influence of controllers on immersion in mobile games.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557345">Paper Link</a>    Pages:371-380</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cairns:Paul_A=">Paul A. Cairns</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Jing">Jing Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Wendy">Wendy Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nordin:A=_Imran">A. Imran Nordin</a></p>
<p>Abstract:
The controls for digital games understandably have an important part in building up the gaming experiences that people have. Whilst there is substantial work on innovative controllers for consoles, like the XBox Kinect, relatively little has been done to understand the effect of the different control mechanisms that can be used to play games on mobile devices like smartphones. A well-defined framework of naturalness has emerged as potentially useful concept in area of game controllers. This paper reports two experiments that look at how the naturalness of the game controls influences the experience of immersion in mobile games. It seems that where there is an a prior natural mapping, this will improve immersion in the game but in the absence of a prior mapping, naturalness alone is not sufficient to account for immersion. This opens up the need for a more thorough investigation of this area.</p>
<p>Keywords:
controllers; gaming experience; immersion; mobile games; natural mappings</p>
<h3 id="42. Combining think-aloud and physiological data to understand video game experiences.">42. Combining think-aloud and physiological data to understand video game experiences.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557326">Paper Link</a>    Pages:381-390</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tan:Chek_Tien">Chek Tien Tan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Leong:Tuck_Wah">Tuck Wah Leong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shen:Songjia">Songjia Shen</a></p>
<p>Abstract:
Think-aloud protocols are commonly used to evaluate player experiences of video games but suffer from a lack of objectivity and timeliness. On the other hand, quantitative captures of physiological data are effective; providing detailed, unbiased and continuous responses of players, but lack contexts for interpretation. This paper documents how both approaches could be used together in practice by comparing video-cued retrospective think-aloud data and physiological data collected during a video gameplay experiment. We observed that many interesting physiological responses did not feature in participants' think-aloud data, and conversely, reports of interesting experiences were sometimes not observed in the collected physiological data. Through learnings from our experiment, we present some of the challenges when combining these approaches and offer some guidelines as to how qualitative and quantitative data can be used together to gain deeper insights into player experiences.</p>
<p>Keywords:
game user research; psychophysiology; think-aloud</p>
<h3 id="43. The MOY framework for collaborative play design in integrated shared and private interactive spaces.">43. The MOY framework for collaborative play design in integrated shared and private interactive spaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557104">Paper Link</a>    Pages:391-400</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Goh:Wooi=Boon">Wooi-Boon Goh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Ming">Ming Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Trinh:Cuong_Hong">Cuong Hong Trinh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tan:Jacquelyn">Jacquelyn Tan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shou:Wei">Wei Shou</a></p>
<p>Abstract:
A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing collaborative play activities in environments that combine both private and shared interactive spaces. A collaborative game designed on a system that integrates multiple mobile devices with an interactive tabletop was presented to demonstrate the implementation of the proposed MOY framework. Observations from field trials involving two groups of children were used to summarize the collaborative behaviors that are likely to be observed under the different interaction design configurations.</p>
<p>Keywords:
collaborative play; cooperative design patterns; interaction design; multi-touch interaction</p>
<h2 id="Force input and haptic feedback    5">Force input and haptic feedback    5</h2>
<h3 id="44. Transient and transitional states: pressure as an auxiliary input modality for bimanual interaction.">44. Transient and transitional states: pressure as an auxiliary input modality for bimanual interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557260">Paper Link</a>    Pages:401-410</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McLachlan:Ross">Ross McLachlan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Boland:Daniel">Daniel Boland</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a></p>
<p>Abstract:
A novel investigation of pressure input is presented where it is characterised as a transient modality, one that has a natural inverse, bounce-back and a state that only persists during interaction. Three empirical studies are described that evaluate pressure for use as a non-dominant hand input modality, where the ability to target and maintain pressure while simultaneously performing a dominant-hand targeting task is investigated. Pressure accuracy was high (93%) and the impact on dominant-hand targeting was low. Mean pressure accuracy when selecting targets by releasing pressure was also high (89%) as was selecting targets by applying pressure from a non-zero starting point (94.4%). The ability to accurately maintain pressure over time was better with larger target pressures. Example applications and design guidelines are presented that enable designers to exploit the transient properties of pressure input in interaction design.</p>
<p>Keywords:
bimanual interaction; non-dominant hand; pressure input; transience</p>
<h3 id="45. VacuumTouch: attractive force feedback interface for haptic interactive surface using air suction.">45. VacuumTouch: attractive force feedback interface for haptic interactive surface using air suction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557252">Paper Link</a>    Pages:411-420</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hachisu:Taku">Taku Hachisu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fukumoto:Masaaki">Masaaki Fukumoto</a></p>
<p>Abstract:
We present VacuumTouch, a novel haptic interface architecture for touch screens that provides attractive force feedback to the user's finger. VacuumTouch consists of an air pump and solenoid air valves that connect to the surface of the touch screen and suck the air above the surface where the user's finger makes contact. VacuumTouch does not require the user to hold or attach additional devices to provide the attractive force, which allows for easy interaction with the surface. This paper introduces the implementation of the VacuumTouch architecture and some applications for enhancement of the graphical user interface, namely a suction button, a suction slider, and a suction dial. The quantitative evaluation was conducted with the suction dial and showed that the attractive force provided by VacuumTouch improved the performance of the dial menu interface and its potential effects. At the end of this paper, we discuss the current prototype's advantages and limitations, as well as possible improvements and potential capabilities.</p>
<p>Keywords:
air suction; attractive force; haptic interface; interactive surface; vacuumtouch</p>
<h3 id="46. Expressive touch: studying tapping force on tabletops.">46. Expressive touch: studying tapping force on tabletops.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557019">Paper Link</a>    Pages:421-430</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pedersen:Esben_Warming">Esben Warming Pedersen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
This paper investigates users' ability to perform force-sensitive tapping and explores its potential as an input modality in touch-based systems. We study force-sensitive tapping using Expressive Touch, a tabletop interface that infers tapping force from the sound waves created by the users' finger upon impact. The first part of the paper describes the implementation details of Expressive Touch and shows how existing tabletop interfaces can be augmented to reliably detect tapping force across the entire surface. The second part of the paper reports on the results of three studies of force-sensitive tapping. First, we use a classic psychophysic task to gain insights into participants' perception of tapping force (Study 1). Results show that although participants tap with different absolute tapping forces, they have a similar perception of relative tapping force. Second, we investigate participants' ability to control tapping force (Study 2) and find that users can produce two force levels with 99% accuracy. For six levels of force, accuracy drops to 58%. Third, we investigate the usability of force tapping by studying participants' reactions to seven force-sensitive touch applications (Study 3).</p>
<p>Keywords:
acoustic sensing; expressive touch; force; tabletop computing; tapping; touch</p>
<h3 id="47. Presstures: exploring pressure-sensitive multi-touch gestures on trackpads.">47. Presstures: exploring pressure-sensitive multi-touch gestures on trackpads.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557146">Paper Link</a>    Pages:431-434</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rendl:Christian">Christian Rendl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Greindl:Patrick">Patrick Greindl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Probst:Kathrin">Kathrin Probst</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Behrens:Martin">Martin Behrens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haller:Michael">Michael Haller</a></p>
<p>Abstract:
In this paper, we present Presstures, an extension to current multi-touch operations that enriches common multi-finger gestures with pressure information. By using the initially applied pressure level for implicit mode switching, a gesture can be enhanced with different functionalities to enlarge the interaction space for multi-touch. To evaluate the feasibility of our concept, we conducted an experiment, which indicates good human sensorimotor skills for performing multi-touch gestures with a few number of pressure levels and without any additional feedback. Based on the experimental results, we discuss implications for the design of pressure-sensitive multi-touch gestures, and propose application scenarios that make optimal use of our concept.</p>
<p>Keywords:
force; multi-touch gestures; pressure; pressure gestures</p>
<h3 id="48. Gaze gestures and haptic feedback in mobile devices.">48. Gaze gestures and haptic feedback in mobile devices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557040">Paper Link</a>    Pages:435-438</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kangas:Jari">Jari Kangas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Akkil:Deepak">Deepak Akkil</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rantala:Jussi">Jussi Rantala</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Isokoski:Poika">Poika Isokoski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Majaranta:P=auml=ivi">Pivi Majaranta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Raisamo:Roope">Roope Raisamo</a></p>
<p>Abstract:
Anticipating the emergence of gaze tracking capable mobile devices, we are investigating the use of gaze as an input modality in handheld mobile devices. We conducted a study of combining gaze gestures with vibrotactile feedback. Gaze gestures were used as an input method in a mobile device and vibrotactile feedback as a new alternative way to give confirmation of interaction events. Our results show that vibrotactile feedback significantly improved the use of gaze gestures. The tasks were completed faster and rated easier and more comfortable when vibrotactile feedback was provided.</p>
<p>Keywords:
gaze interaction; gaze tracking; haptic feedback</p>
<h2 id="Hackerspaces, making and breaking    5">Hackerspaces, making and breaking    5</h2>
<h3 id="49. Emerging sites of HCI innovation: hackerspaces, hardware startups & incubators.">49. Emerging sites of HCI innovation: hackerspaces, hardware startups &amp; incubators.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557132">Paper Link</a>    Pages:439-448</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lindtner:Silvia">Silvia Lindtner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hertz:Garnet_D=">Garnet D. Hertz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dourish:Paul">Paul Dourish</a></p>
<p>Abstract:
In this paper, we discuss how a flourishing scene of DIY makers is turning visions of tangible and ubiquitous computing into products. Drawing on long-term multi-sited ethnographic research and active participation in DIY making, we provide insights into the social, material, and economic processes that undergird this transition from prototypes to products. The contribution of this paper is three-fold. First, we show how DIY maker practice is illustrative of a broader "return to" and interest in physical materials. This has implications for HCI research that investigates questions of materiality. Second, we shed light on how hackerspaces and hardware start-ups are experimenting with new models of manufacturing and entrepreneurship. We argue that we have to take seriously these maker practices, not just as hobbyist or leisure practice, but as a professionalizing field functioning in parallel to research and industry labs. Finally, we end with reflections on the role of HCI researchers and designers as DIY making emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical reflection, paired with a sensibility for materials, tools and design methods.</p>
<p>Keywords:
china; critical making; diy; hackerspace; iot; make; making cultures; manufacturing; materiality</p>
<h3 id="50. Breakdown, obsolescence and reuse: HCI and the art of repair.">50. Breakdown, obsolescence and reuse: HCI and the art of repair.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557332">Paper Link</a>    Pages:449-458</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jackson:Steven_J=">Steven J. Jackson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kang:Laewoo">Laewoo Kang</a></p>
<p>Abstract:
This paper describes an integrated program of theoretical, ethnographic, and building work meant to explore post-humanist alternatives to questions around HCI creativity and design. We review recent theories in the humanities, social sciences, and HCI that argue for different ways of framing the relationship between human agents and the object world around them. We then describe a program of ethnographic work with artists who feature found and broken technologies as central methods and topics of work. Finally, we describe an installation and self-study project of our own, 'Scale,' that extends these lines of analysis through collaborative acts of building with broken and discarded technologies. We argue that such integrated programs of work offer one useful model for leveraging the theoretical, ethnographic and material dimensions of HCI work; and that the distinct 'propensities' of found and broken objects can challenge and extend HCI notions of creativity and design itself.</p>
<p>Keywords:
agency; art; design; ethnography; repair</p>
<h3 id="51. Printing teddy bears: a technique for 3D printing of soft interactive objects.">51. Printing teddy bears: a technique for 3D printing of soft interactive objects.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557338">Paper Link</a>    Pages:459-468</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hudson:Scott_E=">Scott E. Hudson</a></p>
<p>Abstract:
This paper considers the design, construction, and example use of a new type of 3D printer which fabricates three-dimensional objects from soft fibers (wool and wool blend yarn). This printer allows the substantial advantages of additive manufacturing techniques (including rapid turn-around prototyping of physical objects and support for high levels of customization and configuration) to be employed with a new class of material. This material is a form of loose felt formed when fibers from an incoming feed of yarn are entangled with the fibers in layers below it. The resulting objects recreate the geometric forms specified in the solid models which specify them, but are soft and flexible -- somewhat reminiscent in character to hand knitted materials. This extends 3D printing from typically hard and precise forms into a new set of forms which embody a different aesthetic of soft and imprecise objects, and provides a new capability for researchers to explore the use of this class of materials in interactive devices.</p>
<p>Keywords:
additive manufacturing; computational crafts; interactive devices; soft materials</p>
<h3 id="52. Taking things apart: reaching common ground and shared material understanding.">52. Taking things apart: reaching common ground and shared material understanding.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557267">Paper Link</a>    Pages:469-472</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Murer:Martin">Martin Murer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jacobsson:Mattias">Mattias Jacobsson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Skillgate:Siri">Siri Skillgate</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sundstr=ouml=m:Petra">Petra Sundstrm</a></p>
<p>Abstract:
In this note we discuss and argue about how taking things apart and disassembling can be meaningful practices in explorative design projects. In particular, we report on an explorative design exercise about taking apart an unfamiliar device. Relating to this design situation, we provide accounts for how collaborative hands-on experience can support reaching common ground and acquiring shared material understanding in an interdisciplinary design team through establishing a material brief. In the end we reflect and discuss how this may complement our practices regarding materials and interaction design.</p>
<p>Keywords:
artifacts; disassembling; exploration; material</p>
<h3 id="53. "now that's definitely a proper hack": self-made tools in hackerspaces.">53. "now that's definitely a proper hack": self-made tools in hackerspaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557221">Paper Link</a>    Pages:473-476</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Jeffrey">Jeffrey Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Shaowen">Shaowen Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Toombs:Austin">Austin Toombs</a></p>
<p>Abstract:
Cultures of making - that is, social practices of hacking, DIY, tinkering, repair, and craft - continue to rise in prominence, and design researchers have taken note, because of their implications for sustainability, democratization, and alternative models of innovation, design, participation, and education. We contribute to this agenda by exploring our findings on self-made tools, which we encountered in a 9-month ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses that are of interest in design research on making: tools and adhocism. In this paper, we explore ways that tools and adhocism interface with each other, using our findings as a material to think with. We find that this juxtaposition of concepts helps explain a highly generative creative practice - tool-making - within the hackerspace we studied.</p>
<p>Keywords:
ad hoc; design; hackers; hackerspaces; hci; maker culture; tools</p>
<h2 id="Activity recognition    3">Activity recognition    3</h2>
<h3 id="54. Toss 'n' turn: smartphone as sleep and sleep quality detector.">54. Toss 'n' turn: smartphone as sleep and sleep quality detector.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557220">Paper Link</a>    Pages:477-486</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Min:Jun=Ki">Jun-Ki Min</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Doryab:Afsaneh">Afsaneh Doryab</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wiese:Jason">Jason Wiese</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Amini:Shahriyar">Shahriyar Amini</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jason_I=">Jason I. Hong</a></p>
<p>Abstract:
The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06% accuracy, daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of ground truth data to perform well on detecting sleep and sleep quality, respectively. Finally, the features of noise and movement were useful to infer sleep quality.</p>
<p>Keywords:
machine learning; sensors; sleep; smartphone</p>
<h3 id="55. Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness.">55. Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557383">Paper Link</a>    Pages:487-496</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fritz:Thomas">Thomas Fritz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Elaine_M=">Elaine M. Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Murphy:Gail_C=">Gail C. Murphy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmermann_0001:Thomas">Thomas Zimmermann</a></p>
<p>Abstract:
Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly "in the wild" contexts and understand how practices evolve over long-term, naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings, which both support and contrast with those of previous research, paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.</p>
<p>Keywords:
activity monitoring; behavior change; health; personal informatics; persuasive technology; wearable sensing</p>
<h3 id="56. Predictors of life satisfaction based on daily activities from mobile sensor data.">56. Predictors of life satisfaction based on daily activities from mobile sensor data.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557147">Paper Link</a>    Pages:497-500</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Y=uuml=r=uuml=ten:Onur">Onur Yrten</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Jiyong">Jiyong Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pu:Pearl_Huan_Z=">Pearl Huan Z. Pu</a></p>
<p>Abstract:
In recent years much research work has been dedicated to detecting user activity patterns from sensor data such as location, movement and proximity. However, how daily activities are correlated to people's happiness (such as their satisfaction from work and social lives) is not well explored. In this work, we propose an approach to investigate the relationship between users' daily activity patterns and their life satisfaction level. From a well-known longitudinal dataset collected by mobile devices, we extract various activity features through location and proximity information, and compute the entropies of these data to capture the regularities of the behavioral patterns of the participants. We then perform component analysis and structural equation modeling to identify key behavior contributors to self-reported satisfaction scores. Our results show that our analytical procedure can identify meaningful assumptions of causality between activities and satisfaction. Particularly, keeping regularity in daily activities can significantly improve the life satisfaction.</p>
<p>Keywords:
analysis methods; handheld devices and mobile computing; ubiquitous computing/smart environments</p>
<h2 id="Managing income    4">Managing income    4</h2>
<h3 id="57. Pay or delay: the role of technology when managing a low income.">57. Pay or delay: the role of technology when managing a low income.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556961">Paper Link</a>    Pages:501-510</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vines:John">John Vines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dunphy:Paul">Paul Dunphy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Monk:Andrew">Andrew Monk</a></p>
<p>Abstract:
This paper reports on a qualitative study of 38 low-income individuals living in the North East of England. The participants' experiences of money, banking and the role digital technology plays in their financial practices were identified through semi-structured interviews in people's homes and group workshops. A grounded theory analysis of these data characterises how technology both helped and hindered participants to keep close control of their finances. These findings suggest design opportunities for future digital banking technologies that extend the already sophisticated practices of individuals managing a low income, focusing on: delaying, prioritising, planning, watching, and hiding monetary transactions.</p>
<p>Keywords:
banking technologies; financial inclusion; low income; qualitative study</p>
<h3 id="58. Poverty on the cheap: estimating poverty maps using aggregated mobile communication networks.">58. Poverty on the cheap: estimating poverty maps using aggregated mobile communication networks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557358">Paper Link</a>    Pages:511-520</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Smith=Clarke:Christopher">Christopher Smith-Clarke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mashhadi:Afra_J=">Afra J. Mashhadi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Capra:Licia">Licia Capra</a></p>
<p>Abstract:
Governments and other organisations often rely on data collected by household surveys and censuses to identify areas in most need of regeneration and development projects. However, due to the high cost associated with the data collection process, many developing countries conduct such surveys very infrequently and include only a rather small sample of the population, thus failing to accurately capture the current socio-economic status of the country's population. In this paper, we address this problem by means of a methodology that relies on an alternative source of data from which to derive up to date poverty indicators, at a very fine level of spatio-temporal granularity. Taking two developing countries as examples, we show how to analyse the aggregated call detail records of mobile phone subscribers and extract features that are strongly correlated with poverty indexes currently derived from census data.</p>
<p>Keywords:
call detail records; data4d; ict4d; socio-economics</p>
<h3 id="59. Money talks: tracking personal finances.">59. Money talks: tracking personal finances.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556975">Paper Link</a>    Pages:521-530</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kaye:Joseph_Jofish">Joseph Jofish Kaye</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McCuistion:Mary">Mary McCuistion</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gulotta:Rebecca">Rebecca Gulotta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shamma:David_A=">David A. Shamma</a></p>
<p>Abstract:
How do people keep track of their money? In this paper we present a preliminary scoping study of how 14 individuals in the San Francisco Bay Area earn, save, spend and understand money and their personal and family finances. We describe the practices we developed for exploring the sensitive topic of money, and then discuss three sets of findings. The first is the emotional component of the relationship people have with their finances. Second, we discuss the tools and processes people used to keep track of their financial situation. Finally we discuss how people account for the unknown and unpredictable nature of the future through their financial decisions. We conclude by discussing the future of studies of money and finance in HCI, and reflect on the opportunities for improving tools to aid people in managing and planning their finances.</p>
<p>Keywords:
banking; finance; interviews; money</p>
<h3 id="60. Fostering social capital in economically distressed communities.">60. Fostering social capital in economically distressed communities.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557123">Paper Link</a>    Pages:531-540</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dillahunt:Tawanna">Tawanna Dillahunt</a></p>
<p>Abstract:
Past Information and Communication Technology (ICT) literature suggests that engaging in meaningful activities with ICTs may be related to socio-economic security, social inclusion, empowerment, and increased social capital. However, we identify a pervasive lack of understanding in existing literature, which raises an important research question: how can we build social capital where little social capital exists? We conducted a preliminary study to explore whether and if so, how, individuals in an economically distressed population with limited social capital use technologies to increase social capital and achieve socio-economic security. We contribute details about barriers affecting social capital (e.g., difficulties finding and making the right connections and an overall lack of trust within communities). We also suggest ways in which ICTs can assist populations that could benefit most from increased social capital and economic security.</p>
<p>Keywords:
economic mobility; ict4d; social capital; sustainability</p>
<h2 id="Designing and understanding visualizations    4">Designing and understanding visualizations    4</h2>
<h3 id="61. Automatic generation of semantic icon encodings for visualizations.">61. Automatic generation of semantic icon encodings for visualizations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557408">Paper Link</a>    Pages:541-550</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Setlur:Vidya">Vidya Setlur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mackinlay:Jock_D=">Jock D. Mackinlay</a></p>
<p>Abstract:
Authors use icon encodings to indicate the semantics of categorical information in visualizations. The default icon libraries found in visualization tools often do not match the semantics of the data. Users often manually search for or create icons that are more semantically meaningful. This process can hinder the flow of visual analysis, especially when the amount of data is large, leading to a suboptimal user experience. We propose a technique for automatically generating semantically relevant icon encodings for categorical dimensions of data points. The algorithm employs natural language processing in order to find relevant imagery from the Internet. We evaluate our approach on Mechanical Turk by generating large libraries of icons using Tableau Public workbooks that represent real analytical effort by people out in the world. Our results show that the automatic algorithm does nearly as well as the manually created icons, and particularly has higher user satisfaction for larger cardinalities of data.</p>
<p>Keywords:
icon encodings; image retrieval.; natural language processing (nlp); visualization</p>
<h3 id="62. Task-driven evaluation of aggregation in time series visualization.">62. Task-driven evaluation of aggregation in time series visualization.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557200">Paper Link</a>    Pages:551-560</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Albers:Danielle">Danielle Albers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Correll:Michael">Michael Correll</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gleicher:Michael">Michael Gleicher</a></p>
<p>Abstract:
Many visualization tasks require the viewer to make judgments about aggregate properties of data. Recent work has shown that viewers can perform such tasks effectively, for example to efficiently compare the maximums or means over ranges of data. However, this work also shows that such effectiveness depends on the designs of the displays. In this paper, we explore this relationship between aggregation task and visualization design to provide guidance on matching tasks with designs. We combine prior results from perceptual science and graphical perception to suggest a set of design variables that influence performance on various aggregate comparison tasks. We describe how choices in these variables can lead to designs that are matched to particular tasks. We use these variables to assess a set of eight different designs, predicting how they will support a set of six aggregate time series comparison tasks. A crowd-sourced evaluation confirms these predictions. These results not only provide evidence for how the specific visualizations support various tasks, but also suggest using the identified design variables as a tool for designing visualizations well suited for various types of tasks.</p>
<p>Keywords:
information visualization; perceptual study; time series visualization; visualization design</p>
<h3 id="63. Dive in!: enabling progressive loading for real-time navigation of data visualizations.">63. Dive in!: enabling progressive loading for real-time navigation of data visualizations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557195">Paper Link</a>    Pages:561-570</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Glueck:Michael">Michael Glueck</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Khan:Azam">Azam Khan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel_J=">Daniel J. Wigdor</a></p>
<p>Abstract:
We introduce Splash, a framework reducing development overhead for both data curators and visualization developers of client-server visualization systems. Splash streamlines the process of creating a multiple level-of-detail version of the data and facilitates progressive data download, thereby enabling real-time, on-demand navigation with existing visualization toolkits. As a result, system responsiveness is increased and the user experience is improved. We demonstrate the benefit of progressive loading for user interaction on slower networks. Additionally, case study evaluations of Splash with real-world data curators suggest that Splash supports iterative refinement of visualizations and promotes the use of exploratory data analysis.</p>
<p>Keywords:
client-server; data visualization; progressive-loading; real-time interaction</p>
<h3 id="64. Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions.">64. Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557131">Paper Link</a>    Pages:571-580</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Ferreira:Nivan">Nivan Ferreira</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fisher:Danyel">Danyel Fisher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/K=ouml=nig:Arnd_Christian">Arnd Christian Knig</a></p>
<p>Abstract:
We often use datasets that reflect samples, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions emerging from samples, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. "compare two bars") become a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results: that users have a justified confidence in their answers with our system.</p>
<p>Keywords:
boxplot; error bars; incremental visualization; uncertainty visualization; user study</p>
<h2 id="Crowdfunding and crowd storage    3">Crowdfunding and crowd storage    3</h2>
<h3 id="65. Learning to fail: experiencing public failure online through crowdfunding.">65. Learning to fail: experiencing public failure online through crowdfunding.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557110">Paper Link</a>    Pages:581-590</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Greenberg:Michael_D=">Michael D. Greenberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gerber:Elizabeth">Elizabeth Gerber</a></p>
<p>Abstract:
Online crowdfunding platforms like Kickstarter are gaining attention among novice creatives as an effective platform for funding their ventures and engaging in creative work with others. However, a focus on financial success of crowdfunding has obscured the fact that over 58% of crowdfunding projects fail to achieve their funding goals. This population of failed creatives however, gives us an audience to study public creative failure in an online environment. We draw inspiration from work in organizational behavior on failure, and work in Human Computer Interaction (HCI) on online behavior, to study online public failure. Using a mixed-methods approach with data scraped from Kickstarter and interview data with failed crowdfunding project creators, we answer the following question: What do project creators on crowdfunding platforms learn and change through the process of failing? We find that creators who relaunch their projects succeed 43% of the time, and that most individuals find failure to be a positive experience. We conclude the paper with a series of design implications for future creative platforms where public failure is part of the creative process.</p>
<p>Keywords:
crowdfunding; crowdsourcing; failure; feedback</p>
<h3 id="66. Show me the money!: an analysis of project updates during crowdfunding campaigns.">66. Show me the money!: an analysis of project updates during crowdfunding campaigns.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557045">Paper Link</a>    Pages:591-600</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/x/Xu:Anbang">Anbang Xu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Xiao">Xiao Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rao:Huaming">Huaming Rao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fu:Wai=Tat">Wai-Tat Fu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Shih=Wen">Shih-Wen Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bailey:Brian_P=">Brian P. Bailey</a></p>
<p>Abstract:
Hundreds of thousands of crowdfunding campaigns have been launched, but more than half of them have failed. To better understand the factors affecting campaign outcomes, this paper targets the content and usage patterns of project updates -- communications intended to keep potential funders aware of a campaign's progress. We analyzed the content and usage patterns of a large corpus of project updates on Kickstarter, one of the largest crowdfunding platforms. Using semantic analysis techniques, we derived a taxonomy of the types of project updates created during campaigns, and found discrepancies between the design intent of a project update and the various uses in practice (e.g. social promotion). The analysis also showed that specific uses of updates had stronger associations with campaign success than the project's description. Design implications were formulated from the results to help designers better support various uses of updates in crowdfunding campaigns.</p>
<p>Keywords:
crowdfunding; crowdsouring; updates</p>
<h3 id="67. Crowd storage: storing information on existing memories.">67. Crowd storage: storing information on existing memories.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557159">Paper Link</a>    Pages:601-604</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bigham:Jeffrey_P=">Jeffrey P. Bigham</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lasecki:Walter_S=">Walter S. Lasecki</a></p>
<p>Abstract:
This paper introduces the concept of crowd storage, the idea that digital files can be stored and retrieved later from the memories of people in the crowd. Similar to human memory, crowd storage is ephemeral, which means that storage is temporary and the quality of the stored information degrades over time. Crowd storage may be preferred over storing information directly in the cloud, or when it is desirable for information to degrade inline with normal human memories. To explore and validate this idea, we created WeStore, a system that stores and then later retrieves digital files in the existing memories of crowd workers. WeStore does not store information directly, but rather encrypts the files using details of the existing memories elicited from individuals within the crowd as cryptographic keys. The fidelity of the retrieved information is tied to how well the crowd remembers the details of the memories they provided. We demonstrate that crowd storage is feasible using an existing crowd marketplace (Amazon Mechanical Turk), explore design considerations important for building systems that use crowd storage, and outline ideas for future research in this area.</p>
<p>Keywords:
crowdsourcing; memory; storage</p>
<h2 id="Novel approaches to navigation    5">Novel approaches to navigation    5</h2>
<h3 id="68. Walk this way: musically guided walking experiences.">68. Walk this way: musically guided walking experiences.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557250">Paper Link</a>    Pages:605-614</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hazzard:Adrian">Adrian Hazzard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benford:Steve">Steve Benford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Burnett:Gary_E=">Gary E. Burnett</a></p>
<p>Abstract:
Musical soundtracks will be important features of future locative experiences from tours to games. We present a study designed to uncover potential relationships between higher-level musical structures such as harmony, melody, timbre, dynamic intensity and punctuation and users' spatial experiences. We observed twenty-two participants exploring an open field while listening to four contrasting musical compositions, and then interviewed them afterwards. We report their different approaches to interpreting the music, strategies for mapping zones, choice of stopping destinations, and their awareness and appreciation of the music. Our discussion of these findings in relation to the literature leads us to propose six initial principles to guide the composition of mobile and locative soundtracks, and also to articulate a three-layer framework of global, regional and local attachment to help guide the attachment of musical features to different regions within a locative experience.</p>
<p>Keywords:
attachment; conceptual metaphors; design; location based experiences; music composition</p>
<h3 id="69. Simplifying orientation measurement for mobile audio augmented reality applications.">69. Simplifying orientation measurement for mobile audio augmented reality applications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557021">Paper Link</a>    Pages:615-624</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Heller:Florian">Florian Heller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kr=auml=mer:Aaron">Aaron Krmer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borchers:Jan_O=">Jan O. Borchers</a></p>
<p>Abstract:
Audio augmented reality systems overlay the physical world with a virtual audio space. Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. To achieve this, information about the user's location and orientation is necessary which requires additional hardware. In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio. To verify this approach, we present two studies: Our first study in examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. We found that when navigating close to sound sources head tracking is necessary, but that it can potentially be replaced by device tracking in larger or more explorative usage scenarios. These findings help reduce the technical complexity of mobile audio augmented reality systems (MAARS), and enable their wider dissemination as mobile software-only apps.</p>
<p>Keywords:
audio augmented reality; binaural rendering; mobile devices; orientation; presence; spatial audio</p>
<h3 id="70. Gifting personal interpretations in galleries.">70. Gifting personal interpretations in galleries.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557259">Paper Link</a>    Pages:625-634</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fosh:Lesley">Lesley Fosh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benford:Steve">Steve Benford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reeves:Stuart">Stuart Reeves</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Koleva:Boriana">Boriana Koleva</a></p>
<p>Abstract:
The designers of mobile guides for museums and galleries face three major challenges: fostering rich interpretation, delivering deep personalization, and enabling a coherent social visit. We propose an approach to tackling all three simultaneously by inviting visitors to design an interpretation that is specifically tailored for a friend or loved one that they then experience together. We describe a trial of this approach at a contemporary art gallery, revealing how visitors designed personal and sometimes provocative experiences for people they knew well. We reveal how pairs of visitors negotiated these experiences together, showing how our approach could deliver intense experiences for both, but also required them to manage social risk. By interpreting our findings through the lens of 'gift giving' we shed new light on ongoing explorations of interpretation, personalization and social visiting within HCI.</p>
<p>Keywords:
collaboration; galleries; gifting; interpretation; mobile guides; museums; personalization; visiting</p>
<h3 id="71. Visual recognition in museum guide apps: do visitors want it?">71. Visual recognition in museum guide apps: do visitors want it?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557270">Paper Link</a>    Pages:635-638</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wein:Leonard">Leonard Wein</a></p>
<p>Abstract:
In this paper, visual recognition (VisRec) is evaluated as a method to access background information on artworks in mobile museum guide applications (apps) by means of a field experiment. While museums and previous research have explored technical aspects, it is unclear whether visitors actually want to use VisRec. A prototype featuring VisRec, QR codes and number codes was developed and assessed with a usability study in two museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm for VisRec. Compared to previous literature, the results highlight the context-dependency of perceived usability and variability in the importance of usability factors. The results reveal a clear preference for VisRec among participants (53%); only 14% preferred QR codes. Ease of use, enjoyability and distance are identified as the main factors. This provides strong evidence to further explore the potential of VisRec to improve visitors' museum experiences.</p>
<p>Keywords:
access methods; mobile applications; museum guide; usability test; visual recognition</p>
<h3 id="72. A billion signposts: repurposing barcodes for indoor navigation.">72. A billion signposts: repurposing barcodes for indoor navigation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556994">Paper Link</a>    Pages:639-642</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Robinson:Simon">Simon Robinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pearson:Jennifer_S=">Jennifer S. Pearson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Matt">Matt Jones</a></p>
<p>Abstract:
Barcodes are all around us--on books, groceries and other products--but these everyday markers are typically used for a single focused purpose. In this paper we explore the concept of "piggybacking" on ubiquitous markers to facilitate indoor navigation. Our initial probe--BookMark--allows library visitors to scan any nearby book to provide a custom map to the location of a desired item. In contrast to previous indoor navigation systems, our approach repurposes existing markers on physical items that are already in the navigation space, meaning that no additional infrastructure is required. We evaluated the BookMark probe in a large university library, showing its potential with real library users. In addition, we illustrate how the general technique shows further potential in other similar barcode-rich environments.</p>
<p>Keywords:
barcodes; indoor navigation; libraries; piggybacking; reuse</p>
<h2 id="Interfaces for care and support    4">Interfaces for care and support    4</h2>
<h3 id="73. Taking part: role-play in the design of therapeutic systems.">73. Taking part: role-play in the design of therapeutic systems.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557103">Paper Link</a>    Pages:643-652</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Matthews:Mark">Mark Matthews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gay:Geri">Geri Gay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Doherty:Gavin">Gavin Doherty</a></p>
<p>Abstract:
Gaining an understanding of user needs is a central component of HCI design approaches such as user-centred design and participatory design. In some settings, such as mental health care, access to end-users is often constrained. This is a particular difficulty given that the experience of those with mental illness can be difficult for researchers to understand, and is further complicated by its associated stigma. In addition, the therapeutic setting is outside the common experience of most people and protected from outside intrusion. Although role-play has been used in varied ways in HCI, rarely has it been defined with sufficient clarity to enable others to deploy it in a nuanced manner. We argue that role-play is particularly suited for use in mental healthcare settings and, when used judiciously, can address some of the difficulties associated with working in this setting. This paper details a range of role-play formats appropriated from therapeutic role-play, drawing upon the HCI and mental health literature, therapist input and our experience of using role-play for a number of purposes at different stages of the development process. We consider how and why role-play can be used to generate empathy, gain understanding of therapy, provide feedback on designs before clinical use and help train therapists in using technology in the treatment room.</p>
<p>Keywords:
design; healthcare; mental health; role-play; therapy</p>
<h3 id="74. Staccato social support in mobile health applications.">74. Staccato social support in mobile health applications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557297">Paper Link</a>    Pages:653-662</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Adams:Phil">Phil Adams</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baumer:Eric_P=_S=">Eric P. S. Baumer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gay:Geri">Geri Gay</a></p>
<p>Abstract:
Social support plays an important role in health systems. While significant work has explored the role of social support in CMC environments, less analysis has considered social support in mobile health systems. This paper describes socially supportive messages in VERA, a mobile application for sharing health decisions and behaviors. The short and bursty interactions in social awareness streams [36] afford a particular style of social support, for which we offer the label staccato social support. Results indicate that, in comparison to previous work, staccato social support is characterized by a greater prevalence of esteem support, which builds respect and confidence. We further note the presence of 'following up', a positive behavior that contributes to supportive interactions, likely via social pressure and accountability [7,38]. These findings suggest design recommendations to developers of mobile social support systems and contribute to understanding technologically mediated social support for health.</p>
<p>Keywords:
mobile health; social support; user experience</p>
<h3 id="75. My journey compass: a preliminary investigation of a mobile tool for cancer patients.">75. My journey compass: a preliminary investigation of a mobile tool for cancer patients.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557194">Paper Link</a>    Pages:663-672</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jacobs:Maia_L=">Maia L. Jacobs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Clawson:James">James Clawson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mynatt:Elizabeth_D=">Elizabeth D. Mynatt</a></p>
<p>Abstract:
Health information management for cancer care is a challenging and personal process that changes over time based on one's needs, goals, and health status. While technologies supporting health information management appear promising, we do not fully understand how health information tools fit into patients? daily lives. To better understand the opportunities and usage barriers of these tools, we designed and deployed a mobile, tablet-based health management aid: My Journey Compass. After one month of use, we interviewed twelve breast cancer patients to investigate their initial patterns of adoption, adaptation, use and non-use. We found that developing a tool that was customizable, mobile, and integrated into the patients' healthcare system resulted in a set of surprising uses by breast cancer patients for a wide variety of tasks. Our study demonstrates the potential for health management tools to improve the cancer care experience and for HCI research to influence existing healthcare systems.</p>
<p>Keywords:
breast cancer; cancer navigation; mobile health</p>
<h3 id="76. An assistive robotic table for older and post-stroke adults: results from participatory design and evaluation activities with clinical staff.">76. An assistive robotic table for older and post-stroke adults: results from participatory design and evaluation activities with clinical staff.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557333">Paper Link</a>    Pages:673-682</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Threatt:Anthony">Anthony Threatt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Merino:Jessica">Jessica Merino</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Green:Keith_Evan">Keith Evan Green</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Walker:Ian_D=">Ian D. Walker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brooks:Johnell_O=">Johnell O. Brooks</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Healy:Stan">Stan Healy</a></p>
<p>Abstract:
An inevitable new frontier for the CHI community is the development of complex, larger-scale, cyber-physical artifacts where advancements in design, computing and robotics converge. Presented here is a design exemplar: the Assistive, Robotic Table (ART), the key component of our envisioned home suite of networked, robotic furnishings for hospitals and homes, promoting wellbeing and independent living. We begin with the motivations for ART, and present our iterative, five-phase, participatory design-and-evaluation process involving clinicians at a rehabilitation hospital, focusing here on the final usability study. From our wide-ranging design-research activities, which may be characterized as research through design, we found ART to be promising but also challenging. As a design exemplar, ART offers invaluable lessons to the CHI community as it comes to design larger-scale, cyber-physical artifacts cultivating interactions across people and their surroundings that define places of social, cultural and psychological significance.</p>
<p>Keywords:
assistive robotics; design research; eldercare; ethnography; healthcare; human-robot interaction design</p>
<h2 id="Research through design    4">Research through design    4</h2>
<h3 id="77. Experience design theatre: exploring the role of live theatre in scaffolding design dialogues.">77. Experience design theatre: exploring the role of live theatre in scaffolding design dialogues.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556960">Paper Link</a>    Pages:683-692</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vines:John">John Vines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Denman=Cleaver:Tess">Tess Denman-Cleaver</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dunphy:Paul">Paul Dunphy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wright:Peter_C=">Peter C. Wright</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
While theatre has been used in HCI as a tool for engaging participants in design processes, the specific benefits of using live theatre over other communicative mediums, remains underexplored. In this paper we introduce Experience Design Theatre (EDT) as an approach to undertaking experience-centered design with multiple parties in the early stages of design. EDT was motivated by a need to involve several diverse groups of people in the design of a digitally coordinated care service - NetCarers. We used live theatre as a way to engage small groups of participants in dialogues around the design of NetCarers, to qualify their contributions in a refined performance, and to communicate their concerns and aspirations to domain experts. We highlight key benefits to using live theatre in experience-centered design and offer insights for researchers undertaking similar work in the future.</p>
<p>Keywords:
ageing; care; experience-centered design; intergenerational; older people; theatre</p>
<h3 id="78. Non-finito products: a new design space of user creativity for personal user experience.">78. Non-finito products: a new design space of user creativity for personal user experience.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557222">Paper Link</a>    Pages:693-702</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Seok:Jinmin">Jinmin Seok</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Woo:Jong=bum">Jong-bum Woo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lim:Youn=Kyung">Youn-Kyung Lim</a></p>
<p>Abstract:
Conventional wisdom says that to be successful, an idea must be concrete, complete, and certain. However, what if unfinished ideas work? This CHI paper proposes a new design space we call non-finito products for the HCI community. This new design space is about intentionally unfinished products and how they foster new creations by end-users as they are actually used to help people solve their own problems. The central idea comes from the background of the growing complexity associated with IT advancement and from the new way of dealing with it, with the assistance of user creativity in the actual use of the products. This paper begins with the exploration of non-finito products as a new design space for the end-user's creativity in the personal user experience. We then defined and proposed non-finito products. We discussed three case studies that will help to understand the design space of non-finito products, and we framed the new design space by revealing the beneficial contexts and values. Finally, we suggested the implications of designing non-finito products. We believe that non-finito products will open a new design space in HCI, prompt a new means of replacing value-destroying complexity with value-creating version, and help to make a product better fit to user experience.</p>
<p>Keywords:
design perspective; non-finito product; unfinished product; user creativity; user experience</p>
<h3 id="79. Research through design fiction: narrative in real and imaginary abstracts.">79. Research through design fiction: narrative in real and imaginary abstracts.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557098">Paper Link</a>    Pages:703-712</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Blythe:Mark">Mark Blythe</a></p>
<p>Abstract:
This paper reflects on the uses of prototypes in "Research through Design" and considers "Design Fiction" as a technique for exploring the potential value of new design work. It begins with an analysis of Research through Design abstracts in the ACM digital library and identifies an emerging language and structure of papers in this emerging field. The abstracts: frame a problem space, introduce a study, often involving the deployment of a prototype, and conclude with considerations, reflections and discussion. This format is then pastiched in a series of design fictions written for a project investigating new and emerging forms of reproduction in Art. The fictions take the form of "imaginary abstracts" which summarize findings of papers that have not been written about prototypes that do not exist. It is argued that framing concept designs as fictional studies can provide a space for research focused critique and development.</p>
<p>Keywords:
design fiction; prototypes; research through design</p>
<h3 id="80. Research on research: design research at the margins: academia, industry and end-users.">80. Research on research: design research at the margins: academia, industry and end-users.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557261">Paper Link</a>    Pages:713-722</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dachtera:Juri">Juri Dachtera</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Randall:Dave_W=">Dave W. Randall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wulf:Volker">Volker Wulf</a></p>
<p>Abstract:
Design research processes often take place in publicly funded projects. Besides designers and users, public funding increasingly requires industry partners to participate in such projects. We present empirical insights from a joint research project in order to assess the claims connected with such funding structures and to report on challenges for design research within them. We identify three themes of conflict between academic and industry partners and elaborate on the sources of them. The presentation of our results builds on the distinction between 'academia' and 'industry', which is frequently applied by political funding agencies. The analysis of the respective stakeholders' actual interests, however, will prove such a dichotomy to be misleading and simplistic.</p>
<p>Keywords:
design research; joint research; mode2-research</p>
<h2 id="Pointing and cursors    4">Pointing and cursors    4</h2>
<h3 id="81. Impact of form factors and input conditions on absolute indirect-touch pointing tasks.">81. Impact of form factors and input conditions on absolute indirect-touch pointing tasks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556997">Paper Link</a>    Pages:723-732</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gilliot:J=eacute=r=eacute=mie">Jrmie Gilliot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Casiez:G=eacute=ry">Gry Casiez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roussel:Nicolas">Nicolas Roussel</a></p>
<p>Abstract:
Absolute indirect interaction maps the absolute position of a device's end-effector to the absolute position of a remote on-screen object.Despite its long-time use with graphics tablets and growing use in research prototypes, little is known on the influence of form factors and input conditions on pointing performance with such a mapping. The input and display can have different sizes and aspect ratios, for example. The on-screen targets can vary in size. Users can look solely at the display or at the input device as well. They can also hold the input device in certain cases, or let it rest on a table. This paper reports on two experiments designed to investigate the influence of all these factors on absolute indirect-touch pointing performance. We also provide design guidelines for interaction in these situations based on the observed impacting factors.</p>
<p>Keywords:
absolute pointing; form factors; indirect touch; input conditions; performance</p>
<h3 id="82. Beating the bubble: using kinematic triggering in the bubble lens for acquiring small, dense targets.">82. Beating the bubble: using kinematic triggering in the bubble lens for acquiring small, dense targets.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557410">Paper Link</a>    Pages:733-742</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mott:Martez_E=">Martez E. Mott</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a></p>
<p>Abstract:
We present the Bubble Lens, a new target acquisition technique that remedies the limitations of the Bubble Cursor to increase the speed and accuracy of acquiring small, dense targets--precisely those targets for which the Bubble Cursor degenerates to a point cursor. When targets are large and sparse, the Bubble Lens behaves like the Bubble Cursor. But when targets are small and dense, the Bubble Lens automatically magnifies nearby targets, making them larger in both visual- and motor-space. Importantly, magnification is not governed by an explicit user-invoked mode-switch. Rather, magnification is activated through kinematic triggering, a technique that continuously examines an unfolding velocity profile to automatically trigger mode changes based on observed features. In a first study, we found the Bubble Cursor performed poorly when targets had an effective size smaller than 10 pixels. Using this threshold for the Bubble Lens in a second study, we found that the Bubble Lens significantly outperformed the Bubble Cursor, decreasing movement time by 10.2% and error rates by 37.9%, making the Bubble Lens the fastest current pointing technique.</p>
<p>Keywords:
bubble cursor; kinematics; lensing; magnification; mouse pointing; pointing facilitation; pointing techniques; target acquisition; zooming</p>
<h3 id="83. Mouse pointing endpoint prediction using kinematic template matching.">83. Mouse pointing endpoint prediction using kinematic template matching.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557406">Paper Link</a>    Pages:743-752</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pasqual:Phillip_T=">Phillip T. Pasqual</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wobbrock:Jacob_O=">Jacob O. Wobbrock</a></p>
<p>Abstract:
We present a new method of predicting the endpoints of mouse movements. While prior approaches to endpoint prediction have relied upon normative kinematic laws, regression, or control theory, our approach is straightforward but kinematically rich. Our key insight is to regard the unfolding velocity profile of a pointing movement as a 2-D stroke gesture and to use template matching to predict the endpoint based on prior observed movements. We call our technique kinematic template matching (KTM), which is simple to implement, user-adaptable, and kinematically expressive. In a study of 17 able-bodied participants evaluated over movement amplitudes ranging from 100-800 pixels, we found KTM to predict endpoints that were within 83 pixels of the true endpoint at 50% of the way through the movement, within 48 pixels at 75%, and within 39 pixels at 90%, using 1000 templates per participant. These accuracies make KTM as successful an approach to endpoint prediction as any prior technique, while being easier to implement and understand than most.</p>
<p>Keywords:
endpoint prediction; kinematics; mouse pointing; target prediction; template matching</p>
<h3 id="84. The implicit fan cursor: a velocity dependent area cursor.">84. The implicit fan cursor: a velocity dependent area cursor.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557095">Paper Link</a>    Pages:753-762</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Su:Xiaojun">Xiaojun Su</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Au:Oscar_Kin=Chung">Oscar Kin-Chung Au</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lau:Rynson_W=_H=">Rynson W. H. Lau</a></p>
<p>Abstract:
We present the Implicit Fan Cursor (IFC) - a novel target pointing technique using a cursor with a fan-shape activation area. The IFC couples the cursor's activation area with its velocity, i.e., the speed and direction of the mouse motion, behaving like a 2D spotlight cursor at low speed and a circular area cursor at high speed. Thus, it enables the user to precisely acquire distant targets at low speed and easily acquire nearest targets at high speed, without explicit mode switching. This technique minimizes cursor movement, while taking into consideration of the precision of cursor movement at different speeds. It also ensures that only one target is captured at any time. The results of our controlled experiments show that the IFC outperforms the point cursor and the area cursor techniques, particularly in terms of cursor moving distance, and that its performance can be accurately modeled using the Fitts' law.</p>
<p>Keywords:
area cursor; fitts' law; implicit fan cursor; velocity-aware pointing</p>
<h2 id="Always connected: email and social media    4">Always connected: email and social media    4</h2>
<h3 id="85. The product of availability: understanding the economic underpinnings of constant connectivity.">85. The product of availability: understanding the economic underpinnings of constant connectivity.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557381">Paper Link</a>    Pages:763-772</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mazmanian:Melissa">Melissa Mazmanian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Erickson:Ingrid">Ingrid Erickson</a></p>
<p>Abstract:
Constant connectivity and total availability to clients is the rule rather than the exception in many contemporary workplaces. Enabled by developments in information and communication technologies (ICTs), total availability of employees is possible and presumed. Scholars have explored how new technological affordances, cultural shifts, individual personality traits, and/or the development of social expectations that reinforce norms of constant connectivity have led to this state of affairs. We argue that a key factor has been overlooked in current scholarship about stress, intensive work, and constant connectivity. That is, current economic conditions are creating a marketplace in which firms increasing sell the availability of their employees as part of the services offered by the firm. In this paper we use qualitative data to illustrate how total availability is an integral aspect of the 'product' offered by professional service firms and is becoming increasingly prevalent in other service industries. We conclude with a discussion of how the HCI community might address this situation as a design challenge. Drawing on the work of Goffman and Perlow, we suggest that designers attend to the ways in which organizations might maintain front stage impressions of total availability while collectively managing individual time to restrict total availability behind the scenes.</p>
<p>Keywords:
economic constraints; knowledge work; markets of availability; mobile technology; service work; time and temporality</p>
<h3 id="86. Giving up Twitter for Lent: how and why we take breaks from social media.">86. Giving up Twitter for Lent: how and why we take breaks from social media.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556983">Paper Link</a>    Pages:773-782</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schoenebeck:Sarita_Yardi">Sarita Yardi Schoenebeck</a></p>
<p>Abstract:
Social media use is widespread, but many people worry about overuse. This paper explores how and why people take breaks from social media. Using a mixed methods approach, we pair data from users who tweeted about giving up Twitter for Lent with an interview study of social media users. We find that 64% of users who proclaim that they are giving up Twitter for Lent successfully do so. Among those who fail, 31% acknowledge their failure; the other 69% simply return. We observe hedging patterns (e.g. "I thought about giving up Twitter for Lent but"?) that surfaced uncertainty about social media behavior. Interview participants were concerned about the tradeoffs of spending time on social media versus doing other things and of spending time on social media rather than in "real life." We discuss gaps in related theory that might help reduce users' anxieties and open design problems related to designing systems and services that can help users manage their own social media use.</p>
<p>Keywords:
Twitter; breaks; internet; media refusal; self-control; social media; willpower</p>
<h3 id="87. MinEMail: SMS alert system for managing critical emails.">87. MinEMail: SMS alert system for managing critical emails.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557182">Paper Link</a>    Pages:783-792</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rector:Kyle">Kyle Rector</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hailpern:Joshua_M=">Joshua M. Hailpern</a></p>
<p>Abstract:
Email is the primary method of digital communication for most people, but the overwhelming quantity has led to a poverty of attention. Existing manual and automatic solutions that aim to save important emails from falling through the cracks have begun to address this problem, but may increase user workload, sacrifice efficiency, or fail to identify high value communications. In response, we developed MinEMail, an alert system that uses a text message (SMS) to remind and notify users of critical emails that may have been missed or forgotten. MinEMail provides an alert infrastructure as well as accurately labeling and predicting which emails are critical, and when and how they need to be addressed. To motivate our system, we also present an up-front study with 777 participants that aims to understand the state and limitations of email and SMS in enterprise. We conduct an experience sampling study of over 3000 emails in order to construct MinEMail's predictive models. Finally, we present the results from a 15 user ecologically valid real-world deployment of MinEMail in enterprise.</p>
<p>Keywords:
email; information overload; personal information management; sms</p>
<h3 id="88. Overload is overloaded: email in the age of Gmail.">88. Overload is overloaded: email in the age of Gmail.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557013">Paper Link</a>    Pages:793-802</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Grevet:Catherine">Catherine Grevet</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Choi:David">David Choi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kumar:Debra">Debra Kumar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gilbert:Eric">Eric Gilbert</a></p>
<p>Abstract:
The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.</p>
<p>Keywords:
email overload; management strategies; organization; qualitative study; work and personal email</p>
<h2 id="Smart homes and sustainability    3">Smart homes and sustainability    3</h2>
<h3 id="89. Practical trigger-action programming in the smart home.">89. Practical trigger-action programming in the smart home.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557420">Paper Link</a>    Pages:803-812</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/u/Ur:Blase">Blase Ur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McManus:Elyse">Elyse McManus</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Ho:Melwyn_Pak_Yong">Melwyn Pak Yong Ho</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Littman:Michael_L=">Michael L. Littman</a></p>
<p>Abstract:
We investigate the practicality of letting average users customize smart-home devices using trigger-action ("if, then") programming. We find trigger-action programming can express most desired behaviors submitted by participants in an online study. We identify a class of triggers requiring machine learning that has received little attention. We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that real users have written a large number of unique trigger-action interactions. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.</p>
<p>Keywords:
condition-action programming; end-user programming; home automation; internet of things; smart home</p>
<h3 id="90. Doing the laundry with agents: a field trial of a future smart energy system in the home.">90. Doing the laundry with agents: a field trial of a future smart energy system in the home.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557167">Paper Link</a>    Pages:813-822</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Costanza:Enrico">Enrico Costanza</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fischer:Joel_E=">Joel E. Fischer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Colley:James_A=">James A. Colley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rodden:Tom">Tom Rodden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramchurn:Sarvapali_D=">Sarvapali D. Ramchurn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jennings:Nicholas_R=">Nicholas R. Jennings</a></p>
<p>Abstract:
Future energy systems that rely on renewable energy may bring about a radical shift in how we use energy in our homes. We developed and prototyped a future scenario with highly variable, real-time electricity prices due to a grid that mainly relies on renewables. We designed and deployed an agent-based interactive system that enables users to effectively operate the washing machine in this scenario. The system is used to book timeslots of washing machine use so that the agent can help to minimize the cost of a wash by charging a battery at times when electricity is cheap. We carried out a deployment in 10 households in order to uncover the socio-technical challenges around integrating new technologies into everyday routines. The findings reveal tensions that arise when deploying a rationalistic system to manage contingently and socially organized domestic practices. We discuss the trade-offs between utility and convenience inherent in smart grid applications; and illustrate how certain design choices position applications along this spectrum.</p>
<p>Keywords:
autonomous agents; demand response; energy; field trial; real-time pricing; smart grid</p>
<h3 id="91. Making sustainability sustainable: challenges in the design of eco-interaction technologies.">91. Making sustainability sustainable: challenges in the design of eco-interaction technologies.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557380">Paper Link</a>    Pages:823-832</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Rayoung">Rayoung Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Newman:Mark_W=">Mark W. Newman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a></p>
<p>Abstract:
The smart home is here. One area where smart home devices promise to deliver great benefits is in the control of home heating, ventilation, and cooling (HVAC) systems. In this paper, we seek to inform the design of future heating and cooling systems by investigating users' experiences with the Nest Learning Thermostat, a commercially available smart home device. We conducted a qualitative study where we compared people's interactions with conventional thermostats with interactions with the Nest. A key finding was that the Nest impacted users' pattern of HVAC control, but only for a while, and caused new problems in unrealized energy savings. In leveraging these findings, we create a set of design implications for Eco-Interaction, the design of features and human-system interactions with the goal of saving energy.</p>
<p>Keywords:
eco-interaction; smart home; sustainability; thermostat</p>
<h2 id="Multilingual communication    4">Multilingual communication    4</h2>
<h3 id="92. Global connectivity and multilinguals in the Twitter network.">92. Global connectivity and multilinguals in the Twitter network.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557203">Paper Link</a>    Pages:833-842</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hale:Scott_A=">Scott A. Hale</a></p>
<p>Abstract:
This article analyzes the global connectivity of the Twitter retweet and mentions network and the role of multilingual users engaging with content in multiple languages. The network is heavily structured by language with most mentions and retweets directed to users writing in the same language. Users writing in multiple languages are more active, authoring more tweets than monolingual users. These multilingual users play an important bridging role in the global connectivity of the network. The mean level of insularity from speakers in each language does not correlate straightforwardly with the size of the user base as predicted by previous research. Finally, the English language does play more of a bridging role than other languages, but the role played collectively by multilingual users across different languages is the largest bridging force in the network.</p>
<p>Keywords:
cross-language; information diffusion; information discovery; micro-blogs; multilingual; social media; social network analysis</p>
<h3 id="93. Effects of public vs. private automated transcripts on multiparty communication between native and non-native english speakers.">93. Effects of public vs. private automated transcripts on multiparty communication between native and non-native english speakers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557303">Paper Link</a>    Pages:843-852</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gao:Ge">Ge Gao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yamashita:Naomi">Naomi Yamashita</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hautasaari:Ari_M=_J=">Ari M. J. Hautasaari</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Echenique:Andy">Andy Echenique</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fussell:Susan_R=">Susan R. Fussell</a></p>
<p>Abstract:
Real-time transcripts generated by automated speech recognition (ASR) technologies have the potential to facilitate communication between native speakers (NS) and non-native speakers (NNS). Previous studies of ASR have focused on how transcripts aid NNS speech comprehension. In this study, we examine whether transcripts benefit multiparty real-time conversation between NS and NNS. We hypothesized that ASR transcripts would be more beneficial when the transcripts were publicly shared by all group members as opposed to when they were seen only by the NNS. To test our hypothesis, we conducted a lab experiment in which 14 groups of native and non-native speakers engaged in a story-telling task. Half of the groups received private transcripts that were available only to the NNS; the other half received publicly shared transcripts that were available to all group members. NS spoke more clearly, and both NS and NNS rated the quality of communication higher, when transcripts were publicly shared. These findings inform the design of future tools to support multilingual group communication.</p>
<p>Keywords:
automated speech recognition; multilingual communication; real-time transcripts</p>
<h3 id="94. Smart subtitles for vocabulary learning.">94. Smart subtitles for vocabulary learning.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557256">Paper Link</a>    Pages:853-862</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kovacs:Geza">Geza Kovacs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Robert_C=">Robert C. Miller</a></p>
<p>Abstract:
Language learners often use subtitled videos to help them learn. However, standard subtitles are geared more towards comprehension than vocabulary learning, as translations are nonliteral and are provided only for phrases, not vocabulary. This paper presents Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning. Smart Subtitles can be automatically generated from common video sources such as subtitled DVDs. They provide features such as vocabulary definitions on hover, and dialog-based video navigation. In our pilot study with intermediate learners studying Chinese, participants correctly defined over twice as many new words in a post-viewing vocabulary test when they used Smart Subtitles, compared to dual Chinese-English subtitles. Learners spent the same amount of time watching clips with each tool, and enjoyed viewing videos with Smart Subtitles as much as with dual subtitles. Learners understood videos equally well using either tool, as indicated by self-assessments and independent evaluations of their summaries.</p>
<p>Keywords:
interactive videos; language learning; subtitles</p>
<h3 id="95. Using annotations in online group chats.">95. Using annotations in online group chats.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557209">Paper Link</a>    Pages:863-866</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Li:Na">Na Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rosson:Mary_Beth">Mary Beth Rosson</a></p>
<p>Abstract:
Annotating documents has long been a widely used strategy for distilling important contents and externalizing related thoughts and ideas in context. No one has studied the activity of annotating dynamic texts, such as online chat, although online conversation is an important communication media for global companies. In this paper, we investigate Instant Annotation (IA), a real-time annotation-enhanced chat tool. We contrast the use of the enhanced chat tool to a standard chat tool for multilingual groups doing a brainstorming and decision-making task. Results show that group satisfaction and perceived control of the conversation are enhanced for the participants who used IA. We also report new patterns of annotation use and discuss design implications for group chat tools.</p>
<p>Keywords:
conversation control; design; evaluation; instant annotation</p>
<h2 id="Interactive visualization and visual elements    4">Interactive visualization and visual elements    4</h2>
<h3 id="96. Visualizing dynamic networks with matrix cubes.">96. Visualizing dynamic networks with matrix cubes.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557010">Paper Link</a>    Pages:877-886</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bach:Benjamin">Benjamin Bach</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pietriga:Emmanuel">Emmanuel Pietriga</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fekete:Jean=Daniel">Jean-Daniel Fekete</a></p>
<p>Abstract:
Designing visualizations of dynamic networks is challenging, both because the data sets tend to be complex and because the tasks associated with them are often cognitively demand- ing. We introduce the Matrix Cube, a novel visual representation and navigation model for dynamic networks, inspired by the way people comprehend and manipulate physical cubes. Users can change their perspective on the data by rotating or decomposing the 3D cube. These manipulations can produce a range of different 2D visualizations that emphasize specific aspects of the dynamic network suited to particular analysis tasks. We describe Matrix Cubes and the interactions that can be performed on them in the Cubix system. We then show how two domain experts, an astronomer and a neurologist, used Cubix to explore and report on their own network data.</p>
<p>Keywords:
dynamic networks; information visualization; interaction; metaphors; multiple views</p>
<h3 id="97. A table!: improving temporal navigation in soccer ranking tables.">97. A table!: improving temporal navigation in soccer ranking tables.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557379">Paper Link</a>    Pages:887-896</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Perin:Charles">Charles Perin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vuillemot:Romain">Romain Vuillemot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fekete:Jean=Daniel">Jean-Daniel Fekete</a></p>
<p>Abstract:
This article introduces A Table!, an enhanced soccer ranking table providing temporal navigation by combining two novel interaction techniques. Ranking tables order soccer teams represented as rows, according to values of columns containing attributes e.g., accumulated points, or number of scored goals. Because they represent a snapshot of a championship at a time t, tables are regularly updated with new results. Such updates usually change the rows order, which makes the tracking of a specified team over time difficult. We observed that the tables available on the web do not support tracking such changes very well, are generally hard to read, and lack interactions. This contrasts with the extensive use of comments on temporal trends found in soccer analysts articles. To better support such analyzes, the two interactive techniques presented allow exploration of time, and are designed to preserve users' flow: DRAG-CELL is based on direct manipulation of values to browse ranks; VIZ-RANK uses a transient line chart of team ranks to visually explore a championship. An on-line evaluation with 143 participants shows that each technique efficiently supports a set of important temporal tasks not supported by current ranking tables. This paves the way for introducing efficient advanced visual exploration techniques to millions of soccer enthusiasts who use tables everyday.</p>
<p>Keywords:
ranking tables; soccer; temporal navigation; visualization</p>
<h3 id="98. Kinetica: naturalistic multi-touch data visualization.">98. Kinetica: naturalistic multi-touch data visualization.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557231">Paper Link</a>    Pages:897-906</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rzeszotarski:Jeffrey_M=">Jeffrey M. Rzeszotarski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a></p>
<p>Abstract:
Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.</p>
<p>Keywords:
multi-touch; multivariate data; physics; visualization</p>
<h3 id="99. Traffigram: distortion for clarification via isochronal cartography.">99. Traffigram: distortion for clarification via isochronal cartography.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557224">Paper Link</a>    Pages:907-916</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Sungsoo_=Ray=">Sungsoo (Ray) Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Yea=Seul">Yea-Seul Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yoon:Jong=Chul">Jong-Chul Yoon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aragon:Cecilia_R=">Cecilia R. Aragon</a></p>
<p>Abstract:
Most geographic maps visually represent physical distance; however, travel time can in some cases be more important than distance because it directly indicates availability. The technique of creating maps from temporal data is known as isochronal cartography, and is a form of distortion for clarification. In an isochronal map, congestion expands areas, while ideal travel conditions make the map shrink in comparison to the actual distance scale of a traditional map. Although there have been many applications of this technique, detailed user studies of its efficacy remain scarce, and there are conflicting views on its practical value. To attempt to settle this issue, we utilized a user-centered design process to determine which features of isochronal cartography might be most usable in practice. We developed an interactive cartographic visualization system, Traffigram, that features a novel combination of efficient isochronal map algorithms and an interface designed to give map users a quick and seamless experience while preserving geospatial integrity and aesthetics. We validated our design choices with multiple usability studies. We present our results and discuss implications for design.</p>
<p>Keywords:
geographic visualization; information visualization; isochrones; map usage; map user interface; time-space map</p>
<h2 id="Understanding and designing games    5">Understanding and designing games    5</h2>
<h3 id="100. Understanding procedural content generation: a design-centric analysis of the role of PCG in games.">100. Understanding procedural content generation: a design-centric analysis of the role of PCG in games.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557341">Paper Link</a>    Pages:917-926</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Gillian">Gillian Smith</a></p>
<p>Abstract:
Games that use procedural content generation (PCG) do so in a wide variety of ways and for different reasons. One of the most common reasons cited by PCG system creators and game designers is improving replayability by providing a means for automatically creating near-infinite amounts of content, the player can come back and replay the game and refine her strategies over a long period. However, this notion of replayability is both overly broad and incomplete as a motivation. This paper contributes an analytical framework and associated common vocabulary for understanding the role of PCG in games from a design standpoint, with an aim of unpacking some of the broad justifications for PCG use in games, and bringing together technical concerns in designing PCG systems with design concerns related to creating engaging playable experiences.</p>
<p>Keywords:
game ai; game design; game design theory.; mda framework; procedural content generation</p>
<h3 id="101. A systematic review of quantitative studies on the enjoyment of digital entertainment games.">101. A systematic review of quantitative studies on the enjoyment of digital entertainment games.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557078">Paper Link</a>    Pages:927-936</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mekler:Elisa_D=">Elisa D. Mekler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bopp:Julia_Ayumi">Julia Ayumi Bopp</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tuch:Alexandre_N=">Alexandre N. Tuch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Opwis:Klaus">Klaus Opwis</a></p>
<p>Abstract:
Enjoyment has been identified as a central component of the player experience (PX), but various, overlapping concepts within PX make it difficult to develop valid measures and a common understanding of game enjoyment. We conducted a systematic review of 87 quantitative studies, analyzing different operationalizations and measures of game enjoyment, its determinants, and how these were related to other components of PX, such as flow, presence and immersion. Results suggest that game enjoyment describes the positive cognitive and affective appraisal of the game experience, and may in part be associated with the support of player needs and values. Further, we outline that enjoyment is distinct from flow in that it may occur independently of challenge and cognitive involvement, and argue that enjoyment may be understood as the valence of the player experience. We conclude with a discussion of methodological challenges and point out opportunities for future research on game enjoyment.</p>
<p>Keywords:
digital games; enjoyment; flow; player experience</p>
<h3 id="102. The effectiveness (or lack thereof) of aim-assist techniques in first-person shooter games.">102. The effectiveness (or lack thereof) of aim-assist techniques in first-person shooter games.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557308">Paper Link</a>    Pages:937-946</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vicencio=Moreira:Rodrigo">Rodrigo Vicencio-Moreira</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bateman:Scott">Scott Bateman</a></p>
<p>Abstract:
Aim-assistance techniques have been shown to work for player balancing in 2D environments, but little information exists about how well these techniques will work in a 3D FPS game. We carried out three studies of the performance of five different aim assists in an Unreal-based game world. The assists worked well in a target-range scenario (study 1), but their performance was reduced when game elements were introduced in a walkthrough map (study 2). We systematically examined the relationships between realistic game elements and assist performance (study 3). These studies show that two techniques -- bullet magnetism and area cursor -- worked well in a wide variety of situations. Other techniques that worked well were too perceptible, and some previously-successful techniques did not work well in any game-like scenario. Our studies are the first to provide empirical evidence of the performance of aim assist techniques in 3D environments, and the first to identify the complexities in using these techniques in real FPS games.</p>
<p>Keywords:
aim assistance; first-person shooter games; game balancing</p>
<h3 id="103. Design tactics for authentic interactive fiction: insights from alternate reality game designers.">103. Design tactics for authentic interactive fiction: insights from alternate reality game designers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557245">Paper Link</a>    Pages:947-950</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bonsignore:Elizabeth_M=">Elizabeth M. Bonsignore</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moulder:Vicki">Vicki Moulder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Neustaedter:Carman">Carman Neustaedter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hansen:Derek_L=">Derek L. Hansen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraus:Kari">Kari Kraus</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Druin:Allison">Allison Druin</a></p>
<p>Abstract:
This paper presents insights from designers of Alternate Reality Games (ARGs) regarding the design tactics they employ to integrate participatory storytelling and "authentic fiction" into the transmedia experiences they create. Our approach was motivated by recent efforts in HCI to more closely align the development of interaction design theory to the craft knowledge and experiences of designers themselves. The resulting insights enhance our understanding of design approaches that a diverse group of ARG producers follow to create interactive, participatory narratives. We outline narrative-specific themes to support designers who craft similar interactive experiences.</p>
<p>Keywords:
alternate reality games; narrative design; transmedia</p>
<h3 id="104. Jump and shoot!: prioritizing primary and alternative body gestures for intense gameplay.">104. Jump and shoot!: prioritizing primary and alternative body gestures for intense gameplay.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557107">Paper Link</a>    Pages:951-954</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Silpasuwanchai:Chaklam">Chaklam Silpasuwanchai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ren:Xiangshi">Xiangshi Ren</a></p>
<p>Abstract:
Motion gestures enable natural and intuitive input in video games. However, game gestures designed by developers may not always be the optimal gestures for players. A key challenge in designing appropriate game gestures lies in the interaction-intensive nature of video games, i.e., several actions/commands may need to be executed concurrently using different body parts. This study analyzes user preferences in game gestures, with the aim of accommodating high interactivity during gameplay. Two user-elicitation studies were conducted: first, to determine user preferences, participants were asked to define gestures for common game actions/commands; second, to develop effective combined-gestures, participants were asked to define possible game gestures using each body part (one and two hands, one and two legs, head, eyes, and torso). Our study presents a set of suitable and alternative body parts for common game actions/commands. We also present some simultaneously applied game gestures that assist interaction in highly interactive game situations (e.g., selecting a weapon with the feet while shooting with the hand). Interesting design implications are further discussed, e.g., transferability between hand and leg gestures.</p>
<p>Keywords:
concurrent gestures; games; interactivity; motion gestures; user-defined approach</p>
<h2 id="Personal values and preferences    6">Personal values and preferences    6</h2>
<h3 id="105. KnowMe and ShareMe: understanding automatically discovered personality traits from social media and user sharing preferences.">105. KnowMe and ShareMe: understanding automatically discovered personality traits from social media and user sharing preferences.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557398">Paper Link</a>    Pages:955-964</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gou:Liang">Liang Gou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhou:Michelle_X=">Michelle X. Zhou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Huahai">Huahai Yang</a></p>
<p>Abstract:
There is much recent work on using the digital footprints left by people on social media to predict personal traits and gain a deeper understanding of individuals. Due to the veracity of social media, imperfections in prediction algorithms, and the sensitive nature of one's personal traits, much research is still needed to better understand the effectiveness of this line of work, including users' preferences of sharing their computationally derived traits. In this paper, we report a two- part study involving 256 participants, which (1) examines the feasibility and effectiveness of automatically deriving three types of personality traits from Twitter, including Big 5 personality, basic human values, and fundamental needs, and (2) investigates users' opinions of using and sharing these traits. Our findings show there is a potential feasibility of automatically deriving one's personality traits from social media with various factors impacting the accuracy of models. The results also indicate over 61.5% users are willing to share their derived traits in the workplace and that a number of factors significantly influence their sharing preferences. Since our findings demonstrate the feasibility of automatically inferring a user's personal traits from social media, we discuss their implications for designing a new generation of privacy-preserving, hyper-personalized systems.</p>
<p>Keywords:
basic values; big 5 personality; fundamental needs; personality traits; privacy; social media</p>
<h3 id="106. Faces engage us: photos with faces attract more likes and comments on Instagram.">106. Faces engage us: photos with faces attract more likes and comments on Instagram.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557403">Paper Link</a>    Pages:965-974</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bakhshi:Saeideh">Saeideh Bakhshi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shamma:David_A=">David A. Shamma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gilbert:Eric">Eric Gilbert</a></p>
<p>Abstract:
Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing production and distribution. One common type of photo content that is shared on social media, is the photos of people. From studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how presence of a face, it's age and gender might impact social engagement on the photo. We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. This work presents the first results on how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.</p>
<p>Keywords:
age; content; demographics; engagement; face detection; faces; gender; image; image sharing community; instagram; mobile; photo; social media</p>
<h3 id="107. Photo sharing of the subject, by the owner, for the viewer: examining the subject's preference.">107. Photo sharing of the subject, by the owner, for the viewer: examining the subject's preference.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557247">Paper Link</a>    Pages:975-978</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Auk">Auk Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gweon:Gahgene">Gahgene Gweon</a></p>
<p>Abstract:
Photo sharing activities on social networking sites concern not only the person sharing the information (owner) and the person receiving the information (viewer) but also the person who is in the photo (subject). In our exploratory lab study, we asked 29 participants about their comfort level in allowing a photo owner to share a picture containing both the participant (subject) and the owner. Our results show that the photo subject feels more comfortable in sharing a photo when i) the "closeness between the subject and the owner (SO closeness)" is higher, and ii) the "closeness between the subject and the viewer (SV closeness)" is higher. In addition, we observed that both SV and SO closeness are important in determining the subject's picture sharing preference level.</p>
<p>Keywords:
closeness; information sharing preference</p>
<h3 id="108. Does content determine information popularity in social media?: a case study of youtube videos' content and their popularity.">108. Does content determine information popularity in social media?: a case study of youtube videos' content and their popularity.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557285">Paper Link</a>    Pages:979-982</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Figueiredo:Flavio">Flavio Figueiredo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Almeida:Jussara_M=">Jussara M. Almeida</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benevenuto:Fabr=iacute=cio">Fabrcio Benevenuto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gummadi:Krishna_P=">Krishna P. Gummadi</a></p>
<p>Abstract:
We here investigate what drives the popularity of information on social media platforms. Focusing on YouTube, we seek to understand the extent to which content by itself determines a video's popularity. Using mechanical turk as experimental platform, we asked users to evaluate pairs of videos, and compared users' relative perception of the videos' content against their relative popularity reported by YouTube. We found that in most evaluations users could not reach consensus on which video had better content as their perceptions tend to be very subjective. Nevertheless, when consensus was reached, the video with preferred content almost always achieved greater popularity on YouTube, highlighting the importance of content in driving information popularity on social media.</p>
<p>Keywords:
content popularity; social media; user study</p>
<h3 id="109. You read what you value: understanding personal values and reading interests.">109. You read what you value: understanding personal values and reading interests.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556995">Paper Link</a>    Pages:983-986</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hsieh:Gary">Gary Hsieh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Jilin">Jilin Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mahmud:Jalal">Jalal Mahmud</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nichols:Jeffrey">Jeffrey Nichols</a></p>
<p>Abstract:
This paper presents an experiment on the relationship between personal values and reading interests of online articles. Results suggest that individuals' values can predict their topical interests. For example, holding stronger universalism values predict interests towards environmental articles, whereas holding stronger achievement values predict interest towards work-related articles. Findings demonstrate the possibility of targeting based on individuals' personal values, but also highlight certain challenges and limitations when applying this approach for online content.</p>
<p>Keywords:
content targeting; personal values; reading interest; twitter</p>
<h3 id="110. Gaining empathy for non-routine mobile device use through autoethnography.">110. Gaining empathy for non-routine mobile device use through autoethnography.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557179">Paper Link</a>    Pages:987-990</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/O=Kane:Aisling_Ann">Aisling Ann O'Kane</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Yvonne">Yvonne Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blandford:Ann_E=">Ann E. Blandford</a></p>
<p>Abstract:
In this paper, we report on autoethnography as a method to access non-routine usage of mobile devices, such as during business trips, vacations, etc. Autoethnography, a self-study method with the researcher as participant, was employed for the evaluation of a wrist blood pressure monitor used by people with conditions such as hypertension. The findings from the study were surprising, especially with respect to the environmental and social impact on the use of the technology. Although the autoethnographic method can be disruptive for the researcher, it enables them to understand and empathize with the experiences mobile device users can face in difficult to access contexts. This method allows HCI researchers to better understand user experiences with mobile devices, including mobile medical technology, especially during non-routine times that can be difficult to study in-situ with traditional user studies.</p>
<p>Keywords:
autoethnography; context; empathy; healthcare.; mobile</p>
<h2 id="Enabling interactive performances    5">Enabling interactive performances    5</h2>
<h3 id="111. Designing for movement: evaluating computational models using LMA effort qualities.">111. Designing for movement: evaluating computational models using LMA effort qualities.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557251">Paper Link</a>    Pages:991-1000</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Maranan:Diego_Silang">Diego Silang Maranan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alaoui:Sarah_Fdili">Sarah Fdili Alaoui</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schiphorst:Thecla">Thecla Schiphorst</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pasquier:Philippe">Philippe Pasquier</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subyen:Pattarawut">Pattarawut Subyen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bartram:Lyn">Lyn Bartram</a></p>
<p>Abstract:
While single-accelerometers are a common consumer embedded sensors, their use in representing movement data as an intelligent resource remains scarce. Accelerometers have been used in movement recognition systems, but rarely to assess expressive qualities of movement. We present a prototype of wearable system for the real-time detection and classification of movement quality using acceleration data. The system applies Laban Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input using a Machine Learning software that generates classifications in real time. Existing LMA-recognition systems rely on motion capture data and video data, and can only be deployed in controlled settings. Our single-accelerometer system is portable and can be used under a wide range of environmental conditions. We evaluate the performance of the system, present two applications using the system in the digital arts and discuss future directions.</p>
<p>Keywords:
laban effort analysis; movement analysis; movement recognition; movement-based interaction.</p>
<h3 id="112. The vocal chorder: empowering opera singers with a large interactive instrument.">112. The vocal chorder: empowering opera singers with a large interactive instrument.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557050">Paper Link</a>    Pages:1001-1010</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/u/Unander=Scharin:Carl">Carl Unander-Scharin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/u/Unander=Scharin:=Aring=sa">sa Unander-Scharin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=ouml==ouml=k:Kristina">Kristina Hk</a></p>
<p>Abstract:
With The Vocal Chorder, a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations, some on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how opera performances can change with a bodily-oriented instrument such as The Vocal Chorder. Through a designerly exploration, we arrived at a device that offered (1) a tool for singers to take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage.</p>
<p>Keywords:
appropriation; autobiographical design; embodiment; empowerment; interactive instruments; opera</p>
<h3 id="113. Let me catch this!: experiencing interactive 3D cinema through collecting content with a mobile phone.">113. Let me catch this!: experiencing interactive 3D cinema through collecting content with a mobile phone.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557187">Paper Link</a>    Pages:1011-1020</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/H=auml=kkil=auml=:Jonna">Jonna Hkkil</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Posti:Maaret">Maaret Posti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schneegass:Stefan">Stefan Schneegass</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alt:Florian">Florian Alt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gultekin:Kunter">Kunter Gultekin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
The entertainment industry is going through a transformation, and technology development is affecting how we can enjoy and interact with the entertainment media content in new ways. In our work, we explore how to enable interaction with content in the context of 3D cinemas. This allows viewers to use their mobile phone to retrieve, for example, information on the artist of the soundtrack currently playing or a discount coupon on the watch the main actor is wearing. We are particularly interested in the user experience of the interactive 3D cinema concept, and how different interactive elements and interaction techniques are perceived. We report on the development of a prototype application utilizing smart phones and on an evaluation in a cinema context with 20 participants. Results emphasize that designing for interactive cinema experiences should drive for holistic and positive user experiences. Interactive content should be tied together with the actual video content, but integrated into contexts where it does not conflict with the immersive experience with the movie.</p>
<p>Keywords:
3d; interactive cinema; mobile phone interaction; user experience; user studies</p>
<h3 id="114. Coding livecoding.">114. Coding livecoding.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557049">Paper Link</a>    Pages:1021-1024</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Swift:Ben">Ben Swift</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sorensen:Andrew">Andrew Sorensen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Martin:Michael_A=">Michael A. Martin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gardner:Henry_J=">Henry J. Gardner</a></p>
<p>Abstract:
Livecoding is an artistic programming practice in which an artist's low-level interaction can be observed with sufficiently high fidelity to allow for transcription and analysis. This paper presents the first reported "coding" of livecoding videos. From an identified corpus of videos available on the web, we coded performances of two different livecoding artists, recording both the (textual) programming edit events and the musical effect of these edits. Our analysis includes a novel, transition-matrix visualisation of the textual and musical dimensions of this data to create a "performer fingerprint". We show how detailed transcriptions of livecoding videos can be made which, we hope, will provide a foundation for further research into describing and understanding livecoding.</p>
<p>Keywords:
creativity support tools; end-user programming</p>
<h3 id="115. Exploring percussive gesture on iPads with ensemble metatone.">115. Exploring percussive gesture on iPads with ensemble metatone.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557226">Paper Link</a>    Pages:1025-1028</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Martin:Charles">Charles Martin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gardner:Henry_J=">Henry J. Gardner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Swift:Ben">Ben Swift</a></p>
<p>Abstract:
Percussionists are unique among western classical instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble. This paper examines Ensemble Metatone, a group formed to explore the "infiltration" of iPad-based musical instruments into a free-improvisation percussion ensemble. We discuss the design approach for two different iPad percussion instruments and the methodology for exploring them with the group over a series of rehearsals and performances. Qualitative analysis of discussions throughout this process shows that the musicians developed a vocabulary of gestures and musical interactions to make musical sense of these new instruments.</p>
<p>Keywords:
expression; gesture; multitouch; music; percussion; user experience</p>
<h2 id="Battery life and energy harvesting    4">Battery life and energy harvesting    4</h2>
<h3 id="116. How carat affects user behavior: implications for mobile battery awareness applications.">116. How carat affects user behavior: implications for mobile battery awareness applications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557271">Paper Link</a>    Pages:1029-1038</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Athukorala:Kumaripaba">Kumaripaba Athukorala</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lagerspetz:Eemil">Eemil Lagerspetz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/K=uuml=gelgen:Maria_von">Maria von Kgelgen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jylh=auml=:Antti">Antti Jylh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oliner:Adam_J=">Adam J. Oliner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tarkoma:Sasu">Sasu Tarkoma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jacucci:Giulio">Giulio Jacucci</a></p>
<p>Abstract:
Mobile devices have limited battery life, and numerous battery management applications are available that aim to improve it. This paper examines a large-scale mobile battery awareness application, called Carat, to see how it changes user behavior with long-term use. We conducted a survey of current Carat Android users and analyzed their interaction logs. The results show that long-term Carat users save more battery, charge their devices less often, learn to manage their battery with less help from Carat, have a better understanding of how Carat works, and may enjoy competing against other users. Based on these findings, we propose a set of guidelines for mobile battery awareness applications: battery awareness applications should make the reasoning behind their recommendations understandable to the user, be tailored to retain long-term users, take the audience into account when formulating feedback, and distinguish third-party and system applications.</p>
<p>Keywords:
energy awareness; smartphone; user behavior; user retention</p>
<h3 id="117. EnergyBugs: energy harvesting wearables for children.">117. EnergyBugs: energy harvesting wearables for children.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557225">Paper Link</a>    Pages:1039-1048</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ryokai:Kimiko">Kimiko Ryokai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Su:Peiqi">Peiqi Su</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Eungchan">Eungchan Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rollins:Bob">Bob Rollins</a></p>
<p>Abstract:
EnergyBugs are energy harvesting wearables with features that invite children to move their bodies to generate tiny, yet usable amounts of electricity. EnergyBugs not only convert children's kinetic energy into usable electrical energy, but also let children power a specially designed LED lamp with the energy the children have personally harvested. EnergyBugs therefore turn the electrical energy into a tangible object that children can manipulate and think with. Two studies of EnergyBugs with 34 elementary school children have revealed that children carefully observed and negotiated the use of personally harvested energy with their classmates, as well as developed emotional connections to energy. In particular, moving their own bodies to generate energy led the children to more actively ask questions about energy from new perspectives. We report our iterative design process and discuss the implications of our results for HCI.</p>
<p>Keywords:
children; energy harvesting; human-powered microgeneration; kinetic energy; tangible uis; wearable</p>
<h3 id="118. OJAS: open source bi-directional inductive power link.">118. OJAS: open source bi-directional inductive power link.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557041">Paper Link</a>    Pages:1049-1058</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mikkonen:Jussi">Jussi Mikkonen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gowrishankar:Ramyah">Ramyah Gowrishankar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oksanen:Miia">Miia Oksanen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Raittinen:Harri">Harri Raittinen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kolinummi:Arto">Arto Kolinummi</a></p>
<p>Abstract:
We present the design, development and evaluation of a bi-directional inductive power transfer circuit for prototyping purposes in the watt-range. Our device does not require any configuration and is intended for the development of wearable and tangible systems. Our approach allows a bi-directional power flow without any change in the circuit, such that the same circuit can be used for charging and discharging a battery. The contribution of this work is an enabling technology for researchers and practitioners in the fields of Wearable Electronics, Ubiquitous Computing and Human-Computer Interaction interested in exploring new interactions powered by watt-range inductive links. It enables smaller battery sizes, and therefore lighter devices, as the power can be distributed in a way that has not been feasible before. We discuss the motivations, technical details and the workshop evaluating our inductive approach.</p>
<p>Keywords:
bi-directional inductive power; prototyping; smart garments; wearable electronics</p>
<h3 id="119. Using asymmetric cores to reduce power consumption for interactive devices with bi-stable displays.">119. Using asymmetric cores to reduce power consumption for interactive devices with bi-stable displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557135">Paper Link</a>    Pages:1059-1062</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kihm:Jaeyeon">Jaeyeon Kihm</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guimbreti=egrave=re:Fran=ccedil=ois">Franois Guimbretire</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karl:Julia">Julia Karl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Manohar:Rajit">Rajit Manohar</a></p>
<p>Abstract:
Low power "helper" cores have been increasingly included on application processors to accomplish low intensity tasks such as music playing and motion sensing with minimum energy consumption. Recently, Guimbretire et al. [1] demonstrated that such helper cores can also be used to execute simple user interface tasks. We revisit this approach by implementing a similar system on an off-the-shelf application processor (TI OMAP4). Our study shows that in the case of high event rate interactions (pen inking and virtual keyboard), significant battery life gains (1.7 and 2.3 respectively) can be achieved with the helper core executing the interface. Having the helper core only dis-patch input events incurs a 18% penalty relative to the maximum savings rate, but allows for simplified deployment since it merely requires a change in toolkit infrastructure.</p>
<p>Keywords:
asymmetric architecture; bi-stable display; energy efficiency; pen interaction; user interface system</p>
<h2 id="Mid-air gestures    4">Mid-air gestures    4</h2>
<h3 id="120. Consumed endurance: a metric to quantify arm fatigue of mid-air interactions.">120. Consumed endurance: a metric to quantify arm fatigue of mid-air interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557130">Paper Link</a>    Pages:1063-1072</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hincapi=eacute==Ramos:Juan_David">Juan David Hincapi-Ramos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guo:Xiang">Xiang Guo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moghadasian:Paymahn">Paymahn Moghadasian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Irani:Pourang">Pourang Irani</a></p>
<p>Abstract:
Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs, a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue, but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system, and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions, including tasks with repetitive input such as mid-air text-entry. Finally, we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.</p>
<p>Keywords:
consumed endurance; endurance; gorilla-arm; mid-air interactions; mid-air text-entry; seato mid-air keyboard</p>
<h3 id="121. Vulture: a mid-air word-gesture keyboard.">121. Vulture: a mid-air word-gesture keyboard.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556964">Paper Link</a>    Pages:1073-1082</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Markussen:Anders">Anders Markussen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jakobsen:Mikkel_R=oslash=nne">Mikkel Rnne Jakobsen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
Word-gesture keyboards enable fast text entry by letting users draw the shape of a word on the input surface. Such keyboards have been used extensively for touch devices, but not in mid-air, even though their fluent gestural input seems well suited for this modality. We present Vulture, a word-gesture keyboard for mid-air operation. Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users' movement onto the display, and uses pinch as a word delimiter. A first 10-session study suggests text-entry rates of 20.6 Words Per Minute (WPM) and finds hand-movement speed to be the primary predictor of WPM. A second study shows that with training on a few phrases, participants do 28.1 WPM, 59% of the text-entry rate of direct touch input. Participants' recall of trained gestures in mid-air was low, suggesting that visual feedback is important but also limits performance. Based on data from the studies, we discuss improvements to Vulture and some alternative designs for mid-air text entry.</p>
<p>Keywords:
freehand interaction; in-air interaction; mid-air interaction; shape writing; text entry; word-gesture keyboard</p>
<h3 id="122. Understanding finger input above desktop devices.">122. Understanding finger input above desktop devices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557151">Paper Link</a>    Pages:1083-1092</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wacharamanotham:Chat">Chat Wacharamanotham</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Todi:Kashyap">Kashyap Todi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pye:Marty">Marty Pye</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borchers:Jan_O=">Jan O. Borchers</a></p>
<p>Abstract:
Using the space above desktop input devices adds a rich new input channel to desktop interaction. Input in this elevated layer has been previously used to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access vertically stacked menus. However, designing these interactions is challenging because the lack of haptic and direct visual feedback easily leads to input errors. For bare finger input, the user's fingers needs to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space. In this paper, we present the results of two user studies that inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume that users can reliably remain within. We found that when accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into midair. Finally, we propose a technique that reliably distinguishes clicking from homing movements, based on the user's hand shape. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.</p>
<p>Keywords:
finger input; height; midair; near-surface; thickness</p>
<h3 id="123. Exploring the usefulness of finger-based 3D gesture menu selection.">123. Exploring the usefulness of finger-based 3D gesture menu selection.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557122">Paper Link</a>    Pages:1093-1102</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kulshreshth:Arun">Arun Kulshreshth</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/LaViola_Jr=:Joseph_J=">Joseph J. LaViola Jr.</a></p>
<p>Abstract:
Counting using one's fingers is a potentially intuitive way to enumerate a list of items and lends itself naturally to gesture-based menu systems. In this paper, we present the results of the first comprehensive study on Finger-Count menus to investigate its usefulness as a viable option for 3D menu selection tasks. Our study compares 3D gesture-based finger counting (Finger Count menus) with two gesture-based menu selection techniques (Hand-n-Hold, Thumbs-Up), derived from existing motion-controlled video game menu selection strategies, as well as 3D Marking menus. We examined selection time, selection accuracy and user preference for all techniques. We also examined the impact of different spatial layouts for menu items and different menu depths. Our results indicate that Finger-Count menus are significantly faster than the other menu techniques we tested and are the most liked by participants. Additionally, we found that while Finger-Count menus and 3D Marking menus have similar selection accuracy, Finger-Count menus are almost twice as fast compared to 3D Marking menus.</p>
<p>Keywords:
3d interaction; 3d marking menu; depth camera; finger-count menu; gesture recognition; hand-n-hold menu; menu selection; selection; thumbs-up menu; user study; video games</p>
<h2 id="Touch and stylus interaction    4">Touch and stylus interaction    4</h2>
<h3 id="124. In the blink of an eye: investigating latency perception during stylus interaction.">124. In the blink of an eye: investigating latency perception during stylus interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557037">Paper Link</a>    Pages:1103-1112</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Ng:Albert">Albert Ng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Annett:Michelle">Michelle Annett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dietz:Paul">Paul Dietz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gupta:Anoop">Anoop Gupta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bischof:Walter_F=">Walter F. Bischof</a></p>
<p>Abstract:
While pen computing has become increasingly more popular, device responsiveness, or latency, still plagues such interaction. Although there have been advances in digitizer technology over the last few years, commercial end-to-end latencies are unfortunately similar to those found with touchscreens, i.e., 65 - 120 milliseconds. We report on a prototype stylus-enabled device, the High Performance Stylus System (HPSS), designed to display latencies as low as one millisecond while users ink or perform dragging tasks. To understand the role of latency while inking with a stylus, psychophysical just-noticeable difference experiments were conducted using the HPSS. While participants performed dragging and scribbling tasks, very low levels of latency could be discriminated, i.e., ~1 versus 2 milliseconds while dragging and ~7 versus 40 milliseconds while scribbling. The HPSS and our experimentation have provided further motivation for the implementation of latency saving measures in pen-based hardware and software systems.</p>
<p>Keywords:
latency; pen; pen computing; perception; psychophysics; stylus</p>
<h3 id="125. Pinch-drag-flick vs. spatial input: rethinking zoom & pan on mobile displays.">125. Pinch-drag-flick vs. spatial input: rethinking zoom &amp; pan on mobile displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557028">Paper Link</a>    Pages:1113-1122</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Spindler:Martin">Martin Spindler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schuessler:Martin">Martin Schuessler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Martsch:Marcel">Marcel Martsch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dachselt:Raimund">Raimund Dachselt</a></p>
<p>Abstract:
The multi-touch-based pinch to zoom, drag and flick to pan metaphor has gained wide popularity on mobile displays, where it is the paradigm of choice for navigating 2D documents. But is finger-based navigation really the gold standard' In this paper, we present a comprehensive user study with 40 participants, in which we systematically compared the Pinch-Drag-Flick approach with a technique that relies on spatial manipulation, such as lifting a display up/down to zoom. While we solely considered known techniques, we put considerable effort in implementing both input strategies on popular consumer hardware (iPhone, iPad). Our results show that spatial manipulation can significantly outperform traditional Pinch-Drag-Flick. Given the carefully optimized prototypes, we are confident to have found strong arguments that future generations of mobile devices could rely much more on spatial interaction principles.</p>
<p>Keywords:
mobile displays; multi-touch input; spatial input; spatially aware displays; user study</p>
<h3 id="126. InkAnchor: enhancing informal ink-based note taking on touchscreen mobile phones.">126. InkAnchor: enhancing informal ink-based note taking on touchscreen mobile phones.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557302">Paper Link</a>    Pages:1123-1132</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ren:Yi">Yi Ren</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lank:Edward">Edward Lank</a></p>
<p>Abstract:
Although touchscreen mobile phones are widely used for recording informal text notes (e.g., grocery lists, reminders and directions), the lack of efficient mechanisms for combining informal graphical content with text is a persistent challenge. In this paper, we present InkAnchor, a digital ink editor that allows users to easily create ink-based notes by finger drawing and writing on a mobile phone touchscreen. InkAnchor incorporates flexible anchoring, focus-plus-context input, content chunking, and lightweight editing mechanisms to support the capture of informal notes and annotations. We describe the design and evaluation of InkAnchor through a series of user studies, which revealed that the integrated support enabled by InkAnchor is a significant improvement over current mobile note taking applications on a range of mobile note-taking tasks.</p>
<p>Keywords:
digital ink; drawing; mobile interaction; multi-scale sketching; multi-touch; note taking</p>
<h3 id="127. Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion.">127. Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557033">Paper Link</a>    Pages:1133-1142</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wilson:Graham_A=">Graham A. Wilson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carter:Thomas">Thomas Carter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a></p>
<p>Abstract:
Ultrasonic haptic feedback is a promising means of providing tactile sensations in mid-air without encumbering the user with an actuator. However, controlled and rigorous HCI research is needed to understand the basic characteristics of perception of this new feedback medium, and so how best to utilise ultrasonic haptics in an interface. This paper describes two experiments conducted into two fundamental aspects of ultrasonic haptic perception: 1) localisation of a static point and 2) the perception of motion. Understanding these would provide insight into 1) the spatial resolution of an ultrasonic interface and 2) what forms of feedback give the most convincing illusion of movement. Results show an average localisation error of 8.5mm, with higher error along the longitudinal axis. Convincing sensations of motion were produced when travelling longer distances, using longer stimulus durations and stimulating multiple points along the trajectory. Guidelines for feedback design are given.</p>
<p>Keywords:
haptic feedback; localisation; perception; ultrasound</p>
<h2 id="Quantified self    3">Quantified self    3</h2>
<h3 id="128. Understanding quantified-selfers' practices in collecting and exploring personal data.">128. Understanding quantified-selfers' practices in collecting and exploring personal data.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557372">Paper Link</a>    Pages:1143-1152</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Choe:Eun_Kyoung">Eun Kyoung Choe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Nicole_B=">Nicole B. Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Bongshin">Bongshin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pratt:Wanda">Wanda Pratt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kientz:Julie_A=">Julie A. Kientz</a></p>
<p>Abstract:
Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. Despite the barriers, an increasing number of Quantified-Selfers diligently track many kinds of data about themselves, and some of them share their best practices and mistakes through Meetup talks, blogging, and conferences. In this work, we aim to gain insights from these "extreme users," who have used existing technologies and built their own workarounds to overcome different barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand what they did, how they did it, and what they learned. We highlight several common pitfalls to self-tracking, including tracking too many things, not tracking triggers and context, and insufficient scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.</p>
<p>Keywords:
health; per-sonal informatics; personal analytics; quantified self; self-experimentation.; self-monitoring; self-tracking</p>
<h3 id="129. BodyDiagrams: improving communication of pain symptoms through drawing.">129. BodyDiagrams: improving communication of pain symptoms through drawing.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557223">Paper Link</a>    Pages:1153-1162</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jang:Amy">Amy Jang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacLean:Diana_Lynn">Diana Lynn MacLean</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heer:Jeffrey">Jeffrey Heer</a></p>
<p>Abstract:
Thousands of people use the Internet to discuss pain symptoms. While communication between patients and physicians involves both verbal and physical interactions, online discussions of symptoms typically comprise text only. We present BodyDiagrams, an online interface for expressing symptoms via drawings and text. BodyDiagrams augment textual descriptions with pain diagrams drawn over a reference body and annotated with severity and temporal metadata. The resulting diagrams can easily be shared to solicit feedback and advice. We also conduct a two-phase user study to assess BodyDiagrams' communicative efficacy. In the first phase, users describe pain symptoms using BodyDiagrams and a text-only interface; in the second phase, medical professionals evaluate these descriptions. We find that patients are significantly more confident that their BodyDiagrams will be correctly interpreted, while medical professionals rated BodyDiagrams as significantly more informative than text descriptions. Both groups indicated a preference for using diagrams to communicate physical symptoms in the future.</p>
<p>Keywords:
drawing; health; pain diagrams; symptom communication</p>
<h3 id="130. Personal tracking as lived informatics.">130. Personal tracking as lived informatics.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557039">Paper Link</a>    Pages:1163-1172</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rooksby:John">John Rooksby</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rost:Mattias">Mattias Rost</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morrison:Alistair">Alistair Morrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chalmers:Matthew">Matthew Chalmers</a></p>
<p>Abstract:
This paper characterises the use of activity trackers as "lived informatics". This characterisation is contrasted with other discussions of personal informatics and the quantified self. The paper reports an interview study with activity tracker users. The study found: people do not logically organise, but interweave various activity trackers, sometimes with ostensibly the same functionality; that tracking is often social and collaborative rather than personal; that there are different styles of tracking, including goal driven tracking and documentary tracking; and that tracking information is often used and interpreted with reference to daily or short term goals and decision making. We suggest there will be difficulties in personal informatics if we ignore the way that personal tracking is enmeshed with everyday life and people's outlook on their future.</p>
<p>Keywords:
activity tracking; data; qualitative methods</p>
<h2 id="Sustainability perspectives    2">Sustainability perspectives    2</h2>
<h3 id="131. Towards an holistic view of the energy and environmental impacts of domestic media and IT.">131. Towards an holistic view of the energy and environmental impacts of domestic media and IT.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556968">Paper Link</a>    Pages:1173-1182</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bates:Oliver">Oliver Bates</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hazas:Mike">Mike Hazas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Friday:Adrian">Adrian Friday</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morley:Janine">Janine Morley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Clear:Adrian_K=">Adrian K. Clear</a></p>
<p>Abstract:
To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling of appliances within the home, and longevity of portable electronics such as mobile phones. However, there seems to be less awareness of the energy and greenhouse emissions impacts of domestic consumer electronics and information technology. Such awareness is needed to inform HCI sustainability researchers on how best to prioritise efforts around digital media and IT. Grounded in inventories, interview and plug energy data from 33 undergraduate student participants, our findings provide the context for assessing approaches to reducing the energy and carbon emissions of media and IT in the home. In the paper, we use the findings to discuss and inform more fruitful directions that sustainable HCI research might take, and we quantify how various strategies might have modified the energy and emissions impacts for our participants.</p>
<p>Keywords:
embodied emissions; home energy; life cycle assessment; sustainability</p>
<h3 id="132. Beyond ethnography: engagement and reciprocity as foundations for design research out here.">132. Beyond ethnography: engagement and reciprocity as foundations for design research out here.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557374">Paper Link</a>    Pages:1183-1186</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brereton:Margot">Margot Brereton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roe:Paul">Paul Roe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schroeter:Ronald">Ronald Schroeter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Anita_Lee">Anita Lee Hong</a></p>
<p>Abstract:
This paper explores an emerging paradigm for HCI design research based primarily upon engagement, reciprocity and doing. Much HCI research begins with an investigatory and analytic ethnographic approach before translating to design. Design may come much later in the process and may never benefit the community that is researched. However in many settings it is difficult for researchers to access the privileged ethnographer position of observer and investigator. Moreover rapid ethnographic research often does not seem the best or most appropriate course of action. We draw upon a project working with a remote Australian Aboriginal community to illustrate an alternative approach in Indigenous research, where the notion of reciprocity is first and foremost. We argue that this can lead to sustainable designs, valid research and profound innovation.</p>
<p>Keywords:
ict4d; participatory action research; postcolonial hci</p>
<h2 id="Navigating video    5">Navigating video    5</h2>
<h3 id="133. Visualization of personal history for video navigation.">133. Visualization of personal history for video navigation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557106">Paper Link</a>    Pages:1187-1196</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hajri:Abir_Al">Abir Al Hajri</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Gregor">Gregor Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fong:Matthew">Matthew Fong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fels:S=_Sidney">S. Sidney Fels</a></p>
<p>Abstract:
We present an investigation of two different visualizations of video history: Video Timeline and Video Tiles. Video Timeline extends the commonly employed list-based visualization for navigation history by applying size to indicate heuristics and occupying the full screen with a two-sided timeline. Video Tiles visualizes history items in a grid-based layout by following pre-defined templates based on items' heuristics and ordering, utilizing screen space more effectively at the expense of a clearer temporal location. The visualizations are compared against the state-of-the-art method (a filmstrip-based visualization), with ten participants tasked with sharing their previously-seen affective intervals. Our study shows that our visualizations are perceived as intuitive and both outperform and are strongly preferred to the current method. Based on these results, Video Timeline and Video Tiles provide an effective addition to video viewers to help manage the growing quantity of video. They provide users with insight into their navigation patterns, allowing them to quickly find previously-seen intervals, leading to efficient clip sharing, simpler authoring and video summarization.</p>
<p>Keywords:
history; navigation; video; visualization</p>
<h3 id="134. WaaZam!: supporting creative play at a distance in customized video environments.">134. WaaZam!: supporting creative play at a distance in customized video environments.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557382">Paper Link</a>    Pages:1197-1206</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hunter:Seth_E=">Seth E. Hunter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Maes:Pattie">Pattie Maes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tang_0001:Anthony">Anthony Tang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Inkpen:Kori_M=">Kori M. Inkpen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hessey:Susan_M=">Susan M. Hessey</a></p>
<p>Abstract:
We present the design, and evaluation of WaaZam, a video mediated communication system designed to support creative play in customized environments. Users can interact together in virtual environments composed of digital assets layered in 3D space. The goal of the project is to support creative play and increase social engagement during video sessions of geographically separated families. We try to understand the value of customization for individual families with children ages 6-12. We present interviews with creativity experts, a pilot study and a formal evaluation of families playing together in four conditions: separate windows, merged windows, digital play sets, and customized digital environments. We found that playing in the same video space enables new activities and increases social engagement for families. Customization allows families to modify scenes for their needs and support more creative play activities that embody the imagination of the child.</p>
<p>Keywords:
composited video; customized video environments; family play; play at a distance; remote play; shared experiences at a distance; video mediated communication</p>
<h3 id="135. LACES: live authoring through compositing and editing of streaming video.">135. LACES: live authoring through compositing and editing of streaming video.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557304">Paper Link</a>    Pages:1207-1216</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Freeman:Dustin_E=_R=">Dustin E. R. Freeman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Santosa:Stephanie">Stephanie Santosa</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chevalier:Fanny">Fanny Chevalier</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Balakrishnan:Ravin">Ravin Balakrishnan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Singh:Karan">Karan Singh</a></p>
<p>Abstract:
Video authoring activity typically consists of three phases: planning (pre-production), capture (production) and processing (post-production). The status quo is that these phases occur separately, and the latter two have a significant amount of "slack time", where the camera operator is watching the scene unfold during capture, and the editor is re-watching and navigating through recorded footage during post-production. While this process is well suited to creating polished or professional video, video clips produced by casual video makers as seen in online forums could benefit from some editing without the overhead of current authoring tools. We introduce LACES, a tablet-based system enabling simple video manipulations in the midst of filming. Seamless in-situ integration of video capture and manipulation forms a novel workflow, allowing greater spontaneity and exploration of video creation.</p>
<p>Keywords:
compositing; video editing; video production</p>
<h3 id="136. ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging.">136. ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557249">Paper Link</a>    Pages:1217-1220</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Craggs:Barnaby">Barnaby Craggs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Scott:Myles_Kilgallon">Myles Kilgallon Scott</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alexander:Jason">Jason Alexander</a></p>
<p>Abstract:
During online search, the user's expectations often differ from those of the author. This is known as the "intention gap" and is particularly problematic when searching for and discriminating between online video content. An author uses description and meta-data tags to label their content, but often cannot predict alternate interpretations or appropriations of their work. To address this intention gap, we present ThumbReels, a concept for query-sensitive video previews generated from crowdsourced, temporally defined semantic tagging. Further, we supply an open-source tool that supports on-the-fly temporal tagging of videos, whose output can be used for later search queries. A first user study validates the tool and concept. We then present a second study that shows participants found ThumbReels to better represent search terms than contemporary preview techniques.</p>
<p>Keywords:
crowdsourcing; metadata; thumbnails; thumbreels; video; video summarisation; video surrogates</p>
<h3 id="137. Panopticon as an eLearning support search tool.">137. Panopticon as an eLearning support search tool.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557082">Paper Link</a>    Pages:1221-1224</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nicholson:James">James Nicholson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huber:Mark">Mark Huber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jackson:Daniel">Daniel Jackson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
We present an evaluation of Panopticon, a video surrogate system, as an online eLearning support search tool for finding information within video lectures. A comparison was made with a standard video player (YouTube) in two scenarios with two classes of users: revision students and independent learners. Results showed that users of Panopticon were significantly faster at finding information within the lecture videos than users of the YouTube player. It was also found that videos predominantly featuring a talking lecturer took longest to navigate, presenting design implications for lectures to be uploaded to open eLearning platforms.</p>
<p>Keywords:
elearning; video browsing</p>
<h2 id="Crowds and creativity    4">Crowds and creativity    4</h2>
<h3 id="138. Searching for analogical ideas with crowds.">138. Searching for analogical ideas with crowds.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557378">Paper Link</a>    Pages:1225-1234</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yu:Lixiu">Lixiu Yu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a></p>
<p>Abstract:
Seeking solutions from one domain to solve problems in another is an effective process of innovation. This process of analogy searching is difficult for both humans and machines. In this paper, we present a novel approach for re-presenting a problem in terms of its abstract structure, and then allowing people to use this structural representation to find analogies. We propose a crowdsourcing process that helps people navigate a large dataset to find analogies. Through two experiments, we show the benefits of using abstract structural representations to search for ideas that are analogous to a source problem, and that these analogies result in better solutions than alternative approaches. This work provides a useful method for finding analogies, and can streamline innovation for both novices and professional designers.</p>
<p>Keywords:
analogy searching; creativity; crowdsourcing; schema</p>
<h3 id="139. skWiki: a multimedia sketching system for collaborative creativity.">139. skWiki: a multimedia sketching system for collaborative creativity.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557394">Paper Link</a>    Pages:1235-1244</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Zhenpeng">Zhenpeng Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Badam:Sriram_Karthik">Sriram Karthik Badam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chandrasegaran:Senthil_K=">Senthil K. Chandrasegaran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Park:Deok_Gun">Deok Gun Park</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Elmqvist:Niklas">Niklas Elmqvist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kisselburgh:Lorraine_G=">Lorraine G. Kisselburgh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramani:Karthik">Karthik Ramani</a></p>
<p>Abstract:
We present skWiki, a web application framework for collaborative creativity in digital multimedia projects, including text, hand-drawn sketches, and photographs. skWiki overcomes common drawbacks of existing wiki software by providing a rich viewer/editor architecture for all media types that is integrated into the web browser itself, thus avoiding dependence on client-side editors. Instead of files, skWiki uses the concept of paths as trajectories of persistent state over time. This model has intrinsic support for collaborative editing, including cloning, branching, and merging paths edited by multiple contributors. We demonstrate skWiki's utility using a qualitative, sketching-based user study.</p>
<p>Keywords:
collaborative editing; creativity; sketching; wikis</p>
<h3 id="140. Distributed analogical idea generation: inventing with crowds.">140. Distributed analogical idea generation: inventing with crowds.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557371">Paper Link</a>    Pages:1245-1254</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yu:Lixiu">Lixiu Yu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kittur:Aniket">Aniket Kittur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a></p>
<p>Abstract:
Harnessing crowds can be a powerful mechanism for increasing innovation. However, current approaches to crowd innovation rely on large numbers of contributors generating ideas independently in an unstructured way. We introduce a new approach called distributed analogical idea generation, which aims to make idea generation more effective and less reliant on chance. Drawing from the literature in cognitive science on analogy and schema induction, our approach decomposes the creative process in a structured way amenable to using crowds. In three experiments we show that distributed analogical idea generation leads to better ideas than example-based approaches, and investigate the conditions under which crowds generate good schemas and ideas. Our results have implications for improving creativity and building systems for distributed crowd innovation.</p>
<p>Keywords:
analogy; creativity; crowdsourcing; innovation; schema</p>
<h3 id="141. Frenzy: collaborative data organization for creating conference sessions.">141. Frenzy: collaborative data organization for creating conference sessions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557375">Paper Link</a>    Pages:1255-1264</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chilton:Lydia_B=">Lydia B. Chilton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Juho">Juho Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Andr=eacute=:Paul">Paul Andr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cordeiro:Felicia">Felicia Cordeiro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Landay:James_A=">James A. Landay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weld:Daniel_S=">Daniel S. Weld</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dow:Steven_P=">Steven P. Dow</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Robert_C=">Robert C. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Haoqi">Haoqi Zhang</a></p>
<p>Abstract:
Organizing conference sessions around themes improves the experience for attendees. However, the session creation process can be difficult and time-consuming due to the amount of expertise and effort required to consider alternative paper groupings. We present a collaborative web application called Frenzy to draw on the efforts and knowledge of an entire program committee. Frenzy comprises (a) interfaces to support large numbers of experts working collectively to create sessions, and (b) a two-stage process that decomposes the session-creation problem into meta-data elicitation and global constraint satisfaction. Meta-data elicitation involves a large group of experts working simultaneously, while global constraint satisfaction involves a smaller group that uses the meta-data to form sessions. We evaluated Frenzy with 48 people during a deployment at the CSCW 2014 program committee meeting. The session making process was much faster than the traditional process, taking 88 minutes instead of a full day. We found that meta-data elicitation was useful for session creation. Moreover, the sessions created by Frenzy were the basis of the CSCW 2014 schedule.</p>
<p>Keywords:
communitysourcing; crowdsourcing; groupware</p>
<h2 id="Interacting with the web    3">Interacting with the web    3</h2>
<h3 id="142. End-users publishing structured information on the web: an observational study of what, why, and how.">142. End-users publishing structured information on the web: an observational study of what, why, and how.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557036">Paper Link</a>    Pages:1265-1274</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Benson:Edward">Edward Benson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karger:David_R=">David R. Karger</a></p>
<p>Abstract:
End-users are accustomed to filtering and browsing styled collections of data on professional web sites, but they have few ways to create and publish such information architectures for themselves. This paper presents a full-lifecycle analysis of the Exhibit framework - an end-user tool which provides such functionality - to understand the needs, capabilities, and practices of this class of users. We include interviews, as well as analysis of over 1,800 visualizations and 200,000 web interactions with these visualizations. Our analysis reveals important findings about this user population which generalize to the task of providing better end-user structured content publication tools.</p>
<p>Keywords:
faceted browsing; information architectures; web content editing; web design</p>
<h3 id="143. Designing usable web forms: empirical evaluation of web form improvement guidelines.">143. Designing usable web forms: empirical evaluation of web form improvement guidelines.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557265">Paper Link</a>    Pages:1275-1284</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Seckler:Mirjam">Mirjam Seckler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Heinz:Silvia">Silvia Heinz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bargas=Avila:Javier_A=">Javier A. Bargas-Avila</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Opwis:Klaus">Klaus Opwis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tuch:Alexandre_N=">Alexandre N. Tuch</a></p>
<p>Abstract:
This study reports a controlled eye tracking experiment (N = 65) that shows the combined effectiveness of 20 guidelines to improve interactive online forms when applied to forms found on real company websites. Results indicate that improved web forms lead to faster completion times, fewer form submission trials, and fewer eye movements. Data from subjective questionnaires and interviews further show increased user satisfaction. Overall, our findings highlight the importance for web designers to improve their web forms using UX guidelines.</p>
<p>Keywords:
form evaluation; form guidelines; form interaction; internet; web forms; world wide web</p>
<h3 id="144. Choice overload in search engine use?">144. Choice overload in search engine use?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557149">Paper Link</a>    Pages:1285-1294</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chiravirakul:Pawitra">Pawitra Chiravirakul</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Payne:Stephen_J=">Stephen J. Payne</a></p>
<p>Abstract:
Search engines typically return so many results that choosing from the list might be predicted to suffer from the effects of "choice overload". Preliminary work has reported just such an effect [12]. In this paper a series of three experiments was conducted to investigate the choice overload effect in search engine use. Participants were given search tasks and presented with either six or twenty-four returns to choose from. The results revealed that the choice behaviour was strongly influenced by the ranking of returns, and that choice satisfaction was affected by the number of options and the decision time. The main results, from the third experiment, showed that large sets of options yielded a positive effect on participants' satisfaction when they made a decision without time limit. When time was more strongly constrained, choices from small sets led to relatively higher satisfaction. Our studies show how user satisfaction with found information can be affected by processing strategies that are influenced by search engine design features.</p>
<p>Keywords:
choice satisfaction; decision behaviour; search engines</p>
<h2 id="Music, dance, and television    4">Music, dance, and television    4</h2>
<h3 id="145. Coming in from the margins: amateur musicians in the online age.">145. Coming in from the margins: amateur musicians in the online age.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557298">Paper Link</a>    Pages:1295-1304</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hoare:Michaela">Michaela Hoare</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Benford:Steve">Steve Benford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Rachel">Rachel Jones</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Milic=Frayling:Natasa">Natasa Milic-Frayling</a></p>
<p>Abstract:
HCI is increasingly interested in amateurism, but the wider literature suggests that the amateur is a complex and distinctive phenomenon. An interview study reveals the nature of the amateur in the digital age. Even though operating non-professionally at a micro-scale, amateur musicians employ a plethora of online services to sustain local fanbases, reach out to new fans, collaborate internationally, and actively promote both digital and material products. Our findings lead to recommendations for event-oriented promotion tools; community-oriented analytics; tangible and embedded products; and limited-edition digital experiences. We conclude that HCI needs to recognise the amateur as an important class of user, one who is serious about their leisure, and who is also distinct from the professional as from the novice and hobbyist.</p>
<p>Keywords:
amateur; community; craft; distribution; diy; music; promotion; sharing; social media; tangible</p>
<h3 id="146. Watching the footwork: second screen interaction at a dance and music performance.">146. Watching the footwork: second screen interaction at a dance and music performance.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557369">Paper Link</a>    Pages:1305-1314</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Barkhuus:Louise">Louise Barkhuus</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Engstr=ouml=m:Arvid">Arvid Engstrm</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zoric:Goranka">Goranka Zoric</a></p>
<p>Abstract:
Interactive mobile technologies have become part of audience experiences of live performances in terms of both general media sharing and specific (sometimes official) extra content. At the same time, high bandwidth affords streaming of live events to mobile devices. We take advantage of these technologies in our high resolution, panoramic image video stream and study a scenario of audience members viewing the very same live event they are watching on a tablet. The video stream on the tablet is navigational and enables audience members to pan and zoom in the real-time video feed. We studied audience interaction and impressions in three performances of a dance and music show and found distinct uses of the second screen video stream. We emphasize that despite initial reluctance, the observed utilization of the technology opened up for new potential practices. Our study shows how working with perceived conflict in technology can still open up design space for interactive technologies.</p>
<p>Keywords:
interactive television; mobile entertainment; second screen interaction</p>
<h3 id="147. Streaming on twitch: fostering participatory communities of play within live mixed media.">147. Streaming on twitch: fostering participatory communities of play within live mixed media.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557048">Paper Link</a>    Pages:1315-1324</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hamilton:William_A=">William A. Hamilton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Garretson:Oliver">Oliver Garretson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kerne:Andruid">Andruid Kerne</a></p>
<p>Abstract:
Previously, video streaming sites were at the fringes of online social media. In the past two years, live streams of video games, on sites such as Twitch.tv, have become very popular. Live streams serve as meeting grounds for player communities. The Twitch streaming medium combines broadcast video with open IRC chat channels. In conjunction with gameplay, viewer participation and community building gain emphasis. Twitch streams range in size and nature, from intimate communities with fifty viewers, to massive broadcasts with tens of thousands. In this paper, we present an ethnographic investigation of the live streaming of video games on Twitch. We find that Twitch streams act as virtual third places, in which informal communities emerge, socialize, and participate. Over time, stream communities form around shared identities drawn from streams? contents and participants? shared experiences. We describe processes through which stream communities form, the motivations of members, and emergent issues in the medium. Finally, we draw from our findings to derive implications for design of live mixed-media environments to support participatory online communities.</p>
<p>Keywords:
ethnography; live streaming; online communities; third places; twitch; video games</p>
<h3 id="148. Long tail TV revisited: from ordinary camera phone use to pro-am video production.">148. Long tail TV revisited: from ordinary camera phone use to pro-am video production.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557315">Paper Link</a>    Pages:1325-1334</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Juhlin:Oskar">Oskar Juhlin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Engstr=ouml=m:Arvid">Arvid Engstrm</a> ; <a href="http://dblp.uni-trier.de/pers/hd/=/=Ouml=nnevall:Elin">Elin nnevall</a></p>
<p>Abstract:
Pro-Am live video producers broadcast events on a regular basis. They are here selected for an ethnographic study since their continuous content generation can teach us something of what it takes for amateurs, who currently struggle with mastering the video medium, to become proficient producers. We learn from media theory that Pro-Ams are distinguished from professionals in terms of inherent skills and identities, and have therefore focused on these characteristics. We add to this research by showing on-going challenges that the former face in their production, i.e. how their learning practices, such as learning through instructions, are situated and related to particular settings. Learning and development of skills were done as organizations, rather than as individuals. Furthermore, the recurrent nature of both events and broadcasts appears to be an important condition for establishing the terms needed to carry out a production, and to learn the skills of a producer. This understanding may explain in part why accounts in previous research, of single users struggling with the affordances of live video, point to such difficulties in mastering the medium. The findings guide design to better support activities contiguous with the set-up of the production, rather than the broadcast per se.</p>
<p>Keywords:
camera phones; ethnography; identity; learning; live video; media studies; mimicking; negotiation; organization theory; pro-am; user-generated content; video</p>
<h2 id="Social media and health    4">Social media and health    4</h2>
<h3 id="149. Estimating county health statistics with twitter.">149. Estimating county health statistics with twitter.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557139">Paper Link</a>    Pages:1335-1344</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Culotta:Aron">Aron Culotta</a></p>
<p>Abstract:
Understanding the relationships among environment, behavior, and health is a core concern of public health researchers. While a number of recent studies have investigated the use of social media to track infectious diseases such as influenza, little work has been done to determine if other health concerns can be inferred. In this paper, we present a large-scale study of 27 health-related statistics, including obesity, health insurance coverage, access to healthy foods, and teen birth rates. We perform a linguistic analysis of the Twitter activity in the top 100 most populous counties in the U.S., and find a significant correlation with 6 of the 27 health statistics. When compared to traditional models based on demographic variables alone, we find that augmenting models with Twitter-derived information improves predictive accuracy for 20 of 27 statistics, suggesting that this new methodology can complement existing approaches.</p>
<p>Keywords:
natural language processing; public health; social media</p>
<h3 id="150. Unraveling abstinence and relapse: smoking cessation reflected in social media.">150. Unraveling abstinence and relapse: smoking cessation reflected in social media.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557145">Paper Link</a>    Pages:1345-1354</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Murnane:Elizabeth_L=">Elizabeth L. Murnane</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Counts:Scott">Scott Counts</a></p>
<p>Abstract:
Analysis of smokers' posts and behaviors on Twitter reveals factors impacting abstinence and relapse during cessation attempts. Combining automatic and crowdsourced techniques, we detect users trying to quit smoking and analyze tweet and network data from a sample of 653 individuals over a two-year window of quitting. Guided by theory and practice, we derive behavioral, social, and emotional measures to compare users who abstain and relapse. We also examine the cessation process, demonstrating that Twitter can help chronicle how some people go about quitting. Among other results, we show that those who fail in their smoking cessation are far heavier posters and use relatively less positive language, while those who succeed are more social in both network ties and in directed communication. We conclude with insights on how intelligent intervention systems can harness these signals to provide tailored behavior change support.</p>
<p>Keywords:
behavior; cessation; health; smoking; social media; twitter</p>
<h3 id="151. Weaving clinical expertise in online health communities.">151. Weaving clinical expertise in online health communities.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557293">Paper Link</a>    Pages:1355-1364</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huh:Jina">Jina Huh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pratt:Wanda">Wanda Pratt</a></p>
<p>Abstract:
Many patients visit online health communities to receive support. In face-to-face support groups, health professionals facilitate peer-patients exchanging experience while adding their clinical expertise when necessary. However, the large scale of online health communities makes it challenging for such health professional moderators' involvement to happen. To address this challenge of delivering clinical expertise to where patients need them, we explore the idea of semi-automatically providing clinical expertise in online health communities. We interviewed 14 clinicians showing them example peer-patient conversation threads. From the interviews, we examined the ideal practice of clinicians providing expertise to patients. The clinicians continuously assessed when peer-patients were providing appropriate support, what kinds of clinical help they could give online, and when to defer to patients' healthcare providers. The findings inform requirements for building a semi-automated system delivering clinical expertise in online health communities.</p>
<p>Keywords:
health informatics; moderator; online health communities; support group</p>
<h3 id="152. Seeking and sharing health information online: comparing search engines and social media.">152. Seeking and sharing health information online: comparing search engines and social media.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557214">Paper Link</a>    Pages:1365-1376</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Choudhury:Munmun_De">Munmun De Choudhury</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Meredith_Ringel">Meredith Ringel Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/White:Ryen_W=">Ryen W. White</a></p>
<p>Abstract:
Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.</p>
<p>Keywords:
health; search engine; social media; social search; twitter</p>
<h2 id="On and above the surface    5">On and above the surface    5</h2>
<h3 id="153. RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces.">153. RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557336">Paper Link</a>    Pages:1377-1386</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:David">David Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Izadi:Shahram">Shahram Izadi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dostal:Jakub">Jakub Dostal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rhemann:Christoph">Christoph Rhemann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Keskin:Cem">Cem Keskin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zach:Christopher">Christopher Zach</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shotton:Jamie">Jamie Shotton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Large:Timothy_A=">Timothy A. Large</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bathiche:Steven">Steven Bathiche</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nie=szlig=ner:Matthias">Matthias Niener</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Butler:D=_Alex">D. Alex Butler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fanello:Sean_Ryan">Sean Ryan Fanello</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pradeep:Vivek">Vivek Pradeep</a></p>
<p>Abstract:
We present RetroDepth, a new vision-based system for accurately sensing the 3D silhouettes of hands, styluses, and other objects, as they interact on and above physical surfaces. Our setup is simple, cheap, and easily reproducible, comprising of two infrared cameras, diffuse infrared LEDs, and any off-the-shelf retro-reflective material. The retro-reflector aids image segmentation, creating a strong contrast between the surface and any object in proximity. A new highly efficient stereo matching algorithm precisely estimates the 3D contours of interacting objects and the retro-reflective surfaces. A novel pipeline enables 3D finger, hand and object tracking, as well as gesture recognition, purely using these 3D contours. We demonstrate high-precision sensing, allowing robust disambiguation between a finger or stylus touching, pressing or interacting above the surface. This allows many interactive scenarios that seamlessly mix together freehand 3D interactions with touch, pressure and stylus input. As shown, these rich modalities of input are enabled on and above any retro-reflective surface, including custom "physical widgets" fabricated by users. We compare our system with Kinect and Leap Motion, and conclude with limitations and future work.</p>
<p>Keywords:
3D contours; 3D input; contour classification; depth sensing; nui; stereo matching; stylus; touch; vision-based uis</p>
<h3 id="154. SurfaceLink: using inertial and acoustic sensing to enable multi-device interaction on a surface.">154. SurfaceLink: using inertial and acoustic sensing to enable multi-device interaction on a surface.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557120">Paper Link</a>    Pages:1387-1396</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Goel:Mayank">Mayank Goel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Brendan">Brendan Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aumi:Md_Tanvir_Islam">Md Tanvir Islam Aumi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Patel:Shwetak">Shwetak Patel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borriello:Gaetano">Gaetano Borriello</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hibino:Stacie">Stacie Hibino</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Begole:Bo">Bo Begole</a></p>
<p>Abstract:
We present SurfaceLink, a system where users can make natural surface gestures to control association and information transfer among a set of devices that are placed on a mutually shared surface (e.g., a table). SurfaceLink uses a combination of on-device accelerometers, vibration motors, speakers and microphones (and, optionally, an off-device contact microphone for greater sensitivity) to sense gestures performed on the shared surface. In a controlled evaluation with 10 participants, SurfaceLink detected the presence of devices on the same surface with 97.7% accuracy, their relative arrangement with 89.4% accuracy, and various single- and multi-touch surface gestures with an average accuracy of 90.3%. A usability analysis showed that SurfaceLink has advantages over current multi-device interaction techniques in a number of situations.</p>
<p>Keywords:
acoustic sensing; inertial sensing; mobile phones; multi-device interaction; surface interaction</p>
<h3 id="155. Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction.">155. Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557276">Paper Link</a>    Pages:1397-1406</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pan:Ye">Ye Pan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steptoe:William">William Steptoe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steed:Anthony">Anthony Steed</a></p>
<p>Abstract:
We report on two experiments that investigate the influence of display type and viewing angle on how people place their trust during avatar-mediated interaction. By monitoring advice seeking behavior, our first experiment demonstrates that if participants observe an avatar at an oblique viewing angle on a flat display, they are less able to discriminate between expert and non-expert advice than if they observe the avatar face-on. We then introduce a novel spherical display and a ray-traced rendering technique that can display an avatar that can be seen correctly from any viewing direction. We expect that a spherical display has advantages over a flat display because it better supports non-verbal cues, particularly gaze direction, since it presents a clear and undistorted viewing aspect at all angles. Our second experiment compares the spherical display to a flat display. Whilst participants can discriminate expert advice regardless of display, a negative bias towards the flat screen emerges at oblique viewing angles. This result emphasizes the ability of the spherical display to be viewed qualitatively similarly from all angles. Together the experiments demonstrate how trust can be altered depending on how one views the avatar.</p>
<p>Keywords:
avatars; mixed reality; spherical displays; telecommunication; trust</p>
<h3 id="156. PrintSense: a versatile sensing technique to support multimodal flexible surface interaction.">156. PrintSense: a versatile sensing technique to support multimodal flexible surface interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557173">Paper Link</a>    Pages:1407-1410</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gong:Nan=Wei">Nan-Wei Gong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steimle:J=uuml=rgen">Jrgen Steimle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olberding:Simon">Simon Olberding</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hodges:Steve">Steve Hodges</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gillian:Nicholas_Edward">Nicholas Edward Gillian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kawahara:Yoshihiro">Yoshihiro Kawahara</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paradiso:Joseph_A=">Joseph A. Paradiso</a></p>
<p>Abstract:
We present a multimodal on-surface and near-surface sensing technique for planar, curved and flexible surfaces. Our technique leverages temporal multiplexing of signals coming from a universal interdigitated electrode design, which is printed as a single conductive layer on a flexible substrate. It supports sensing of touch and proximity input, and moreover is capable of capturing several levels of pressure and flexing. We leverage recent developments in conductive inkjet printing as a way to prototype electrode patterns, and combine this with our hardware module for supporting the full range of sensing methods. As the technique is low-cost and easy to implement, it is particularly well-suited for prototyping touch- and hover-based user interfaces, including curved and deformable ones.</p>
<p>Keywords:
interactive surface; conductive inkjet printed electronics; flexible sensor; multimodal input; touch input</p>
<h3 id="157. Let's kick it: how to stop wasting the bottom third of your large screen display.">157. Let's kick it: how to stop wasting the bottom third of your large screen display.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557316">Paper Link</a>    Pages:1411-1414</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jota:Ricardo">Ricardo Jota</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lopes:Pedro">Pedro Lopes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel">Daniel Wigdor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jorge:Joaquim_A=">Joaquim A. Jorge</a></p>
<p>Abstract:
Large-scale touch surfaces have been widely studied in literature and adopted for public installations such as interactive billboards. However, current designs do not take into consideration that touching the interactive surface at different heights is not the same; for body-height displays, the bottom portion of the screen is within easier reach of the foot than the hand. We explore the design space of foot input on vertical surfaces, and propose three distinct interaction modalities: hand, foot tapping, and foot gesturing. Our design exploration pays particular attention to areas of the touch surface that were previously overlooked: out of hand's reach and close to the floor. We instantiate our design space with a working prototype of an interactive surface, in which we are able to distinguish between finger and foot tapping and extend the input area beyond the bottom of the display to support foot gestures.</p>
<p>Keywords:
floor input; foot interaction; kick; large-scale display</p>
<h2 id="Interactive whiteboards and public displays    3">Interactive whiteboards and public displays    3</h2>
<h3 id="158. Communiplay: a field study of a public display mediaspace.">158. Communiplay: a field study of a public display mediaspace.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557001">Paper Link</a>    Pages:1415-1424</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller_0001:J=ouml=rg">Jrg Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Eberle:Dieter">Dieter Eberle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tollmar:Konrad">Konrad Tollmar</a></p>
<p>Abstract:
We present Communiplay, a public display media space. People passing by see their own contour mirrored on a public display and can start to play with virtual objects. At the same time, they see others playing at remote displays within the same virtual space. We are interested whether people would use such a public display media space, and if so, how and why. We evaluate Communiplay in a field study in six connected locations and find a remote honey-pot effect, i.e. people interacting at one location attract people at other locations. The conversion rate (percentage of passers-by starting to interact) rose by +136% when people saw others playing at remote locations. We also provide the first quantification of the (local) honey-pot effect (in our case it raised the conversion rate by +604% when people saw others playing at the same location). We conclude that the integration of multiple public displays into a media space is a promising direction for public displays and can make them more attractive and valuable.</p>
<p>Keywords:
in-the-wild study; media space; public displays</p>
<h3 id="159. Posting for community and culture: considerations for the design of interactive digital bulletin boards.">159. Posting for community and culture: considerations for the design of interactive digital bulletin boards.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556970">Paper Link</a>    Pages:1425-1434</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fortin:Claude">Claude Fortin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Neustaedter:Carman">Carman Neustaedter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hennessy:Kate">Kate Hennessy</a></p>
<p>Abstract:
The next decade is likely to see a shift in digital public displays moving from non-interactive to interactive content. This will likely create a need for digital bulletin boards and for a better understanding of how such displays should be designed to encourage community members to interact with them. Our study addresses this by exploring community bulletin boards as a ubiquitous type of participatory non-digital display "in the wild". Our results highlight how they are used for content of local and contextual relevance, and how cultures of participation, personalization, location, the tangible character of architecture, access, control and flexibility might affect community members' level of engagement with them. Our analysis suggests entry points as design considerations intrinsically linked to the users' sense of agency within a delineated space. Overlaps with related work are identified throughout to provide further validation of previous findings in this area of research.</p>
<p>Keywords:
cultures of participation; digital bulletin boards; entry points; large public displays; observation; urban computing</p>
<h3 id="160. I can wait a minute: uncovering the optimal delay time for pre-moderated user-generated content on public displays.">160. I can wait a minute: uncovering the optimal delay time for pre-moderated user-generated content on public displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557186">Paper Link</a>    Pages:1435-1438</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Greis:Miriam">Miriam Greis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alt:Florian">Florian Alt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Henze:Niels">Niels Henze</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Memarovic:Nemanja">Nemanja Memarovic</a></p>
<p>Abstract:
Public displays have advanced from isolated and non interactive "ad" displays which show images and videos to displays that are networked, interactive, and open to a wide variety of content and applications. Prior work has shown large potential of user-generated content on public displays. However, one of the problems with user-generated content on public displays is moderation as content may be explicit or troublesome for a particular location. In this work we explore the expectations of users with regard to content moderation on public displays. An online survey revealed that people not only think that display content should be moderated but also that a delay of up to 10 minutes is acceptable if display content is moderated. In a subsequent in the wild deployment we compared different moderation delays. We found that a moderation delay significantly decreases the number of user-generated posts while at the same time there is no significant effect on users' decision to repeatedly post on the display.</p>
<p>Keywords:
content moderation; public displays; twitter</p>
<h2 id="Human-robot interaction    5">Human-robot interaction    5</h2>
<h3 id="161. Design patterns for exploring and prototyping human-robot interactions.">161. Design patterns for exploring and prototyping human-robot interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557057">Paper Link</a>    Pages:1439-1448</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Saupp=eacute=:Allison">Allison Saupp</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mutlu:Bilge">Bilge Mutlu</a></p>
<p>Abstract:
Robotic products are envisioned to offer rich interactions in a range of environments. While their specific roles will vary across applications, these products will draw on fundamental building blocks of interaction, such as greeting people, narrating information, providing instructions, and asking and answering questions. In this paper, we explore how such building blocks might serve as interaction design patterns that enable design exploration and prototyping for human-robot interaction. To construct a pattern library, we observed human interactions across different scenarios and identified seven patterns, such as question-answer pairs. We then designed and implemented Interaction Blocks, a visual authoring environment that enabled prototyping of robot interactions using these patterns. Design sessions with designers and developers demonstrated the promise of using a pattern language for designing robot interactions, confirmed the usability of our authoring environment, and provided insights into future research on tools for human-robot interaction design.</p>
<p>Keywords:
authoring environment; design exploration; design patterns; design sessions; human-robot interaction; interaction design; prototyping</p>
<h3 id="162. Improving social presence in human-agent interaction.">162. Improving social presence in human-agent interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557180">Paper Link</a>    Pages:1449-1458</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pereira:Andr=eacute=_Tiago">Andr Tiago Pereira</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Prada:Rui">Rui Prada</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paiva:Ana">Ana Paiva</a></p>
<p>Abstract:
Humans have a tendency to consider media devices as social beings. Social agents and artificial opponents can be examined as one instance of this effect. With today's technology it is already possible to create artificial agents that are perceived as socially present. In this paper, we start by identifying the factors that influence perceptions of social presence in human-agent interactions. By taking these factors into account and by following previously defined guidelines for building socially present artificial opponents, a case study was created in which a social robot plays the Risk board game against three human players. An experiment was performed to ascertain whether the agent created in this case study is perceived as socially present. The experiment suggested that by following the guidelines for creating socially present artificial board game opponents, the perceived social presence of users towards the artificial agent improves.</p>
<p>Keywords:
artificial opponents; board games; human-robot interaction (hri); social presence</p>
<h3 id="163. Robot gestures make difficult tasks easier: the impact of gestures on perceived workload and task performance.">163. Robot gestures make difficult tasks easier: the impact of gestures on perceived workload and task performance.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557274">Paper Link</a>    Pages:1459-1466</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lohse:Manja">Manja Lohse</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rothuis:Reinier">Reinier Rothuis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perez:Jorge_Gallego">Jorge Gallego Perez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karreman:Daphne_E=">Daphne E. Karreman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Evers:Vanessa">Vanessa Evers</a></p>
<p>Abstract:
Gestures are important non-verbal signals in human communication. Research with virtual agents and robots has started to add to the scientific knowledge about gestures but many questions with respect to the use of gestures in human-computer interaction are still open. This paper investigates the influence of robot gestures on the users' perceived workload and task performance (i.e. information recall) in a direction-giving task. We conducted a 2 x 2 (robot gestures vs. no robot gestures x easy vs. difficult task) experiment. The results indicate that robot gestures increased user performance and decreased perceived workload in the difficult task but not in the easy task. Thus, robot gestures are a promising means to improve human-robot interaction particularly in challenging tasks.</p>
<p>Keywords:
gestures; human-robot interaction; perceived workload; task performance</p>
<h3 id="164. Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces.">164. Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557174">Paper Link</a>    Pages:1467-1470</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bidwell:Jonathan">Jonathan Bidwell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Holloway:Alexandra">Alexandra Holloway</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davidoff:Scott">Scott Davidoff</a></p>
<p>Abstract:
Many tasks call for efficient user interaction under time delay-controlling space instruments, piloting remote aircraft and operating search and rescue robots. In this paper we identify an underexplored design opportunity for building robotic teleoperation user interfaces following an evaluation of operator performance during a time-delayed robotic arm block-stacking task in twenty-two participants. More delay resulted in greater operator hesitation and a decreased ratio of active to inactive input. This ratio can serve as a useful proxy for measuring an operator's ability to anticipate the outcome of their control inputs before receiving delayed visual feedback. High anticipatory input ratio (AIR) scores indicate times when robot operators enter commands before waiting for visual feedback. Low AIR scores highlight when operators must wait for visual feedback before continuing. We used this measurement to help us identify particular sub-tasks where operators would likely benefit from additional support.</p>
<p>Keywords:
human-robot interface; metric; teleoperation; time delay</p>
<h3 id="165. Stay on the boundary: artifact analysis exploring researcher and user framing of robot design.">165. Stay on the boundary: artifact analysis exploring researcher and user framing of robot design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557395">Paper Link</a>    Pages:1471-1474</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Hee_Rin">Hee Rin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sabanovic:Selma">Selma Sabanovic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stolterman:Erik">Erik Stolterman</a></p>
<p>Abstract:
In recent years, HCI researchers have increased their focus on studying the power relationships between researchers and users, and developing methodologies for eliciting design ideas that are sensitive to existing epistemic hierarchies in technology design. The differential value given to expert versus lay knowledge is a central factor in these debates. We apply Artifact Analysis, developed to help designers handle the complexity of digital artifacts, as a method to explore how experts and non-experts understand and frame robots, a technology characterized by significant complexity. Our results show that both non-expert users and expert researchers have knowledge that is significant to future robot development, but they focus on different aspects of the technology - users address mediated and interaction complexity while researchers focus on internal and external complexity. We also found that robots function as boundary objects between experts and users, and suggest that one task designers can perform is to "stay on the boundary" and mediate between the different ways in which experts and non-experts frame emerging technology to develop designs that benefit from insights from both user and researcher perspectives.</p>
<p>Keywords:
artifact analysis; boundary objects; epistemic hierarchy</p>
<h2 id="Emergency response    4">Emergency response    4</h2>
<h3 id="166. Help beacons: design and evaluation of an ad-hoc lightweight s.o.s. system for smartphones.">166. Help beacons: design and evaluation of an ad-hoc lightweight s.o.s. system for smartphones.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557002">Paper Link</a>    Pages:1485-1494</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Al=Akkad:Amro">Amro Al-Akkad</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramirez:Leonardo">Leonardo Ramirez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Boden:Alexander">Alexander Boden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Randall:Dave_W=">Dave W. Randall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmermann:Andreas">Andreas Zimmermann</a></p>
<p>Abstract:
We present the design and evaluation of a lightweight mobile S.O.S. system that facilitates ad-hoc communication between first responders and victims in emergency situations. Our approach leverages established protocols and standards in unforeseen ways to provide a platform supporting the creation of short-lived communication links. The system comprises two mobile applications: one victim application that allows the broadcasting of distress signals by a novel use of Wi-Fi SSIDs; and a responder application that allows first responders to discover and trace the people broadcasting the signals. The main difference of our system with other platforms enabling communication in crisis situations is that our system is independent from existing network infrastructure and runs on off-the-shelf, commercially available smartphones. We describe the results of our evaluation process in the context of both a design evaluation during a real-world emergency response exercise and of two user workshops in preparation for an upcoming large-scale exercise.</p>
<p>Keywords:
ad-hoc communication; emergency response; mobile computing; smartphones</p>
<h3 id="167. Upvoting hurricane Sandy: event-based news production processes on a social news site.">167. Upvoting hurricane Sandy: event-based news production processes on a social news site.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557140">Paper Link</a>    Pages:1495-1504</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Leavitt:Alex">Alex Leavitt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Clark:Joshua_A=">Joshua A. Clark</a></p>
<p>Abstract:
This paper uses the case of Hurricane Sandy and reddit's topical community (subreddit) /r/sandy to examine the production and curation of news content around events on a social news site. Through qualitative analysis, we provide a coded topology of produced content and describe how types of networked gatekeeping impact the framing of a crisis situation. This study also examines, through quantitative modeling, what kind of information becomes negotiated and voted as relevant. We suggest that highly scored content shared in a social news setting focused more on human-interest media and perspective-based citizen journalism than professional news reports. We conclude by discussing how the mechanisms of social news sites conflict with the social norms and culture of reddit to produce differing expectations around news.</p>
<p>Keywords:
crisis communication; mixed methods; networked gatekeeping; news framing; news production; reddit; social news site</p>
<h3 id="168. Online public communications by police & fire services during the 2012 Hurricane Sandy.">168. Online public communications by police &amp; fire services during the 2012 Hurricane Sandy.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557227">Paper Link</a>    Pages:1505-1514</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hughes:Amanda_Lee">Amanda Lee Hughes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Denis:Lise_Ann_St=">Lise Ann St. Denis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Palen:Leysia">Leysia Palen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Anderson:Kenneth_Mark">Kenneth Mark Anderson</a></p>
<p>Abstract:
Social media and other online communication tools are a subject of great interest in mass emergency response. Members of the public are turning to these solutions to seek and offer emergency information. Emergency responders are working to determine what social media policies should be in terms of their "public information" functions. We report on the online communications from all the coastal fire and police departments within a 100 mile radius of Hurricane Sandy's US landfall. Across four types of online communication media, we collected data from 840 fire and police departments. Findings indicate that few departments used these online channels in their Sandy response efforts, and that communications differed between fire and police departments and across media type. However, among the highly engaged departments, there is evidence that they bend and adapt policies about what constitutes appropriate public communication in the face of emergency demands; therefore, we propose that flexibility is important in considering future emergency online communication policy. We conclude with design recommendations for making online communication media more "listenable" for both emergency managers and members of the public.</p>
<p>Keywords:
crisis informatics; disaster; emergency; microblogging; risk communication; social computing; social media</p>
<h3 id="169. EmergencyMessenger: a text based communication concept for indoor firefighting.">169. EmergencyMessenger: a text based communication concept for indoor firefighting.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557188">Paper Link</a>    Pages:1515-1524</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Betz:Matthias">Matthias Betz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wulf:Volker">Volker Wulf</a></p>
<p>Abstract:
Finding and rescuing missing or injured people or fighting fire inside burning buildings is a central challenge for fire brigades. To ensure the safety of indoor work, monitoring the operations of firefighting units is crucial. As in most countries, firefighters in Germany utilize radio sets to establish voice communication between indoor operating units and the supervisory structure outside. Based on findings from a long term ethnographic study in cooperation with different German fire brigades over a time span of more than 5 years we analyzed the advantages and disadvantages of the current voice over radio communication tactics and techniques. We designed and evaluated a complementary text based communication device the EMERGENCY-MESSENGER to support the time critical work of indoor units working under harsh conditions, wearing Self-Contained-Breathing-Apparatus (SCBA). We conducted 13 full scale training missions including extensive debriefings to design and evaluate the communication concept and the corresponding device.</p>
<p>Keywords:
autonomy; communication; cooperation; firefighting; indoor; messaging; monitoring; safety; security; text</p>
<h2 id="Sensemaking and information in use    5">Sensemaking and information in use    5</h2>
<h3 id="170. Odin: contextual document opinions on the go.">170. Odin: contextual document opinions on the go.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556959">Paper Link</a>    Pages:1525-1534</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hailpern:Joshua_M=">Joshua M. Hailpern</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huberman:Bernardo_A=">Bernardo A. Huberman</a></p>
<p>Abstract:
Information overload is a systemic problem for knowledge workers in enterprise. For a long time, information was scarce and therefore valuable. While, the explosion of digital information has made information plentiful, time to read and process that content is now scarce. This problem is only exacerbated by our increased mobility, and the expectation to be "on top" of the continuous barrage of documents while on the go. Knowledge workers in enterprise need solutions that are designed with quick methods for finding what to read in a large collection of documents (e.g. financial reports, legal documents, news), and ways of presenting it within small visual real estate. Unlike reviews, document collections are long, more varied, and context is extremely important. In response, we present Odin, a mobile web-based window onto a user's document corpus. Rather than performing corpus summarization, Odin users can quickly find opinions and documents that are Aligned or Divergent from the corpus' consensus, or those that are the most Relevant given the overall corpus' of opinions. Odin presents this information through a simple and intuitive mobile interface. To the authors' knowledge, this is the first UI/system (and support algorithm) to allow mobile users to place documents and their opinions in context through alignment rather than raw word count or sentiment. Positive results from two evaluations are also presented.</p>
<p>Keywords:
alignment; consensus; divergence; economics of attention; interaction; interface; mobile; opinions</p>
<h3 id="171. Monadic exploration: seeing the whole through its parts.">171. Monadic exploration: seeing the whole through its parts.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557083">Paper Link</a>    Pages:1535-1544</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/D=ouml=rk:Marian">Marian Drk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Comber:Rob">Rob Comber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dade=Robertson:Martyn">Martyn Dade-Robertson</a></p>
<p>Abstract:
Monadic exploration is a new approach to interacting with relational information spaces that challenges the distinction between the whole and its parts. Building on the work of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad as a useful lens on online communities and collections that expands the possibility for creating meaning in their navigation. While existing interfaces tend to emphasize either the structure of the whole or details of a part, monadic exploration brings these opposing perspectives closer together in continuous movements between partially overlapping points of view. We present a visualization that reflects a given node's relative position within a network using radial displacements and visual folding. To investigate the potential of monadic exploration we report on an iterative design process of a web-based visualization of a highly cross-referenced book and its six-month deployment.</p>
<p>Keywords:
exploratory search; information seeking; information visualization; network visualization; philosophy; theory</p>
<h3 id="172. Photographing information needs: the role of photos in experience sampling method-style research.">172. Photographing information needs: the role of photos in experience sampling method-style research.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557192">Paper Link</a>    Pages:1545-1554</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yue:Zhen">Zhen Yue</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Litt:Eden">Eden Litt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cai:Carrie_J=">Carrie J. Cai</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stern:Jeff">Jeff Stern</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baxter:Kathy">Kathy Baxter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guan:Zhiwei">Zhiwei Guan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sharma:Nikhil">Nikhil Sharma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Guangqiang_=George=">Guangqiang (George) Zhang</a></p>
<p>Abstract:
The Experience Sampling Method (ESM) enables researchers to capture information about participants' experiences in the moment. Adding an end-of-day retrospective survey also allows participants to elaborate on those experiences. Although the use of photos in retrospective interviews and surveys for memory elicitation is well known, little research has investigated the use of photos in ESM studies. As smartphone adoption increases facilitating ESM studies and making photo sharing easier, researchers need to continuously evaluate the method and investigate the role of photos in such studies. We conducted a large-scale ESM and retrospective survey study via Android smartphones with more than 1,000 US participants, and analyzed participants' photo submissions, including how photo use correlated with participants' data quality and what, if any, value photos added for researchers. Our study sheds light on the role of photos in ESM and retrospective studies that researchers can reference when constructing future study designs.</p>
<p>Keywords:
experience sampling method; information need; photo-elicitation; retrospective study method</p>
<h3 id="173. Design insights for the next wave ontology authoring tools.">173. Design insights for the next wave ontology authoring tools.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557284">Paper Link</a>    Pages:1555-1558</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vigo:Markel">Markel Vigo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jay:Caroline">Caroline Jay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stevens:Robert">Robert Stevens</a></p>
<p>Abstract:
Ontologies have been employed across scientific and business domains for some time, and the proliferation of linked data means the number and range of potential authors is set to increase significantly. Ontologies using the Web Ontology Language (OWL) are complex artefacts, however: the authoring process requires not only knowledge of the application domain, but also skills in programming and logics. To date, there has been no systematic attempt to understand the effectiveness of existing tools, or explore what users really require to build successful ontologies. Here we address this shortfall, presenting insights from an interview study with 15 ontology authors. We identify the problems reported by authors, and the strategies they employ to solve them. We map the data to a set of design recommendations, which describe how tools of the future can support ontology authoring. A key challenge is dealing with information overload: improving the user's ability to navigate, populate and debug large ontologies will revolutionise the engineering process, and open ontology authoring up to a new generation of users.</p>
<p>Keywords:
authoring tools; ontologies; semantic web</p>
<h3 id="174. The role of interactive biclusters in sensemaking.">174. The role of interactive biclusters in sensemaking.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557337">Paper Link</a>    Pages:1559-1562</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sun:Maoyuan">Maoyuan Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bradel:Lauren">Lauren Bradel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/North:Christopher_L=">Christopher L. North</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramakrishnan:Naren">Naren Ramakrishnan</a></p>
<p>Abstract:
Visual exploration of relationships within large, textual datasets is an important aid for human sensemaking. By understanding computed, structural relationships between entities of different types (e.g., people and locations), users can leverage domain expertise and intuition to determine the importance and relevance of these relationships for tasks, such as intelligence analysis. Biclusters are a potentially desirable method to facilitate this, because they reveal coordinated relationships that can represent meaningful relationships. Bixplorer, a visual analytics prototype, supports interactive exploration of textual datasets in a spatial workspace with biclusters. In this paper, we present results of a study that analyzes how users interact with biclusters to solve an intelligence analysis problem using Bixplorer. We found that biclusters played four principal roles in the analytical process: an effective starting point for analysis, a revealer of two levels of connections, an indicator of potentially important entities, and a useful label for clusters of organized information.</p>
<p>Keywords:
biclustering; intelligence analysis; visual interaction</p>
<h2 id="Presentation technologies    4">Presentation technologies    4</h2>
<h3 id="175. SmartVoice: a presentation support system for overcoming the language barrier.">175. SmartVoice: a presentation support system for overcoming the language barrier.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557161">Paper Link</a>    Pages:1563-1570</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Li:Xiang">Xiang Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rekimoto:Jun">Jun Rekimoto</a></p>
<p>Abstract:
In most cases, speeches or presentations at an international event are required to be given in a common language (e.g. English). However, for people who are not proficient in that common language, delivering presentations fluently is very difficult. Simultaneous translation seems to be a solution, but besides its high cost, simultaneous translation undermines the nature of the presentation by substituting the real voice of the lecturer as well as his/her emotions. In this paper, we propose "SmartVoice", a presentation support system, which aims to overcome language barriers. By tracking the lip motion of the lecturer, SmartVoice controls the playback of the narration, which is a sound data prepared in advance or created automatically using a voice synthesizer. SmartVoice also controls the intonation of the sound based on the position and shape of the lecturer's mouth. As the lecturer can talk at his/her own pace with the voice automatically following, it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed that audiences find it difficult to distinguish between the narration generated by SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice to fields other than multi-language presentation support, such as Automated Dialogue Replacement and language study.</p>
<p>Keywords:
face tracking; facial actions; language barrier; lip sync; presentation support; user interface</p>
<h3 id="176. PitchPerfect: integrated rehearsal environment for structured presentation preparation.">176. PitchPerfect: integrated rehearsal environment for structured presentation preparation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557286">Paper Link</a>    Pages:1571-1580</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Trinh:Ha">Ha Trinh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yatani:Koji">Koji Yatani</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edge:Darren">Darren Edge</a></p>
<p>Abstract:
Rehearsal is a critical component of preparing to give an oral presentation, yet it is frequently abbreviated, performed in ways that are inefficient or ineffective, or simply omitted. We conducted an exploratory study to understand the relationship between the theory and practice of presentation rehearsal, classifying our qualitative results into five themes to motivate more structured rehearsal support deeply integrated in slide presentation software. In a within-subject study (N=12) comparing against participants' existing rehearsal practices, we found that our resulting PitchPerfect system significantly improved overall presentation quality and content coverage as well as provided greater support for content mastery, time management, and confidence building.</p>
<p>Keywords:
powerpoint; presentation rehearsal; slideware</p>
<h3 id="177. DemoWiz: re-performing software demonstrations for a live presentation.">177. DemoWiz: re-performing software demonstrations for a live presentation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557254">Paper Link</a>    Pages:1581-1590</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chi:Pei=Yu">Pei-Yu Chi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Bongshin">Bongshin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Drucker:Steven_M=">Steven M. Drucker</a></p>
<p>Abstract:
Showing a live software demonstration during a talk can be engaging, but it is often not easy: presenters may struggle with (or worry about) unexpected software crashes and encounter issues such as mismatched screen resolutions or faulty network connectivity. Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time. An alternative is to present with pre-recorded screencast videos. It is, however, challenging to precisely match the narration to the video when using existing video players. We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations. DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight editing. A user study shows that our design significantly improves the presenters' perceived ease of narration and timing compared to a system without visualizations that was similar to a standard playback control. Furthermore, nine (out of ten) participants preferred DemoWiz over the standard playback control with the last expressing no preference.</p>
<p>Keywords:
demo; demonstration; presentation; software demo; video</p>
<h3 id="178. TurningPoint: narrative-driven presentation planning.">178. TurningPoint: narrative-driven presentation planning.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557389">Paper Link</a>    Pages:1591-1594</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pschetz:Larissa">Larissa Pschetz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yatani:Koji">Koji Yatani</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edge:Darren">Darren Edge</a></p>
<p>Abstract:
Once upon a time, people told stories unencumbered by slides. What modern presentations gain through visual slide support, however, is often at the expense of storytelling. We present TurningPoint, a probe to investigate the potential use of narrative-driven talk planning in slideware. Our study of TurningPoint reveals a delicate balance between narrative templates focusing author attention in ways that save time, and fixating attention in ways that limit experimentation.</p>
<p>Keywords:
narrative templates; slide presentations; storytelling</p>
<h2 id="Personal health and wellbeing    4">Personal health and wellbeing    4</h2>
<h3 id="179. Supporting treatment of people living with HIV / AIDS in resource limited settings with IVRs.">179. Supporting treatment of people living with HIV / AIDS in resource limited settings with IVRs.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557236">Paper Link</a>    Pages:1595-1604</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Joshi:Anirudha_N=">Anirudha N. Joshi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rane:Mandar">Mandar Rane</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roy:Debjani">Debjani Roy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Emmadi:Nagraj">Nagraj Emmadi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Srinivasan:Padma">Padma Srinivasan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kumarasamy:N=">N. Kumarasamy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pujari:Sanjay">Sanjay Pujari</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Solomon:Davidson">Davidson Solomon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rodrigues:Rashmi">Rashmi Rodrigues</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Saple:D=_G=">D. G. Saple</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sen:Kamalika">Kamalika Sen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Veldeman:Els">Els Veldeman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rutten:Romain">Romain Rutten</a></p>
<p>Abstract:
We developed an interactive voice response (IVR) system called TAMA (Treatment Advice by Mobile Alerts) that provides treatment support to people living with HIV / AIDS (PLHA) in developing countries, who are on antiret-roviral therapy (ART). We deployed TAMA with 54 PLHA in 5 HIV clinics in India for a period of 12 weeks. During the study, we gathered feedback about TAMA's design and usage. Additionally, we conducted detailed qualitative interviews and analysed usage logs. We found that TAMA was usable and viable in the real life settings of PLHA and it had many desirable effects on their treatment adherence. We developed insights that inform the design of TAMA and some of these can be generalised to design of other long-term, frequent-use IVR applications for users in developing countries in the healthcare domain and beyond.</p>
<p>Keywords:
aids; developing countries; frequent-use applications; healthcare; hiv; ivr; tama; treatment support</p>
<h3 id="180. Reflection through design: immigrant women's self-reflection on managing health and wellness.">180. Reflection through design: immigrant women's self-reflection on managing health and wellness.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557119">Paper Link</a>    Pages:1605-1614</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brown:Deana">Deana Brown</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ayo:Victoria">Victoria Ayo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grinter:Rebecca_E=">Rebecca E. Grinter</a></p>
<p>Abstract:
Women comprise nearly half of the immigrant population worldwide and are susceptible to a wider range of health challenges compared to immigrant men. We present the findings of four participatory design sessions with immigrant women from the Caribbean to identify health and wellness challenges they faced and to conceptualize technologies to help them manage these issues. Stress, dietary challenges (specifically obesity), mental health, and domestic abuse, as identified by the women, form the focal themes for the design sessions. Their design approaches emphasized rebuilding the support structure, reducing stressors through entertainment and relaxation and encouraging positive gradational lifestyle changes. In conceiving health and wellness technologies for immigrant women, our work highlights opportunities for HCI to consider the role of others (and who benefits) and to reflect on the role of design and the underlying values and themes designs encompass. Finally, we emphasize how the technologies conceived by these women support rather than replace social solutions to the health and wellness challenges faced by these and other immigrant women.</p>
<p>Keywords:
caribbean; culture; health and wellness; immigrant women; participatory design</p>
<h3 id="181. DDFSeeks same: sexual health-related language in online personal ads for men who have sex with men.">181. DDFSeeks same: sexual health-related language in online personal ads for men who have sex with men.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557077">Paper Link</a>    Pages:1615-1624</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Haimson:Oliver_L=">Oliver L. Haimson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brubaker:Jed_R=">Jed R. Brubaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hayes:Gillian_R=">Gillian R. Hayes</a></p>
<p>Abstract:
The HIV/AIDS crisis of the 1980s fundamentally changed sexual practices of men who have sex with men (MSM) in the U.S., including increased usage of sexual health-related (SHR) language in personal advertisements. Analyzing online personal ads from Craigslist, we found a substantial increase in SHR language, from ~23% in 1988 to over 53% today, echoing continuing concern about rising HIV rates. We argue that SHR language in Craigslist ads can be used as a sensor to provide insight into HIV epidemiology as well as discourse among particular communities. We show a positive significant relationship between prevalence rate of HIV in an ad's location and use of SHR language in that location. Analysis highlights the opportunity for SHR information found in Craigslist personal ads to serve as a data source for HIV prevention research. More broadly, we argue for mining large-scale user-generated content to inform HCI design of health and other systems, and explore use of such data to examine temporal changes in language to facilitate improved user-interface design.</p>
<p>Keywords:
computational linguistics; craigslist; digital identity; health informatics; hiv/aids; lgbt; online dating; personal ads</p>
<h3 id="182. Support matching and satisfaction in an online breast cancer support community.">182. Support matching and satisfaction in an online breast cancer support community.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557108">Paper Link</a>    Pages:1625-1634</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vlahovic:Tatiana_A=">Tatiana A. Vlahovic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Yi=Chia">Yi-Chia Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Levine:John_M=">John M. Levine</a></p>
<p>Abstract:
Research suggests that online health support benefits chronically ill users. Their satisfaction might be an indicator that they perceive group interactions as beneficial and a precursor to group commitment. We examined whether receiving emotional and informational support is satisfying in its own right, or whether satisfaction depends on matches between what users sought and what they received. Two studies collected judgments in a breast cancer support community of support users sought, support they received, and their expressed satisfaction. While receiving emotional or informational support in general positively predicted satisfaction, users expressed less satisfaction when they sought informational support but received emotional support. There was also a tendency for users to express more satisfaction when they sought and received informational support. On the other hand, users were equally satisfied with emotional and informational support after seeking emotional support. Implications for membership commitment and interventions in online support groups are discussed.</p>
<p>Keywords:
breast cancer; computer-mediated communication; health informatics; social support; support groups</p>
<h2 id="Design theory    4">Design theory    4</h2>
<h3 id="183. Between theory and practice: bridging concepts in HCI research.">183. Between theory and practice: bridging concepts in HCI research.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557342">Paper Link</a>    Pages:1635-1644</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dalsg=aring=rd:Peter">Peter Dalsgrd</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dindler:Christian">Christian Dindler</a></p>
<p>Abstract:
We present the notion of "bridging concepts" as a particular form of intermediary knowledge in HCI research, residing between theory and practice. We argue that bridging concepts address the challenge of facilitating exchange between theory and practice in HCI, and we compare it to other intermediary forms of knowledge such as strong concepts and conceptual constructs. We propose that bridging concepts have three defining constituents: a theoretical foundation, a set of design articulations and a range of exemplars that demonstrate the scope and potential of their application. These constituents specify how bridging concepts, as a form of knowledge, are accountable to both theory and practice. We present an analysis of the concept of "peepholes" as an example of a bridging concept aimed at spurring user curiosity and engagement.</p>
<p>Keywords:
analytical frameworks; engagement; experience-oriented design; interaction design theory</p>
<h3 id="184. Evolution of design competence in UX practice.">184. Evolution of design competence in UX practice.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557264">Paper Link</a>    Pages:1645-1654</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gray:Colin_M=">Colin M. Gray</a></p>
<p>Abstract:
There has been increasing interest in the adoption of UX within corporate environments, and what competencies translate into effective UX design. This paper addresses the space between pedagogy and UX practice through the lens of competence, with the goal of understanding how students are initiated into the practice community, how their perception of competence shifts over time, and what factors influence this shift. A 12-week longitudinal data collection, including surveys and interviews, documents this shift, with participants beginning internships and full-time positions in UX. Students and early professionals were asked to assess their level of competence and factors that influenced competence. A co-construction of identity between the designer and their environment is proposed, with a variety of factors relating to tool and representational knowledge, complexity, and corporate culture influencing perceptions of competence in UX over time. Opportunities for future research, particularly in building an understanding of competency in UX based on this preliminary framing of early UX practice are addressed.</p>
<p>Keywords:
competence; design capability; expertise; identity; ux practice</p>
<h3 id="185. Causal interactions.">185. Causal interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557216">Paper Link</a>    Pages:1655-1664</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Darlow:Adam">Adam Darlow</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Goldin:Gideon">Gideon Goldin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sloman:Steven">Steven Sloman</a></p>
<p>Abstract:
In this paper we present two design guidelines, causal order and continuity, to be used as rules of thumb for designing intuitive interactions based on principles of causal reasoning. We propose that designing interactions to behave like real-world systems of cause and effect makes them more intuitive. Using these basic principles avoids the limitations inherent to specific metaphors. In three experiments, participants solved puzzles using variations of a novel graphical interface. Participants using interfaces that were consistent with the causal guidelines consistently solved the puzzle faster than participants using inconsistent interfaces. We also discuss common interactions already consistent with the causal guidelines as well as areas where the guidelines are likely to apply successfully. The causal order guidelines provide specific utility while also demonstrating how principles of causal psychology can be applied to help interface designers better convey the functionality of their interfaces.</p>
<p>Keywords:
causal reasoning; design guidelines; graphical interfaces; gui; interaction design; psychology</p>
<h3 id="186. Personas is applicable: a study on the use of personas in Denmark.">186. Personas is applicable: a study on the use of personas in Denmark.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557080">Paper Link</a>    Pages:1665-1674</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nielsen:Lene">Lene Nielsen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hansen:Kira_Storgaard">Kira Storgaard Hansen</a></p>
<p>Abstract:
The persona method is gaining widespread use and support. Many researchers have reported from single cases and novel domains how they have used the method. Few have conducted literature studies in order to identify and discuss the different understandings of the method. Fewer still have reported on ethnographic studies of practice. This paper falls within the last category, reporting on a study on how practitioners in Denmark use the method, and their perceptions of benefits and challenges when using the method. Finally, different casts of personas obtained from the involved companies are analyzed. The findings are compared to reported studies of practice. Contrary to the existing findings the study reports that the method is well integrated into existing practices.</p>
<p>Keywords:
application; personas; practice-study; scenarios</p>
<h2 id="Novel keyboards    5">Novel keyboards    5</h2>
<h3 id="187. GestKeyboard: enabling gesture-based interaction on ordinary physical keyboard.">187. GestKeyboard: enabling gesture-based interaction on ordinary physical keyboard.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557362">Paper Link</a>    Pages:1675-1684</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Haimo">Haimo Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a></p>
<p>Abstract:
Stroke gestures are intuitive and efficient but often require gesture-capable input hardware such as a touchscreen. In this paper, we present GestKeyboard, a novel technique for gesturing over an ordinary, unmodified physical keyboard that remains the major input modality for existing desktop and laptop computers. We discuss an exploratory study for understanding the design space of gesturing on a physical keyboard and our algorithms for detecting gestures in a modeless way, without interfering with the keyboard's major functionality such as text entry and shortcuts activation. We explored various features for detecting gestures from a keyboard event stream. Our experiment based on the data collected from 10 participants indicated it is feasible to reliably detect gestures from normal keyboard use, 95% detection accuracy within a maximum latency of 200ms.</p>
<p>Keywords:
gesture detection; modeless interaction; physical keyboard</p>
<h3 id="188. Gesture script: recognizing gestures and their structure using rendering scripts and interactively trained parts.">188. Gesture script: recognizing gestures and their structure using rendering scripts and interactively trained parts.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557263">Paper Link</a>    Pages:1685-1694</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/L=uuml=:Hao">Hao L</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fogarty:James">James Fogarty</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yang">Yang Li</a></p>
<p>Abstract:
Gesture-based interactions have become an essential part of the modern user interface. However, it remains challenging for developers to create gestures for their applications. This paper studies unistroke gestures, an important category of gestures defined by their single-stroke trajectories. We present Gesture Script, a tool for creating unistroke gesture recognizers. Gesture Script enhances example-based learning with interactive declarative guidance through rendering scripts and interactively trained parts. The structural information from the rendering scripts allows Gesture Script to synthesize gesture variations and generate a more accurate recognizer that also automatically extracts gesture attributes needed by applications. The results of our study with developers show that Gesture Script preserves the threshold of familiar example based gesture tools, while raising the ceiling of the recognizers created in such tools.</p>
<p>Keywords:
gesture recognition; interactive machine learning</p>
<h3 id="189. Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.">189. Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557030">Paper Link</a>    Pages:1695-1704</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Stuart">Stuart Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Keskin:Cem">Cem Keskin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hilliges:Otmar">Otmar Hilliges</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Izadi:Shahram">Shahram Izadi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Helmes:John">John Helmes</a></p>
<p>Abstract:
We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.</p>
<p>Keywords:
gesture recognition; input devices; keyboard</p>
<h3 id="190. B#: chord-based correction for multitouch braille input.">190. B#: chord-based correction for multitouch braille input.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557269">Paper Link</a>    Pages:1705-1708</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nicolau:Hugo">Hugo Nicolau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Montague:Kyle">Kyle Montague</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guerreiro:Tiago_Jo=atilde=o">Tiago Joo Guerreiro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guerreiro:Jo=atilde=o">Joo Guerreiro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hanson:Vicki_L=">Vicki L. Hanson</a></p>
<p>Abstract:
Braille has paved its way into mobile touchscreen devices, providing faster text input for blind people. This advantage comes at the cost of accuracy, as chord typing over a flat surface has proven to be highly error prone. A misplaced finger on the screen translates into a different or unrecognized character. However, the chord itself gathers information that can be leveraged to improve input performance. We present B#, a novel correction system for multitouch Braille input that uses chords as the atomic unit of information rather than characters. Experimental results on data collected from 11 blind people revealed that B# is effective in correcting errors at character-level, thus providing opportunities for instant corrections of unrecognized chords; and at word-level, where it outperforms a popular spellchecker by providing correct suggestions for 72% of incorrect words (against 38%). We finish with implications for designing chord-based correction system and avenues for future work.</p>
<p>Keywords:
braille; chord; error correction; mobile; touchscreen</p>
<h3 id="191. Representatively memorable: sampling the right phrase set to get the text entry experiment right.">191. Representatively memorable: sampling the right phrase set to get the text entry experiment right.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557024">Paper Link</a>    Pages:1709-1712</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Leiva:Luis_A=">Luis A. Leiva</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sanchis=Trilles:Germ=aacute=n">Germn Sanchis-Trilles</a></p>
<p>Abstract:
In text entry experiments, memorability is a desired property of the phrases used as stimuli. Unfortunately, to date there is no automated method to achieve this effect. As a result, researchers have to use either manually curated English-only phrase sets or sampling procedures that do not guarantee phrases being memorable. In response to this need, we present a novel sampling method based on two core ideas: a multiple regression model over language-independent features, and the statistical analysis of the corpus from which phrases will be drawn. Our results show that researchers can finally use a method to successfully curate their own stimuli targeting potentially any language or domain. The source code as well as our phrase sets are publicly available.</p>
<p>Keywords:
memorability; representativeness; sampling; text entry</p>
<h2 id="DIY and hacking    4">DIY and hacking    4</h2>
<h3 id="192. Sketching in circuits: designing and building electronics on paper.">192. Sketching in circuits: designing and building electronics on paper.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557391">Paper Link</a>    Pages:1713-1722</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/q/Qi:Jie">Jie Qi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Buechley:Leah">Leah Buechley</a></p>
<p>Abstract:
The field of new methods and techniques for building electronics is quickly growing - from research in new materials for circuit building, to modular toolkits, and more recently to untoolkits, which aim to incorporate more off-the-shelf parts. However, the standard mediums for circuit design and construction remain the breadboard, protoboard, and printed circuit board (PCB). As an alternative, we introduce a method in which circuits are hand-made on ordinary paper substrates, connected with conductive foil tape and off-the-shelf circuit components with the aim of supporting the durability, scalability, and accessibility needs of novice and expert circuit builders alike. We also used electrified notebooks to investigate how the circuit design and build process would be affected by the constraints and affordances of the bound book. Our ideas and techniques were evaluated through a series of workshops, through which we found our methods supported a wide variety of approaches and results - both technical and expressive - to electronics design and construction.</p>
<p>Keywords:
circuit prototyping; paper computing; sketchbooks; toolkits</p>
<h3 id="193. Do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy.">193. Do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557309">Paper Link</a>    Pages:1723-1732</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mellis:David_A=">David A. Mellis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Buechley:Leah">Leah Buechley</a></p>
<p>Abstract:
This paper describes our do-it-yourself cellphone and our use of it to investigate the possibilities and limits of high-tech DIY practice. We describe our autobiographical approach -- making the phone and using it in our daily lives -- and our work disseminating the cellphone in workshops and online. This informs a discussion of the implications of technology for DIY practice. We suggest an understanding of DIY as an individual's ability to combine existing technologies into a desired product, enabled and limited by ecosystems of industrial actors and individuals. We distinguish different pathways into high-tech DIY practice, consider the relationship between prototyping and production, and discuss the effect of technology on DIY's relevance and tools, and on notions of transparency. We conclude by reflecting on the relationship between DIY and empowerment: the extent to which making devices gives people control over the technology in their lives.</p>
<p>Keywords:
cellphone; digital fabrication; diy; electronics; microcontrollers; prototyping; toolkits</p>
<h3 id="194. 3D printed interactive speakers.">194. 3D printed interactive speakers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557046">Paper Link</a>    Pages:1733-1742</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/i/Ishiguro:Yoshio">Yoshio Ishiguro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Poupyrev:Ivan">Ivan Poupyrev</a></p>
<p>Abstract:
We propose technology for designing and manufacturing interactive 3D printed speakers. With the proposed technology, sound reproduction can easily be integrated into vari-ous objects at the design stage and little assembly is required. The speaker can take the shape of anything from an abstract spiral to a rubber duck, opening new opportunities in product design. Furthermore, both audible sound and inaudible ultrasound can be produced with the same design, allowing for identifying and tracking 3D printed objects in space using common integrated microphones. The design of 3D printed speakers is based on electrostatic loudspeaker technology first explored in the early 1930s but not broadly applied until now. These speakers are simpler than common electromagnetic speakers, while allowing for sound reproduction at 60 dB levels with arbitrary directivity ranging from focused to omnidirectional. Our research of 3D printed speakers contributes to the growing body of work exploring functional 3D printing in interactive applications.</p>
<p>Keywords:
3d printing; additive manufacturing; audio; rapid prototyping; speakers; tangible; tracking; ultrasonic</p>
<h3 id="195. Circuit stickers: peel-and-stick construction of interactive electronic prototypes.">195. Circuit stickers: peel-and-stick construction of interactive electronic prototypes.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557150">Paper Link</a>    Pages:1743-1746</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hodges:Steve">Steve Hodges</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Villar:Nicolas">Nicolas Villar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Nicholas">Nicholas Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chugh:Tushar">Tushar Chugh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/q/Qi:Jie">Jie Qi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nowacka:Diana">Diana Nowacka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kawahara:Yoshihiro">Yoshihiro Kawahara</a></p>
<p>Abstract:
We present a novel approach to the construction of electronic prototypes which can support a variety of interactive devices. Our technique, which we call circuit stickers, involves adhering physical interface elements such as LEDs, sounders, buttons and sensors onto a cheap and easy-to-make substrate which provides electrical connectivity. This assembly may include control electronics and a battery for standalone operation, or it can be interfaced to a microcontroller or PC. In this paper we illustrate different points in the design space and demonstrate the technical feasibility of our approach. We have found circuit stickers to be versatile and low-cost, supporting quick and easy construction of physically flexible interactive prototypes. Building extra copies of a device is straightforward. We believe this technology has potential for design exploration, research proto-typing, education and for hobbyist projects.</p>
<p>Keywords:
conductive inkjet; physical computing; rapid prototyping; silver ink; solderless electronics; tangible interfaces</p>
<h2 id="User models and prediction    4">User models and prediction    4</h2>
<h3 id="196. Modeling the perception of user performance.">196. Modeling the perception of user performance.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557355">Paper Link</a>    Pages:1747-1756</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nicosia:Max">Max Nicosia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kristensson:Per_Ola">Per Ola Kristensson</a></p>
<p>Abstract:
This paper studies how users perceive their own performance in two alternative user interfaces. We extend methodology from psychophysics to the study of interactive performance and conduct two experiments in order to create a model of users' perception of their own performance. In our studies, two interfaces are sequentially used in a pointing task, and users are asked to rate in which interface their performance was higher. We first differentiate the effects of objective performance (speed and accuracy) versus interface qualities (distance between elements and width of elements) on perceived performance. We then derive a model that predicts the amount of change required in an interface for users to reliably detect a difference. The model is useful as a heuristic for predicting if a new interface design is better enough for users to reliably appreciate the obtained gain in user performance. We validate the model via a separate user study, and conclude by discussing how to apply our findings to design problems.</p>
<p>Keywords:
perception of user performance; psychophysics</p>
<h3 id="197. Edit distance modulo bisimulation: a quantitative measure to study evolution of user models.">197. Edit distance modulo bisimulation: a quantitative measure to study evolution of user models.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557191">Paper Link</a>    Pages:1757-1766</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zade:Himanshu">Himanshu Zade</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Adimoolam:Santosh_Arvind">Santosh Arvind Adimoolam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gollapudi:Sai">Sai Gollapudi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dey:Anind_K=">Anind K. Dey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Choppella:Venkatesh">Venkatesh Choppella</a></p>
<p>Abstract:
When a user learns to use a new device, her understanding of it evolves. A progressive comparison of the evolving user models towards the device target model, for analysing learning, involves determining the behavioral proximity between them. To quantify the gap between a user model and a target model, we introduce an edit distance metric for measuring their behavioral proximity using a bisimulation-based equivalence relation. We define edit distance to be the minimum number of edges and states with incident edges required to be deleted from and/or added to a user model to make it bisimilar to the target model. We propose an algorithm to compute edit distance between two models and employ the heuristic procedure on experimental data for computing edit distance between target and user models. The data is organised into two experiments depending on the device the user interacted with: (a) a simple device resembling a vending machine and (b) a close to real-world vehicle transmission model. The results validate our proposed metric as edit distance converges with progressive user learning, increases for erroneous learning, and remains unchanged indicating no learning.</p>
<p>Keywords:
behavioral proximity.; finite state machines; learning</p>
<h3 id="198. The law of unintended consequences: the case of external subgoal support.">198. The law of unintended consequences: the case of external subgoal support.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557422">Paper Link</a>    Pages:1767-1776</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Trafton:J=_Gregory">J. Gregory Trafton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ratwani:Raj_M=">Raj M. Ratwani</a></p>
<p>Abstract:
Many interfaces have been designed to prevent or reduce errors. These interfaces may, in fact, reduce the error rate of specific error classes, but may also have unintended consequences. In this paper, we show a series of studies where a better interface did not reduce the number of errors but instead shifted errors from one error class (omissions) to another error class (perseverations). We also show that having access to progress tracking (a progress bar) does not reduce the number of errors. We propose and demonstrate a solution -- a predictive error system -- that reduces errors based on the error class, not on the type of interface.</p>
<p>Keywords:
computer human interaction; error prediction; interface subgoal support; progress tracking</p>
<h3 id="199. Causality: a conceptual model of interaction history.">199. Causality: a conceptual model of interaction history.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556990">Paper Link</a>    Pages:1777-1786</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nancel:Mathieu">Mathieu Nancel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a></p>
<p>Abstract:
Simple history systems such as Undo and Redo permit retrieval of earlier or later interaction states, but advanced systems allow powerful capabilities to reuse or reapply combinations of commands, states, or data across interaction contexts. Whether simple or powerful, designing interaction history mechanisms is challenging. We begin by reviewing existing history systems and models, observing a lack of tools to assist designers and researchers in specifying, contemplating, combining, and communicating the behaviour of history systems. To resolve this problem, we present CAUSALITY, a conceptual model of interaction history that clarifies the possibilities for temporal interactions. The model includes components for the work artifact (such as the text and formatting of a Word document), the system context (such as the settings and parameters of the user interface), the linear timeline (the commands executed in real time), and the branching chronology (a structure of executed commands and their impact on the artifact and/or context, which may be navigable by the user). We then describe and exemplify how this model can be used to encapsulate existing user interfaces and reveal limitations in their behaviour, and we also show in a conceptual evaluation how the model stimulates the design of new and innovative opportunities for interacting in time.</p>
<p>Keywords:
conceptual model; history systems; paradoxes; undo</p>
<h2 id="Engage and educate children    5">Engage and educate children    5</h2>
<h3 id="200. Conversing with children: cartoon and video people elicit similar conversational behaviors.">200. Conversing with children: cartoon and video people elicit similar conversational behaviors.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557280">Paper Link</a>    Pages:1787-1796</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hyde:Jennifer">Jennifer Hyde</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kiesler:Sara_B=">Sara B. Kiesler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hodgins:Jessica_K=">Jessica K. Hodgins</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carter:Elizabeth_J=">Elizabeth J. Carter</a></p>
<p>Abstract:
Interactive animated characters have the potential to engage and educate children, but there is little research on children's interactions with animated characters and real people. We conducted an experiment with 69 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as a person. A subset of the participants interacted with characters that displayed exaggerated and damped facial motion. The children completed two conversations with an adult confederate who appeared once as herself through video and once as a cartoon character. We measured how much the children spoke and compared their gaze and gesture patterns. We asked them to rate their conversations and indicate their preferred partner. There was no difference in children's conversation behavior with the cartoon character and the person on video, even among those who preferred the person and when the cartoon exhibited altered motion. These results suggest that children will interact with animated characters as they would another person.</p>
<p>Keywords:
agent; animated character; avatar; behavior; children; conversation; facial motion</p>
<h3 id="201. Involving children in content control: a collaborative and education-oriented content filtering approach.">201. Involving children in content control: a collaborative and education-oriented content filtering approach.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557128">Paper Link</a>    Pages:1797-1806</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hashish:Yasmeen">Yasmeen Hashish</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bunt:Andrea">Andrea Bunt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Young:James_Everett">James Everett Young</a></p>
<p>Abstract:
We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate. A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach. Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction. In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.</p>
<p>Keywords:
children and technology; collaborative content filtering; parental control strategies</p>
<h3 id="202. What did spot hide?: a question-answering game for preschool children.">202. What did spot hide?: a question-answering game for preschool children.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557205">Paper Link</a>    Pages:1807-1816</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tewari:Anuj">Anuj Tewari</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Canny:John">John Canny</a></p>
<p>Abstract:
Early literacy is critical to child development, and determines a child's later educational and life opportunities. Moreover, preschool children are incessantly inquisitive, and will readily engage in question answering and asking activities if given the opportunity. We argue here that question asking/answering technologies can play a major role in early literacy. We describe the design and evaluation of a conversational agent called Spot, with the goal of engaging children in a 20-questions game. Towards this goal, we conducted a feasibility study to determine if children's questions are "on-topic" and suitable for ASR/dialogue systems. We evaluated Spot's performance at conducting a game of 20-questions against that of a human partner.</p>
<p>Keywords:
conversational agents; games; preschool literacy; question-answering</p>
<h3 id="203. Rafigh: a living media interface for speech intervention.">203. Rafigh: a living media interface for speech intervention.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557402">Paper Link</a>    Pages:1817-1820</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hamidi:Foad">Foad Hamidi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baljko:Melanie">Melanie Baljko</a></p>
<p>Abstract:
Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.</p>
<p>Keywords:
embedded computing; living media interfaces; speech intervention</p>
<h3 id="204. A comparative study about children's and adults' perception of targeted web search engines.">204. A comparative study about children's and adults' perception of targeted web search engines.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557031">Paper Link</a>    Pages:1821-1824</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gossen:Tatiana">Tatiana Gossen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=ouml=bel:Juliane">Juliane Hbel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/N=uuml=rnberger:Andreas">Andreas Nrnberger</a></p>
<p>Abstract:
In this paper we describe an eye-tracking study where we compare children's and adults' search behavior and perception of search interface elements on search engine results pages (SERPs) during an informational and a navigational search with Google and a search engine for children. Our first results indicate that children employ an exhaustive scanning strategy combined with cued visual jumps. Then they navigate to the next result page and only then modify their query. Adults only scan the first three results, following the F-shaped strategy, and immediately reformulate the query. Children pay less attention to textual summaries and more to thumbnails than adults do. Children take notice of a navigational menu with categories while adults do not.</p>
<p>Keywords:
children; eye-tracker; search engine; user study</p>
<h2 id="Studying visualization    2">Studying visualization    2</h2>
<h3 id="205. Structuring the space: a study on enriching node-link diagrams with visual references.">205. Structuring the space: a study on enriching node-link diagrams with visual references.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557112">Paper Link</a>    Pages:1825-1834</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Alper:Basak">Basak Alper</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Riche:Nathalie_Henry">Nathalie Henry Riche</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/H=ouml=llerer:Tobias">Tobias Hllerer</a></p>
<p>Abstract:
Exploring large visualizations that do not fit in the screen raises orientation and navigation challenges. Structuring the space with additional visual references such as grids or contour lines provide spatial landmarks that may help viewers form a mental model of the space. However, previous studies report mixed results regarding their utility. While some evidence showed that grid and other visual embellishments improve memorability, experiments with contour lines suggest otherwise. In this work, we describe an evaluation framework to capture the impact of introducing visual references in node-link diagrams. We present the results of three controlled experiments that deepen our understanding on enriching large visualization spaces with visual structures. In particular, we provide the first tangible evidence that contour lines have significant benefits when navigating large node-link diagrams.</p>
<p>Keywords:
information visualization; navigation; network diagrams; revisitation</p>
<h3 id="206. Highlighting interventions and user differences: informing adaptive information visualization support.">206. Highlighting interventions and user differences: informing adaptive information visualization support.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557141">Paper Link</a>    Pages:1835-1844</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Carenini:Giuseppe">Giuseppe Carenini</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Conati:Cristina">Cristina Conati</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hoque:Enamul">Enamul Hoque</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steichen:Ben">Ben Steichen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Toker:Dereck">Dereck Toker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Enns:James">James Enns</a></p>
<p>Abstract:
There is increasing evidence that the effectiveness of information visualization techniques can be impacted by the particular needs and abilities of each user. This suggests that it is important to investigate information visualization systems that can dynamically adapt to each user. In this paper, we address the question of how to adapt. In particular, we present a study to evaluate a variety of visual prompts, called "interventions", that can be performed on a visualization to help users process it. Our results show that some of the tested interventions perform better than a condition in which no intervention is provided, both in terms of task performance as well as subjective user ratings. We also discuss findings on how intervention effectiveness is influenced by individual differences and task complexity.</p>
<p>Keywords:
adaptive information visualization; user characteristics</p>
<h2 id="Exploring exergames    4">Exploring exergames    4</h2>
<h3 id="207. Exertion in the small: improving differentiation and expressiveness in sports games with physical controls.">207. Exertion in the small: improving differentiation and expressiveness in sports games with physical controls.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557385">Paper Link</a>    Pages:1845-1854</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sheinin:Mike">Mike Sheinin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a></p>
<p>Abstract:
Many sports video games contain elements such as running or throwing that are based on real-world physical activities, but the translation of these activities to game controllers means that the original physicality is lost. This results in games where players have limited opportunity to improve their physical skills, where there is little differentiation in people's physical abilities, and where skills do not change over the course of a game. To explore ways of adding these elements back into sports games, we developed two games with small-scale physical controls for running and throwing -- one game was a simple running race, and one was a team-based handball-style game called Jelly Polo. In two studies (three track-and-field tournaments for the running game, and a four-week league for Jelly Polo), we observed the effects of physical controls on gameplay. Our studies showed that the physical controls enabled substantial individual differences in running and passing skill, allowed people to increase their expertise over time, and led to fatigue-based changes in performance during a game. Physical controls increased the games' challenge, complexity, and unpredictability, and dramatically improved player interest, expressiveness, and enjoyment. Our work shows that game designers should consider the idea of "exertion in the small" as a way to improve play experience in games based on physical activities.</p>
<p>Keywords:
exertion games; physical controls; sports video games</p>
<h3 id="208. "healthifying" exergames: improving health outcomes through intentional priming.">208. "healthifying" exergames: improving health outcomes through intentional priming.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557246">Paper Link</a>    Pages:1855-1864</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Frank_X=">Frank X. Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/King:Abby_C=">Abby C. King</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hekler:Eric_B=">Eric B. Hekler</a></p>
<p>Abstract:
Exergames, video game systems that require exertion and interaction, have been rising in popularity in the past years. However, research on popular exergames shows mixed health benefits, potentially due to minimal energy expenditure and decreasing use over time. This paper presents a 2x2 experimental study (N = 44), using a popular exergame, where we vary the framing of intention (i.e., "Gameplay" or "Exercise") and feedback (i.e., "Health" or "No health") to explore their single and interactive impacts on perceived exertion, objectively measured energy expenditure, affect, and duration of usage in a single session. Our study showed that participants primed with exercise used the system significantly longer than those primed with game play (M = 49.2 2.0 min versus M = 39.3 2.0 min). We discuss our results and possible design implications based on our single-session experiment. We conclude with a discussion on the potential impact of focusing on "healthifying" exergames -highlighting an exergames" dual purpose as both a game and exercise - as opposed to gamifying health behaviors.</p>
<p>Keywords:
exergaming; fitness; persuasive technology; priming</p>
<h3 id="209. Human factors of speed-based exergame controllers.">209. Human factors of speed-based exergame controllers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557091">Paper Link</a>    Pages:1865-1874</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Park:Taiwoo">Taiwoo Park</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Uichin">Uichin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacKenzie:Scott">Scott MacKenzie</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moon:Miri">Miri Moon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hwang:Inseok">Inseok Hwang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Song:Junehwa">Junehwa Song</a></p>
<p>Abstract:
Exergame controllers are intended to add fun to monotonous exercise. However, studies on exergame controllers mostly focus on designing new controllers and exploring specific application domains without analyzing human factors, such as performance, comfort, and effort. In this paper, we examine the characteristics of a speed-based exergame controller that bear on human factors related to body movement and exercise. Users performed tasks such as changing and maintaining exercise speed for avatar control while their performance was measured. The exergame controller follows Fitts' law, but requires longer movement time than a gamepad and Wiimote. As well, resistance force and target speed affect performance. User experience data confirm that the comfort and mental effort are adequate as practical game controllers. The paper concludes with discussion on applying our findings to practical exergame design.</p>
<p>Keywords:
exergame; game controller; speed-based control</p>
<h3 id="210. Establishing design guidelines in interactive exercise gaming: preliminary data from two posing studies.">210. Establishing design guidelines in interactive exercise gaming: preliminary data from two posing studies.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557329">Paper Link</a>    Pages:1875-1884</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zaczynski:Monica">Monica Zaczynski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whitehead:Anthony_D=">Anthony D. Whitehead</a></p>
<p>Abstract:
Interactive gaming has demonstrated promise as a low-cost, at-home training and fitness instruction alternative. Gaming systems offer convenience and the ability to provide enhanced reporting and progress data if body measurement information is collected effectively. However, commercially available systems today are designed primarily for entertainment and as a result, the quality of instruction delivery and level of involvement may not meet the needs of a user performing a disciplined activity. This paper will look at adapting for occlusion and lack of visibility; learning and orientation; and providing feedback in an effort to determine if there is an ideal visual demonstration delivery that maximizes pose understanding and user self-efficacy, determine whether supplementary modalities are important for instruction, and determine if there is an ideal feedback delivery that promotes pose comprehension, confidence and motivation. This information can provide a guideline for designing clear and supportive, interactive training systems that can engage users, prevent injury and help maintain fitness.</p>
<p>Keywords:
design guidelines; feedback; haptic feedback; low-paced exercise training; panning; usability; visual delivery; wii balance board; yoga</p>
<h2 id="Narratives and storytelling    4">Narratives and storytelling    4</h2>
<h3 id="211. The dept. of hidden stories: playful digital storytelling for children in a public library.">211. The dept. of hidden stories: playful digital storytelling for children in a public library.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557034">Paper Link</a>    Pages:1885-1894</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wood:Gavin">Gavin Wood</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vines:John">John Vines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Balaam:Madeline">Madeline Balaam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor_0002:Nick">Nick Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Thomas">Thomas Smith</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Crivellaro:Clara">Clara Crivellaro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mensah:Juliana">Juliana Mensah</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Limon:Helen">Helen Limon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Challis:John">John Challis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Anderson_0001:Linda">Linda Anderson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Clarke:Adam">Adam Clarke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wright:Peter_C=">Peter C. Wright</a></p>
<p>Abstract:
We detail the design of the Department of Hidden Stories (DoHS), a mobile-based game to support playful digital storytelling among primary school children in public libraries. Through a process of iterative design in collaboration with library staff and children's writers we designed DoHS to support the potential for playful storytelling through interactions with books. A deployment of DoHS with two classes of 8 to 10 years olds as part of their regular library visits revealed insights related to how to balance the expectations of a child-at-play and the requirement to further develop their creative reading and writing skills. Based on our experiences we recommend that designers create playful digitally based activities that encourage children to explore libraries and experience new interactions with physical books.</p>
<p>Keywords:
augmenting books; children's library; play; storytelling</p>
<h3 id="212. Visualizing interactive narratives: employing a branching comic to tell a story and show its readings.">212. Visualizing interactive narratives: employing a branching comic to tell a story and show its readings.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557296">Paper Link</a>    Pages:1895-1904</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Andrews:Daniel">Daniel Andrews</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baber:Chris">Chris Baber</a></p>
<p>Abstract:
This paper describes the design and evaluation of a branching comic to compare how readers recall a visual narrative when presented as an interactive, digital program, or as a linear sequence on paper. The layout of the comic is used to visualize this data as heat maps and explore patterns of users' recollections. We describe the theoretical justification for this based upon previous work in narrative visualizations, interactive stories and comics. Having tested the comic with school boys aged 11-12; we saw patterns in the data that complement other research in both interactive stories and visualizations. We argue that the heat maps helped identify these patterns, which have implications for future designs and analyses of interactive visual and/or narrative media.</p>
<p>Keywords:
branching comics; interactive stories; narrative visualization; story comprehension</p>
<h3 id="213. FOCUS: enhancing children's engagement in reading by using contextual BCI training sessions.">213. FOCUS: enhancing children's engagement in reading by using contextual BCI training sessions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557339">Paper Link</a>    Pages:1905-1908</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Jin">Jin Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yu:Chun">Chun Yu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Yuntao">Yuntao Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Yuhang">Yuhang Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Siqi">Siqi Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mo:Chou">Chou Mo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Jie">Jie Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Lie">Lie Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shi:Yuanchun">Yuanchun Shi</a></p>
<p>Abstract:
Reading is an important aspect of a child's development. Reading outcome is heavily dependent on the level of engagement while reading. In this paper, we present FOCUS, an EEG-augmented reading system which monitors a child's engagement level in real time, and provides contextual BCI training sessions to improve a child's reading engagement. A laboratory experiment was conducted to assess the validity of the system. Results showed that FOCUS could significantly improve engagement in terms of both EEG-based measurement and teachers' subjective measure on the reading outcome.</p>
<p>Keywords:
brain-computer interface (BCI); contextual reading; reading engagement</p>
<h3 id="214. Sensing a live audience.">214. Sensing a live audience.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557154">Paper Link</a>    Pages:1909-1912</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Chen">Chen Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Geelhoed:Erik">Erik Geelhoed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stenton:Phil">Phil Stenton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/C=eacute=sar:Pablo">Pablo Csar</a></p>
<p>Abstract:
Psychophysiological measurement has the potential to play an important role in audience research. Currently, such research is still in its infancy and it usually involves collecting data in the laboratory, where during each experimental session one individual watches a video recording of a performance. We extend the experimental paradigm by simultaneously measuring Galvanic Skin Response (GSR) of a group of participants during a live performance. GSR data were synchronized with video footage of performers and audience. In conjunction with questionnaire data, this enabled us to identify a strongly correlated main group of participants, describe the nature of their theatre experience and map out a minute-by-minute unfolding of the performance in terms of psycho-physiological engagement. The benefits of our approach are twofold. It provides a robust and accurate mechanism for assessing a performance. Moreover, our infrastructure can enable, in the future, real-time feedback from remote audiences for online performances.</p>
<p>Keywords:
audience engagement; galvanic skin response.</p>
<h2 id="Designing for older adults and demographic change    4">Designing for older adults and demographic change    4</h2>
<h3 id="215. Interface design for older adults with varying cultural attitudes toward uncertainty.">215. Interface design for older adults with varying cultural attitudes toward uncertainty.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557124">Paper Link</a>    Pages:1913-1922</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Haddad:Shathel">Shathel Haddad</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/McGrenere:Joanna">Joanna McGrenere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jacova:Claudia">Claudia Jacova</a></p>
<p>Abstract:
This work reports on the design and evaluation of culturally appropriate technology for older adults. Our design context was Cognitive Testing on a Computer (C-TOC): a self-administered computerized test under development, intended to screen older adults for cognitive impairments. Using theory triangulation of cultural attitudes toward uncertainty, we designed two interfaces (one minimal and one rich) for one C-TOC subtest and hypothesized they would be culturally appropriate for older adult Caucasians and East Asians respectively. We ran an experiment with 36 participants to investigate cultural differences in performance, preference and anxiety. We found that Caucasians preferred the interface with minimal elements (i.e. those essential for the primary task) or had no preference. By contrast, East Asians preferred the rich interface augmented with security and learning support and felt less anxious with it than the minimal.</p>
<p>Keywords:
computerized cognitive assessment; cultural design; experiment; older adults; uncertainty avoidance</p>
<h3 id="216. Social dependency and mobile autonomy: supporting older adults' mobility with ridesharing ict.">216. Social dependency and mobile autonomy: supporting older adults' mobility with ridesharing ict.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557300">Paper Link</a>    Pages:1923-1932</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Meurer:Johanna">Johanna Meurer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stein:Martin">Martin Stein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Randall:David">David Randall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rohde:Markus">Markus Rohde</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wulf:Volker">Volker Wulf</a></p>
<p>Abstract:
Alternative mobility modes for older adults are increasingly important for economic, ecological and social reasons. A promising option is ridesharing, defined as use of the same vehicle by two or more people traveling to a common destination. In particular, mobile computer supported ridesharing provides a promising way to enlarge older adults' mobility choices in addition to private driving and public transportation options. In order to understand the opportunities and obstacles of ridesharing from the point of view of elderly people, we conducted an interview study in order to examining ridesharing experiences. It turns out that "mobile independence" and "decisional autonomy" are key issues for mobile wellbeing. This partially conflicts with common ridesharing concepts. Hence, we further analyze older adults' strategies dealing with these conflicts and show that these strategies offer departure points for the design ridesharing solutions, which are better suited to the demands of older adults.</p>
<p>Keywords:
design; dynamic ridesharing; elderly; ethnography; social experiences</p>
<h3 id="217. From checking on to checking in: designing for low socio-economic status older adults.">217. From checking on to checking in: designing for low socio-economic status older adults.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557084">Paper Link</a>    Pages:1933-1936</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Arreola:Ingrid">Ingrid Arreola</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Zan">Zan Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Francisco:Matthew">Matthew Francisco</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Connelly:Kay">Kay Connelly</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Caine:Kelly_E=">Kelly E. Caine</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/White:Ginger_E=">Ginger E. White</a></p>
<p>Abstract:
In this paper we describe the design evolution of a novel technology that collects and displays presence information to be used in the homes of older adults. The first two iterations, the Ambient Plant and Presence Clock, were designed for higher socio-economic status (SES) older adults, whereas the Check-In Tree was designed for low SES older adults. We describe how feedback from older adult participants drove our design decisions, and give an in-depth account of how the Check-In Tree evolved from concept to a final design ready for in situ deployment.</p>
<p>Keywords:
aging in place; caregivers; older adults; peer production</p>
<h3 id="218. Invisible connections: investigating older people's emotions and social relations around objects.">218. Invisible connections: investigating older people's emotions and social relations around objects.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557314">Paper Link</a>    Pages:1937-1940</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vaisutis:Kate">Kate Vaisutis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brereton:Margot">Margot Brereton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Robertson:Toni">Toni Robertson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vetere:Frank">Frank Vetere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Durick:Jeannette">Jeannette Durick</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nansen:Bjorn">Bjorn Nansen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Buys:Laurie">Laurie Buys</a></p>
<p>Abstract:
The advent of the Internet of Things creates an interest in how people might interrelate through and with networks of internet enabled objects. With an emphasis on fostering social connection and physical activity among older people, this preliminary study investigated objects that people over the age of 65 years viewed as significant to them. We conducted contextual interviews in people's homes about their significant objects in order to understand the role of the objects in their lives, the extent to which they fostered emotional and social connections and physical activity, and how they might be augmented through internet connection. Discussion of significant objects generated considerable emotion in the participants. We identified objects of comfort and routine, objects that exhibited status, those that fostered independence and connection, and those that symbolized relationships with loved ones. These findings lead us to consider implications for the design of interconnected objects.</p>
<p>Keywords:
ageing; internet of things; objects; social relations; socio-material relations; tangible interaction</p>
<h2 id="Critical design    4">Critical design    4</h2>
<h3 id="219. Always somewhere, never there: using critical design to understand database interactions.">219. Always somewhere, never there: using critical design to understand database interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557055">Paper Link</a>    Pages:1941-1950</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Feinberg:Melanie">Melanie Feinberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carter:Daniel">Daniel Carter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bullard:Julia">Julia Bullard</a></p>
<p>Abstract:
Structured databases achieve effective searching and sorting by enacting sharply delineated category boundaries around their contents. While this enables precise retrieval, it also distorts identities that exist between category lines. A choice between Single and Married, for example, blurs distinctions within the Single group: single, perhaps, merely because same-sex marriage is not legal in one's locality. Sociologists Susan Leigh Star and Geoffrey Bowker describe such residual states as inevitable byproducts of information systems. To minimize residuality, traditional practice for descriptive metadata seeks to demarcate clear and objective classes. In this study, we use critical design to question this position by creating information collections that foreground the residual, instead of diminishing it. We then interrogate our design experiments with solicited critical responses from invited experts and student designers. Inspired by the anthropologist Tim Ingold, we argue that our experiments illuminate a form of interacting with databases characterized by notions of wayfaring, or inhabiting a space, as opposed to notions of transport, or reaching a known destination. We suggest that the form of coherence that shapes a wayfaring database is enacted through its flow, or fluid integration between structure and content.</p>
<p>Keywords:
classification; collections; criticism; design; metadata</p>
<h3 id="220. Reading critical designs: supporting reasoned interpretations of critical design.">220. Reading critical designs: supporting reasoned interpretations of critical design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557137">Paper Link</a>    Pages:1951-1960</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Jeffrey">Jeffrey Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Shaowen">Shaowen Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stolterman:Erik">Erik Stolterman</a></p>
<p>Abstract:
Critical Design has emerged as an important concept in HCI research and practice. Yet researchers have noted that its uptake has been limited by certain lacks of intellectual infrastructure theories, methodologies, canons and exemplars, and a community of practice. We argue that one way to create this infrastructure is to cultivate a community adept at reading that is, critically interpreting and making reasoned judgments about critical designs. We propose an approach to developing close readings of critical designs, which are both evidence-based and carefully reasoned. The approach highlights analytical units of analysis, the relevance of design languages and social norms, and the analytical contemplation of critical aspects of a design. It is intended to be relatively easy to learn, to try out, and to teach, in the hopes of inviting more members of the HCI community to engage in this practice. We exemplify the approach with readings of two critical designs and reflect on different ways that a design might serve a critical purpose or offer a critical argument about design, society, and the future.</p>
<p>Keywords:
art; critical design; criticism; design theory; interpretation</p>
<h3 id="221. Designing for slowness, anticipation and re-visitation: a long term field study of the photobox.">221. Designing for slowness, anticipation and re-visitation: a long term field study of the photobox.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557178">Paper Link</a>    Pages:1961-1970</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Odom:William">William Odom</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sellen:Abigail">Abigail Sellen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Banks:Richard">Richard Banks</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kirk:David_S=">David S. Kirk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Regan:Tim">Tim Regan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Selby:Mark">Mark Selby</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a></p>
<p>Abstract:
We describe the design, implementation and deployment of Photobox, a domestic technology that prints four or five randomly selected photos from the owner's Flickr collection at random intervals each month. We deployed Photobox in three homes for fourteen months, to explore how the slow pace at which it operates could support experiences of anticipation and re-visitation of the past. Findings reveal changes in attitude toward the device, from frustration to eventual acceptance. Participants drew on the photos to reflect on past life events and reactions indicated a renewed interest for their Flickr collection. Photobox also provoked reflection on technology in and around the home. These findings suggest several opportunities, such as designing for anticipation, better supporting reflection on the past, and, more generally, expanding the slow technology research program within the HCI community.</p>
<p>Keywords:
design; home; interaction design; slow technology</p>
<h3 id="222. Generating implications for design through design research.">222. Generating implications for design through design research.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557357">Paper Link</a>    Pages:1971-1980</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sas:Corina">Corina Sas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dow:Steven">Steven Dow</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forlizzi:Jodi">Jodi Forlizzi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zimmerman:John">John Zimmerman</a></p>
<p>Abstract:
A central tenet of HCI is that technology should be user-centric, with designs being based around social science findings about users. Nevertheless a repeated but critical challenge in design is translating empirical findings into actionable ideas that inform design, or generating implications for design. Despite various design methods aiming to bridge this gap, knowledge informing design is still seen as problematic. However there has been little empirical exploration into what design researchers understand by such design knowledge, the functions and principles behind their creation. We report on interviews with twelve expert HCI design researchers probing the roles and types of design implications, and the process of generating and evaluating them. We synthesize different types of design implications into a framework to guide their generation. Our findings identify a broader range than previously described, additional sources and heuristics supporting their development as well some important evaluation criteria. We discuss the value of these findings for interaction design research.</p>
<p>Keywords:
design knowledge; design research; implications for design</p>
<h2 id="Understanding and modeling touch    6">Understanding and modeling touch    6</h2>
<h3 id="223. Investigating the effects of encumbrance on one- and two- handed interactions with mobile devices.">223. Investigating the effects of encumbrance on one- and two- handed interactions with mobile devices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557312">Paper Link</a>    Pages:1981-1990</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Ng:Alexander">Alexander Ng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williamson:John_H=">John H. Williamson</a></p>
<p>Abstract:
In this paper, we investigate the effects of encumbrance (carrying typical objects such as shopping bags during interaction) and walking on target acquisition on a touchscreen mobile phone. Users often hold objects and use mobile devices at the same time and we examined the impact encumbrance has on one- and two- handed interactions. Three common input postures were evaluated: two-handed index finger, one-handed preferred thumb and two-handed both thumbs, to assess the effects on performance of carrying a bag in each hand while walking. The results showed a significant decrease in targeting performance when users were encumbered. For example, input accuracy dropped to 48.1% for targeting with the index finger when encumbered, while targeting error using the preferred thumb to input was 4.2mm, an increase of 40% compared to unencumbered input. We also introduce a new method to evaluate the user's preferred walking speed when interacting - PWS&amp;I, and suggest future studies should use this to get a more accurate measure of the user's input performance.</p>
<p>Keywords:
encumbrance; mobile interactions; one- and two- handed input; target acquisition</p>
<h3 id="224. Modeling the functional area of the thumb on mobile touchscreen surfaces.">224. Modeling the functional area of the thumb on mobile touchscreen surfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557354">Paper Link</a>    Pages:1991-2000</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bergstrom=Lehtovirta:Joanna">Joanna Bergstrom-Lehtovirta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a></p>
<p>Abstract:
We present a predictive model for the functional area of the thumb on a touchscreen surface: the area of the interface reachable by the thumb of the hand that is holding the device. We derive a quadratic formula by analyzing the kinematics of the gripping hand. Model fit is high for the thumb-motion trajectories of 20 participants. The model predicts the functional area for a given 1) surface size, 2) hand size, and 3) position of the index finger on the back of the device. Designers can use this model to ensure that a user interface is suitable for interaction with the thumb. The model can also be used inversely - that is, to infer the grips assumed by a given user interface layout.</p>
<p>Keywords:
functional area; predictive model; thumb; touchscreen</p>
<h3 id="225. Coordination of tilt and touch in one- and two-handed use.">225. Coordination of tilt and touch in one- and two-handed use.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557088">Paper Link</a>    Pages:2001-2004</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Tsandilas:Theophanis">Theophanis Tsandilas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Appert:Caroline">Caroline Appert</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bezerianos:Anastasia">Anastasia Bezerianos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bonnet:David">David Bonnet</a></p>
<p>Abstract:
Our goal is to enhance navigation in mobile interfaces with quick command gestures that do not make use of explicit mode-switching actions. TilTouch gestures extend the vocabulary of navigation interfaces by combining motion tilt with directional touch. We consider sixteen directional TilTouch gestures that rely on tilt and touch movements along the four main compass directions. An experiment explores their effectiveness for both one-handed and two-handed use. Results identify the best combinations of TilTouch gestures in terms of performance, motor coordination, and user preferences.</p>
<p>Keywords:
gestures; mobile devices; tilt; touch; touchscreen</p>
<h3 id="226. 28 frames later: predicting screen touches from back-of-device grip changes.">226. 28 frames later: predicting screen touches from back-of-device grip changes.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557148">Paper Link</a>    Pages:2005-2008</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Noor:Mohammad_Faizuddin_Mohd">Mohammad Faizuddin Mohd Noor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramsay:Andrew">Andrew Ramsay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hughes:Stephen">Stephen Hughes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Simon">Simon Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williamson:John">John Williamson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Murray=Smith:Roderick">Roderick Murray-Smith</a></p>
<p>Abstract:
We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.</p>
<p>Keywords:
back-of-device; capacitive; machine learning; touch</p>
<h3 id="227. Probabilistic palm rejection using spatiotemporal touch features and iterative classification.">227. Probabilistic palm rejection using spatiotemporal touch features and iterative classification.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557056">Paper Link</a>    Pages:2009-2012</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schwarz:Julia">Julia Schwarz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/x/Xiao:Robert">Robert Xiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mankoff:Jennifer">Jennifer Mankoff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hudson:Scott_E=">Scott E. Hudson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Chris">Chris Harrison</a></p>
<p>Abstract:
Tablet computers are often called upon to emulate classical pen-and-paper input. However, touchscreens typically lack the means to distinguish between legitimate stylus and finger touches and touches with the palm or other parts of the hand. This forces users to rest their palms elsewhere or hover above the screen, resulting in ergonomic and usability problems. We present a probabilistic touch filtering approach that uses the temporal evolution of touch contacts to reject palms. Our system improves upon previous approaches, reducing accidental palm inputs to 0.016 per pen stroke, while correctly passing 98% of stylus inputs.</p>
<p>Keywords:
palm rejection; pen and stylus input; tablet computing; touch interaction; touchscreen</p>
<h3 id="228. Orientation matters: efficiency of translation-rotation multitouch tasks.">228. Orientation matters: efficiency of translation-rotation multitouch tasks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557399">Paper Link</a>    Pages:2013-2016</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nguyen_0001:Quan">Quan Nguyen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kipp:Michael">Michael Kipp</a></p>
<p>Abstract:
The translation and rotation of objects with two fingers is a well explored multitouch technique. However, there are some unsolved questions regarding the optimal conditions under which this technique functions best. Does it matter in which direction the movement is oriented? Does parallel or sequential performance of the two operations work best? This study attempts to answer this question using a typical Fitts' Law setup but with varying translation-rotation orientation combinations. The results show that right-oriented movements were faster and easier than left-oriented ones. Movement combinations which went in different directions (translation right, rotation left, and vice versa) were found more tiresome and resulted in more strategy switches compared to equi-directional combinations. Our findings can inform positioning decisions in interaction design and contribute to theoretical adjustments to Fitts' Law.</p>
<p>Keywords:
2d translation and rotation; fitts law; multitouch interaction techniques</p>
<h2 id="3D interaction: modeling and prototyping    5">3D interaction: modeling and prototyping    5</h2>
<h3 id="229. MotionMontage: a system to annotate and combine motion takes for 3D animations.">229. MotionMontage: a system to annotate and combine motion takes for 3D animations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557218">Paper Link</a>    Pages:2017-2026</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gupta_0002:Ankit">Ankit Gupta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agrawala:Maneesh">Maneesh Agrawala</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Curless:Brian">Brian Curless</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cohen:Michael_F=">Michael F. Cohen</a></p>
<p>Abstract:
We present MotionMontage, a system for recording multiple motion takes of a rigid virtual object and compositing them together into a montage. Our system incorporates a Kinect-based performance capture setup that allows animators to create 3D animations by tracking the motion of a rigid physical object and mapping it in realtime onto a virtual object. The animator then temporally annotates the best parts of each take. MotionMontage merges the annotated motions into a single composite montage using a combination of dynamic time warping and optimization of a Semi-Markov Conditional Random Field. Our system also supports the creation of layered animations in which multiple objects are moving at the same time. To aid the animator in coordinating the motions of the objects we provide spatial markers which indicate the positions of previously recorded objects at user-specified points in time. We perform a user study to evaluate the perceived quality of the montages created with our system and find that viewers (including both the original animators and new viewers) generally prefer the animation montage to any individual take.</p>
<p>Keywords:
active visual feedback; animation; depth camera; montage</p>
<h3 id="230. History assisted view authoring for 3D models.">230. History assisted view authoring for 3D models.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557009">Paper Link</a>    Pages:2027-2036</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Hsiang=Ting">Hsiang-Ting Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wei:Li=Yi">Li-Yi Wei</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt:Ryan_M=">Ryan M. Schmidt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hartmann:Bj=ouml=rn">Bjrn Hartmann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Agrawala:Maneesh">Maneesh Agrawala</a></p>
<p>Abstract:
3D modelers often wish to showcase their models for sharing or review purposes. This may consist of generating static viewpoints of the model or authoring animated fly-throughs. Manually creating such views is often tedious and few automatic methods are designed to interactively assist the modelers with the view authoring process. We present a view authoring assistance system that supports the creation of informative view points, view paths, and view surfaces, allowing modelers to author the interactive navigation experience of a model. The key concept of our implementation is to analyze the model's workflow history, to infer important regions of the model and representative viewpoints of those areas. An evaluation indicated that the viewpoints generated by our algorithm are comparable to those manually selected by the modeler. In addition, participants of a user study found our system easy to use and effective for authoring viewpoint summaries.</p>
<p>Keywords:
3D model; editing history; viewpoint authoring</p>
<h3 id="231. FrameBox and MirrorBox: tools and guidelines to support designers in prototyping interfaces for 3D displays.">231. FrameBox and MirrorBox: tools and guidelines to support designers in prototyping interfaces for 3D displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557183">Paper Link</a>    Pages:2037-2046</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Broy:Nora">Nora Broy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schneegass:Stefan">Stefan Schneegass</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alt:Florian">Florian Alt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
In this paper, we identify design guidelines for stereoscopic 3D (S3D) user interfaces (UIs) and present the MirrorBox and the FrameBox, two UI prototyping tools for S3D displays. As auto-stereoscopy becomes available for the mass market we believe the design of S3D UIs for devices, for example, mobile phones, public displays, or car dashboards, will rapidly gain importance. A benefit of such UIs is that they can group and structure information in a way that makes them easily perceivable for the user. For example, important information can be shown in front of less important information. This paper identifies core requirements for designing S3D UIs and derives concrete guidelines. The requirements also serve as a basis for two depth layout tools we built with the aim to overcome limitations of traditional prototyping when sketching S3D UIs. We evaluated the tools with usability experts and compared them to traditional paper prototyping.</p>
<p>Keywords:
prototyping; stereoscopic 3d; user interfaces</p>
<h3 id="232. Direct drawing on 3D shapes with automated camera control.">232. Direct drawing on 3D shapes with automated camera control.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557242">Paper Link</a>    Pages:2047-2050</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Ortega:Michael">Michael Ortega</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vincent:Thomas">Thomas Vincent</a></p>
<p>Abstract:
We present ACCD, an interaction technique that allows direct drawing of long curves on 3D shapes with a tablet display over both multiple depth layers and multiple viewpoints. ACCD reduces the number of explicit viewpoint manipulations by combining self-occlusion management and automated camera control. As such it enables drawing on occluded faces but also around a 3D shape while keeping a constant drawing precision. Our experimental results indicates the efficacy of ACCD over conventional techniques.</p>
<p>Keywords:
3d interaction technique; 3d painting; camera controls</p>
<h3 id="233. Interactively stylizing camera motion.">233. Interactively stylizing camera motion.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556966">Paper Link</a>    Pages:2051-2054</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Joshi:Neel">Neel Joshi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Dan">Dan Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cohen:Michael_F=">Michael F. Cohen</a></p>
<p>Abstract:
Movie directors and cinematographers impart style onto video using techniques that are learned through years of experience: camera movement, framing, color, lighting, etc. Without this experience and expensive equipment, it is very difficult to control stylistic aspects of a video. We introduce a novel approach for post-hoc editing of one specific aspect of cinematography -- camera motion style -- via an equalizer-like set of controls that manipulates the power spectra of a video's apparent motion path. We explore free manipulation of apparent camera motion as well as the transfer of motion styles from an example video to a new video to create a wide range of stylistic variations. We report on a user study confirming the ability of non-expert users to create motion styles.</p>
<p>Keywords:
camera motion editing; video stylization</p>
<h2 id="The eyes have it    4">The eyes have it    4</h2>
<h3 id="234. Stimulating a blink: reduction of eye fatigue with visual stimulus.">234. Stimulating a blink: reduction of eye fatigue with visual stimulus.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557129">Paper Link</a>    Pages:2055-2064</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Crnovrsanin:Tarik">Tarik Crnovrsanin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Yang">Yang Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Ma:Kwan=Liu">Kwan-Liu Ma</a></p>
<p>Abstract:
Computers make incredible amounts of information available at our fingertips. As computers become integral parts of our lives, we spend more time staring at computer monitor than ever before, sometimes with negative effects. One major concern is the increasing number of people suffering from Computer Vision Syndrome (CVS). CVS is caused by extensive use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes, and blurred vision. It is possible to partially alleviate CVS if we can remind users to blink more often. We present a prototype system that uses a camera to monitor a user's blink rate, and when the user has not blinked in a while, the system triggers a blink stimulus. We investigated four different types of eye-blink stimulus: screen blurring, screen flashing, border flashing, and pop-up notifications. Users also rated each stimulus type in terms of effectiveness, intrusiveness, and satisfaction. Results from our user studies show that our stimuli are effective in increasing user blink rate with screen blurring being the best.</p>
<p>Keywords:
blink detection; blink stimulus; cvs; user study</p>
<h3 id="235. Smart photo selection: interpret gaze as personal interest.">235. Smart photo selection: interpret gaze as personal interest.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557025">Paper Link</a>    Pages:2065-2074</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Walber:Tina_Caroline">Tina Caroline Walber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Scherp:Ansgar">Ansgar Scherp</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Staab:Steffen">Steffen Staab</a></p>
<p>Abstract:
Manually selecting subsets of photos from large collections in order to present them to friends or colleagues or to print them as photo books can be a tedious task. Today, fully automatic approaches are at hand for supporting users. They make use of pixel information extracted from the images, analyze contextual information such as capture time and focal aperture, or use both to determine a proper subset of photos. However, these approaches miss the most important factor in the photo selection process: the user. The goal of our approach is to consider individual interests. By recording and analyzing gaze information from the user's viewing photo collections, we obtain information on user's interests and use this information in the creation of personal photo selections. In a controlled experiment with 33 participants, we show that the selections can be significantly improved over a baseline approach by up to 22% when taking individual viewing behavior into account. We also obtained significantly better results for photos taken at an event participants were involved in compared with photos from another event.</p>
<p>Keywords:
eye tracking; photo selection; usage-based image selection</p>
<h3 id="236. Pupil responses during discrete goal-directed movements.">236. Pupil responses during discrete goal-directed movements.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557086">Paper Link</a>    Pages:2075-2084</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/j/Jiang:Xianta">Xianta Jiang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Atkins:M=_Stella">M. Stella Atkins</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tien:Geoffrey">Geoffrey Tien</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bednarik:Roman">Roman Bednarik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zheng:Bin">Bin Zheng</a></p>
<p>Abstract:
Pupil size is known to correlate with the changes of cognitive task workloads, but how the pupil responds to requirements of basic goal-directed motor tasks involved in human-machine interactions is not yet clear. This work conducted a user study to investigate the pupil dilations during aiming in a tele-operation setting, with the purpose of better understanding how the changes in task requirements are reflected by the changes of pupil size. The task requirements, managed by Fitts' index of difficulty (ID), i.e. the size and distance apart of the targets, were varied between tasks, and pupil responses to different task IDs were recorded. The results showed that pupil diameter can be employed as an indicator of task requirements in goal-directed movements-higher task difficulty evoked higher valley to peak pupil dilation, and the peak pupil dilation occurred after a longer delay. These findings contribute to the foundation for developing methods to objectively evaluate interactive task requirements using pupil parameters during goal-directed movements in HCI.</p>
<p>Keywords:
fitts' law; goal-directed movement; movement-evoked pupillary response; pupil diameter</p>
<h3 id="237. Collocating interface objects: zooming into maps.">237. Collocating interface objects: zooming into maps.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557279">Paper Link</a>    Pages:2085-2094</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/May:Jon">Jon May</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gamble:Tim">Tim Gamble</a></p>
<p>Abstract:
May, Dean and Barnard (2003) used a theoretically based model to argue that objects in a wide range of interfaces should be collocated following screen changes such as a zoom-in to detail. Many existing online maps do not follow this principle, but move a clicked point to the centre of the subsequent display, leaving the user looking at an unrelated location. This paper presents three experiments showing that collocating the point clicked on a map so that the detailed location appears in the place previously occupied by the overview location makes the map easier to use, reducing eye movements and interaction duration. We discuss the benefit of basing design principles on theoretical models so that they can be applied to novel situations, and so designers can infer when to use and not use them.</p>
<p>Keywords:
cinematography; cognitive models; collocation; eye-tracking; maps; zooming</p>
<h2 id="Learning and education    4">Learning and education    4</h2>
<h3 id="238. Showing face in video instruction: effects on information retention, visual attention, and affect.">238. Showing face in video instruction: effects on information retention, visual attention, and affect.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557207">Paper Link</a>    Pages:2095-2102</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kizilcec:Ren=eacute=_F=">Ren F. Kizilcec</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Papadopoulos:Kathryn">Kathryn Papadopoulos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sritanyaratana:Lalida">Lalida Sritanyaratana</a></p>
<p>Abstract:
The amount of online educational content is rapidly increasing, particularly in the form of video lectures. The goal is to design video instruction to facilitate an experience that maximizes learning and satisfaction. A widely used but understudied design element in video instruction is the overlay of a small video of the instructor over lecture slides. We conducted an experiment with eye-tracking and recall tests to investigate how adding the instructor's face to video instruction affects information retention, visual attention, and affect. Participants strongly preferred instruction with the face and perceived it as more educational. They spent about 41% of time looking at the face and switched between the face and slide every 3.7 seconds. Consistent with prior work, no significant difference in short- and medium-term recall ability was found. Including the face in video instruction is encouraged based on learners' positive affective response. More fine-grained analytics combining eye-tracking with detailed learning assessment could shed light on the mechanisms by which the face aids or hinders learning.</p>
<p>Keywords:
audiovisual instruction; eye-tracking; multimedia learning</p>
<h3 id="239. Supporting learners in collecting and exploring data from immersive simulations in collective inquiry.">239. Supporting learners in collecting and exploring data from immersive simulations in collective inquiry.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557162">Paper Link</a>    Pages:2103-2112</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lui:Michelle">Michelle Lui</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kuhn:Alex_C=">Alex C. Kuhn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Acosta:Alisa">Alisa Acosta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/q/Quintana:Chris">Chris Quintana</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Slotta:James_D=">James D. Slotta</a></p>
<p>Abstract:
Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers' data through large visualization displays and personal mobile devices. Two iterations of the design were tested, which resulted in higher quality student explanations constructed. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. We also found that patterns of collective ideas influenced student performance, and that visualizations, as ambient or plenary displays, supported both teacher and students in reviewing patterns of collected data.</p>
<p>Keywords:
digitally augmented physical spaces; large displays; mobile computing; multi-device environments; science inquiry; smart classroom; visualizations</p>
<h3 id="240. Learning to see the body: supporting instructional practices in laparoscopic surgical procedures.">240. Learning to see the body: supporting instructional practices in laparoscopic surgical procedures.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557387">Paper Link</a>    Pages:2113-2122</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mentis:Helena_M=">Helena M. Mentis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chellali:Amine">Amine Chellali</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwaitzberg:Steven_D=">Steven D. Schwaitzberg</a></p>
<p>Abstract:
Learning the practices and the performance of physically manipulating instruments in minimally invasive surgeries is an impetus for the development of surgical training simulators. However, an often-overlooked aspect of surgical training is learning how to see the body through the various imaging mechanisms. With this study, we address the ways in which surgeons demonstrate and instruct residents in seeing the body during minimally invasive surgical procedures. Drawing on observations and analysis of video recordings of minimally invasive surgical operations, we examine how particular anatomy and movement within the body to see and conceptualize that anatomy are made visible by the instructive practices of the surgeon. We use these findings to discuss further directions for minimally invasive surgical training through mechanisms for making the body visible during situated surgical training and surgical training simulation systems.</p>
<p>Keywords:
gestures; movement; surgery; training; vision</p>
<h3 id="241. Information-building applications: designing for data exploration and analysis by elementary school students.">241. Information-building applications: designing for data exploration and analysis by elementary school students.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557294">Paper Link</a>    Pages:2123-2132</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shelley:Tia">Tia Shelley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lyons:Leilah">Leilah Lyons</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moher:Tom">Tom Moher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dasgupta:Chandan">Chandan Dasgupta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Silva:Brenda_L=oacute=pez">Brenda Lpez Silva</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Silva_0002:Alexandra">Alexandra Silva</a></p>
<p>Abstract:
The propagation of Inquiry Based Learning has lead to many more elementary students interacting with authentic scientific tools and practices. However, the more problematic realities of scientific data collection, such as noise and large data sets, are often deliberately hidden from students. Students will need to confront these realities and be able to make skillful data scoping decisions in order to make sense of ever more prevalent large datasets. We dub software designed to support these activities Information-Building Applications (IBAs). This paper presents the design considerations that went into building an exemplar IBA, PhotoMAT (Photo Management and Analysis Tool), a brief user study to show how the solutions enacted by following these principles are taken up by actual students, and a discussion of how the design considerations identified by our work might be applied to another IBA.</p>
<p>Keywords:
information-building applications; k-12 science education; learner centered design</p>
<h2 id="Telepresence and connecting over video    5">Telepresence and connecting over video    5</h2>
<h3 id="242. Remote handshaking: touch enhances video-mediated social telepresence.">242. Remote handshaking: touch enhances video-mediated social telepresence.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557169">Paper Link</a>    Pages:2143-2152</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nakanishi:Hideyuki">Hideyuki Nakanishi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tanaka:Kazuaki">Kazuaki Tanaka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wada:Yuya">Yuya Wada</a></p>
<p>Abstract:
Since past studies on haptic and visual communication have tended to be isolated from each other, it has remained unclear whether a touch channel can still enrich mediated communication where video and audio channels are already available. To clarify this, we analyzed remote handshaking in which a robot hand that was attached just under a videoconferencing terminal's display moved according to the opening and closing motion of a conversation partner's hand. Combining touch and video channels raises a question as to whether the partner's action of touching a haptic device should be visible to the user. If it can be invisible, the action may be unnecessary, and a unilaterally controlled device may be enough to establish an effective touch channel. Our analysis revealed that the feeling of being close to the partner can be enhanced by mutual touch in which the partner's action needs to occur but should be invisible.</p>
<p>Keywords:
haptic devices; humanoid robots; social interaction; social telepresence; social touch; video-mediated communication; videoconferencing</p>
<h3 id="243. Bodies in motion: mobility, presence, and task awareness in telepresence.">243. Bodies in motion: mobility, presence, and task awareness in telepresence.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557047">Paper Link</a>    Pages:2153-2162</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rae:Irene">Irene Rae</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mutlu:Bilge">Bilge Mutlu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Takayama:Leila">Leila Takayama</a></p>
<p>Abstract:
Robotic telepresence systems - videoconferencing systems that allow a remote user to drive around in another location - provide an alternative to video-mediated communications as a way of interacting over distances. These systems, which are seeing increasing use in business and medical settings, are unique in their ability to grant the remote user the ability to maneuver in a distant location. While this mobility promises increased feelings of "being there" for remote users and thus greater support for task collaboration, whether these promises are borne out, providing benefits in task performance, is unknown. To better understand the role that mobility plays in shaping the remote user's sense of presence and its potential benefits, we conducted a two-by-two (system mobility: stationary vs. mobile; task demands for mobility: low vs. high) controlled laboratory experiment. We asked participants (N=40) to collaborate in a construction task with a confederate via a robotic telepresence system. Our results showed that mobility significantly increased the remote user's feelings of presence, particularly in tasks with high mobility requirements, but decreased task performance. Our findings highlight the positive effects of mobility on feelings of "being there," while illustrating the need to design support for effective use of mobility in high-mobility tasks.</p>
<p>Keywords:
mobility; presence; remote collaboration; robot-mediated communication; robotic telepresence; task awareness</p>
<h3 id="244. Exploring video streaming in public settings: shared geocaching over distance using mobile video chat.">244. Exploring video streaming in public settings: shared geocaching over distance using mobile video chat.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557198">Paper Link</a>    Pages:2163-2172</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Procyk:Jason">Jason Procyk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Neustaedter:Carman">Carman Neustaedter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pang:Carolyn">Carolyn Pang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tang_0001:Anthony">Anthony Tang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Judge:Tejinder_K=">Tejinder K. Judge</a></p>
<p>Abstract:
Our research explores the use of mobile video chat in public spaces by people participating in parallel experiences, where both a local and remote person are doing the same activity together at the same time. We prototyped a wearable video chat experience and had pairs of friends and family members participate in 'shared geocaching' over distance. Our results show that video streaming works best for navigation tasks but is more challenging to use for fine-grained searching tasks. Video streaming also creates a very intimate experience with a remote partner, but this can lead to distraction from the 'real world' and even safety concerns. Overall, privacy concerns with streaming from a public space were not typically an issue; however, people tended to rely on assumptions of what were acceptable. The implications are that designers should consider appropriate feedback, user disembodiment, and asymmetry when designing for parallel experiences.</p>
<p>Keywords:
geocaching; shared experiences; video communication</p>
<h3 id="245. A gaze-preserving situated multiview telepresence system.">245. A gaze-preserving situated multiview telepresence system.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557320">Paper Link</a>    Pages:2173-2176</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pan:Ye">Ye Pan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steed:Anthony">Anthony Steed</a></p>
<p>Abstract:
Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.</p>
<p>Keywords:
camera arrays; gaze; non-planar displays</p>
<h3 id="246. OneSpace: shared visual scenes for active freeplay.">246. OneSpace: shared visual scenes for active freeplay.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557117">Paper Link</a>    Pages:2177-2180</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cohen:Maayan">Maayan Cohen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dillman:Kody_R=">Kody R. Dillman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacLeod:Haley">Haley MacLeod</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hunter:Seth_E=">Seth E. Hunter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tang_0001:Anthony">Anthony Tang</a></p>
<p>Abstract:
Children engage in free play for emotional, physical and social development; researchers have explored supporting free play between physically remote playmates using videoconferencing tools. We show that the configuration of the video conferencing setup affects play. Specifically, we show that a shared visual scene configuration promotes fundamentally active forms of engaged, co-operative play.</p>
<p>Keywords:</p>
<h2 id="Exergame design    4">Exergame design    4</h2>
<h3 id="247. i-dentity: innominate movement representation as engaging game element.">247. i-dentity: innominate movement representation as engaging game element.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557257">Paper Link</a>    Pages:2181-2190</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Garner:Jayden">Jayden Garner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wood:Gavin">Gavin Wood</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pijnappel:Sebastiaan">Sebastiaan Pijnappel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Murer:Martin">Martin Murer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mueller_0001:Florian">Florian Mueller</a></p>
<p>Abstract:
Movement-based digital games typically make it clear whose movement representation belongs to which player. In contrast, we argue that selectively concealing whose movement controls which representation can facilitate engaging play experiences. We call this "innominate movement representation" and explore this opportunity through our game "i-dentity", where players have to guess who makes everyone's controller light up based on his/her movements. Our work reveals five dimensions for the design of innominate movement representation: concealing the association between movement and representation; number of represented movements; number of players with representations; location of representation in relation to the body and technical attributes of representation. We also present five strategies for how innominate representation can be embedded into a play experience. With our work we hope to expand the range of digital movement games.</p>
<p>Keywords:
ambiguity; digital play; engagement; entertainment; game design; movement representation; social play</p>
<h3 id="248. Movement-based game guidelines.">248. Movement-based game guidelines.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557163">Paper Link</a>    Pages:2191-2200</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mueller_0001:Florian">Florian Mueller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Isbister:Katherine">Katherine Isbister</a></p>
<p>Abstract:
Movement-based digital games are becoming increasingly popular, yet there is limited comprehensive guidance on how to design these games. We present a set of guidelines for movement-based game design that has emerged from our research-based game development practice. These guidelines have been examined and refined by 14 movement-based game design experts with experience in the academic, independent and commercial game development domains. We contextualize the guidelines using current findings about movement-based game and interaction design, taken from both published research papers and game design venues. Our primary contribution is a body of generative intermediate-level knowledge in the design research tradition that is readily accessible and actionable for the design of future movement-based games.</p>
<p>Keywords:
digital games; exertion; movement-based games; play; whole-body interaction</p>
<h3 id="249. Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames.">249. Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556963">Paper Link</a>    Pages:2201-2210</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gerling:Kathrin_Maria">Kathrin Maria Gerling</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Matthew_K=">Matthew K. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Birk:Max_Valentin">Max Valentin Birk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smeddinck:Jan_David">Jan David Smeddinck</a></p>
<p>Abstract:
Game balancing can help players with different skill levels play multiplayer games together; however, little is known about how the balancing approach affects performance, experience, and self-esteem'especially when differences in player strength result from given abilities, rather than learned skill. We explore three balancing approaches in a dance game and show that the explicit approach commonly used in commercial games reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing improves self-esteem and reduces score differential without affecting game outcome. We apply our results in a second study with dyads where one player had a mobility disability and used a wheelchair. By making motion-based games accessible for people with different physical abilities, and by enabling people with mobility disabilities to compete on a par with able-bodied peers, we show how to provide empowering experiences through enjoyable games that have the potential to increase physical activity and self-esteem.</p>
<p>Keywords:
balancing; exergames; motion-based games; physical abilities; player experience</p>
<h3 id="250. Supporting the creative game design process with exertion cards.">250. Supporting the creative game design process with exertion cards.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557272">Paper Link</a>    Pages:2211-2220</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mueller_0001:Florian">Florian Mueller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gibbs:Martin_R=">Martin R. Gibbs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vetere:Frank">Frank Vetere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edge:Darren">Darren Edge</a></p>
<p>Abstract:
Advances in sensing technologies have led to research into exertion games that support physically effortful experiences. Despite the existence of theoretical frameworks that can be used to analyze such exertion experiences, there are few tools to support the hands-on practice of exertion game design. To address this, we present a set of design cards based on the "Exertion Framework", grounded in our experience of creating exertion games for over a decade. We present results demonstrating the value and utility of these Exertion Cards based on our studies of their use in three workshops held over seven sessions with 134 design students and experts. We also articulate lessons learned from transforming a theoretical framework into a design tool that aims to support designers in their practice.</p>
<p>Keywords:
creative process; design cards; exergame; exertion interface; game design; whole-body interaction; workshops</p>
<h2 id="Designing and modeling GUIs    5">Designing and modeling GUIs    5</h2>
<h3 id="251. WADE: simplified GUI add-on development for third-party software.">251. WADE: simplified GUI add-on development for third-party software.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557349">Paper Link</a>    Pages:2221-2230</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Meng:Xiaojun">Xiaojun Meng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Yongfeng">Yongfeng Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Zhongyuan">Zhongyuan Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Eagan:James">James Eagan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Ramanathan">Ramanathan Subramanian</a></p>
<p>Abstract:
We present the WADE Integrated Development Environment (IDE), which simplifies interface and functionality modification of existing third-party software without access to source code. WADE clones the Graphical User Interface (GUI) of a host program through dynamic-link library (DLL) injection, enabling modifications to (1) the GUI in a WYSIWYG fashion and (2) software functionality. We compare WADE with an alternative state-of-the-art runtime toolkit overloading approach in a user-study, whose results demonstrate that WADE significantly simplifies the task of GUI-based add-on development.</p>
<p>Keywords:
GUI; IDE; WADE; add-on integration; wysiwyg</p>
<h3 id="252. Pixel-based methods for widget state and style in a runtime implementation of sliding widgets.">252. Pixel-based methods for widget state and style in a runtime implementation of sliding widgets.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556979">Paper Link</a>    Pages:2231-2240</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dixon:Morgan_E=">Morgan E. Dixon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Laput:Gierad">Gierad Laput</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fogarty:James_A=">James A. Fogarty</a></p>
<p>Abstract:
Pixel-based methods offer unique potential for modifying existing interfaces independent of their underlying implementation. Prior work has demonstrated a variety of modifications to existing interfaces, including accessibility enhancements, interface language translation, testing frameworks, and interaction techniques. But pixel-based methods have also been limited in their understanding of the interface and therefore the complexity of modifications they can support. This work examines deeper pixel-level understanding of widgets and the resulting capabilities of pixel-based runtime enhancements. Specifically, we present three new sets of methods: methods for pixel-based modeling of widgets in multiple states, methods for managing the combinatorial complexity that arises in creating a multitude of runtime enhancements, and methods for styling runtime enhancements to preserve consistency with the design of an existing interface. We validate our methods through an implementation of Moscovich et al.'s Sliding Widgets, a novel runtime enhancement that could not have been implemented with prior pixel-based methods.</p>
<p>Keywords:
hybrid touch and mouse interaction; pixel-based runtime modification; prefab; real-world interfaces; sliding widgets</p>
<h3 id="253. The usability of CommandMaps in realistic tasks.">253. The usability of CommandMaps in realistic tasks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556976">Paper Link</a>    Pages:2241-2250</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Scarr:Joey">Joey Scarr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bunt:Andrea">Andrea Bunt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cechanowicz:Jared">Jared Cechanowicz</a></p>
<p>Abstract:
CommandMaps are a promising interface technique that flattens command hierarchies and exploits human spatial memory to provide rapid access to commands. CommandMaps have performed favorably in constrained cued-selection studies, but have not yet been tested in the context of real tasks. In this paper we present two real-world implementations of CommandMaps: one for Microsoft Word and one for an image editing program called Pinta. We use these as our experimental platforms in two experiments. In the first, we show that CommandMaps demonstrate performance and subjective advantages in a realistic task. In the second, we observe naturalistic use of CommandMaps over the course of a week, and gather qualitative data from interviews, questionnaires, and conversations. Our results provide substantial insight into users' reactions to CommandMaps, showing that they are positively received by users and allowing us to provide concrete recommendations to designers regarding when and how they should be implemented in real applications.</p>
<p>Keywords:
commandmaps; hierarchies; real tasks; spatial memory</p>
<h3 id="254. Novice use of a predictive human performance modeling tool to produce UI recommendations.">254. Novice use of a predictive human performance modeling tool to produce UI recommendations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556972">Paper Link</a>    Pages:2251-2254</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Kyung_Wha">Kyung Wha Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Amant:Robert_St=">Robert St. Amant</a></p>
<p>Abstract:
This note describes two studies of the use of a performance modeling tool, CogTool, for making recommendations to improve a user interface. The first study replicates findings by Bonnie John [7]: the rates at which novice modelers made correct recommendations (88.1%) and supported them (68.2%) are close to the values in John's study (91.7% and 75.1%, respectively). A follow-on study of novice modelers on the same task without CogTool produced sig-nificantly lower values. CogTool improves the UI design recommendations made by novices.</p>
<p>Keywords:
cogtool; interface design; usability analysis</p>
<h3 id="255. On the selection of 2D objects using external labeling.">255. On the selection of 2D objects using external labeling.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557288">Paper Link</a>    Pages:2255-2258</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Balata:Jan">Jan Balata</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cmolik:Ladislav">Ladislav Cmolik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mikovec:Zdenek">Zdenek Mikovec</a></p>
<p>Abstract:
We present an external labeling laid over small and/or overlapping 2D objects as an efficient representation for their selection. The approximation of objects with points allows us to transform the labeling problem to graph layout problem, which we solve by means of force-based algorithm. The input parameters allow us to influence the resulting layout of label boxes (e.g. to adapt their distance for imprecise input devices). In a study with 15 participants two implementations of our algorithm were compared against labeling method, where all label boxes share the same offset from corresponding objects. The results of the study show that implementation using a special functionality (temporary freezing of the label box position recalculation) was 14% faster with a comparable accuracy. The subjective evaluation revealed that the implementation with temporary freezing is perceived as most comfortable, fastest and most accurate. The implementation without temporary freezing showed much higher error rate and cannot be recommended.</p>
<p>Keywords:
external labeling; object selection; user study; visualization</p>
<h2 id="Health and everyday life    5">Health and everyday life    5</h2>
<h3 id="256. Real-time feedback for improving medication taking.">256. Real-time feedback for improving medication taking.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557210">Paper Link</a>    Pages:2259-2268</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Matthew_L=">Matthew L. Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dey:Anind_K=">Anind K. Dey</a></p>
<p>Abstract:
Medication taking is a self-regulatory process that requires individuals to self-monitor their medication taking behaviors, but this can be difficult because medication taking is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential to sense everyday behaviors and provide the objective feedback necessary for self-regulation of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented pillbox and an ambient display that provides near real-time visual feedback about how well medications are being taken. In contrast to other systems that focus on reminding before medication taking, our approach uses feedback after medication taking to allow the individual to develop their own routines through self-regulation. We evaluated this system in the homes of older adults in a 10-month deployment. Feedback helped improve the consistency of medication-taking behaviors as well as increased ratings of self-efficacy. However, the improved performance did not persist after the feedback display was removed, because individuals had integrated the feedback display into their routines to support their self-awareness, identify mistakes, guide the timing of medication taking, and provide a sense of security that they are taking their medications well. Finally, we reflect on design considerations for feedback systems to support the process of self-regulation of everyday behaviors.</p>
<p>Keywords:
ambient display; behavior change; feedback; medication adherence; self-efficacy; self-regulation; sensors</p>
<h3 id="257. Don't forget your pill!: designing effective medication reminder apps that support users' daily routines.">257. Don't forget your pill!: designing effective medication reminder apps that support users' daily routines.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557079">Paper Link</a>    Pages:2269-2278</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Stawarz:Katarzyna">Katarzyna Stawarz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cox:Anna_Louise">Anna Louise Cox</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blandford:Ann">Ann Blandford</a></p>
<p>Abstract:
Despite the fact that a third of all cases of unintentional medication non-adherence are caused by simple forgetfulness, the majority of interventions neglect this issue. Even though patients have access to smartphone applications ("apps") designed to help them remember medication, neither their quality nor effectiveness has been evaluated yet. We report the findings of a functionality review of 229 medication reminder apps and a thematic analysis of their 1,012 user reviews. Our research highlights the gap between the theory and practice: while the literature shows that many medication regimens are habitual in nature and the presence of daily routines supports remembering, existing apps rely on timer-based reminders. To address this disparity, we present design requirements for building medication reminders that support the routine aspect of medication-taking and its individual nature, and demonstrate how they could be implemented to move from passive alerts to a smarter memory and routine assistant.</p>
<p>Keywords:
forgetfulness; habits; medication reminders; routines; smartphone apps</p>
<h3 id="258. @BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones.">258. @BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557386">Paper Link</a>    Pages:2279-2288</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Suh:Hyewon">Hyewon Suh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Porter:John_R=">John R. Porter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hiniker:Alexis">Alexis Hiniker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kientz:Julie_A=">Julie A. Kientz</a></p>
<p>Abstract:
The tracking of developmental milestones in young children is an important public health goal for ensuring early detection and treatment for developmental delay. While numerous paper-based and web-based solutions are available for tracking milestones, many busy parents often forget to enter information on a regular basis. To help address this need, we have developed an interactive system called @BabySteps for allowing parents who use Twitter to track and respond to tweets about developmental milestones using a special hashtag syntax. Parent responses are parsed automatically and written into a central database that can be accessed via the web. We deployed @BabySteps with 14 parents over a 3-week period and found that parents were able to learn how to use the system to track their children's progress, with some using it to communicate with other parents. The study helped to identify a number of ways to improve the approach, including simplifying the hashtag syntax, allowing for private responses via direct messaging, and improving the social component. We provide a discussion of lessons learned and suggestions for the design of interactive public health systems.</p>
<p>Keywords:
children; data capture; health; memories; microblogging; parents; public health; social media; twitter</p>
<h3 id="259. DoDo game, a color vision deficiency screening test for young children.">259. DoDo game, a color vision deficiency screening test for young children.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557334">Paper Link</a>    Pages:2289-2292</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nguyen:Linh_Chi">Linh Chi Nguyen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Do:Ellen_Yi=Luen">Ellen Yi-Luen Do</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chia:Audrey">Audrey Chia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Yuan">Yuan Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Duh:Henry_Been=Lirn">Henry Been-Lirn Duh</a></p>
<p>Abstract:
This paper presents 'DoDo's Catching Adventure,' a new color vision deficient screening test for young children. Early detection of color blindness among children is useful for parents and teachers to better understand children's needs, to overcome difficulties in learning, and for life and career planning. Unfortunately, current color screening tests are not designed for young children; most require more advanced verbal or cognitive skills. DoDo game has taken a new approach by embedding game elements into a color vision screening test. A user study conducted at Singapore National Eye Centre on twenty-eight children, identified fourteen as Red-Green deficient subjects as did by Ishihara screening test, showed that DoDo was adequately effective in identifying Red-Green color vision deficiency and comparable to two current gold standard colorblind tests, Ishihara and D15.</p>
<p>Keywords:
children game; color deficiency test; digital game</p>
<h3 id="260. The influence of emotion on number entry errors.">260. The influence of emotion on number entry errors.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557065">Paper Link</a>    Pages:2293-2296</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cairns:Paul_A=">Paul A. Cairns</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pandab:Pratyush">Pratyush Pandab</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Power:Christopher">Christopher Power</a></p>
<p>Abstract:
Given the proliferation of devices like infusion pumps in hospitals, number entry and in particular number entry error is an emerging important concern in HCI. There are clearly design features that could greatly improve accuracy in entering numbers but the context of the task could also play an important role. In particular, the emotional state of a person is known to strongly influence their response to a difficult situation and hence the errors that they make. In this paper, we consider the impact of the emotional state of the user on the accuracy with which people enter numbers. Our experiment shows that participants who are in a more positive emotional state are more accurate. The effect is small but could be very important when considering the potentially highly-charged emotional contexts where many healthcare devices are used.</p>
<p>Keywords:
affect; healthcare; human error; number entry</p>
<h2 id="Text entry and evaluation    2">Text entry and evaluation    2</h2>
<h3 id="261. Both complete and correct?: multi-objective optimization of touchscreen keyboard.">261. Both complete and correct?: multi-objective optimization of touchscreen keyboard.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557414">Paper Link</a>    Pages:2297-2306</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bi:Xiaojun">Xiaojun Bi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Ouyang:Tom">Tom Ouyang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhai:Shumin">Shumin Zhai</a></p>
<p>Abstract:
Correcting erroneous input (i.e., correction) and completing a word based on partial input (i.e., completion) are two important "smart" capabilities of a modern intelligent touchscreen keyboard. However little is known whether these two capabilities are conflicting or compatible with each other in the keyboard parameter tuning. Applying computational optimization methods, this work explores the optimality issues related to them. The work demonstrates that it is possible to simultaneously optimize a keyboard algorithm for both correction and completion. The keyboard simultaneously optimized for both introduces no compromise to correction and only a slight compromise to completion when compared to the keyboards exclusively optimized for one objective. Our research also demonstrates the effectiveness of the proposed optimization method in keyboard algorithm design, which is based on the Pareto multi-objective optimization and the Metropolis algorithm. For the development and test datasets used in our experiments, computational optimization improved the correction accuracy rate by 8.3% and completion power by 17.7%.</p>
<p>Keywords:
completion; correction; intelligent user interfaces; keyboard algorithm; mobile; optimization; smart touch screen keyboard; text input</p>
<h3 id="262. Uncertain text entry on mobile devices.">262. Uncertain text entry on mobile devices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557412">Paper Link</a>    Pages:2307-2316</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Weir:Daryl">Daryl Weir</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pohl:Henning">Henning Pohl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Simon">Simon Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vertanen:Keith">Keith Vertanen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kristensson:Per_Ola">Per Ola Kristensson</a></p>
<p>Abstract:
Users often struggle to enter text accurately on touchscreen keyboards. To address this, we present a flexible decoder for touchscreen text entry that combines probabilistic touch models with a language model. We investigate two different touch models. The first touch model is based on a Gaussian Process regression approach and implicitly models the inherent uncertainty of the touching process. The second touch model allows users to explicitly control the uncertainty via touch pressure. Using the first model we show that the character error rate can be reduced by up to 7% over a baseline method, and by up to 1.3% over a leading commercial keyboard. Using the second model we demonstrate that providing users with control over input certainty reduces the amount of text users have to correct manually and increases the text entry rate.</p>
<p>Keywords:
keyboard error correction; mobile text entry</p>
<h2 id="Emotions and mobiles    3">Emotions and mobiles    3</h2>
<h3 id="263. Mobile attachment causes and consequences for emotional bonding with mobile phones.">263. Mobile attachment causes and consequences for emotional bonding with mobile phones.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557295">Paper Link</a>    Pages:2317-2326</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Meschtscherjakov:Alexander">Alexander Meschtscherjakov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wilfinger:David">David Wilfinger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tscheligi:Manfred">Manfred Tscheligi</a></p>
<p>Abstract:
This paper addresses the phenomenon of emotional attachments to mobile phones. We introduce the term "mobile attachment" and define it as a bond between a person's self and a mobile phone that varies in strength. Based on a critical reflection of interdisciplinary literature, a conceptual mobile attachment model is developed. Within this model causes, consequences and influencing factors of mobile attachment are exposed and elaborated. We argue that mobile attachment emerges when the mobile phone becomes part of the user's self concept. The link between the user and their mobile phone may be fostered when it empowers, enriches, or gratifies the user's self. Attachment causes lead to "design space determinants" that enable user experience designers to design for mobile attachment. Attachment consequences may be operationalized for user experience evaluation.</p>
<p>Keywords:
emotional attachment; mobile phones; user experience</p>
<h3 id="264. Hooked on smartphones: an exploratory study on smartphone overuse among college students.">264. Hooked on smartphones: an exploratory study on smartphone overuse among college students.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557366">Paper Link</a>    Pages:2327-2336</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Uichin">Uichin Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Joonwon">Joonwon Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Ko:Minsam">Minsam Ko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Changhun">Changhun Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Yuhwan">Yuhwan Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Subin">Subin Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yatani:Koji">Koji Yatani</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gweon:Gahgene">Gahgene Gweon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chung:Kyong=Mee">Kyong-Mee Chung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Song:Junehwa">Junehwa Song</a></p>
<p>Abstract:
The negative aspects of smartphone overuse on young adults, such as sleep deprivation and attention deficits, are being increasingly recognized recently. This emerging issue motivated us to analyze the usage patterns related to smartphone overuse. We investigate smartphone usage for 95 college students using surveys, logged data, and interviews. We first divide the participants into risk and non-risk groups based on self-reported rating scale for smartphone overuse. We then analyze the usage data to identify between-group usage differences, which ranged from the overall usage patterns to app-specific usage patterns. Compared with the non-risk group, our results show that the risk group has longer usage time per day and different diurnal usage patterns. Also, the risk group users are more susceptible to push notifications, and tend to consume more online content. We characterize the overall relationship between usage features and smartphone overuse using analytic modeling and provide detailed illustrations of problematic usage behaviors based on interview data.</p>
<p>Keywords:
measurement; smartphone overuse</p>
<h3 id="265. Broken display = broken interface': the impact of display damage on smartphone interaction.">265. Broken display = broken interface': the impact of display damage on smartphone interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557067">Paper Link</a>    Pages:2337-2346</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schaub:Florian">Florian Schaub</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Seifert:Julian">Julian Seifert</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Honold:Frank">Frank Honold</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller:Michael">Michael Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rukzio:Enrico">Enrico Rukzio</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weber_0001:Michael">Michael Weber</a></p>
<p>Abstract:
This paper is the first to assess the impact of touchscreen damage on smartphone interaction. We gathered a dataset consisting of 95 closeup images of damaged smartphones and extensive information about a device's usage history, damage severity, and impact on use. 88% of our participants continued to use their damaged smartphone for at least three months; 32% plan to use it for another year or more, mainly due to high repair and replacement costs. From the dataset, we identified three categories of damaged smartphone displays. Reading and text input were most affected. Further interviews (n=11) revealed that users adapt to damage with diverse coping strategies, closely tailored to specific interaction issues. In total, we identified 23 different strategies. Based on our results, we proposed guidelines for interaction design in order to provide a positive user experience when display damage occurs.</p>
<p>Keywords:
broken display; display damage; mobile interaction; smartphone; user experience</p>
<h2 id="Privacy    4">Privacy    4</h2>
<h3 id="266. Leakiness and creepiness in app space: perceptions of privacy and mobile app use.">266. Leakiness and creepiness in app space: perceptions of privacy and mobile app use.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557421">Paper Link</a>    Pages:2347-2356</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shklovski:Irina">Irina Shklovski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mainwaring:Scott_D=">Scott D. Mainwaring</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sk=uacute=lad=oacute=ttir:Halla_Hrund">Halla Hrund Skladttir</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Borgthorsson:H=ouml=skuldur">Hskuldur Borgthorsson</a></p>
<p>Abstract:
Mobile devices are playing an increasingly intimate role in everyday life. However, users can be surprised when informed of the data collection and distribution activities of apps they install. We report on two studies of smartphone users in western European countries, in which users were confronted with app behaviors and their reactions assessed. Users felt their personal space had been violated in "creepy" ways. Using Altman's notions of personal space and territoriality, and Nissenbaum's theory of contextual integrity, we account for these emotional reactions and suggest that they point to important underlying issues, even when users continue using apps they find creepy.</p>
<p>Keywords:
bodily integrity; creepiness; data privacy; learned helplessness; mobile devices</p>
<h3 id="267. Personalisation and privacy in future pervasive display networks.">267. Personalisation and privacy in future pervasive display networks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557287">Paper Link</a>    Pages:2357-2366</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Davies:Nigel">Nigel Davies</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Langheinrich:Marc">Marc Langheinrich</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Clinch:Sarah">Sarah Clinch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Elhart:Ivan">Ivan Elhart</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Friday:Adrian">Adrian Friday</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kubitza:Thomas">Thomas Kubitza</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Surajbali:Bholanathsingh">Bholanathsingh Surajbali</a></p>
<p>Abstract:
There is increasing interest in using digital signage to deliver highly personalised content. However, display personalization presents a number of architectural design challenges in particular, how best to provide personalisation without unduly compromising viewers' privacy. While previous research has focused on understanding specific elements of the overall vision, our work presents details of the first significant attempt at a system that integrates future pervasive display networks and mobile devices to support display personalisation. We describe a series of usage models and design goals for display personalisation and then present Tacita, a system that supports these models and goals. Our architecture includes mobile, display and cloud-based elements and provides comprehensive personalisation features while preventing the creation of user profiles within the display infrastructure, thus helping to preserve users' privacy. An initial evaluation of our prototype implementation of the architecture is also included and demonstrates the viability of the Tacita approach.</p>
<p>Keywords:
architecture; digital signage; personalisation; privacy</p>
<h3 id="268. A field trial of privacy nudges for facebook.">268. A field trial of privacy nudges for facebook.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557413">Paper Link</a>    Pages:2367-2376</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wang_0005:Yang">Yang Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Leon:Pedro_Giovanni">Pedro Giovanni Leon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Acquisti:Alessandro">Alessandro Acquisti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranor:Lorrie_Faith">Lorrie Faith Cranor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Forget:Alain">Alain Forget</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sadeh:Norman_M=">Norman M. Sadeh</a></p>
<p>Abstract:
Anecdotal evidence and scholarly research have shown that Internet users may regret some of their online disclosures. To help individuals avoid such regrets, we designed two modifications to the Facebook web interface that nudge users to consider the content and audience of their online disclosures more carefully. We implemented and evaluated these two nudges in a 6-week field trial with 28 Facebook users. We analyzed participants' interactions with the nudges, the content of their posts, and opinions collected through surveys. We found that reminders about the audience of posts can prevent unintended disclosures without major burden; however, introducing a time delay before publishing users' posts can be perceived as both beneficial and annoying. On balance, some participants found the nudges helpful while others found them unnecessary or overly intrusive. We discuss implications and challenges for designing and evaluating systems to assist users with online disclosures.</p>
<p>Keywords:
behavioral bias; facebook; nudge; online disclosure; privacy; regret; social media; soft-paternalism</p>
<h3 id="269. In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies.">269. In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557352">Paper Link</a>    Pages:2377-2386</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Denning:Tamara">Tamara Denning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dehlawi:Zakariya">Zakariya Dehlawi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kohno:Tadayoshi">Tadayoshi Kohno</a></p>
<p>Abstract:
Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals' privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in cafs and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacy-mediating technologies.</p>
<p>Keywords:
augmented reality; privacy; surveillance; wearable camera</p>
<h2 id="Issues that matter    3">Issues that matter    3</h2>
<h3 id="270. Listening to the forest and its curators: lessons learnt from a bioacoustic smartphone application deployment.">270. Listening to the forest and its curators: lessons learnt from a bioacoustic smartphone application deployment.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557022">Paper Link</a>    Pages:2387-2396</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Moran:Stuart">Stuart Moran</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pantidi:Nadia">Nadia Pantidi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rodden:Tom">Tom Rodden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chamberlain:Alan">Alan Chamberlain</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Griffiths:Chloe">Chloe Griffiths</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zilli:Davide">Davide Zilli</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Merrett:Geoff_V=">Geoff V. Merrett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Alex">Alex Rogers</a></p>
<p>Abstract:
Our natural environment is complex and sensitive, and is home to a number of species on the verge of extinction. Surveying is one approach to their preservation, and can be supported by technology. This paper presents the deployment of a smartphone-based citizen science biodiversity application. Our findings from interviews with members of the biodiversity community revealed a tension between the technology and their established working practices. From our experience, we present a series of general guidelines for those designing citizen science apps.</p>
<p>Keywords:
bioacoustics; biodiversity; citizen science; community practices; mobile; participatory sensing; tension; tradition</p>
<h3 id="271. Making public things: how HCI design can express matters of concern.">271. Making public things: how HCI design can express matters of concern.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557359">Paper Link</a>    Pages:2397-2406</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/DiSalvo:Carl_F=">Carl F. DiSalvo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lukens:Jonathan">Jonathan Lukens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lodato:Thomas">Thomas Lodato</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jenkins:Tom">Tom Jenkins</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Tanyoung">Tanyoung Kim</a></p>
<p>Abstract:
Science studies scholar Bruno Latour suggests that contemporary democracy is shifting from "matters of fact"to "matters of concern": contentious conditions entwined with everyday life. What is the role of human-computer interaction (HCI) design in this shift' In this paper we draw from five design projects to explore how design can express matters of concern by communicating the factors and consequences of issues. In the process, we consider the role of design in contributing to the formation of publics and discuss an emerging orientation to publics in HCI design.</p>
<p>Keywords:
design; matters of concern; public design; publics</p>
<h3 id="272. Just awful enough: the functional dysfunction of the something awful forums.">272. Just awful enough: the functional dysfunction of the something awful forums.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557193">Paper Link</a>    Pages:2407-2410</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pater:Jessica_Annette">Jessica Annette Pater</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nadji:Yacin">Yacin Nadji</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mynatt:Elizabeth_D=">Elizabeth D. Mynatt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bruckman:Amy_S=">Amy S. Bruckman</a></p>
<p>Abstract:
The Something Awful Forums (SAF) is an online community comprised of a loosely connected federation of forums, united in a distinctive brand of humor with a focus on the quality of member contributions. In this case study we find that the site has sustained success while deviating from common conventions and norms of online communities. Humor and the quality of content contributed by SAF members foster practices that seem counterintuitive to the development of a stable and thriving community. In this case study we show how design decisions are contextual and inter-dependent and together these heuristics create a different kind of online third place that challenges common practices.</p>
<p>Keywords:
case study; design; online community; third place</p>
<h2 id="Understanding and using social media    4">Understanding and using social media    4</h2>
<h3 id="273. Everyday ideation: all of my ideas are on pinterest.">273. Everyday ideation: all of my ideas are on pinterest.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557273">Paper Link</a>    Pages:2411-2420</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Linder:Rhema">Rhema Linder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Snodgrass:Clair">Clair Snodgrass</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kerne:Andruid">Andruid Kerne</a></p>
<p>Abstract:
We develop new understanding of how people engage in digital curation. We interview twenty users of Pinterest, a social curation platform. We find that through collecting, organizing, and sharing image bookmarks, users engage in processes of everyday ideation. That is, they use digital found objects as creative resources to develop ideas for shaping their lives. Curators assemble information into new contexts, forming and sharing ideas with practical and emotional value. We investigate cognitive and social aspects of creativity that affect the digital curation practices of everyday ideation. We derive implications for the design of curation environments that support information-based ideation.</p>
<p>Keywords:
creativity; curation; everyday design; information-based ideation; pinterest</p>
<h3 id="274. Understanding user adaptation strategies for the launching of facebook timeline.">274. Understanding user adaptation strategies for the launching of facebook timeline.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557363">Paper Link</a>    Pages:2421-2430</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wisniewski:Pamela_J=">Pamela J. Wisniewski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/x/Xu:Heng">Heng Xu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Yunan">Yunan Chen</a></p>
<p>Abstract:
This paper applies coping theory to understand user adaptation strategies to major interface changes on Social Networking Sites (SNSs). Specifically, we qualitatively examine 1,149 user comments posted to the Facebook's official Timeline blog in order to get a large and unobtrusive sample of real Facebook users' perceptions about the launch of Timeline. Our data suggests a high level of stress associated with the transition to the new interface introduced by Timeline. We also found evidence which suggests that increasing users' perceptions of control over major interface changes may help facilitate user adaptation to these changes. This study offers valuable insights to SNSs for mitigating user stress and facilitating successful adaptation during major interface changes.</p>
<p>Keywords:
change; coping; facebook timeline; privacy; stress; user adaptation</p>
<h3 id="275. Curation through use: understanding the personal value of social media.">275. Curation through use: understanding the personal value of social media.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557291">Paper Link</a>    Pages:2431-2440</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Xuan">Xuan Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lindley:Si=acirc=n_E=">Sin E. Lindley</a></p>
<p>Abstract:
Content generation on social network sites has been considered mainly from the perspective of individuals interacting with social network contacts. Yet research has also pointed to the potential for social media to become a meaningful personal archive over time. The aim of this paper is to consider how social media, over time and across sites, forms part of the wider digital archiving space for individuals. Our findings, from a qualitative study of 14 social media users, highlight how although some sites are more associated with 'keepable' social media than others, even those are not seen as archives in the usual sense of the word. We show how this perception is bound up with five contradictions, which center on social media as curated, as a reliable repository of meaningful content, as readily encountered and as having the potential to present content as a compelling narrative. We conclude by highlighting opportunities for design relating to curation through use and what this implies for personal digital archives, which are known to present difficulties in terms of curation and re-finding.</p>
<p>Keywords:
archive; exhibition; personal information management</p>
<h3 id="276. Together alone: motivations for live-tweeting a television series.">276. Together alone: motivations for live-tweeting a television series.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557070">Paper Link</a>    Pages:2441-2450</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schirra:Steven">Steven Schirra</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sun:Huan">Huan Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bentley:Frank">Frank Bentley</a></p>
<p>Abstract:
In this paper, we explore motivations for live-tweeting across a season of a television show. Using the third season of Downton Abbey as a case study, we followed 2,234 live-tweeters from the show's premiere episode to its finale, finding that nearly a third of users returned each week to tweet. Semi-structured interviews with 11 diverse live-tweeters revealed that the decision to live-tweet is dependent upon a variety of personal considerations and social conventions forming around this emerging TV viewing practice. This includes the desire to feel connected to a larger community that is interested in the show. Participants actively sought to protect the user experience of others by following good live-tweeting "etiquette", including limiting their number of posts and censoring content that might spoil the show for others. Over time, live-tweeting helped users build and maintain a network of fellow Downton Abbey viewers with shared interests.</p>
<p>Keywords:
annotation; live-tweeting; second screen; social television; twitter; user research</p>
<h2 id="Working together    3">Working together    3</h2>
<h3 id="277. Documentscape: intertextuality, sequentiality, & autonomy at work.">277. Documentscape: intertextuality, sequentiality, &amp; autonomy at work.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557305">Paper Link</a>    Pages:2451-2460</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Christensen:Lars_Rune">Lars Rune Christensen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bj=oslash=rn:Pernille">Pernille Bjrn</a></p>
<p>Abstract:
On the basis of an ethnographic field study, this article introduces the concept of documentscape to the analysis of document-centric work practices. The concept of documentscape refers to the entire ensemble of documents in their mutual intertextual interlocking. Providing empirical data from a global software development case, we show how hierarchical structures and sequentiality across the interlocked documents are critical to how actors make sense of the work of others and what to do next in a geographically distributed setting. Furthermore, we found that while each document is created as part of a quasi-sequential order, this characteristic does not make the document, as a single entity, into a stable object. Instead, we found that the documents were malleable and dynamic while suspended in intertextual structures. Our concept of documentscape points to how the hierarchical structure, sequentiality, and authorless nature of documents serve as a constitutive platform for the development of iterative and emergent work practices, making it possible for highly distributed actors to collaborate with limited communication, as the documentscape serves as a vehicle of coordination.</p>
<p>Keywords:
documents; documentscape; global interaction; global software development</p>
<h3 id="278. Cloudy forecast: an exploration of the factors underlying shared repository use.">278. Cloudy forecast: an exploration of the factors underlying shared repository use.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557042">Paper Link</a>    Pages:2461-2470</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Massey:Charlotte">Charlotte Massey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lennig:Thomas">Thomas Lennig</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a></p>
<p>Abstract:
Many teams are now adopting shared repositories for their work. Such adoption is paradoxical, however, as past research has repeatedly shown major co-organizational barriers; teams cannot agree a common organizational scheme, making it difficult to retrieve information organized by others. Another barrier is email competition; email provides a reliable alternative for distributing files that are then personally organized. To address this paradox, we explored how 27 participants actively using shared repositories overcome these barriers in a qualitative study. We found teams addressed co-organization using 4 strategies. First they create ContentMaps that provide explicit structure to organize shared information. Participants also co-organize using implicit strategies based on task structure, expertise, and tool affordances. Greater shared repository use also leads to a changed role for email. Versioning problems mean email is not used for distributing attachments, instead for task management. We present technical implications suggesting how new tools might be better integrated with email facilitating these continued email uses.</p>
<p>Keywords:
co-organization; contentmaps; email competition; shared repositories; versioning</p>
<h3 id="279. Designing information savvy societies: an introduction to assessability.">279. Designing information savvy societies: an introduction to assessability.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557072">Paper Link</a>    Pages:2471-2480</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Forte:Andrea">Andrea Forte</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Andalibi:Nazanin">Nazanin Andalibi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Park:Thomas_H=">Thomas H. Park</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Willever=Farr:Heather">Heather Willever-Farr</a></p>
<p>Abstract:
This paper provides first steps toward an empirically grounded design vocabulary for assessable design as an HCI response to the global need for better information literacy skills. We present a framework for synthesizing literatures called the Interdisciplinary Literacy Framework and use it to highlight gaps in our understanding of information literacy that HCI as a field is particularly well suited to fill. We report on two studies that lay a foundation for developing guidelines for assessable information system design. The first is a study of Wikipedians', librarians', and laypersons' information assessment practices from which we derive two important features of assessable designs: information provenance and stewardship. The second is an experimental study in which we operationalize these concepts in designs and test them using Amazon Mechanical Turk (MTurk).</p>
<p>Keywords:
assessability; credibility; information literacy; wikipedia</p>
<h2 id="Programming and development tools    4">Programming and development tools    4</h2>
<h3 id="280. Addressing misconceptions about code with always-on programming visualizations.">280. Addressing misconceptions about code with always-on programming visualizations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557409">Paper Link</a>    Pages:2481-2490</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lieber:Thomas">Thomas Lieber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brandt:Joel_R=">Joel R. Brandt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Robert_C=">Robert C. Miller</a></p>
<p>Abstract:
We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.</p>
<p>Keywords:
code understanding; debugging; programming</p>
<h3 id="281. Emergent, crowd-scale programming practice in the IDE.">281. Emergent, crowd-scale programming practice in the IDE.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556998">Paper Link</a>    Pages:2491-2500</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fast:Ethan">Ethan Fast</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steffee:Daniel">Daniel Steffee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Lucy">Lucy Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brandt:Joel_R=">Joel R. Brandt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bernstein:Michael_S=">Michael S. Bernstein</a></p>
<p>Abstract:
While emergent behaviors are uncodified across many domains such as programming and writing, interfaces need explicit rules to support users. We hypothesize that by codifying emergent programming behavior, software engineering interfaces can support a far broader set of developer needs. To explore this idea, we built Codex, a knowledge base that records common practice for the Ruby programming language by indexing over three million lines of popular code. Codex enables new data-driven interfaces for programming systems: statistical linting, identifying code that is unlikely to occur in practice and may constitute a bug; pattern annotation, automatically discovering common programming idioms and annotating them with metadata using expert crowdsourcing; and library generation, constructing a utility package that encapsulates and reflects emergent software practice. We evaluate these applications to find Codex captures a broad swatch of programming practice, statistical linting detects problematic code snippets, and pattern annotation discovers nontrivial idioms such as basic HTTP authentication and database migration templates. Our work suggests that operationalizing practice-driven knowledge in structured domains such as programming can enable a new class of user interfaces.</p>
<p>Keywords:
data mining; programming tools</p>
<h3 id="282. Design considerations for parallel performance tools.">282. Design considerations for parallel performance tools.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557350">Paper Link</a>    Pages:2501-2510</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Atachiants:Roman">Roman Atachiants</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gregg:David">David Gregg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jarvis:Kim">Kim Jarvis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Doherty:Gavin">Gavin Doherty</a></p>
<p>Abstract:
In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.</p>
<p>Keywords:
many-core; multi-core; parallel programing; qualitative study; visualisation</p>
<h3 id="283. The patchworks code editor: toward faster navigation with less code arranging and fewer navigation mistakes.">283. The patchworks code editor: toward faster navigation with less code arranging and fewer navigation mistakes.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557073">Paper Link</a>    Pages:2511-2520</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Henley:Austin_Z=">Austin Z. Henley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fleming:Scott_D=">Scott D. Fleming</a></p>
<p>Abstract:
Increasingly, people are faced with navigating large information spaces, and making such navigation efficient is of paramount concern. In this paper, we focus on the problems programmers face in navigating large code bases, and propose a novel code editor, Patchworks, that addresses the problems. In particular, Patchworks leverages two new interface idioms - the patch grid and the ribbon - to help programmers navigate more quickly, make fewer navigation errors, and spend less time arranging their code. To validate Patchworks, we conducted a user study that compared Patchworks to two existing code editors: the traditional file-based editor, Eclipse, and the newer canvas-based editor, Code Bubbles. Our results showed (1) that programmers using Patchworks were able to navigate significantly faster than with Eclipse (and comparably with Code Bubbles), (2) that programmers using Patchworks made significantly fewer navigation errors than with Code Bubbles or Eclipse, and (3) that programmers using Patchworks spent significantly less time arranging their code than with Code Bubbles (and comparably with Eclipse).</p>
<p>Keywords:
code editor; integrated development environment (ide); navigation; user study</p>
<h2 id="Interactive technologies for rehabilitation    5">Interactive technologies for rehabilitation    5</h2>
<h3 id="284. A novel knee rehabilitation system for the home.">284. A novel knee rehabilitation system for the home.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557353">Paper Link</a>    Pages:2521-2530</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Ayoade:Mobolaji">Mobolaji Ayoade</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baillie:Lynne">Lynne Baillie</a></p>
<p>Abstract:
In this paper, we describe the design and evaluation of an interactive home-based rehabilitation visualisation system used by a wide variety of ages (users in our studies were aged from 47-89) to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation visualization system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that our users were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation.</p>
<p>Keywords:
home knee rehabilitation; inertial sensors; usability; user design; visualizations</p>
<h3 id="285. GaitAssist: a daily-life support and training system for parkinson's disease patients with freezing of gait.">285. GaitAssist: a daily-life support and training system for parkinson's disease patients with freezing of gait.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557278">Paper Link</a>    Pages:2531-2540</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mazilu:Sinziana">Sinziana Mazilu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blanke:Ulf">Ulf Blanke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hardegger:Michael">Michael Hardegger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tr=ouml=ster:Gerhard">Gerhard Trster</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gazit:Eran">Eran Gazit</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hausdorff:Jeffrey_M=">Jeffrey M. Hausdorff</a></p>
<p>Abstract:
Patients with Parkinson's disease often experience freezing of gait, which bears a high risk of falling, a prevalent cause for morbidity and mortality. In this work we present GaitAssist, a wearable system for freezing of gait support in daily life. The system provides real-time auditory cueing after the onset of freezing episodes. Furthermore, GaitAssist implements training exercises to learn how to handle freezing situations. GaitAssist is the result of a design process where we considered the input of engineers, clinicians and 18 Parkinson's disease patients, in order to find an optimal trade-off between system wearability and performance. We tested the final system in a user study with 5 additional patients. They reported a reduction in the freezing of gait duration as a result of the auditory stimulation provided, and that they feel the system enhanced their confidence during walking.</p>
<p>Keywords:
freezing of gait; gait impairment; on-body sensors; user-centered; wearable support</p>
<h3 id="286. A technology probe of wearable in-home computer-assisted physical therapy.">286. A technology probe of wearable in-home computer-assisted physical therapy.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557416">Paper Link</a>    Pages:2541-2550</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Kevin">Kevin Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sparto:Patrick_J=">Patrick J. Sparto</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kiesler:Sara_B=">Sara B. Kiesler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smailagic:Asim">Asim Smailagic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mankoff:Jennifer">Jennifer Mankoff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Siewiorek:Daniel_P=">Daniel P. Siewiorek</a></p>
<p>Abstract:
Physical therapists could make better treatment decisions if they had accurate patient home exercise data but today this information is only available from patient self-report. A more accurate source of data could be gained from wearable computing designed for physical therapy exercise support. Existing systems have been tested in the lab but we have little information about issues they may face in home settings. We designed a technology probe, SenseCap, and deployed it for seven days in ten physical therapy patients' homes. SenseCap is a wearable physical therapy support system that gathers patient exercise compliance and performance data and summarizes the data in charts on an iPad Dashboard for physical therapists to view when patients return to the clinic. In this paper, we present the results of our deployment, show in-home patient exercise data gathered by the probe, and make design recommendations based on patient and physical therapist responses.</p>
<p>Keywords:
exercise; ipod; mobile; physical therapy; quantifying; rehabilitation; technology probe; ubiquitous computing; wearable</p>
<h3 id="287. Exploring the acceptability of google glass as an everyday assistive device for people with parkinson's.">287. Exploring the acceptability of google glass as an everyday assistive device for people with parkinson's.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557092">Paper Link</a>    Pages:2551-2554</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McNaney:Roisin">Roisin McNaney</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vines:John">John Vines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roggen:Daniel">Daniel Roggen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Balaam:Madeline">Madeline Balaam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Pengfei">Pengfei Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Poliakov:Ivan">Ivan Poliakov</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
We describe a qualitative study investigating the acceptability of the Google Glass eyewear computer to people with Parkinson's disease (PD). We held a workshop with 5 PD patients and 2 carers exploring perceptions of Glass. This was followed by 5-day field trials of Glass with 4 PD patients, where participants wore the device during everyday activities at home and in public. We report generally positive responses to Glass as a device to instil confidence and safety for this potentially vulnerable group. We also raise concerns related to the potential for Glass to reaffirm dependency on others and stigmatise wearers.</p>
<p>Keywords:
field trial; google glass; parkinson's disease; qualitative</p>
<h3 id="288. Non-intrusive tongue machine interface.">288. Non-intrusive tongue machine interface.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556981">Paper Link</a>    Pages:2555-2558</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Qiao">Qiao Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gollakota:Shyamnath">Shyamnath Gollakota</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taskar:Ben">Ben Taskar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rao:Raj_P=_N=">Raj P. N. Rao</a></p>
<p>Abstract:
There has been recent interest in designing systems that use the tongue as an input interface. Prior work however either require surgical procedures or in-mouth sensor placements. In this paper, we introduce TongueSee, a non-intrusive tongue machine interface that can recognize a rich set of tongue gestures using electromyography (EMG) signals from the surface of the skin. We demonstrate the feasibility and robustness of TongueSee with experimental studies to classify six tongue gestures across eight participants. TongueSee achieves a classification accuracy of 94.17% and a false positive probability of 0.000358 per second using three-protrusion preamble design.</p>
<p>Keywords:
electromyography (emg); tongue gesture interface</p>
<h2 id="Shape-changing interfaces    5">Shape-changing interfaces    5</h2>
<h3 id="289. Causing commotion with a shape-changing bench: experiencing shape-changing interfaces in use.">289. Causing commotion with a shape-changing bench: experiencing shape-changing interfaces in use.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557360">Paper Link</a>    Pages:2559-2568</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gr=ouml=nvall:Erik">Erik Grnvall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kinch:Sofie">Sofie Kinch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Petersen:Marianne_Graves">Marianne Graves Petersen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rasmussen:Majken_Kirkegaard">Majken Kirkegaard Rasmussen</a></p>
<p>Abstract:
In this paper we describe results from testing coMotion, a shape-changing bench, in three different contexts: a concert hall foyer, an airport departure hall and a shopping mall. We have gathered insights from more than 120 people, with regard to how users experience and make sense of the bench's shape changing capability. The paper applies McCarthy and Wright's six different sense making processes (anticipating, connecting, interpreting, reflecting, appropriating and recounting) as an instrument to analyse people's experience with shape-changing furniture in the wild. The paper also introduces exploring as a seventh sense making process. Based on this analysis, the paper points to three relevant aspects when designing shape-changing artefacts for the wild, namely: 1) Affordance of shape-changing interfaces, 2) Transitions between background and foreground and 3) Interpreting physically dynamic objects.</p>
<p>Keywords:
design; in situ; interactive furniture; sense-making; shape-changing interface; user experience</p>
<h3 id="290. Paddle: highly deformable mobile devices with physical controls.">290. Paddle: highly deformable mobile devices with physical controls.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557340">Paper Link</a>    Pages:2569-2578</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ramakers:Raf">Raf Ramakers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sch=ouml=ning:Johannes">Johannes Schning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Luyten:Kris">Kris Luyten</a></p>
<p>Abstract:
We present the concept of highly deformable mobile devices that can be transformed into various special-purpose controls in order to bring physical controls to mobile devices. Physical controls have the advantage of exploiting people's innate abilities for manipulating physical objects in the real world. We designed and implemented a prototype, called Paddle, to demonstrate our concept. Additionally, we explore the interaction techniques enabled by this concept and conduct an in-depth study to evaluate our transformable physical controls. Our findings show that these physical controls provide several benefits over traditional touch interaction techniques commonly used on mobile devices.</p>
<p>Keywords:
deformable interfaces; mobile devices; tangible interfaces</p>
<h3 id="291. Is my phone alive?: a large-scale study of shape change in handheld devices using videos.">291. Is my phone alive?: a large-scale study of shape change in handheld devices using videos.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557018">Paper Link</a>    Pages:2579-2588</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pedersen:Esben_Warming">Esben Warming Pedersen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
Shape-changing handheld devices are emerging as research prototypes, but it is unclear how users perceive them and which experiences they engender. The little data we have on user experience is from single prototypes, only covering a small part of the possibilities in shape change. We produce 51 videos of a shape-changing handheld device by systematically varying seven parameters of shape change. In a crowd-sourced study, 187 participants watched the videos and described their experiences using rating scales and free text. We find significant and large differences among parameters of shape change. Shapes that have previously been used for notifications were rated the least urgent; the degree of shape change was found to impact experience more than type of shape change. The experience of shape change was surprisingly complex: hedonic quality were inversely related to urgency, and some shapes were perceived as ugly, yet useful. We discuss how to advance models of shape change and improve research on the experience of shape change.</p>
<p>Keywords:
actuated interfaces; organic user interfaces; shape displays; shape-changing interfaces</p>
<h3 id="292. Evaluating the effectiveness of physical shape-change for in-pocket mobile device notifications.">292. Evaluating the effectiveness of physical shape-change for in-pocket mobile device notifications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557164">Paper Link</a>    Pages:2589-2592</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dimitriadis:Panteleimon">Panteleimon Dimitriadis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alexander:Jason">Jason Alexander</a></p>
<p>Abstract:
Audio and vibrotactile output are the standard mechanisms mobile devices use to attract their owner's attention. Yet in busy and noisy environments, or when the user is physically active, these channels sometimes fail. Recent work has explored the use of physical shape-change as an additional method for conveying notifications when the device is in-hand or viewable. However, we do not yet understand the effectiveness of physical shape-change as a method for communicating in-pocket notifications. This paper presents three robustly implemented, mobile-device sized shape-changing devices, and two user studies to evaluate their effectiveness at conveying notifications. The studies reveal that (1) different types and configurations of shape-change convey different levels of urgency and; (2) fast pulsing shape-changing notifications are missed less often and recognised more quickly than the standard slower vibration pulse rates of a mobile device.</p>
<p>Keywords:
mobile devices; notifications; shape-change</p>
<h3 id="293. Changibles: analyzing and designing shape changing constructive assembly.">293. Changibles: analyzing and designing shape changing constructive assembly.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557006">Paper Link</a>    Pages:2593-2596</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Roudaut:Anne">Anne Roudaut</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reed:Rebecca">Rebecca Reed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hao:Tianbo">Tianbo Hao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a></p>
<p>Abstract:
Advances in shape changing assemblies have been made in reconfiguration algorithms, hardware designs and interaction techniques. However no tools exist for guiding designers in building those modular devices and especially for choosing the shape of the units. The task becomes even more complex when the units themselves can change their shapes to animate the entire assembly. In this paper, we contribute with the first analysis tool which helps the designer to both choose the right subset of forms for the units and to create an assembly with maximum accuracy from the set of given objects. We introduce the concept of Changibles that are interactive wireless units that can reshape themselves and be attached together to create an animated assembly. We present a use case to demonstrate the use of our tool, with an instantiation of six Changibles that are used to construct a pulsing heart assembly.</p>
<p>Keywords:
actuated display; constructive assembly; modular robot.; shape changing object</p>
<h2 id="Touch input    4">Touch input    4</h2>
<h3 id="294. Expanding touch input vocabulary by using consecutive distant taps.">294. Expanding touch input vocabulary by using consecutive distant taps.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557234">Paper Link</a>    Pages:2597-2606</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Heo:Seongkook">Seongkook Heo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gu:Jiseong">Jiseong Gu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Geehyuk">Geehyuk Lee</a></p>
<p>Abstract:
In recent years, touch screens have emerged and matured as the main input interface for mobile and tablet computers calling for extended touch input possibilities. In this paper, we explore the use of consecutive distant taps to expand the touch screen input vocabulary. We analyzed time intervals and distances between consecutive taps during common applications on a tablet and verified that consecutive distant taps can be used conflict-free with existing touch gestures. We designed the two interaction techniques Ta-tap and Ta-Ta-tap that utilize consecutive distant taps. Ta-tap uses two consecutive distant taps to invoke alternative touch operations for multi-touch emulation, whereas Ta-Ta-tap uses a series of consecutive distant taps to define a spatial gesture. We verified the feasibility of both interaction techniques through a series of experiments and a user study. The high recognition rate of Ta-tap and Ta-Ta-tap gestures, the few conflicts with existing gestures, and the positive feedback from the participants assert the potential of consecutive distant taps as a new design space to enrich touch screen interactions.</p>
<p>Keywords:
command shortcut; consecutive distant taps; ta-ta-tap; ta-tap; touch screen</p>
<h3 id="295. LinearDragger: a linear selector for target acquisition on touch screens.">295. LinearDragger: a linear selector for target acquisition on touch screens.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557096">Paper Link</a>    Pages:2607-2616</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Au:Oscar_Kin=Chung">Oscar Kin-Chung Au</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Su:Xiaojun">Xiaojun Su</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lau:Rynson_W=_H=">Rynson W. H. Lau</a></p>
<p>Abstract:
Touch input is increasingly popular nowadays, especially for mobile devices such as smartphones and tablet computers. However, the human finger has considerably large fingertip size and finger input is imprecise. As such, acquiring small targets on a touch screen is still a challenging task. In this paper, we present the LinearDragger, a new and integrated one-finger target acquisition technique for small and clustered targets. The proposed method has three advantages. First, it allows users to select targets in dense clustered groups easily with a single touch-drag-release operation. Second, it maps the 2D selection problem into a more precise 1D selection problem, which is independent of the target distribution. Third, it avoids finger occlusion and does not create visual distraction. As a result, it is particularly suitable for applications with dense targets and rich visual elements. Results of our controlled experiments show that when selecting small targets, LinearDragger takes about 70% and 30% less selection time than target acquisition without using any techniques and with the state-of-the-art target acquisition technique that involves a single touch operation, respectively, while maintaining a reasonable error rate.</p>
<p>Keywords:
dense target selection; target acquisition; touch input</p>
<h3 id="296. Faster command selection on tablets with FastTap.">296. Faster command selection on tablets with FastTap.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557136">Paper Link</a>    Pages:2617-2626</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Scarr:Joey">Joey Scarr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Malacria:Sylvain">Sylvain Malacria</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olson:Scott_C=">Scott C. Olson</a></p>
<p>Abstract:
Touch-based tablet UIs provide few shortcut mechanisms for rapid command selection; as a result, command selection on tablets often requires slow traversal of menus. We developed a new selection technique for multi-touch tablets, called FastTap, that uses thumb-and-finger touches to show and choose from a spatially-stable grid-based overlay interface. FastTap allows novices to view and inspect the full interface, but once item locations are known, FastTap allows people to select commands with a single quick thumb-and-finger tap. The interface helps users develop expertise, since the motor actions carried out as a novice rehearse the expert behavior. A controlled study showed that FastTap was significantly faster (by 33% per selection overall) than marking menus, both for novices and experts, and without reduction in accuracy or subjective preference. Our work introduces a new and efficient selection mechanism that supports rapid command execution on touch tablets, for both novices and experts.</p>
<p>Keywords:
command selection; expertise; tablet uis</p>
<h3 id="297. Crossing-based selection with direct touch input.">297. Crossing-based selection with direct touch input.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557397">Paper Link</a>    Pages:2627-2636</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Luo:Yuexing">Yuexing Luo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vogel_0001:Daniel">Daniel Vogel</a></p>
<p>Abstract:
Fundamental performance results for crossing-based selec-tion tasks with direct touch input are presented. A close adaptation of Accot and Zhai's indirect stylus crossing ex-periment reveals similar trends for direct touch input: touch crossing task time is faster or equivalent to touch pointing; continuous selection of large orthogonal crossing targets is most effective; and continuous selection of small collinear targets is least effective. Unlike indirect stylus and mouse crossing, not every kind of direct touch pointing perfor-mance is modeled accurately with standard Fitts' law. Instead, Fitts' law, used previously for touch pointing with small targets, is used to more accurately model discrete touch crossing with a directionally constrained target. In addition, visual touch feedback is shown to have a strong effect on absolute accuracy. Our work empirically validates touch crossing as a practical and efficient selection technique, and motivates the exploration of novel forms of expressive multi-touch crossing.</p>
<p>Keywords:
crossing; ffitts; fitts; goal crossing; multi-touch; pen input; pointing; stylus input; target selection; touch input</p>
<h2 id="Risks and security    5">Risks and security    5</h2>
<h3 id="298. Easy does it: more usable CAPTCHAs.">298. Easy does it: more usable CAPTCHAs.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557322">Paper Link</a>    Pages:2637-2646</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bursztein:Elie">Elie Bursztein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moscicki:Angelique">Angelique Moscicki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fabry:Celine">Celine Fabry</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bethard:Steven">Steven Bethard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mitchell:John_C=">John C. Mitchell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jurafsky:Dan">Dan Jurafsky</a></p>
<p>Abstract:
Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. In this paper we describe how we designed two new CAPTCHA schemes for Google that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the usability of different feature combinations. Then we studied user preferences using Google's consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes first on Mechanical Turk and then on a fraction of production traffic. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7.</p>
<p>Keywords:
CAPTCHA; empirical methods; quantitative usability testing and evaluation; security; user studies; world wide web</p>
<h3 id="299. Using personal examples to improve risk communication for security & privacy decisions.">299. Using personal examples to improve risk communication for security &amp; privacy decisions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556978">Paper Link</a>    Pages:2647-2656</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harbach:Marian">Marian Harbach</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hettig:Markus">Markus Hettig</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weber:Susanne">Susanne Weber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith_0001:Matthew">Matthew Smith</a></p>
<p>Abstract:
IT security systems often attempt to support users in taking a decision by communicating associated risks. However, a lack of efficacy as well as problems with habituation in such systems are well known issues. In this paper, we propose to leverage the rich set of personal data available on smartphones to communicate risks using personalized examples. Examples of private information that may be at risk can draw the users' attention to relevant information for a decision and also improve their response. We present two experiments that validate this approach in the context of Android app permissions. Private information that becomes accessible given certain permissions is displayed when a user wants to install an app, demonstrating the consequences this installation might have. We find that participants made more privacy-conscious choices when deciding which apps to install. Additionally, our results show that our approach causes a negative affect in participants, which makes them pay more attention.</p>
<p>Keywords:
android; consequences; examples; permissions; personalization; privacy; risks; usable security</p>
<h3 id="300. "My religious aunt asked why i was trying to sell her viagra": experiences with account hijacking.">300. "My religious aunt asked why i was trying to sell her viagra": experiences with account hijacking.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557330">Paper Link</a>    Pages:2657-2666</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shay:Richard">Richard Shay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Ion:Iulia">Iulia Ion</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reeder:Robert_W=">Robert W. Reeder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Consolvo:Sunny">Sunny Consolvo</a></p>
<p>Abstract:
With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of a survey about people's experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are often valuable to victims, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users acknowledge some responsibility for keeping their accounts secure, (4) users' understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for user adoption.</p>
<p>Keywords:
account compromise; account hijacking; attackers; authentication; google consumer survey; mechanical turk; microsurvey; online accounts; security; survey</p>
<h3 id="301. Experimenting at scale with google chrome's SSL warning.">301. Experimenting at scale with google chrome's SSL warning.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557292">Paper Link</a>    Pages:2667-2670</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Felt:Adrienne_Porter">Adrienne Porter Felt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reeder:Robert_W=">Robert W. Reeder</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Almuhimedi:Hazim">Hazim Almuhimedi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Consolvo:Sunny">Sunny Consolvo</a></p>
<p>Abstract:
Web browsers show HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and measured 130,754 impressions.</p>
<p>Keywords:
SSL warnings; active warnings; browser security warnings; interruptive warnings; interstitials</p>
<h3 id="302. Betrayed by updates: how negative experiences affect future security.">302. Betrayed by updates: how negative experiences affect future security.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557275">Paper Link</a>    Pages:2671-2674</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vaniea:Kami">Kami Vaniea</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rader:Emilee_J=">Emilee J. Rader</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wash:Rick">Rick Wash</a></p>
<p>Abstract:
Installing security-relevant software updates is one of the best computer protection mechanisms. However, users do not always choose to install updates. Through interviewing non-expert Windows users, we found that users frequently decide not to install future updates, regardless of whether they are important for security, after negative experiences with past updates. This means that even non-security updates (such as user interface changes) can impact the security of a computer. We discuss three themes impacting users' willingness to install updates: unexpected new features in an update, the difficulty of assessing whether an update is ``worth it', and confusion about why an update is necessary.</p>
<p>Keywords:
human factors; security; software updates</p>
<h2 id="CHI for social development    4">CHI for social development    4</h2>
<h3 id="303. Understanding sustained community engagement: a case study in heritage preservation in rural argentina.">303. Understanding sustained community engagement: a case study in heritage preservation in rural argentina.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557323">Paper Link</a>    Pages:2675-2684</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Balestrini:Mara">Mara Balestrini</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bird:Jon">Jon Bird</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Paul">Paul Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zaro:Alberto">Alberto Zaro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Yvonne">Yvonne Rogers</a></p>
<p>Abstract:
HCI projects are increasingly evaluating technologies in the wild, which typically involves working with communities over extended periods, often with the goal of effecting sustainable change. However, there are few descriptions of projects that have been successful in the long-term. In this paper we investigate what factors are important for developing long lasting community ICT interventions. We do this by analysing a successful action research project and provide five recommendations for facilitating sustained community engagement. CrowdMemo aimed to preserve local heritage in a town in rural Argentina and the project was set up so that it could be continued by the community once researchers had left. Participants created videos about personal memories of the town and over 600 people attended the premiere where they were first screened. The impact has not just been short-term and there has been sustained engagement with the project by stakeholders in the town and wider region: the local school integrated digital storytelling into its curriculum; the approach has been adopted by two nearby towns; and the project has influenced regional government educational policy.</p>
<p>Keywords:
action research; community engagement; digital storytelling; hci4d; research in the wild</p>
<h3 id="304. Human values in curating a human rights media archive.">304. Human values in curating a human rights media archive.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557196">Paper Link</a>    Pages:2685-2694</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Durrant:Abigail">Abigail Durrant</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kirk:David_S=">David S. Kirk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reeves:Stuart">Stuart Reeves</a></p>
<p>Abstract:
Cultural institutions, such as museums, often curate politically and ethically sensitive materials. Increasingly, Internet-enabled, digital technology intersects with these curatorial practices offering new opportunities for public and scholarly engagement. We report on a case study of human rights media archiving at a genocide memorial centre in Rwanda, motivated by our interests in ICT support to memorialisation practices. Through an analysis of our discussions with staff about their work, we report on how accounts of the Rwandan Genocide are being captured and curated to support the centre's humanitarian agenda and associated values. We identify transferable curatorial concerns for human rights media communication amongst scholarly networks and public audiences worldwide, elucidating interaction design challenges for supportive ICT and contributing to HCI discourses on Value Sensitive Design and cultural engagement with sensitive materials.</p>
<p>Keywords:
curation; genocide; human rights media; memorial; rwanda; value sensitive design</p>
<h3 id="305. Protibadi: a platform for fighting sexual harassment in urban bangladesh.">305. Protibadi: a platform for fighting sexual harassment in urban bangladesh.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557376">Paper Link</a>    Pages:2695-2704</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Ahmed:Syed_Ishtiaque">Syed Ishtiaque Ahmed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jackson:Steven_J=">Steven J. Jackson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ahmed:Nova">Nova Ahmed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Ferdous:Hasan_Shahid">Hasan Shahid Ferdous</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rifat:Md=_Rashidujjaman">Md. Rashidujjaman Rifat</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rizvi:A=_S=_M=">A. S. M. Rizvi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ahmed:Shamir">Shamir Ahmed</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mansur:Rifat_Sabbir">Rifat Sabbir Mansur</a></p>
<p>Abstract:
Public sexual harassment has emerged as a large and growing concern in urban Bangladesh, with deep and damaging implications for gender security, justice, and rights of public participation. In this paper we describe an integrated program of ethnographic and design work meant to understand and address such problems. For one year we conducted surveys, interviews, and focus groups around sexual harassment with women at three different universities in Dhaka. Based on this input, we developed "Protibadi", a web and mobile phone based application designed to report, map, and share women's stories around sexual harassment in public places. In August 2013 the system launched, user studies were conducted, and public responses were monitored to gauge reactions, strengths, and limits of the system. This paper describes the findings of our ethnographic and design-based work, and suggests lessons relevant to other HCI efforts to understand and design around difficult and culturally sensitive problems.</p>
<p>Keywords:
bangladesh; design; ethnography; hci4d; ictd; postcolonial computing; sexual harassment</p>
<h3 id="306. How technology supports family communication in rural, suburban, and urban kenya.">306. How technology supports family communication in rural, suburban, and urban kenya.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557277">Paper Link</a>    Pages:2705-2714</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Oduor:Erick">Erick Oduor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Neustaedter:Carman">Carman Neustaedter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Judge:Tejinder_K=">Tejinder K. Judge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hennessy:Kate">Kate Hennessy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pang:Carolyn">Carolyn Pang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hillman:Serena">Serena Hillman</a></p>
<p>Abstract:
Much ICTD research for sub-Saharan Africa has focused on how technology related interventions have aimed to incorporate marginalized communities towards global economic growth. Our work builds on this. We present results from an exploratory qualitative study on the family communication practices of family members who communicate both within and between rural, suburban, and urban settings in Kenya. Our findings reveal that family communication focuses on economic support, well-being, life advice, and everyday coordination of activities. We also outline social factors that affect family communication, including being an eldest child, having a widowed sibling, and having reduced access to technology because of gender, literacy, or one's financial situation. Lastly, we discuss new opportunities for technology design and articulate the challenges that designers will face if creating or deploying family communication technologies in Kenya.</p>
<p>Keywords:
awareness; family communication; ict4d; mobile devices</p>
<h2 id="Question and answer systems    5">Question and answer systems    5</h2>
<h3 id="307. Towards crowd-based customer service: a mixed-initiative tool for managing Q&A sites.">307. Towards crowd-based customer service: a mixed-initiative tool for managing Q&amp;A sites.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557202">Paper Link</a>    Pages:2725-2734</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Piccardi:Tiziano">Tiziano Piccardi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Convertino:Gregorio">Gregorio Convertino</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zancanaro:Massimo">Massimo Zancanaro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Ji">Ji Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Archambeau:C=eacute=dric">Cdric Archambeau</a></p>
<p>Abstract:
In this paper, we propose a mixed-initiative approach to integrate a Q&amp;A site based on a crowd of volunteers with a standard operator-based help desk, ensuring quality of customer service. Q&amp;A sites have emerged as an efficient way to address questions in various domains by leveraging crowd knowledge. However, they lack sufficient reliability to be the sole basis of customer service applications. We built a proof-of-concept mixed-initiative tool that helps a crowd-manager to decide if a question will get a satisfactory and timely answer by the crowd or if it should be redirected to a dedicated operator. A user experiment found that our tool reduced the participants' cognitive load and improved their performance, in terms of their precision and recall. In particular, those with higher performance benefited more than those with lower performance.</p>
<p>Keywords:
crowdsourcing; customer care; mixed initiative; q&amp;a</p>
<h3 id="308. Estimating the social costs of friendsourcing.">308. Estimating the social costs of friendsourcing.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557181">Paper Link</a>    Pages:2735-2744</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rzeszotarski:Jeffrey_M=">Jeffrey M. Rzeszotarski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Meredith_Ringel">Meredith Ringel Morris</a></p>
<p>Abstract:
Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others' time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.</p>
<p>Keywords:
crowdsourcing; friendsourcing; sns q&a; twitter</p>
<h3 id="309. Expert voices in echo chambers: effects of source expertise indicators on exposure to diverse opinions.">309. Expert voices in echo chambers: effects of source expertise indicators on exposure to diverse opinions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557240">Paper Link</a>    Pages:2745-2754</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Liao:Qingzi_Vera">Qingzi Vera Liao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fu:Wai=Tat">Wai-Tat Fu</a></p>
<p>Abstract:
We studied how a source expertise indicator impacted users' information seeking behavior when using a system aggregating diverse opinions, and how it interacted with a source position indicator to shape users' selectivity of information. We found that, for both attitude consistent and inconsistent information, the expertise indicator increased the selection of sources indicated to have high expertise and decreased that of low expertise. Moreover, when both source expertise and position indicators were present, users' selective exposure tendency, i.e., preferential selection of attitude consistent sources over inconsistent ones, decreased among expert sources. Moreover, we found that the expertise indicator could benefit encouraging common ground seeking with different others by increasing the agreement with, and perceived expertise of inconsistent sources indicated to be experts. Design implications for moderating selective exposure by highlighting the utility of dissonant information were discussed.</p>
<p>Keywords:
diversity seeking; selective exposure; source expertise</p>
<h3 id="310. Is anyone out there?: unpacking Q&A hashtags on twitter.">310. Is anyone out there?: unpacking Q&amp;A hashtags on twitter.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557175">Paper Link</a>    Pages:2755-2758</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rzeszotarski:Jeffrey_M=">Jeffrey M. Rzeszotarski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Spiro:Emma_S=">Emma S. Spiro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matias:Jorge_Nathan">Jorge Nathan Matias</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Monroy=Hern=aacute=ndez:Andr=eacute=s">Andrs Monroy-Hernndez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Meredith_Ringel">Meredith Ringel Morris</a></p>
<p>Abstract:
In addition to posting news and status updates, many Twitter users post questions that seek various types of subjective and objective information. These questions are often labeled with 'Q&amp;A' hashtags, such as #lazyweb or #twoogle. We surveyed Twitter users and found they employ these Q&amp;A hashtags both as a topical signifier (this tweet needs an answer!) and to reach out to those beyond their immediate followers (a community of helpful tweeters who monitor the hashtag). However, our log analysis of thousands of hashtagged Q&amp;A exchanges reveals that nearly all replies to hashtagged questions come from a user's immediate follower network, contradicting users' beliefs that they are tapping into a larger community by tagging their question tweets. This finding has implications for designing next-generation social search systems that reach and engage a wide audience of answerers.</p>
<p>Keywords:
hashtags; information seeking; q&a; social search; twitter</p>
<h3 id="311. What if we ask a different question?: social inferences create product ratings faster.">311. What if we ask a different question?: social inferences create product ratings faster.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557081">Paper Link</a>    Pages:2759-2762</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gilbert:Eric">Eric Gilbert</a></p>
<p>Abstract:
Consumer product reviews are the backbone of commerce online. Most commonly, sites ask users for their personal opinions on a product or service. I conjecture, however, that this traditional method of eliciting reviews often invites idiosyncratic viewpoints. In this paper, I present a statistical study examining the differences between traditionally elicited product ratings (i.e., "How do you rate this product'") and social inference ratings (i.e., "How do you think other people will rate this product'"). In 5 of 6 trials, I find that social inference ratings produce the same aggregate product rating as the one produced via traditionally elicited ratings. In all cases, however, social inferences yield less variance. This is significant because using social inference ratings 1) therefore converges on the true aggregate product rating faster, and 2) is a cheap design intervention on the part of existing sites.</p>
<p>Keywords:
ecommerce; product reviews; ratings; social psychology</p>
<h2 id="Cross-device interaction    4">Cross-device interaction    4</h2>
<h3 id="312. Smarties: an input system for wall display development.">312. Smarties: an input system for wall display development.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556956">Paper Link</a>    Pages:2763-2772</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chapuis:Olivier">Olivier Chapuis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bezerianos:Anastasia">Anastasia Bezerianos</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Frantzeskakis:Stelios">Stelios Frantzeskakis</a></p>
<p>Abstract:
Wall-sized displays can support data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It consists of an interface running on touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to.</p>
<p>Keywords:
cscw; hand-held touch devices; input toolkit; multi-cursors; wall display</p>
<h3 id="313. Conductor: enabling and understanding cross-device interaction.">313. Conductor: enabling and understanding cross-device interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557170">Paper Link</a>    Pages:2773-2782</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hamilton:Peter">Peter Hamilton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel_J=">Daniel J. Wigdor</a></p>
<p>Abstract:
The proliferation of inexpensive connected devices has created a situation where a person, at any given moment, is surrounded by interactive computers. Despite this fact, there are very few means by which a user may take advantage of this large number of screens. We present Conductor, a prototype framework which serves as an exemplar for the construction of cross-device applications. We present a series of interaction methods by which users can easily share information, chain tasks across devices, and manage sessions across devices. We also present a cross-device usage scenario which utilizes several cross-device applications built within our prototype framework. We also describe a user study, which helped us to understand how users will take advantage of a large number of devices in support of performance of a sense making task.</p>
<p>Keywords:
cross-device applications; distributed user interfaces; information sharing; multi-device environments; optimization; user interface design</p>
<h3 id="314. Panelrama: enabling easy specification of cross-device web applications.">314. Panelrama: enabling easy specification of cross-device web applications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557199">Paper Link</a>    Pages:2783-2792</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Jishuo">Jishuo Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel">Daniel Wigdor</a></p>
<p>Abstract:
We present Panelrama, a web-based framework for the construction of applications using distributed user interfaces (DUIs). Our implementation provides developers with low migration costs through built-in mechanisms for the synchronization of a UI state, requiring minimal changes to existing languages. Additionally, we describe a solution to categorize device characteristics and dynamically change UI allocation to best-fit devices. We illustrate the use of Panelrama through three sample applications which demonstrate its support for known interaction methods, we also present the results of a developer study, which validates our belief that cross-device application experiences can be easily implemented using our framework.</p>
<p>Keywords:
distributed user interfaces; multi-device environments</p>
<h3 id="315. Interactive development of cross-device user interfaces.">315. Interactive development of cross-device user interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556980">Paper Link</a>    Pages:2793-2802</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Nebeling:Michael">Michael Nebeling</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mintsi:Theano">Theano Mintsi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Husmann:Maria">Maria Husmann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Norrie:Moira_C=">Moira C. Norrie</a></p>
<p>Abstract:
Current GUI builders provide a design environment for user interfaces that target either a single type or fixed set of devices, and provide little support for scenarios in which the user interface, or parts of it, are distributed over multiple devices. Distributed user interfaces have received increasing attention over the past years. There are different, often model-based, approaches that focus on technical issues. This paper presents XDStudio--a new GUI builder designed to support interactive development of cross-device web interfaces. XDStudio implements two complementary authoring modes with a focus on the design process of distributed user interfaces. First, simulated authoring allows designing for a multi-device environment on a single device by simulating other target devices. Second, on-device authoring allows the design process itself to be distributed over multiple devices, as design and development take place on the target devices themselves. To support interactive development for multi-device environments, where not all devices may be present at design and run-time, XDStudio supports switching between the two authoring modes, as well as between design and use modes, as required. This paper focuses on the design of XDStudio, and evaluates its support for two distribution scenarios.</p>
<p>Keywords:
distributed authoring; distributed user interfaces; multi-device; simulated authoring</p>
<h2 id="Exergaming for health and fitness    4">Exergaming for health and fitness    4</h2>
<h3 id="316. Motivating people with chronic pain to do physical activity: opportunities for technology design.">316. Motivating people with chronic pain to do physical activity: opportunities for technology design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557268">Paper Link</a>    Pages:2803-2812</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Singh:Aneesha">Aneesha Singh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Klapper:Annina">Annina Klapper</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jia:Jinni">Jinni Jia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fidalgo:Antonio">Antonio Fidalgo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tajadura=Jim=eacute=nez:Ana">Ana Tajadura-Jimnez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kanakam:Natalie">Natalie Kanakam</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bianchi=Berthouze:Nadia">Nadia Bianchi-Berthouze</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Williams:Amanda_C=_de_C=">Amanda C. de C. Williams</a></p>
<p>Abstract:
Physical activity is important for improving quality of life in people with chronic pain. However, actual or anticipated pain exacerbation, and lack of confidence when doing physical activity, make it difficult to maintain and build towards long-term activity goals. Research guiding the design of interactive technology to motivate and support physical activity in people with chronic pain is lacking. We conducted studies with: (1) people with chronic pain, to understand how they maintained and increased physical activity in daily life and what factors deterred them; and (2) pain-specialist physiotherapists, to understand how they supported people with chronic pain. Building on this understanding, we investigated the use of auditory feedback to address some of the psychological barriers and needs identified and to increase self-efficacy, motivation and confidence in physical activity. We conclude by discussing further design opportunities based on the overall findings.</p>
<p>Keywords:
auditory feedback; chronic pain; interactive systems design; physical activity</p>
<h3 id="317. Investigating the long-term use of exergames in the home with elderly fallers.">317. Investigating the long-term use of exergames in the home with elderly fallers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557160">Paper Link</a>    Pages:2813-2822</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/u/Uzor:Stephen">Stephen Uzor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baillie:Lynne">Lynne Baillie</a></p>
<p>Abstract:
Rehabilitation has been shown to significantly reduce the risk of falling in older adults. However, low adherence to rehabilitation exercises in the home means that seniors often do not get the therapy that they require. We propose that the use of tailored exergames could encourage adherence to falls rehabilitation in the home, as exergames have proved successful in clinical settings. We describe the results from the first known study to investigate the long-term (12 weeks) use of exergames, designed in close collaboration with elderly users, for falls rehabilitation in the home. Our findings suggest that there is an untapped potential of exergames for home rehabilitation use, as our findings show that there was better adherence to exercise in participants who used the exergames, versus those who used standard care. Finally, we make recommendations for designers, on the design of exergames for the rehabilitation of seniors.</p>
<p>Keywords:
elderly; exergames; falls; games; home; rehabilitation.; user studies</p>
<h3 id="318. StepStream: a school-based pervasive social fitness system for everyday adolescent health.">318. StepStream: a school-based pervasive social fitness system for everyday adolescent health.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557190">Paper Link</a>    Pages:2823-2832</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Andrew_D=">Andrew D. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mynatt:Elizabeth_D=">Elizabeth D. Mynatt</a></p>
<p>Abstract:
Computer-supported fitness interventions for adolescents have the potential to improve adolescents' attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings.</p>
<p>Keywords:
adolescents; deployments; fitness intervention; pervasive health; social computing; youth</p>
<h3 id="319. Social fabric fitness: the design and evaluation of wearable E-textile displays to support group running.">319. Social fabric fitness: the design and evaluation of wearable E-textile displays to support group running.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557299">Paper Link</a>    Pages:2833-2842</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mauriello:Matthew_Louis">Matthew Louis Mauriello</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gubbels:Michael">Michael Gubbels</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Froehlich:Jon">Jon Froehlich</a></p>
<p>Abstract:
Group exercise has multiple benefits including greater adherence to fitness regimens, increased enjoyment among participants, and enhanced workout intensity. While a large number of technology tools have emerged to support real-time feedback of individual performance, tools to support group fitness are limited. In this paper, we present a set of wearable e-textile displays for running groups called Social Fabric Fitness (SFF). SFF provides a glanceable, shared screen on the back of the wearer's shirt to increase awareness and motivation of group fitness performance. We discuss parallel prototyping of three designs-one flexible e-ink and two flexible LED-based displays; the selection and refinement of one design; and two evaluations'a field study of 10 running groups and two case studies of running races. Our qualitative findings indicate that SFF improves awareness of individual and group performance, helps groups stay together, and improves in-situ motivation. We close with reflections for future athletic e-textile displays.</p>
<p>Keywords:
fitness; glanceable displays; personal informatics; quantified self; visualization; wearables</p>
<h2 id="Sensory experiences: smell and taste    4">Sensory experiences: smell and taste    4</h2>
<h3 id="320. Opportunities for odor: experiences with smell and implications for technology.">320. Opportunities for odor: experiences with smell and implications for technology.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557008">Paper Link</a>    Pages:2843-2852</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Obrist:Marianna">Marianna Obrist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tuch:Alexandre_N=">Alexandre N. Tuch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a></p>
<p>Abstract:
Technologies for capturing and generating smell are emerging, and our ability to engineer such technologies and use them in HCI is rapidly developing. Our understanding of how these technologies match the experiences with smell that people have or want to have is surprisingly limited. We therefore investigated the experience of smell and the emotions that accompany it. We collected stories from 439 participants who described personally memorable smell experiences in an online questionnaire. Based on the stories we developed 10 categories of smell experience. We explored the implications of the categories for smell-enhanced technology design by (a) probing participants to envision technologies that match their smell story and (b) having HCI researchers brainstorm technologies using the categories as design stimuli. We discuss how our findings can benefit research on personal memories, momentary and first time experiences, and wellbeing.</p>
<p>Keywords:
crowdsourcing; design brainstorming; designing for smell.; narratives; odor; olfaction; smell; smell experiences; smell stories; smell-enhanced technology; user experience</p>
<h3 id="321. Temporal, affective, and embodied characteristics of taste experiences: a framework for design.">321. Temporal, affective, and embodied characteristics of taste experiences: a framework for design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557007">Paper Link</a>    Pages:2853-2862</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Obrist:Marianna">Marianna Obrist</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Comber:Rob">Rob Comber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Piqueras=Fiszman:Betina">Betina Piqueras-Fiszman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Velasco:Carlos">Carlos Velasco</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Spence:Charles">Charles Spence</a></p>
<p>Abstract:
We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings, based on a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes elicit. These findings are discussed on the basis of established psychological and behavioral phenomena, highlighting the potential for taste-enhanced design.</p>
<p>Keywords:
explicitation interview technique; sensory research; sensual evaluation tool; taste; taste experiences; user experience</p>
<h3 id="322. SensaBubble: a chrono-sensory mid-air display of sight and smell.">322. SensaBubble: a chrono-sensory mid-air display of sight and smell.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557087">Paper Link</a>    Pages:2863-2872</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Seah:Sue_Ann">Sue Ann Seah</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Plasencia:Diego_Martinez">Diego Martinez Plasencia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bennett:Peter_D=">Peter D. Bennett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Karnik:Abhijit">Abhijit Karnik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Otrocol:Vlad_Stefan">Vlad Stefan Otrocol</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Knibbe:Jarrod">Jarrod Knibbe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a></p>
<p>Abstract:
We present SensaBubble, a chrono-sensory mid-air display system that generates scented bubbles to deliver information to the user via a number of sensory modalities. The system reliably produces single bubbles of specific sizes along a directed path. Each bubble produced by SensaBubble is filled with fog containing a scent relevant to the notification. The chrono-sensory aspect of SensaBubble means that information is presented both temporally and multimodally. Temporal information is enabled through two forms of persistence: firstly, a visual display projected onto the bubble which only endures until it bursts; secondly, a scent released upon the bursting of the bubble slowly disperses and leaves a longer-lasting perceptible trace of the event. We report details of SensaBubble's design and implementation, as well as results of technical and user evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use in a wide range of application contexts -- from an ambient peripheral display for persistent alerts, to an engaging display for gaming or education.</p>
<p>Keywords:
ambient displays; bubbles; ephemeral interfaces; interactive displays; multimodality.</p>
<h3 id="323. Food messaging: using edible medium for social messaging.">323. Food messaging: using edible medium for social messaging.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557026">Paper Link</a>    Pages:2873-2882</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wei:Jun">Jun Wei</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Ma:Xiaojuan">Xiaojuan Ma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a></p>
<p>Abstract:
Food is more than just a means of survival; it is also a form of communication. In this paper, we investigate the potential of food as a social message carrier (a.k.a., food messaging). To investigate how people accept, use, and perceive food messaging, we conducted exploratory interviews, a field study, and follow-up interviews over four weeks in a large information technology (IT) company. We collected 904 messages sent by 343 users. Our results suggest strong acceptance of food messaging as an alternative message channel. Further analysis implies that food messaging embodies characteristics of both text messaging and gifting. It is preferred in close relationships for its evocation of positive emotions. As the first field study on edible social messaging, our empirical findings provide valuable insights into the uniqueness of food as a message carrier and its capabilities to promote greater social bonding.</p>
<p>Keywords:
affective communication; edible social messaging; field study; food hci; food messaging; food printer</p>
<h2 id="Multitouch interaction    4">Multitouch interaction    4</h2>
<h3 id="324. Multi-finger chords for hand-held tablets: recognizable and memorable.">324. Multi-finger chords for hand-held tablets: recognizable and memorable.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556958">Paper Link</a>    Pages:2883-2892</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wagner:Julie">Julie Wagner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lecolinet:Eric">Eric Lecolinet</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Selker:Ted">Ted Selker</a></p>
<p>Abstract:
Despite the demonstrated benefits of multi-finger input, todays gesture vocabularies offer a limited number of postures and gestures. Previous research designed several posture sets, but does not address the limited human capacity of retaining them. We present a multi-finger chord vocabulary, introduce a novel hand-centric approach to detect the identity of fingers on off-the-shelf hand-held tablets, and report on the detection accuracy. A between-subjects experiment comparing "random" to a "categorized" chord-command mapping found that users retained categorized mappings more accurately over one week than random ones. In response to the logical posture-language structure, people adapted to logical memorization strategies, such as 'exclusion', 'order', and 'category', to minimize the amount of information to retain. We conclude that structured chord-command mappings support learning, short-, and long-term retention of chord- command mappings.</p>
<p>Keywords:
chord-command mapping; finger identification; hand-held tablet; multi-finger chord</p>
<h3 id="325. Prospective motor control on tabletops: planning grasp for multitouch interaction.">325. Prospective motor control on tabletops: planning grasp for multitouch interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557029">Paper Link</a>    Pages:2893-2902</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Olafsdottir:Halla_B=">Halla B. Olafsdottir</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tsandilas:Theophanis">Theophanis Tsandilas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Appert:Caroline">Caroline Appert</a></p>
<p>Abstract:
Substantial amount of research in Psychology has studied how people manipulate objects in the physical world. This work has unveiled that people show strong signs of prospective motor planning, i.e., they choose initial grasps that avoid uncomfortable end postures and facilitate object manipulation. Interactive tabletops allow their users great flexibility in the manipulation of virtual objects but to our knowledge previous work has never examined whether prospective motor control takes place in this context. To test this, we ran three experiments. We systematically studied how users adapt their grasp when asked to translate and rotate virtual objects on a multitouch tabletop. Our results demonstrate that target position and orientation significantly affect the orientation of finger placement on the object. We analyze our results in the light of the most recent model of planning for manipulating physical objects and identify their implications for the design of tabletop interfaces. \</p>
<p>Keywords:
acquisition and manipulation; end-state comfort effect; movement planning; multitouch; range of motion; tabletops</p>
<h3 id="326. Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects.">326. Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557282">Paper Link</a>    Pages:2903-2912</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Alzayat:Ayman">Ayman Alzayat</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hancock:Mark_S=">Mark S. Hancock</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nacenta:Miguel_A=">Miguel A. Nacenta</a></p>
<p>Abstract:
Over the past decade, multi-touch surfaces have become commonplace, with many researchers and practitioners describing the benefits of their natural, physical-like interactions. We present a pair of studies that empirically investigates the psychophysical effects of direct interaction with both physical and virtual artefacts. We use the phenomenon of Kinesthetic Figural After Effects-a change in understanding of the physical size of an object after a period of exposure to an object of different size. Our studies show that, while this effect is robustly reproducible when using physical artefacts, this same effect does not manifest when manipulating virtual artefacts on a direct, multi-touch tabletop display. We contribute quantitative evidence suggesting a psychophysical difference in our response to physical vs. virtual objects, and discuss future research directions to explore measurable phenomena to evaluate the presence of physical-like changes from virtual on-screen objects.</p>
<p>Keywords:
embodied interaction; multi-touch; physical interaction; tabletop displays; tangible user interfaces</p>
<h3 id="327. TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction.">327. TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557012">Paper Link</a>    Pages:2913-2916</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harrison:Chris">Chris Harrison</a> ; <a href="http://dblp.uni-trier.de/pers/hd/x/Xiao:Robert">Robert Xiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwarz:Julia">Julia Schwarz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hudson:Scott_E=">Scott E. Hudson</a></p>
<p>Abstract:
The average person can skillfully manipulate a plethora of tools, from hammers to tweezers. However, despite this remarkable dexterity, gestures on today's touch devices are simplistic, relying primarily on the chording of fingers: one-finger pan, two-finger pinch, four-finger swipe and similar. We propose that touch gesture design be inspired by the manipulation of physical tools from the real world. In this way, we can leverage user familiarity and fluency with such tools to build a rich set of gestures for touch interaction. With only a few minutes of training on a proof-of-concept system, users were able to summon a variety of virtual tools by replicating their corresponding real-world grasps.</p>
<p>Keywords:
capacitive sensing; gesture design; multitouch; surface computing; tangible computing; touchscreen</p>
<h2 id="Authentication and passwords    5">Authentication and passwords    5</h2>
<h3 id="328. Passhint: memorable and secure authentication.">328. Passhint: memorable and secure authentication.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557153">Paper Link</a>    Pages:2917-2926</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chowdhury:Soumyadeb">Soumyadeb Chowdhury</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Poet:Ron">Ron Poet</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mackenzie:Lewis">Lewis Mackenzie</a></p>
<p>Abstract:
People find it difficult to remember multiple alphanumeric as well as graphical passwords. We propose a Passhint authentication system (PHAS), where the users have to choose four images and create hints for each one of them in order to register a new password. During authentication, they have to recognize only the target images, which are displayed with their corresponding hints, among collections of 15 decoy images, in a four step process. A usability study was conducted with 40 subjects. They created 1 Mikon, 1 doodle, 1 art and 1 object password and then recalled each password after a period of two weeks (without any practice sessions). The results demonstrated that the memorability of multiple passwords in PHAS is better than in existing Graphical authentication systems (GASs). Although the registration time is high, authentication time for successful attempts is either equivalent to or less than the time reported for previous GASs. A guessability study conducted with the same subjects revealed that art passwords are the least guessable, followed by Mikon, doodle and objects in that order. The results strongly suggest the use of art passwords in PHAS, which would offer usable as well as secure authentication. The preliminary results indicate that PHAS has solved the memorability problem with multiple passwords. We propose two new features that could enhance the security offered by PHAS, but the usability of these features would need to be tested before they could be adopted in practice.</p>
<p>Keywords:
graphical authentication; guessability; usability</p>
<h3 id="329. Can long passwords be secure and usable?">329. Can long passwords be secure and usable?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557377">Paper Link</a>    Pages:2927-2936</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shay:Richard">Richard Shay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Komanduri:Saranga">Saranga Komanduri</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Durity:Adam_L=">Adam L. Durity</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huh:Phillip_=Seyoung=">Phillip (Seyoung) Huh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mazurek:Michelle_L=">Michelle L. Mazurek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Segreti:Sean_M=">Sean M. Segreti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/u/Ur:Blase">Blase Ur</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bauer:Lujo">Lujo Bauer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Christin:Nicolas">Nicolas Christin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cranor:Lorrie_Faith">Lorrie Faith Cranor</a></p>
<p>Abstract:
To encourage strong passwords, system administrators employ password-composition policies, such as a traditional policy requiring that passwords have at least 8 characters from 4 character classes and pass a dictionary check. Recent research has suggested, however, that policies requiring longer passwords with fewer additional requirements can be more usable and in some cases more secure than this traditional policy. To explore long passwords in more detail, we conducted an online experiment with 8,143 participants. Using a cracking algorithm modified for longer passwords, we evaluate eight policies across a variety of metrics for strength and usability. Among the longer policies, we discover new evidence for a security/usability tradeoff, with none being strictly better than another on both dimensions. However, several policies are both more usable and more secure that the traditional policy we tested. Our analyses additionally reveal common patterns and strings found in cracked passwords. We discuss how system administrators can use these results to improve password-composition policies.</p>
<p>Keywords:
authentication; password-composition policies; passwords; security policy; usable security</p>
<h3 id="330. Now you see me, now you don't: protecting smartphone authentication from shoulder surfers.">330. Now you see me, now you don't: protecting smartphone authentication from shoulder surfers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557097">Paper Link</a>    Pages:2937-2946</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Luca:Alexander_De">Alexander De Luca</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harbach:Marian">Marian Harbach</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zezschwitz:Emanuel_von">Emanuel von Zezschwitz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Maurer:Max=Emanuel">Max-Emanuel Maurer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Slawik:Bernhard_Ewald">Bernhard Ewald Slawik</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hussmann:Heinrich">Heinrich Hussmann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith_0001:Matthew">Matthew Smith</a></p>
<p>Abstract:
In this paper, we present XSide, an authentication mechanism that uses the front and the back of smartphones to enter stroke-based passwords. Users can switch sides during input to minimize the risk of shoulder surfing. We performed a user study (n = 32) to explore how switching sides during authentication affects usability and security of the system. The results indicate that switching the sides increases security while authentication speed stays relatively fast ( 4 seconds). The paper furthermore provides insights on accuracy of eyes-free input (as used in XSide) and shows how 3D printed prototype cases can improve the back-of-device interaction experience.</p>
<p>Keywords:
authentication; back-of-device interaction; security</p>
<h3 id="331. The presentation effect on graphical passwords.">331. The presentation effect on graphical passwords.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557212">Paper Link</a>    Pages:2947-2950</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Thorpe:Julie">Julie Thorpe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Al=Badawi:Muath">Muath Al-Badawi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacRae:Brent">Brent MacRae</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Salehi=Abari:Amirali">Amirali Salehi-Abari</a></p>
<p>Abstract:
We provide a simple yet powerful demonstration of how an unobtrusive change to a graphical password interface can modify the distribution of user chosen passwords, and thus possibly the security it provides. The only change to the interface is how the background image is presented to the user in the password creation phase--we call the effect of this change the "presentation effect". We demonstrate the presentation effect by performing a comparative user study of two groups using the same background image, where the image is presented in two different ways prior to password creation. Our results show a statistically different distribution of user's graphical passwords, with no observed usability consequences.</p>
<p>Keywords:
graphical passwords; passwords; user authentication</p>
<h3 id="332. An implicit author verification system for text messages based on gesture typing biometrics.">332. An implicit author verification system for text messages based on gesture typing biometrics.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557346">Paper Link</a>    Pages:2951-2954</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Burgbacher:Ulrich">Ulrich Burgbacher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hinrichs:Klaus_H=">Klaus H. Hinrichs</a></p>
<p>Abstract:
Gesture typing is a popular text input method used on smartphones. Gesture keyboards are based on word gestures that subsequently trace all letters of a word on a virtual keyboard. Instead of tapping a word key by key, the user enters a word gesture with a single continuous stroke. In this paper, we introduce an implicit user verification approach for short text messages that are entered with a gesture keyboard. We utilize the way people interact with gesture keyboards to extract behavioral biometric features. We propose a proof-of-concept classification framework that learns the gesture typing behavior of a person and is able to decide whether a gestured message was written by the legitimate user or an imposter. Data collected from gesture keyboard users in a user study is used to assess the performance of the classification framework, demonstrating that the technique has considerable promise.</p>
<p>Keywords:
behavioral biometrics; gesture keyboards; implicit authentication; mobile phone security</p>
<h2 id="Policies and practice: doing the right thing    3">Policies and practice: doing the right thing    3</h2>
<h3 id="333. HCI as a means to prosociality in the economy.">333. HCI as a means to prosociality in the economy.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557367">Paper Link</a>    Pages:2955-2964</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harvey:John">John Harvey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Golightly:David">David Golightly</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Andrew">Andrew Smith</a></p>
<p>Abstract:
HCI research often involves intervening in the economic lives of people, but researchers only rarely give explicit consideration to what actually constitutes prosociality in the economy. Much has been said previously regarding sustainability but this has largely focused on environmental rather than interpersonal relations. This paper provides an analysis of how prosocial HCI has been discussed and continues to be defined as a research field. Based on a corpus of published works, we describe a variety of genres of work relating to prosocial HCI. Key intellectual differences are explored, including the epistemological and ethical positions involved in designing for prosocial outcomes as well as how HCI researchers posit economic decision-making. Finally, emerging issues and opportunities for further debate and collaboration are discussed in turn.</p>
<p>Keywords:
economic anthropology; hci; prosocial</p>
<h3 id="334. Towards a closer dialogue between policy and practice: responsible design in HCI.">334. Towards a closer dialogue between policy and practice: responsible design in HCI.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557364">Paper Link</a>    Pages:2965-2974</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Grimpe:Barbara">Barbara Grimpe</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hartswood:Mark">Mark Hartswood</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jirotka:Marina">Marina Jirotka</a></p>
<p>Abstract:
Given the potent and pervasive nature of modern technologies, this paper lays out the complexities involved in achieving responsible design. In order to do this we will first compare an emerging policy-oriented programme of research known as RRI (Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities and differences may highlight to what extent responsibility is already and successfully embedded within the concerns and practices of design and use, and what may yet need to be incorporated for responsible design. The paper then discusses the challenges of 'naturalising' the very ambitious programme of RRI within specific design activities and concerns, through the lens of four analytic concepts: reflexivity; responsiveness; inclusion; and anticipation. Finally, we make a case for a pragmatic, 'unromantic', but engaged reinterpretation of RRI for HCI.</p>
<p>Keywords:
critical design; ethics; governance; innovation; participatory design; responsible design; risk society; user-centered design; value-sensitive design</p>
<h3 id="335. Towards community-centered support for peer-to-peer service exchange: rethinking the timebanking metaphor.">335. Towards community-centered support for peer-to-peer service exchange: rethinking the timebanking metaphor.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557061">Paper Link</a>    Pages:2975-2984</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bellotti:Victoria">Victoria Bellotti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cambridge:Sara">Sara Cambridge</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hoy:Karen">Karen Hoy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shih:Patrick_C=">Patrick C. Shih</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Handalian:Lisa_Renery">Lisa Renery Handalian</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Han:Kyungsik">Kyungsik Han</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Carroll:John_M=">John M. Carroll</a></p>
<p>Abstract:
Commercial peer-to-peer service exchange businesses, such as AirBnB, Lyft and TaskRabbit, are expanding rapidly, but their non-profit counterparts are lagging behind. We conducted a field study of the most prominent of these, timebanking; a system in which 'time dollars' are earned and spent by people providing services for and receiving them from each other. Our study exposed problems with the very metaphor of banking itself, which deter participation. In this paper we discuss how these problems can be tackled with user experience design for systems supporting timebanking. Our design ideas emphasize the personal and social benefits of participation, and avoid such unappealing concepts as debt and neediness that the timebanking metaphor falls afoul of.</p>
<p>Keywords:
field study; timebanking; user experience design</p>
<h2 id="Journalism and social news    4">Journalism and social news    4</h2>
<h3 id="336. Designing for dabblers and deterring drop-outs in citizen science.">336. Designing for dabblers and deterring drop-outs in citizen science.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557262">Paper Link</a>    Pages:2985-2994</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Eveleigh:Alexandra">Alexandra Eveleigh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jennett:Charlene">Charlene Jennett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blandford:Ann">Ann Blandford</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brohan:Philip">Philip Brohan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cox:Anna_Louise">Anna Louise Cox</a></p>
<p>Abstract:
In most online citizen science projects, a large proportion of participants contribute in small quantities. To investigate how low contributors differ from committed volunteers, we distributed a survey to members of the Old Weather project, followed by interviews with respondents selected according to a range of contribution levels. The studies reveal a complex relationship between motivations and contribution. Whilst high contributors were deeply engaged by social or competitive features, low contributors described a solitary experience of 'dabbling' in projects for short periods. Since the majority of participants exhibit this small-scale contribution pattern, there is great potential value in designing interfaces to tempt lone workers to complete 'just another page', or to lure early drop-outs back into participation. This includes breaking the work into components which can be tackled without a major commitment of time and effort, and providing feedback on the quality and value of these contributions.</p>
<p>Keywords:
citizen science; dabblers; engagement; motivation</p>
<h3 id="337. Utilising insight journalism for community technology design.">337. Utilising insight journalism for community technology design.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557054">Paper Link</a>    Pages:2995-3004</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Taylor_0002:Nick">Nick Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Frohlich:David_M=">David M. Frohlich</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Egglestone:Paul">Paul Egglestone</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Justin">Justin Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Jon">Jon Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blum=Ross:Alicia">Alicia Blum-Ross</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mills:John">John Mills</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shorter:Mike">Mike Shorter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
We describe the process of insight journalism, in which local amateur journalists were used to generate unique insights into the digital needs of a community. We position this as a means for communities to represent themselves to designers, both as a method of designing community technologies and as a first step towards supporting innovation at a local level. To demonstrate insight journalism, we present two case studies of community technologies that were directly inspired, informed and evaluated by journalistic content. Based on this experience, we evaluate the role that insight journalism can play in designing for communities, the particular characteristics that it lends to the design process and how it might be employed to support sustainable community innovation.</p>
<p>Keywords:
citizen journalism; co-design; community; design; ethnography; local innovation; participatory design</p>
<h3 id="338. NewsViews: an automated pipeline for creating custom geovisualizations for news.">338. NewsViews: an automated pipeline for creating custom geovisualizations for news.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557228">Paper Link</a>    Pages:3005-3014</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gao:Tong">Tong Gao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hullman:Jessica">Jessica Hullman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Adar:Eytan">Eytan Adar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hecht:Brent">Brent Hecht</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Diakopoulos:Nicholas">Nicholas Diakopoulos</a></p>
<p>Abstract:
Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews' maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of 'found' databases, and techniques adapted from cartography to identify and create visually 'interesting' thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, 'interestingness' of representation and annotation quality).</p>
<p>Keywords:
geovisualization; interactive maps; narrative information visualization; online news; text summarization</p>
<h3 id="339. Finding "real people": trust and diversity in the interface between professional and citizen journalists.">339. Finding "real people": trust and diversity in the interface between professional and citizen journalists.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557114">Paper Link</a>    Pages:3015-3024</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Garbett:Andrew_Thomas">Andrew Thomas Garbett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Comber:Rob">Rob Comber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Egglestone:Paul">Paul Egglestone</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Glancy:Maxine">Maxine Glancy</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
The increase of social media and web blogs has enabled a new generation of citizen journalism to provide new perspectives into local communities. However traditional news organisations are currently struggling to incorporate this new form of journalism into their existing organisational workflow. We present an analysis from 10 interviews with professional journalists and explore the current issues faced by professional journalists when searching for reliable and reputable local news sources as well as the perceived role of citizen journalists within a large news organisation. From this analysis we present a set of design implications for building systems that support interaction between citizen and professional journalists in order to encourage participatory news production and diversify national news perspectives.</p>
<p>Keywords:
citizen journalism; diversity; journalism; reputation; trust</p>
<h2 id="Interruptions and distractions    4">Interruptions and distractions    4</h2>
<h3 id="340. Bored mondays and focused afternoons: the rhythm of attention and online activity in the workplace.">340. Bored mondays and focused afternoons: the rhythm of attention and online activity in the workplace.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557204">Paper Link</a>    Pages:3025-3034</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mark:Gloria">Gloria Mark</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Iqbal:Shamsi_T=">Shamsi T. Iqbal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Czerwinski:Mary">Mary Czerwinski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Johns:Paul">Paul Johns</a></p>
<p>Abstract:
While distractions using digital media have received attention in HCI, understanding engagement in workplace activities has been little explored. We logged digital activity and continually probed perspectives of 32 information workers for five days in situ to understand how attentional states change with context. We present a framework of how engagement and challenge in work relate to focus, boredom, and rote work. Overall, we find more focused attention than boredom in the workplace. Focus peaks mid-afternoon while boredom is highest in early afternoon. People are happiest doing rote work and most stressed doing focused work. On Mondays people are most bored but also most focused. Online activities are associated with different attentional states, showing different patterns at beginning and end of day, and before and after a mid-day break. Our study shows how rhythms of attentional states are associated with context and time, even in a dynamic workplace environment.</p>
<p>Keywords:
attention; computer logging; empirical study; engagement; experience sampling; focus; multi-tasking; workplace</p>
<h3 id="341. CRISP: an interruption management algorithm based on collaborative filtering.">341. CRISP: an interruption management algorithm based on collaborative filtering.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557109">Paper Link</a>    Pages:3035-3044</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shrot:Tammar">Tammar Shrot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rosenfeld:Avi">Avi Rosenfeld</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Golbeck:Jennifer">Jennifer Golbeck</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraus:Sarit">Sarit Kraus</a></p>
<p>Abstract:
Interruptions can have a significant impact on users working to complete a task. When people are collaborating, either with other users or with systems, coordinating interruptions is an important factor in maintaining efficiency and preventing information overload. Computer systems can observe user behavior, model it, and use this to optimize the interruptions to minimize disruption. However, current techniques often require long training periods that make them unsuitable for online collaborative environments where new users frequently participate. In this paper, we present a novel synthesis between Collaborative Filtering methods and machine learning classification algorithms to create a fast learning algorithm, CRISP. CRISP exploits the similarities between users in order to apply data from known users to new users, therefore requiring less information on each person. Results from user studies indicate the algorithm significantly improves users' performances in completing the task and their perception of how long it took to complete each task.</p>
<p>Keywords:
classification algorithm; collaborative filtering; interruption management (cost estimation)</p>
<h3 id="342. Interrupted by a phone call: exploring designs for lowering the impact of call notifications for smartphone users.">342. Interrupted by a phone call: exploring designs for lowering the impact of call notifications for smartphone users.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557066">Paper Link</a>    Pages:3045-3054</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/B=ouml=hmer_0001:Matthias">Matthias Bhmer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lander:Christian">Christian Lander</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gehring:Sven">Sven Gehring</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brumby:Duncan_P=">Duncan P. Brumby</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kr=uuml=ger:Antonio">Antonio Krger</a></p>
<p>Abstract:
Mobile phones have evolved significantly in recent years from single-purpose communication devices to multi-purpose computing devices. Despite this evolution, the interaction model for how incoming calls are handled has barely changed. Current-generation smartphones still use abrupt full-screen notifications to alert users to incoming calls, demanding a decision to either accept or decline the call. These full-screen notifications forcibly interrupt whatever activity the user was already engaged in. This might be undesirable when the user's primary task was more important than the incoming call. This paper explores the design space for how smartphones can alert users to incoming calls. We consider designs that allow users to postpone calls and also to multiplex by way of a smaller partial-screen notification. These design alternatives were evaluated in both a small-scale controlled lab study as well as a large-scale naturalistic in-the-wild study. Results show that a multiplex design solution works best because it allows people to continue working on their primary task while being made aware that there is a caller on the line. The contribution of this work is an enhanced interaction design for handling phone calls, and an understanding of how people use it for handling incoming calls.</p>
<p>Keywords:
app usage; interruptions; phone calls; smartphones</p>
<h3 id="343. Large-scale assessment of mobile notifications.">343. Large-scale assessment of mobile notifications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557189">Paper Link</a>    Pages:3055-3064</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shirazi:Alireza_Sahami">Alireza Sahami Shirazi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Henze:Niels">Niels Henze</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dingler:Tilman">Tilman Dingler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pielot:Martin">Martin Pielot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weber:Dominik">Dominik Weber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
Notifications are a core feature of mobile phones. They inform users about a variety of events. Users may take immediate action or ignore them depending on the importance of a notification as well as their current context. The nature of notifications is manifold, applications use them both sparsely and frequently. In this paper we present the first large-scale analysis of mobile notifications with a focus on users' subjective perceptions. We derive a holistic picture of notifications on mobile phones by collecting close to 200 million notifications from more than 40,000 users. Using a data-driven approach, we break down what users like and dislike about notifications. Our results reveal differences in importance of notifications and how users value notifications from messaging apps as well as notifications that include information about people and events. Based on these results we derive a number of findings about the nature of notifications and guidelines to effectively use them.</p>
<p>Keywords:
apps; in the wild; large-scale; mobile hci; mobile phone; notification</p>
<h2 id="Decisions, recommendations, and machine learning    5">Decisions, recommendations, and machine learning    5</h2>
<h3 id="344. Customization bias in decision support systems.">344. Customization bias in decision support systems.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557211">Paper Link</a>    Pages:3065-3074</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Solomon:Jacob">Jacob Solomon</a></p>
<p>Abstract:
Many Decision Support Systems (DSS) afford customization of inputs or algorithms before generating recommendations to a decision maker. This paper describes an experiment in which users make decisions assisted by recommendations of a DSS in a fantasy baseball game. This experiment shows that the act of customizing a DSS can lead to biased decision making. I show that users who believe they have customized a DSS's recommendation algorithm are more likely to follow the recommendations regardless of their accuracy. I also show that this customization bias is the result of using a DSS to seek confirmatory information in a recommendation.</p>
<p>Keywords:
decision support systems; fantasy sports</p>
<h3 id="345. Structured labeling for facilitating concept evolution in machine learning.">345. Structured labeling for facilitating concept evolution in machine learning.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557238">Paper Link</a>    Pages:3075-3084</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kulesza:Todd">Todd Kulesza</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Amershi:Saleema">Saleema Amershi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Caruana:Rich">Rich Caruana</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fisher:Danyel">Danyel Fisher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Charles:Denis_Xavier">Denis Xavier Charles</a></p>
<p>Abstract:
Labeling data is a seemingly simple task required for training many machine learning systems, but is actually fraught with problems. This paper introduces the notion of concept evolution, the changing nature of a person's underlying concept (the abstract notion of the target class a person is labeling for, e.g., spam email, travel related web pages) which can result in inconsistent labels and thus be detrimental to machine learning. We introduce two structured labeling solutions, a novel technique we propose for helping people define and refine their concept in a consistent manner as they label. Through a series of five experiments, including a controlled lab study, we illustrate the impact and dynamics of concept evolution in practice and show that structured labeling helps people label more consistently in the presence of concept evolution than traditional labeling.</p>
<p>Keywords:
concept evolution; interactive machine learning</p>
<h3 id="346. Choice-based preference elicitation for collaborative filtering recommender systems.">346. Choice-based preference elicitation for collaborative filtering recommender systems.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557069">Paper Link</a>    Pages:3085-3094</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Loepp:Benedikt">Benedikt Loepp</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hussein:Tim">Tim Hussein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Ziegler_0001:J=uuml=rgen">Jrgen Ziegler</a></p>
<p>Abstract:
We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations. In a user study, we compare the system with three alternative approaches including manual search and automatic recommending. The results show significant advantages of our approach over the three competing alternatives in 15 out of 24 possible parameter comparisons, in particular with respect to item fit, interaction effort and user control. The findings corroborate our assumption that the proposed method achieves a good trade-off between automated and interactive functions in recommender systems.</p>
<p>Keywords:
interactive recommending; matrix factorization; recommender systems; user interfaces</p>
<h3 id="347. Finding dependencies between actions using the crowd.">347. Finding dependencies between actions using the crowd.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557176">Paper Link</a>    Pages:3095-3098</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lasecki:Walter_S=">Walter S. Lasecki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weingard:Leon">Leon Weingard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Ferguson:George">George Ferguson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bigham:Jeffrey_P=">Jeffrey P. Bigham</a></p>
<p>Abstract:
Activity recognition can provide computers with the context underlying user inputs, enabling more relevant responses and more fluid interaction. However, training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity. Prior work has enabled the crowd to provide labels in real-time to train automated systems on-the-fly, but numerous examples are still needed before the system can recognize an activity on its own. To reduce the need to collect this data by observing users, we introduce ARchitect, a system that uses the crowd to capture the dependency structure of the actions that make up activities. Our tests show that over seven times as many examples can be collected using our approach versus relying on direct observation alone, demonstrating that by leveraging the understanding of the crowd, it is possible to more easily train automated systems.</p>
<p>Keywords:
activity recognition; constraint finding; crowdsourcing</p>
<h3 id="348. Scalable multi-label annotation.">348. Scalable multi-label annotation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557011">Paper Link</a>    Pages:3099-3102</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Deng:Jia">Jia Deng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Russakovsky:Olga">Olga Russakovsky</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Krause:Jonathan">Jonathan Krause</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bernstein:Michael_S=">Michael S. Bernstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Berg:Alexander_C=">Alexander C. Berg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Fei=Fei">Fei-Fei Li</a></p>
<p>Abstract:
We study strategies for scalable multi-label annotation, or for efficiently acquiring multiple labels from humans for a collection of items. We propose an algorithm that exploits correlation, hierarchy, and sparsity of the label distribution. A case study of labeling 200 objects using 20,000 images demonstrates the effectiveness of our approach. The algorithm results in up to 6x reduction in human computation time compared to the naive method of querying a human annotator for the presence of every object in every image.</p>
<p>Keywords:
crowdsourcing; human computation</p>
<h2 id="Accessibility    4">Accessibility    4</h2>
<h3 id="349. Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users.">349. Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557237">Paper Link</a>    Pages:3103-3112</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Carrington:Patrick">Patrick Carrington</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hurst:Amy">Amy Hurst</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kane:Shaun_K=">Shaun K. Kane</a></p>
<p>Abstract:
Power wheelchair users often use and carry multiple mobile computing devices. Many power wheelchair users have some upper body motor impairment that can make using these devices difficult. We believe that mobile device accessibility could be improved through designs that take into account users' functional abilities and take advantage of available space around the wheelchair itself. In this paper we present findings from multiple design sessions and interviews with 13 power wheelchair users and 30 clinicians, exploring the placement and form factor possibilities for input and output on a power wheelchair. We found that many power wheelchair users could benefit from chairable technology that is designed to work within the workspace of the wheelchair, whether worn on the body or mounted on he wheelchair frame. We present participants' preferences for chairable input and output devices, and identify possible design configurations for wearable and chairable devices.</p>
<p>Keywords:
accessibility; input; mobile computing; natural user interface; output; participatory design; power wheelchair; wearable computers</p>
<h3 id="350. The last meter: blind visual guidance to a target.">350. The last meter: blind visual guidance to a target.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557328">Paper Link</a>    Pages:3113-3122</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Manduchi:Roberto">Roberto Manduchi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Coughlan:James_M=">James M. Coughlan</a></p>
<p>Abstract:
Smartphone apps can use object recognition software to provide information to blind or low vision users about objects in the visual environment. A crucial challenge for these users is aiming the camera properly to take a well-framed picture of the desired target object. We investigate the effects of two fundamental constraints of object recognition -- frame rate and camera field of view -- on a blind person's ability to use an object recognition smartphone app. The app was used by 18 blind participants to find visual targets beyond arm's reach and approach them to within 30 cm. While we expected that a faster frame rate or wider camera field of view should always improve search performance, our experimental results show that in many cases increasing the field of view does not help, and may even hurt, performance. These results have important implications for the design of object recognition systems for blind users.</p>
<p>Keywords:
assistive technology; blindness; camera-based access to information; wayfinding</p>
<h3 id="351. Current and future mobile and wearable device use by people with visual impairments.">351. Current and future mobile and wearable device use by people with visual impairments.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557085">Paper Link</a>    Pages:3123-3132</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Ye:Hanlu">Hanlu Ye</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Malu:Meethu">Meethu Malu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oh:Uran">Uran Oh</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Findlater:Leah">Leah Findlater</a></p>
<p>Abstract:
With the increasing popularity of mainstream wearable devices, it is critical to assess the accessibility implications of such technologies. For people with visual impairments, who do not always need the visual display of a mobile phone, alternative means of eyes-free wearable interaction are particularly appealing. To explore the potential impacts of such technology, we conducted two studies. The first was an online survey that included 114 participants with visual impairments and 101 sighted participants; we compare the two groups in terms of current device use. The second was an interview and design probe study with 10 participants with visual impairments. Our findings expand on past work to characterize a range of trends in smartphone use and accessibility issues therein. Participants with visual impairments also responded positively to two eyes-free wearable device scenarios: a wristband or ring and a glasses-based device. Discussions on projected use of these devices suggest that small, easily accessible, and discreet wearable input could positively impact the ability of people with visual impairments to access information on the go and to participate in certain social interactions.</p>
<p>Keywords:
accessibility; visual impairments; wearable computing</p>
<h3 id="352. Visually impaired users on an online social network.">352. Visually impaired users on an online social network.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557415">Paper Link</a>    Pages:3133-3142</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wu:Shaomei">Shaomei Wu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Adamic:Lada_A=">Lada A. Adamic</a></p>
<p>Abstract:
In this paper we present the first large-scale empirical study of how visually impaired people use online social networks, specifically Facebook. We identify a sample of 50K visually impaired users, and study the activities they perform, the content they produce, and the friendship networks they build on Facebook. We find that visually impaired users participate on Facebook (e.g. status updates, comments, likes) as much as the general population, and receive more feedback (i.e., comments and likes) on average on their content. By analyzing the content produced by visually impaired users, we find that they share their experience and issues related to vision impairment. We also identify distinctive patterns in their language and technology use. We also show that, compared to other users, visually impaired users have smaller social networks, but such differences have decreased over time. Our findings have implications for improving the utility and usability of online social networks for visually impaired users.</p>
<p>Keywords:
facebook; social media; social networking sites; vision disability; visually impaired users</p>
<h2 id="Tangible interactions and technologies    4">Tangible interactions and technologies    4</h2>
<h3 id="353. Kickables: tangibles for feet.">353. Kickables: tangibles for feet.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557016">Paper Link</a>    Pages:3143-3152</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt:Dominik">Dominik Schmidt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Ramakers:Raf">Raf Ramakers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pedersen:Esben_Warming">Esben Warming Pedersen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jasper:Johannes">Johannes Jasper</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/K=ouml=hler_0004:Sven">Sven Khler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pohl:Aileen">Aileen Pohl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rantzsch:Hannes">Hannes Rantzsch</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rau:Andreas">Andreas Rau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt:Patrick">Patrick Schmidt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sterz:Christoph">Christoph Sterz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yurchenko:Yanina">Yanina Yurchenko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baudisch:Patrick">Patrick Baudisch</a></p>
<p>Abstract:
We introduce the concept of tangibles that users can manipulate with their feet. We call them kickables. Unlike traditional tangibles, kickables allow for very large interaction surfaces as kickables reside on the ground. The main benefit of kickables over other foot-based modalities, such as foot touch, is their strong affordance, which we validate in two user studies. This affordance makes kickables well-suited for walk-up installations, such as tradeshows or museum exhibits. We present a custom design as well as five families of standard kickables to help application designers create kickable applications faster. Each family supports multiple standard controls, such as push buttons, switches, dials, and sliders. Each type explores a different design principle, in particular different mechanical constraints. We demonstrate an implementation on our pressure-sensing floor.</p>
<p>Keywords:
affordance.; foot-based interaction; interactive floor; tangibles</p>
<h3 id="354. GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays.">354. GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557105">Paper Link</a>    Pages:3153-3162</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Liang:Rong=Hao">Rong-Hao Liang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chan:Li=Wei">Li-Wei Chan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tseng:Hung=Yu">Hung-Yu Tseng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kuo:Han=Chih">Han-Chih Kuo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Da=Yuan">Da-Yuan Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:De=Nian">De-Nian Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Bing=Yu">Bing-Yu Chen</a></p>
<p>Abstract:
This work describes a novel building block system for tangible interaction design, GaussBricks, which enables real-time constructive tangible interactions on portable displays. Given its simplicity, the mechanical design of the magnetic building blocks facilitates the construction of configurable forms. The form constructed by the magnetic building blocks, which are connected by the magnetic joints, allows users to stably manipulate with various elastic force feedback mechanisms. With an analog Hall-sensor grid mounted to its back, a portable display determines the geometrical configuration and detects various user interactions in real time. This work also introduce several methods to enable shape changing, multi-touch input, and display capabilities in the construction. The proposed building block system enriches how individuals interact with the portable displays physically.</p>
<p>Keywords:
constructive assembly; magnetism; portable displays; tangible interactions</p>
<h3 id="355. Designing tangible video games: lessons learned from the sifteo cubes.">355. Designing tangible video games: lessons learned from the sifteo cubes.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556991">Paper Link</a>    Pages:3163-3166</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pillias:Cl=eacute=ment">Clment Pillias</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Robert=Bouchard:Rapha=euml=l">Raphal Robert-Bouchard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Levieux:Guillaume">Guillaume Levieux</a></p>
<p>Abstract:
In this paper, we present a collaborative game designed for Sifteo Cubes, a new tangible interface for multiplayer games. We discuss how this game exploits the platform's interface to transfer some of the game mechanics into the non-digital world, and how this approach affects both the player's experience and the design process. We present the technical limitations encountered during game development and analyze video recordings of play sessions with regard to the play strategies developed by the players. Then, we identify two properties that this game shares with many other games on tangible platforms and discuss how these properties influence both the game design process and the player experience. We advocate that these properties provide players with more freedom and relatedness, while helping to create an easy-to-learn and customizable gameplay, despite their own design limitations.</p>
<p>Keywords:
mixed-reality games; player strategies; sifteo cubes; tangible user interface; tangible video game; video game design</p>
<h3 id="356. A low-cost transparent electric field sensor for 3d interaction on mobile devices.">356. A low-cost transparent electric field sensor for 3d interaction on mobile devices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557331">Paper Link</a>    Pages:3167-3170</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Goc:Mathieu_Le">Mathieu Le Goc</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Stuart">Stuart Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Izadi:Shahram">Shahram Izadi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Keskin:Cem">Cem Keskin</a></p>
<p>Abstract:
We contribute a thin, transparent, and low-cost design for electric field sensing, allowing for 3D finger and hand tracking and gestures on mobile devices. Our approach requires no direct instrumentation of the hand or body, and is non-optical, allowing for a compact form-factor that is resilient to ambient illumination. Our simple driver electronics are based on an off-the-shelf chip that removes the need for building custom analog electronics. We describe the design of our transparent electrode array, and present a machine learning algorithm for mapping from signal measurements at the receivers to 3D positions. We demonstrate non-contact motion gestures, and precise 3D hand and finger localization. We conclude by discussing limitations and future work.</p>
<p>Keywords:
3d sensing; electric-field sensing; mobile; non-optical; nui</p>
<h2 id="Head-worn displays    4">Head-worn displays    4</h2>
<h3 id="357. The personal cockpit: a spatial interface for effective task switching on head-worn displays.">357. The personal cockpit: a spatial interface for effective task switching on head-worn displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557058">Paper Link</a>    Pages:3171-3180</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/e/Ens:Barrett_M=">Barrett M. Ens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Finnegan:Rory">Rory Finnegan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Irani:Pourang_P=">Pourang P. Irani</a></p>
<p>Abstract:
As wearable computing goes mainstream, we must improve the state of interface design to keep users productive with natural-feeling interactions. We present the Personal Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate empty space around the user to situate virtual windows for use with direct input. Through a design-space exploration, we run a series of user studies to fine-tune our layout of the Personal Cockpit. In our final evaluation, we compare our design against two baseline interfaces for switching between everyday mobile applications. This comparison highlights the deficiencies of current view-fixed displays, as the Personal Cockpit provides a 40% improvement in application switching time. We demonstrate of several useful implementations and a discussion of important problems for future implementation of our design on current and near-future wearable devices.</p>
<p>Keywords:
head-mounted display; head-worn display; multi-display environment; spatial input; spatial user interface; task switching; virtual window management</p>
<h3 id="358. Exploring the use of hand-to-face input for interacting with head-worn displays.">358. Exploring the use of hand-to-face input for interacting with head-worn displays.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556984">Paper Link</a>    Pages:3181-3190</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Serrano:Marcos">Marcos Serrano</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Ens:Barrett_M=">Barrett M. Ens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Irani:Pourang_P=">Pourang P. Irani</a></p>
<p>Abstract:
We propose the use of Hand-to-Face input, a method to interact with head-worn displays (HWDs) that involves contact with the face. We explore Hand-to-Face interaction to find suitable techniques for common mobile tasks. We evaluate this form of interaction with document navigation tasks and examine its social acceptability. In a first study, users identify the cheek and forehead as predominant areas for interaction and agree on gestures for tasks involving continuous input, such as document navigation. These results guide the design of several Hand-to-Face navigation techniques and reveal that gestures performed on the cheek are more efficient and less tiring than interactions directly on the HWD. Initial results on the social acceptability of Hand-to-Face input allow us to further refine our design choices, and reveal unforeseen results: some gestures are considered culturally inappropriate and gender plays a role in selection of specific Hand-to-Face interactions. From our overall results, we provide a set of guidelines for developing effective Hand-to-Face interaction techniques.</p>
<p>Keywords:
body interaction; head-worn display; hmd; hwd; input techniques; mobile interfaces</p>
<h3 id="359. Permulin: mixed-focus collaboration on multi-view tabletops.">359. Permulin: mixed-focus collaboration on multi-view tabletops.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557405">Paper Link</a>    Pages:3191-3200</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lissermann:Roman">Roman Lissermann</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huber:Jochen">Jochen Huber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmitz:Martin">Martin Schmitz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steimle:J=uuml=rgen">Jrgen Steimle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=hlh=auml=user:Max">Max Mhlhuser</a></p>
<p>Abstract:
We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.</p>
<p>Keywords:
collaborative coupling styles; mixed-focus collaboration; multi touch; multi-view; personal input; tabletop</p>
<h3 id="360. In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time.">360. In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557063">Paper Link</a>    Pages:3201-3204</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lauber:Felix">Felix Lauber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Butz:Andreas">Andreas Butz</a></p>
<p>Abstract:
One unique property of head-mounted displays (HMDs) is that content can easily be displayed at a fixed position within the user's field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulator, comparing different warning visualizations in a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better head-stabilized notifications.</p>
<p>Keywords:
driver safety; head-mounted displays; head-up displays</p>
<h2 id="Applications of body sensing    4">Applications of body sensing    4</h2>
<h3 id="361. Kinect-taped communication: using motion sensing to study gesture use and similarity in face-to-face and computer-mediated brainstorming.">361. Kinect-taped communication: using motion sensing to study gesture use and similarity in face-to-face and computer-mediated brainstorming.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557060">Paper Link</a>    Pages:3205-3214</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Hao=Chuan">Hao-Chuan Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lai:Chien=Tung">Chien-Tung Lai</a></p>
<p>Abstract:
One key difference between face-to-face (F2F) communication and computer-mediated communication (CMC) is the availability of visual cues. It is often assumed that the reduction of visibility in audio and video conferencing may negatively impact the use of gesture to communicate, and thus negatively influence other outcomes. In this paper we "Kinect-taped" F2F and CMC communication in brainstorming groups by using motion sensors to record and analyze group members' hand movements during communication. We investigate how different media influence gesture use and gestural similarity, and how the use of gesture associates with level of understanding and brainstorming performance. Implications to future research and design are discussed.</p>
<p>Keywords:
communication accommodation; computer-mediated communication; gesture; kinect; motion sensing; non-verbal communication</p>
<h3 id="362. Is motion capture-based biomechanical simulation valid for HCI studies?: study and implications.">362. Is motion capture-based biomechanical simulation valid for HCI studies?: study and implications.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557027">Paper Link</a>    Pages:3215-3224</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bachynskyi:Myroslav">Myroslav Bachynskyi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Palmas:Gregorio">Gregorio Palmas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weinkauf:Tino">Tino Weinkauf</a></p>
<p>Abstract:
Motion-capture-based biomechanical simulation is a non-invasive analysis method that yields a rich description of posture, joint, and muscle activity in human movement. The method is presently gaining ground in sports, medicine, and industrial ergonomics, but it also bears great potential for studies in HCI where the physical ergonomics of a design is important. To make the method more broadly accessible, we study its predictive validity for movements and users typical to studies in HCI. We discuss the sources of error in biomechanical simulation and present results from two validation studies conducted with a state-of-the-art system. Study I tested aimed movements ranging from multitouch gestures to dancing, finding out that the critical limiting factor is the size of movement. Study II compared muscle activation predictions to surface-EMG recordings in a 3D pointing task. The data shows medium-to-high validity that is, however, constrained by some characteristics of the movement and the user. We draw concrete recommendations to practitioners and discuss challenges to developing the method further.</p>
<p>Keywords:
biomechanical simulation; empirical methods; optical motion capture.; physical ergonomics; validity</p>
<h3 id="363. RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises.">363. RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557116">Paper Link</a>    Pages:3225-3234</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Dan">Dan Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Saponas:T=_Scott">T. Scott Saponas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guillory:Andrew">Andrew Guillory</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kelner:Ilya">Ilya Kelner</a></p>
<p>Abstract:
Although numerous devices exist to track and share exercise routines based on running and walking, these devices offer limited functionality for strength-training exercises. We introduce RecoFit, a system for automatically tracking repetitive exercises - such as weight training and calisthenics - via an arm-worn inertial sensor. Our goal is to provide real-time and post-workout feedback, with no user-specific training and no intervention during a workout. Toward this end, we address three challenges: (1) segmenting exercise from intermittent non-exercise periods, (2) recognizing which exercise is being performed, and (3) counting repetitions. We present cross-validation results on our training data and results from a study assessing the final system, totaling 114 participants over 146 sessions. We achieve precision and recall greater than 95% in identifying exercise periods, recognition of 99%, 98%, and 96% on circuits of 4, 7, and 13 exercises respectively, and counting that is accurate to 1 repetition 93% of the time. These results suggest that our approach enables a new category of fitness tracking devices.</p>
<p>Keywords:
fitness; inertial sensors; machine learning</p>
<h3 id="364. Improving automatic speech recognition through head pose driven visual grounding.">364. Improving automatic speech recognition through head pose driven visual grounding.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556957">Paper Link</a>    Pages:3235-3238</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vosoughi:Soroush">Soroush Vosoughi</a></p>
<p>Abstract:
In this paper, we present a multimodal speech recognition system for real world scene description tasks. Given a visual scene, the system dynamically biases its language model based on the content of the visual scene and visual attention of the speaker. Visual attention is used to focus on likely objects within the scene. Given a spoken description the system then uses the visually biased language model to process the speech. The system uses head pose as a proxy for the visual attention of the speaker. Readily available standard computer vision algorithms are used to recognize the objects in the scene and automatic real time head pose estimation is done using depth data captured via a Microsoft Kinect. The system was evaluated on multiple participants. Overall, incorporating visual information into the speech recognizer greatly improved speech recognition accuracy. The rapidly decreasing cost of 3D sensing technologies such as the Kinect allows systems with similar underlying principles to be used for many speech recognition tasks where there is visual information.</p>
<p>Keywords:
automatic speech recognition; head pose estimation; language models; visual attention; visual grounding</p>
<h2 id="Urban communities and social media    4">Urban communities and social media    4</h2>
<h3 id="365. Tensions in scaling-up community social media: a multi-neighborhood study of nextdoor.">365. Tensions in scaling-up community social media: a multi-neighborhood study of nextdoor.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557319">Paper Link</a>    Pages:3239-3248</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Masden:Christina_A=">Christina A. Masden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grevet:Catherine">Catherine Grevet</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grinter:Rebecca_E=">Rebecca E. Grinter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gilbert:Eric">Eric Gilbert</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Edwards:W=_Keith">W. Keith Edwards</a></p>
<p>Abstract:
This paper presents a study of Nextdoor, a social media system designed to support local neighborhoods. While not the first system designed to support community engagement, Nextdoor has a number of attributes that make it distinct. Our study, across three communities in a major U.S. city, illustrates that Nextdoor inhabits an already-rich ecosystem of community-oriented social media, but is being appropriated by its users for use in different ways than these existing media. Nextdoor also raises tensions in how it defines the boundaries of neighborhoods, and in the privacy issues it raises among its users.</p>
<p>Keywords:
civic engagement; local social media; nextdoor; social media</p>
<h3 id="366. Curated city: capturing individual city guides through social curation.">366. Curated city: capturing individual city guides through social curation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557401">Paper Link</a>    Pages:3249-3258</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cranshaw:Justin">Justin Cranshaw</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Luther:Kurt">Kurt Luther</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kelley:Patrick_Gage">Patrick Gage Kelley</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sadeh:Norman_M=">Norman M. Sadeh</a></p>
<p>Abstract:
We report on our design of Curated City, a website that lets people build their own personal guide to the city's neighborhoods by chronicling their favorite experiences. Although users make their own personal guides, they are immersed in a social curatorial experience where they are influenced directly and indirectly by the guides of others. We use a 2-week field trial involving 20 residents of Pittsburgh as a technological probe to explore the initial design decisions, and we further refine the design landscape through subject interviews. Based on this study, we identify a set of design recommendations for building scalable social platforms for curating the experiences of the city.</p>
<p>Keywords:
local search; location-based services; mental maps; neighborhoods; social computing; social curation; urban computing</p>
<h3 id="367. ZWERM: a modular component network approach for an urban participation game.">367. ZWERM: a modular component network approach for an urban participation game.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557053">Paper Link</a>    Pages:3259-3268</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Laureyssens:Thomas">Thomas Laureyssens</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Coenen:Tanguy">Tanguy Coenen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Claeys:Laurence">Laurence Claeys</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mechant:Peter">Peter Mechant</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Criel:Johan">Johan Criel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Moere:Andrew_Vande">Andrew Vande Moere</a></p>
<p>Abstract:
As information technology is increasingly embedded in our cities, opportunities arise to design novel applications that benefit urban communities. We describe the design and evaluation of ZWERM (Dutch for the term 'swarm'), a public game that was specifically designed for augmenting community participation in urban neighborhoods. A network of ten components has been designed, some of which had different interfaces and design approaches: from totem-like Trees for gathering around with RFID cards to playful Sparrows that react on whistle sounds. After implementing the urban game in two city neighborhoods, we investigated the impact of each of these components on their communities. Our insights are useful for the public interaction design of future urban, interactive networks that aim to positively influence community participation and social cohesion.</p>
<p>Keywords:
gamification; network; social cohesion; social engagement; social informatics; urban game; urban intervention</p>
<h3 id="368. Studying digital graffiti as a location-based social network.">368. Studying digital graffiti as a location-based social network.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557266">Paper Link</a>    Pages:3269-3278</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/McGookin:David_K=">David K. McGookin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Christov:Georgi">Georgi Christov</a></p>
<p>Abstract:
Increasing amounts of geo-tagged social media have led to interest in how that media can be re-integrated into the physical environment. Yet, although location information is often automatically appended to media, little is know about how users consider location in its creation and viewing. Using Graffiti as a design meme, we developed a novel social media service to investigate these issues. A two week field study showed how users incorporated both utilitarian and playful aspects of location into their social media creation, as well as revealing a disconnect between the location-media relationship intended by creators and perceived by viewers. We outline implications of our work for services that seek to repurpose existing geo-tagged social media in the design of novel services.</p>
<p>Keywords:
digigraff; geo-social media; graffiti; pico projection</p>
<h2 id="Social media usage    4">Social media usage    4</h2>
<h3 id="369. Social epistemic cognition in online interactions.">369. Social epistemic cognition in online interactions.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556977">Paper Link</a>    Pages:3289-3298</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Chan:Rosanna_Yuen=Yan">Rosanna Yuen-Yan Chan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Silu">Silu Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hui:Diane">Diane Hui</a></p>
<p>Abstract:
Social media and online social networks dramatically change the way in which knowledge is acquired and disseminated. How do we re-understand about human knowledge and knowing? This work aims at extending the current understanding of human epistemic cognition in online social environments, where epistemic cognition refers to cognitions and cognitive processes related to epistemic matters such as knowledge and beliefs justification. We approach our inquiry with mixed methods: (1) quantitative study to test whether epistemic cognition might differ in individual and social contexts, and whether online interactions might mediate the later; and (2) social cognitive task analysis with interviews to manifest the intricate interplay of dynamics between social epistemic cognition and online interactions. We introduce the new construct of social epistemic cognition and contribute to the field of HCI with an evolved theory which states that epistemic cognition can be promoted in online social environments as mediated by online interactions.</p>
<p>Keywords:
cognitive task analysis; cscl; epistemic cognition; learning sciences.; online interactions; social epistemology</p>
<h3 id="370. Share your view: impact of co-navigation support and status composition in collaborative online shopping.">370. Share your view: impact of co-navigation support and status composition in collaborative online shopping.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557143">Paper Link</a>    Pages:3299-3308</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/y/Yue:Yanzhen">Yanzhen Yue</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Ma:Xiaojuan">Xiaojuan Ma</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jiang:Zhenhui">Zhenhui Jiang</a></p>
<p>Abstract:
Collaborative online shopping, an emerging paradigm in e-commerce, allows remote shoppers to extend purchase-oriented social interactions into the digital environment. Online vendors have been experimenting ways to facilitate this activity. However, more research needs to be done on identifying what feature can create a pleasing shopping experience and ultimately encourage spending. In this paper, we present an exploration of the impact of co-navigation supports, including location cue, split screen, and shared view, on the experiences and performance of 60 co-shopper dyads. We also studied if status composition of shopping companions played a role in this process. By analyzing about 1800 minutes of eye-tracking data, video footages, and web logs, we found that split screen encouraged more diverse product search, shared view enabled better coordination, and location cue was the least distracting. Co-buyers achieved better factual and inference understanding, though buyer-advisor dyads were more likely to stay together.</p>
<p>Keywords:
buyer-advisor; co-buyers; co-navigation; collaborative online shopping; eye-tracking; location cue; shared view; split screen; status composition</p>
<h3 id="371. Nutriflect: reflecting collective shopping behavior and nutrition.">371. Nutriflect: reflecting collective shopping behavior and nutrition.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557384">Paper Link</a>    Pages:3309-3318</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Reitberger:Wolfgang">Wolfgang Reitberger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Spreicer:Wolfgang">Wolfgang Spreicer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzpatrick:Geraldine">Geraldine Fitzpatrick</a></p>
<p>Abstract:
A poor nutritional state, as is the case for many people today, can increase risks for cancer, cardiovascular disease and obesity. Technology supported approaches could potentially be used to positively influence food consumption. We present the Nutriflect system, which utilizes users' shopping data to inform them about their long term shopping behavior. In an initial study we conducted structured interviews in grocery stores. Based on the results we implemented a system that visualized a household's collective shopping information via situated displays. The aim was to raise awareness about shopping habits and to enable reflection about nutrition without burdening the users with the manual entry of their eating habits. We evaluated the system in a 4 week field study in 8 households with 21 users. The results indicate that contextually situated displays, showing shopping patterns against personal nutrition goals, can foster a reflective and respectful approach towards better shopping and nutrition.</p>
<p>Keywords:
awareness; behavior change; field study; nutrition; reflection; shopping; situated displays</p>
<h3 id="372. Didn't you see my message?: predicting attentiveness to mobile instant messages.">372. Didn't you see my message?: predicting attentiveness to mobile instant messages.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556973">Paper Link</a>    Pages:3319-3328</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pielot:Martin">Martin Pielot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oliveira:Rodrigo_de">Rodrigo de Oliveira</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kwak:Haewoon">Haewoon Kwak</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oliver:Nuria">Nuria Oliver</a></p>
<p>Abstract:
Mobile instant messaging (e.g., via SMS or WhatsApp) often goes along with an expectation of high attentiveness, i.e., that the receiver will notice and read the message within a few minutes. Hence, existing instant messaging services for mobile phones share indicators of availability, such as the last time the user has been online. However, in this paper we not only provide evidence that these cues create social pressure, but that they are also weak predictors of attentiveness. As remedy, we propose to share a machine-computed prediction of whether the user will view a message within the next few minutes or not. For two weeks, we collected behavioral data from 24 users of mobile instant messaging services. By the means of machine-learning techniques, we identified that simple features extracted from the phone, such as the user's interaction with the notification center, the screen activity, the proximity sensor, and the ringer mode, are strong predictors of how quickly the user will attend to the messages. With seven automatically selected features our model predicts whether a phone user will view a message within a few minutes with 70.6% accuracy and a precision for fast attendance of 81.2%</p>
<p>Keywords:
asynchronous communication; attentiveness; availability; messaging; mobile devices; prediction</p>
<h2 id="Games and education    4">Games and education    4</h2>
<h3 id="373. Using extracted features to inform alignment-driven design ideas in an educational game.">373. Using extracted features to inform alignment-driven design ideas in an educational game.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557393">Paper Link</a>    Pages:3329-3338</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Harpstead:Erik">Erik Harpstead</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/MacLellan:Christopher_J=">Christopher J. MacLellan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Aleven:Vincent">Vincent Aleven</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Myers:Brad_A=">Brad A. Myers</a></p>
<p>Abstract:
As educational games have become a larger field of study, there has been a growing need for analytic methods that can be used to assess game design and inform iteration. While much previous work has focused on the measurement of student engagement or learning at a gross level, we argue that new methods are necessary for measuring the alignment of a game to its target learning goals at an appropriate level of detail to inform design decisions. We present a novel technique that we have employed to examine alignment in an open-ended educational game. The approach is based on examining how the game reacts to representative student solutions that do and do not obey target principles. We demonstrate this method using real student data and discuss how redesign might be informed by these techniques.</p>
<p>Keywords:
alignment; analytics; educational games; game user research</p>
<h3 id="374. Brain points: a growth mindset incentive structure boosts persistence in an educational game.">374. Brain points: a growth mindset incentive structure boosts persistence in an educational game.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557157">Paper Link</a>    Pages:3339-3348</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/O=Rourke:Eleanor">Eleanor O'Rourke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haimovitz:Kyla">Kyla Haimovitz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Ballweber:Christy">Christy Ballweber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dweck:Carol_S=">Carol S. Dweck</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Popovic:Zoran">Zoran Popovic</a></p>
<p>Abstract:
There is great interest in leveraging video games to improve student engagement and motivation. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children's learning-related behavior. In this work, we argue that educational games can be improved by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present "brain points," a system that encourages the development of growth mindset behaviors by directly incentivizing effort, use of strategy, and incremental progress. Through a study of 15,000 children, we show that the "brain points" system encourages more low-performing students to persist in the educational game Refraction when compared to a control, and increases overall time played, strategy use, and perseverance after challenge. We believe that this growth mindset incentive structure has great potential in many educational environments.</p>
<p>Keywords:
educational games; growth mindset; incentive structures</p>
<h3 id="375. Towards automatic experimentation of educational knowledge.">375. Towards automatic experimentation of educational knowledge.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557392">Paper Link</a>    Pages:3349-3358</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Yun=En">Yun-En Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandel:Travis">Travis Mandel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brunskill:Emma">Emma Brunskill</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Popovic:Zoran">Zoran Popovic</a></p>
<p>Abstract:
We present a general automatic experimentation and hypothesis generation framework that utilizes a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. We briefly discuss our results in the context of the wider educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.</p>
<p>Keywords:
datamining; education; games</p>
<h3 id="376. Spending real money: purchasing patterns of virtual goods in an online social game.">376. Spending real money: purchasing patterns of virtual goods in an online social game.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557074">Paper Link</a>    Pages:3359-3368</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wohn:Donghee_Yvette">Donghee Yvette Wohn</a></p>
<p>Abstract:
Researchers have found that 'social' factors contribute to purchasing intentions of virtual goods in an online social game, but little is known about actual purchasing behavior. Study 1 examined the relationship between social factors and virtual goods purchasing patterns using large scale data obtained by server logs of an online social game. Exchange of virtual goods and number of friends increased the likelihood of spending real money compared to no spending. Among those who did spend real money, giving virtual goods to others was the strongest factor associated with the amount of spending. Study 2 examined purchasing patterns of players who spent real money: high real-money spenders were buying items for visual customization while low spenders were buying consumable items necessary to sustain playing the game.</p>
<p>Keywords:
big data; consumer behavior; customization; e-commerce; social exchange; social game; virtual goods</p>
<h2 id="Learning and games    4">Learning and games    4</h2>
<h3 id="377. CADament: a gamified multiplayer software tutorial system.">377. CADament: a gamified multiplayer software tutorial system.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556954">Paper Link</a>    Pages:3369-3378</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Li_0002:Wei">Wei Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
We present CADament, a gamified multiplayer tutorial system for learning AutoCAD. Compared with existing gamified software tutorial systems, CADament generates engaging learning experience through competitions. We investigate two variations of our game, where over-the-shoulder learning was simulated by providing viewports into other player's screens. We introduce an empirical lab study methodology where participants compete with one another, and we study knowledge transfer effects by tracking the migration of strategies between players during the study session. Our study shows that CADament has an advantage over pre-authored tutorials for improving learners' performance, increasing motivation, and stimulating knowledge transfer.</p>
<p>Keywords:
game; learning; multiplayer; tutorial</p>
<h3 id="378. Combining crowdsourcing and learning to improve engagement and performance.">378. Combining crowdsourcing and learning to improve engagement and performance.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557217">Paper Link</a>    Pages:3379-3388</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dontcheva:Mira">Mira Dontcheva</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morris:Robert_R=">Robert R. Morris</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brandt:Joel_R=">Joel R. Brandt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gerber:Elizabeth_M=">Elizabeth M. Gerber</a></p>
<p>Abstract:
Crowdsourcing complex creative tasks remains difficult, in part because these tasks require skilled workers. Most crowdsourcing platforms do not help workers acquire the skills necessary to accomplish complex creative tasks. In this paper, we describe a platform that combines learning and crowdsourcing to benefit both the workers and the requesters. Workers gain new skills through interactive step-by-step tutorials and test their knowledge by improving real-world images submitted by requesters. In a series of three deployments spanning two years, we varied the design of our platform to enhance the learning experience and improve the quality of the crowd work. We tested our approach in the context of LevelUp for Photoshop, which teaches people how to do basic photograph improvement tasks using Adobe Photoshop. We found that by using our system workers gained new skills and produced high-quality edits for requested images, even if they had little prior experience editing images.</p>
<p>Keywords:
crowdsourcing; games; training</p>
<h3 id="379. A game-based learning approach to road safety: the code of everand.">379. A game-based learning approach to road safety: the code of everand.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557281">Paper Link</a>    Pages:3389-3398</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dunwell:Ian">Ian Dunwell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Freitas:Sara_de">Sara de Freitas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Petridis:Panagiotis">Panagiotis Petridis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hendrix:Maurice">Maurice Hendrix</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Arnab:Sylvester">Sylvester Arnab</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lameras:Petros">Petros Lameras</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stewart:Craig_D=">Craig D. Stewart</a></p>
<p>Abstract:
Game and gamification elements are increasingly seeing use as part of interface designs for applications seeking to engage and retain users whilst transferring information. This paper presents an evaluation of a game-based approach seeking to improve the road safety behaviour amongst children aged 9-15 within the UK, made available outside of a classroom context as an online, browser-based, free-to-play game. The paper reports on data for 99,683 players over 315,882 discrete logins, supplemented by results from a nationally-representative survey of children at UK schools (n=1,108), an incentivized survey of the player-base (n=1,028), and qualitative data obtained through a series of one-to-one interviews aged 9-14 (n=28). Analysis demonstrates the reach of the game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female ratio was observed amongst players surveyed, with an age distribution across the target range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it is suggested such an approach to user engagement and retention can surpass typical contact times obtained through other forms of web-based content. The size of the player-base attracted to the game and players' qualitative feedback demonstrates the potential for serious games deployed on a national scale.</p>
<p>Keywords:
attitudinal change; e-learning; game-based interfaces; gamification; road safety; serious games</p>
<h3 id="380. L.IVE: an integrated interactive video-based learning environment.">380. L.IVE: an integrated interactive video-based learning environment.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557368">Paper Link</a>    Pages:3399-3402</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Monserrat:Toni=Jan_Keith_Palma">Toni-Jan Keith Palma Monserrat</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Li:Yawen">Yawen Li</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Shengdong">Shengdong Zhao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cao:Xiang">Xiang Cao</a></p>
<p>Abstract:
In this paper, we introduce L.IVE: an online interactive video-based learning environment with an alternative design and architecture that integrates three major interface components: video, comment threads, and assessments. This is in contrast with the approach of existing interfaces which visually separate these components. Our study, which compares L.IVE with existing popular video-based learning environments, suggests advantages in this integrated approach as compared to the separated approach in learning.</p>
<p>Keywords:
interactive video; l.ive; video-based online learning</p>
<h2 id="Persuasive technologies and applications    4">Persuasive technologies and applications    4</h2>
<h3 id="381. Persuasive technology for overcoming food cravings and improving snack choices.">381. Persuasive technology for overcoming food cravings and improving snack choices.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557099">Paper Link</a>    Pages:3403-3412</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hsu:Anne">Anne Hsu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Jing">Jing Yang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yilmaz:Yigit_Han">Yigit Han Yilmaz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haque:Md_Sanaul">Md Sanaul Haque</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Can:Cengiz">Cengiz Can</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blandford:Ann_E=">Ann E. Blandford</a></p>
<p>Abstract:
A central challenge in weight management is the difficulty of overcoming desires for excessive and unhealthy food. Yet, studies show that when people are able to resist their desires for unhealthy choices, they experience pride and satisfaction. In order to alleviate the former and support the latter, we designed, implemented and tested a mobile application for improving snacking behavior. Our application delivers a food craving reduction intervention at the moment of need and allows users to track how often they successfully resisted cravings. Our craving reduction intervention is based on recent research that shows that food cravings can be reduced through imagery techniques. We conducted a week-long evaluation of our application, comparing the effectiveness of our application to a basic tracking application. We found that our imagery application significantly reduced both overall snacking and unhealthy snacking compared to a simple snack-tracking application.</p>
<p>Keywords:
behavior change; mobile; persuasive technologies; user-centered design; weight management; wellness</p>
<h3 id="382. The effects of embodied persuasive games on player attitudes toward people using wheelchairs.">382. The effects of embodied persuasive games on player attitudes toward people using wheelchairs.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556962">Paper Link</a>    Pages:3413-3422</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Gerling:Kathrin_Maria">Kathrin Maria Gerling</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mandryk:Regan_L=">Regan L. Mandryk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Birk:Max_Valentin">Max Valentin Birk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Matthew_K=">Matthew K. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Orji:Rita">Rita Orji</a></p>
<p>Abstract:
People using wheelchairs face barriers in their daily lives, many of which are created by people who surround them. Promoting positive attitudes towards persons with disabilities is an integral step in removing these barriers and improving their quality of life. In this context, persuasive games offer an opportunity of encouraging attitude change. We created a wheelchair-controlled persuasive game to study how embodied interaction can be applied to influence player attitudes over time. Our results show that the game intervention successfully raised awareness for challenges that people using wheelchairs face, and that embodied interaction is a more effective approach than traditional input in terms of retaining attitude change over time. Based on these findings, we provide design strategies for embodied interaction in persuasive games, and outline how our findings can be leveraged to help designers create effective persuasive experiences beyond games.</p>
<p>Keywords:
attitude change; disability; embodied interaction; persuasive games</p>
<h3 id="383. Spent: changing students' affective learning toward homelessness through persuasive video game play.">383. Spent: changing students' affective learning toward homelessness through persuasive video game play.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557390">Paper Link</a>    Pages:3423-3432</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ruggiero:Dana_N=">Dana N. Ruggiero</a></p>
<p>Abstract:
To investigate whether a persuasive game may serve as a way to increase affective learning about homelessness, this study examined the effects of procedural rhetoric and ethos in a video game designed to put the player in the shoes of an almost-homeless person. Data were collected from 5139 students across four states. Examination revealed that playing the game or doing the reading significantly increased the affective learning score after treatment with the game group scoring 1.57 points higher and the reading group scoring .66 points higher out of a score of 6. Findings indicate that students who played Spent sustained significantly higher scores after three weeks. Overall, findings suggest that when students play a video game that is designed using persuasive mechanics an affective change can be measured empirically.</p>
<p>Keywords:
affective learning; persuasive mechanics; video games</p>
<h3 id="384. Incentives to participate in online research: an experimental examination of "surprise" incentives.">384. Incentives to participate in online research: an experimental examination of "surprise" incentives.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557418">Paper Link</a>    Pages:3433-3442</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fiore:Andrew_T=">Andrew T. Fiore</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cheshire:Coye">Coye Cheshire</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taylor:Lindsay_Shaw">Lindsay Shaw Taylor</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mendelsohn:G=_A=">G. A. Mendelsohn</a></p>
<p>Abstract:
The recruitment of participants for online survey research presents many challenges. In this work, we present four experiments examining how two different kinds of "surprise" financial incentives affect the rate of participation in a longitudinal study when participants are initially solicited with either an appeal to intrinsic motivation to participate in research or one that also offers extrinsic financial incentives. We find that unexpected financial incentives ("existence surprises") presented to people who click a recruitment advertisement focused on intrinsic incentives lead to a lower recruitment rate than do the same incentives offered to those who clicked an advertisement that led them to expect it. However, when potential participants expect a financial incentive, surprising them with a higher amount ("amount surprises") yields a higher recruitment rate. We interpret these results in the context of crowding theory. Neither type of surprise affected ongoing participation, measured as the number of questions and questionnaires completed over the course of the study.</p>
<p>Keywords:
incentives; motivation; online research recruitment</p>
<h2 id="Whole body sensing and interaction    4">Whole body sensing and interaction    4</h2>
<h3 id="385. Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces.">385. Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556989">Paper Link</a>    Pages:3443-3452</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Schwarz:Julia">Julia Schwarz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marais:Charles_Claudius">Charles Claudius Marais</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Leyvand:Tommer">Tommer Leyvand</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hudson:Scott_E=">Scott E. Hudson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mankoff:Jennifer">Jennifer Mankoff</a></p>
<p>Abstract:
Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer from the Midas Touch problem: every user motion can be interpreted as an interaction. In response, we developed an algorithm that combines facial features, body pose and motion to approximate a user's intention to interact with the system. We show how this can be used to determine when to pay attention to a user's actions and when to ignore them. To demonstrate the value of our approach, we present results from a 30-person lab study conducted to compare four engagement algorithms in single and multi-user scenarios. We found that combining intention to interact with a 'raise an open hand in front of you' gesture yielded the best results. The latter approach offers a 12% improvement in accuracy and a 20% reduction in time to engage over a baseline 'wave to engage' gesture currently used on the Xbox 360.</p>
<p>Keywords:
free-space interaction; input segmentation; learned models; user engagement; vision-based input</p>
<h3 id="386. Wave to me: user identification using body lengths and natural gestures.">386. Wave to me: user identification using body lengths and natural gestures.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557043">Paper Link</a>    Pages:3453-3462</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hayashi:Eiji">Eiji Hayashi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Maas:Manuel">Manuel Maas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jason_I=">Jason I. Hong</a></p>
<p>Abstract:
We introduce a body-based identification system that leverages individual differences in body segment lengths and hand waving gesture patterns. The system identifies users based on a two-second hand waving gesture captured by a Microsoft Kinect. To evaluate our system, we collected 8640 gesture measurements from 75 participants through two lab studies and a field study. In the first lab study, we evaluated the feasibility of our concept and basic properties of features to narrow down the design space. In the second lab study, our system achieved a 1% equal error rate in user identification among seven registered users after two weeks following initial registration. We also found that our system was robust even when lower body segments could not be measured because of occlusions. In the field study, our system achieved 0.5 to 1.6% equal error rates, demonstrating that the system also works well in ecologically valid situations. Lastly, throughout the studies, our participants were positive about the system.</p>
<p>Keywords:
gesture; natural user interface; user identification</p>
<h3 id="387. Haptic turk: a motion platform based on people.">387. Haptic turk: a motion platform based on people.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557101">Paper Link</a>    Pages:3463-3472</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Cheng:Lung=Pan">Lung-Pan Cheng</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/L=uuml=hne:Patrick">Patrick Lhne</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lopes:Pedro">Pedro Lopes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sterz:Christoph">Christoph Sterz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baudisch:Patrick">Patrick Baudisch</a></p>
<p>Abstract:
Motion platforms are used to increase the realism of virtual interaction. Unfortunately, their size and weight is proportional to the size of what they actuate. We present haptic turk, a different approach to motion platforms that is light and mobile. The key idea is to replace motors and mechanical components with humans. All haptic turk setups consist of a player who is supported by one or more turkers. The player enjoys an interactive experience, such as a flight simulation. The motion in the player's experience is generated by the turkers who manually lift, tilt, and push the player's limbs or torso. To get the timing and force right, timed motion instructions in a format familiar from rhythm games are displayed on turkers' mobile devices, which they attach to the player's body. We demonstrate a range of installations based on mobile phones, projectors, and head-mounted displays. In our user study, participants rated not only the experience as player as enjoyable (6.1/7), but also the experience as a turker (4.4/7). The approach of leveraging humans allows us to deploy our approach anytime anywhere, as we demonstrate by experimentally deploying at an art festival in the Nevada desert.</p>
<p>Keywords:
force-feedback; haptics; immersion; motion platform</p>
<h3 id="388. Audience experience in social videogaming: effects of turn expectation and game physicality.">388. Audience experience in social videogaming: effects of turn expectation and game physicality.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556965">Paper Link</a>    Pages:3473-3482</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Downs:John">John Downs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vetere:Frank">Frank Vetere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Howard:Steve">Steve Howard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Loughnan:Steve">Steve Loughnan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Smith:Wally">Wally Smith</a></p>
<p>Abstract:
Videogames are often played socially with both co-players and audiences. Audience members' experiences are not well understood, nor are the factors of videogaming sessions that influence their experience. We conducted a study to examine the effects of game physicality and turn anticipation on audience members' experiences in social videogaming sessions. Pairs of participants played games under three conditions of physicality (controller-based, Wii, and Kinect) and their expectation of turn-taking was manipulated. Their enjoyment, game engagement, social engagement and sense of participation were measured. We found that the introduction of turn-taking into the session had positive effects for audience members -- both anticipated and residual play effects -- and that Kinect gameplay resulted in a more enjoyable experience for audience members. We argue that audience members' experience changes as they become more active within a session, and suggest there are design opportunities between purely active 'players' and passive 'audience members'.</p>
<p>Keywords:
audience experience; physical videogames; social gaming; turn-taking</p>
<h2 id="Novel mobile displays and devices    4">Novel mobile displays and devices    4</h2>
<h3 id="389. Exploiting thermal reflection for interactive systems.">389. Exploiting thermal reflection for interactive systems.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557208">Paper Link</a>    Pages:3483-3492</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Shirazi:Alireza_Sahami">Alireza Sahami Shirazi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Abdelrahman:Yomna">Yomna Abdelrahman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Henze:Niels">Niels Henze</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schneegass:Stefan">Stefan Schneegass</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Khalilbeigi:Mohammadreza">Mohammadreza Khalilbeigi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmidt_0001:Albrecht">Albrecht Schmidt</a></p>
<p>Abstract:
Thermal cameras have recently drawn the attention of HCI researchers as a new sensory system enabling novel interactive systems. They are robust to illumination changes and make it easy to separate human bodies from the image background. Far-infrared radiation, however, has another characteristic that distinguishes thermal cameras from their RGB or depth counterparts, namely thermal reflection. Common surfaces reflect thermal radiation differently than visual light and can be perfect thermal mirrors. In this paper, we show that through thermal reflection, thermal cameras can sense the space beyond their direct field-of-view. A thermal camera can sense areas besides and even behind its field-of-view through thermal reflection. We investigate how thermal reflection can increase the interaction space of projected surfaces using camera-projection systems. We moreover discuss the reflection characteristics of common surfaces in our vicinity in both the visual and thermal radiation bands. Using a proof-of-concept prototype, we demonstrate the increased interaction space for hand-held camera-projection system. Furthermore, we depict a number of promising application examples that can benefit from the thermal reflection characteristics of surfaces.</p>
<p>Keywords:
camera-projector system; heat; reflection; roughness; thermal imaging</p>
<h3 id="390. MisTable: reach-through personal screens for tabletops.">390. MisTable: reach-through personal screens for tabletops.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557325">Paper Link</a>    Pages:3493-3502</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Plasencia:Diego_Martinez">Diego Martinez Plasencia</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Joyce:Edward">Edward Joyce</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a></p>
<p>Abstract:
We present MisTable, a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface. These personal screens, built using fog, are both see-through and reach-through. Being see-through provides direct line of sight of the personal screen and the elements behind it on the tabletop. Being reach-through allows the user to switch from interacting with the personal screen to reaching through it to interact with the tabletop or the space above it. The personal screen allows a range of customisations and novel interactions such as presenting 2D personal contents on the screen, 3D contents above the tabletop or augmenting and relighting tangible objects differently for each user. Besides, having a personal screen for each user allows us to customize the view of each of them according to their identity or preferences. Finally, the personal screens preserve all well-established tabletop interaction techniques like touch and tangible interactions. We explore the challenges in building such a reach-through system through a proof-of-concept implementation and discuss the possibilities afforded by the system.</p>
<p>Keywords:
fog screens.; reach-through displays; see-through displays; tabletops systems</p>
<h3 id="391. What is a device bend gesture really good for?">391. What is a device bend gesture really good for?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557306">Paper Link</a>    Pages:3503-3512</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Ahmaniemi:Teemu_Tuomas">Teemu Tuomas Ahmaniemi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kildal:Johan">Johan Kildal</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haveri:Merja">Merja Haveri</a></p>
<p>Abstract:
Device deformation allows new types of gestures to be used in interaction. We identify that the gesture/use-case pairings proposed by interaction designers are often driven by factors relating improved tangibility, spatial directionality and strong metaphorical bonds. With this starting point, we argue that some of the designs may not make use of the full potential of deformation gestures as continuous, bipolar input techniques. In two user studies, we revisited the basics of deformation input by taking a new systematic look at the question of matching gestures with use cases. We observed comparable levels of UX when using bend input in different continuous bipolar interactions, irrespective of the choice of tangibility, directionality and metaphor. We concluded that device bend gestures use their full potential when used to control continuous bipolar parameters, and when quick reactions are needed. From our studies, we also identify relative strengths of absolute and relative mappings, and report a Fitts' law study for device bending input.</p>
<p>Keywords:
absolute mapping; bend input; device deformation; fitts' law; organic ui; relative mapping</p>
<h3 id="392. SurfacePhone: a mobile projection device for single- and multiuser everywhere tabletop interaction.">392. SurfacePhone: a mobile projection device for single- and multiuser everywhere tabletop interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557075">Paper Link</a>    Pages:3513-3522</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Winkler:Christian">Christian Winkler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/L=ouml=chtefeld:Markus">Markus Lchtefeld</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dobbelstein:David">David Dobbelstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kr=uuml=ger:Antonio">Antonio Krger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rukzio:Enrico">Enrico Rukzio</a></p>
<p>Abstract:
To maintain a mobile form factor, the screen real estate of a mobile device canIn this paper we present SurfacePhone; a novel configuration of a projector phone which aligns the projector to project onto a physical surface to allow tabletop-like interaction in a mobile setup. The projection is created behind the upright standing phone and is touch and gesture-enabled. Multiple projections can be merged to create shared spaces for multi-user collaboration. We investigate this new setup, starting with the concept that we evaluated with a concept prototype. Furthermore we present our technical prototype, a mobile phone case with integrated projector that allows for the aforementioned interaction. We discuss its technical requirements and evaluate the accuracy of interaction in a second user study. We conclude with lessons learned and design guidelines.</p>
<p>Keywords:
interactive surfaces; mobile multi display environment; projector phone</p>
<h2 id="HCI paradigms: past, present and future    4">HCI paradigms: past, present and future    4</h2>
<h3 id="393. Is once enough?: on the extent and content of replications in human-computer interaction.">393. Is once enough?: on the extent and content of replications in human-computer interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557004">Paper Link</a>    Pages:3523-3532</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hornb=aelig=k:Kasper">Kasper Hornbk</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sander:S=oslash=ren_S=">Sren S. Sander</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bargas=Avila:Javier_Andr=eacute=s">Javier Andrs Bargas-Avila</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Simonsen:Jakob_Grue">Jakob Grue Simonsen</a></p>
<p>Abstract:
A replication is an attempt to confirm an earlier study's findings. It is often claimed that research in Human-Computer Interaction (HCI) contains too few replications. To investigate this claim we examined four publication outlets (891 papers) and found 3% attempting replication of an earlier result. The replications typically confirmed earlier findings, but treated replication as a confirm/not-confirm decision, rarely analyzing effect sizes or comparing in depth to the replicated paper. When asked, most authors agreed that their studies were replications, but rarely planned them as such. Many non-replication studies could have corroborated earlier work if they had analyzed data differently or used minimal effort to collect extra data. We discuss what these results mean to HCI, including how reporting of studies could be improved and how conferences/journals may change author instructions to get more replications.</p>
<p>Keywords:
replications</p>
<h3 id="394. Binding the material and the discursive with a relational approach of affordances.">394. Binding the material and the discursive with a relational approach of affordances.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557185">Paper Link</a>    Pages:3533-3542</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sun:Huatong">Huatong Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hart=Davidson:William">William Hart-Davidson</a></p>
<p>Abstract:
As Norman's vision of affordances developed twenty-six years ago is unable to address complex challenges faced by today's designers, we outline a view of affordances as discursive relations in HCI design. This argument is framed in the discussion of a larger trend of work beyond the HCI field, the scholarship on relational affordances from the fields of communication and organization studies. Through comparison and interrogation, we maintain a relational approach of affordances that bind the material and the discursive will help us to address design issues such as discursive power, cultural values, performed identities, mediated agency, and articulated voices in this increasingly globalized world and design culturally sensitive technology for transformation and emancipation. With a few cases, this paper deciphers the hidden power relationship of interaction design and suggests ways of we should design for social affordances.</p>
<p>Keywords:
affordance; critical design; cross-cultural design; culture; discursive; hci; hci4d; identity; ideology; materiality</p>
<h3 id="395. The turn to practice in HCI: towards a research agenda.">395. The turn to practice in HCI: towards a research agenda.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557111">Paper Link</a>    Pages:3543-3552</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kuutti:Kari">Kari Kuutti</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bannon:Liam_J=">Liam J. Bannon</a></p>
<p>Abstract:
This paper argues that a new paradigm for HCI research, which we label the 'practice' perspective, has been emerging in recent years. This stands in contrast to the prevailing mainstream HCI paradigm, which we term the 'interaction' perspective. The 'practice turn', as it has been dubbed in the social sciences, provides a conceptual frame to organize a variety of issues emerging in more recent HCI research. While this approach has been present in certain strands of HCI research for some time, it has not been articulated fully to date. In this paper, we provide a short account of the main tenets of this perspective, and then show how it can illuminate some of the recent debates within HCI. Our argument is one which does not seek to replace extant HCI theories, but rather to provide an alternative, complementary theoretical lens which may illuminate the present confusion among both researchers and practitioners as to the direction of HCI. The paper articulates a set of issues which can help direct HCI research programs, as well as highlighting the potential contribution of the HCI field to this practice approach itself, in terms of a more nuanced understanding of emerging practices.</p>
<p>Keywords:
methodology; practice; research; theory</p>
<h3 id="396. CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis.">396. CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556969">Paper Link</a>    Pages:3553-3562</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Yong">Yong Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gon=ccedil=alves:Jorge">Jorge Gonalves</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Ferreira:Denzil">Denzil Ferreira</a> ; <a href="http://dblp.uni-trier.de/pers/hd/x/Xiao:Bei">Bei Xiao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hosio:Simo">Simo Hosio</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kostakos:Vassilis">Vassilis Kostakos</a></p>
<p>Abstract:
This study employs hierarchical cluster analysis, strategic diagrams and network analysis to map and visualize the intellectual landscape of the CHI conference on Human Computer Interaction through the use of co-word analysis. The study quantifies and describes the thematic evolution of the field based on a total of 3152 CHI articles and their associated 16035 keywords published between 1994 and 2013. The analysis is conducted for two time periods (1994-2003, 2004-2013) and a comparison between them highlights the underlying trends in our community. More significantly, this study identifies the evolution of major themes in the discipline, and highlights individual topics as popular, core, or backbone research topics within HCI.</p>
<p>Keywords:
bibliometric study; co-word analysis; coherence; cohesion; conceptual evolution; hci</p>
<h2 id="PolitiCHI    4">PolitiCHI    4</h2>
<h3 id="397. "Narco" emotions: affect and desensitization in social media during the mexican drug war.">397. "Narco" emotions: affect and desensitization in social media during the mexican drug war.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557197">Paper Link</a>    Pages:3563-3572</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Choudhury:Munmun_De">Munmun De Choudhury</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Monroy=Hern=aacute=ndez:Andr=eacute=s">Andrs Monroy-Hernndez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mark:Gloria">Gloria Mark</a></p>
<p>Abstract:
Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010 - Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.</p>
<p>Keywords:
affect; crisis informatics; desensitization; social media</p>
<h3 id="398. A pool of dreams: facebook, politics and the emergence of a social movement.">398. A pool of dreams: facebook, politics and the emergence of a social movement.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557100">Paper Link</a>    Pages:3573-3582</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/c/Crivellaro:Clara">Clara Crivellaro</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Comber:Rob">Rob Comber</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bowers:John">John Bowers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wright:Peter_C=">Peter C. Wright</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
In this paper we present insights from an empirical analysis of data from an emergent social movement primarily located on a Facebook page to contribute understanding of the conduct of everyday politics in social media and through this open up research agendas for HCI. The analysis focuses on how interactions and contributions facilitated the emergence of a collective with political will. We lay out an exploration of the intrinsic relationship between cultural memories, cultural expression and everyday politics and show how diverging voices co-constructed dynamic collectives capable of political action. We look at how interactions through the Facebook page challenge traditional ways for conceiving politics and the political. We outline possible research agendas in the field of everyday politics, which are sensitive to the everyday acts of resistance enclosed in the ordinary.</p>
<p>Keywords:
activism; collectives; discourse; politics; social media</p>
<h3 id="399. Shared values/conflicting logics: working around e-government systems.">399. Shared values/conflicting logics: working around e-government systems.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556971">Paper Link</a>    Pages:3583-3592</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Voida:Amy">Amy Voida</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dombrowski:Lynn">Lynn Dombrowski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hayes:Gillian_R=">Gillian R. Hayes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mazmanian:Melissa">Melissa Mazmanian</a></p>
<p>Abstract:
In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.</p>
<p>Keywords:
e-government; social services; values</p>
<h3 id="400. Rethinking plan A for sustainable HCI.">400. Rethinking plan A for sustainable HCI.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557311">Paper Link</a>    Pages:3593-3596</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Knowles:Bran">Bran Knowles</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Blair:Lynne">Lynne Blair</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Coulton:Paul">Paul Coulton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lochrie:Mark">Mark Lochrie</a></p>
<p>Abstract:
This paper challenges the sustainable HCI community to move away from a focus on demand and instead address climate change as a supply problem. We identify a new route to impact, namely addressing the psychological barriers that interfere with political mobilization toward limiting the use of fossil fuels. Five barriers are explored as a means of re-focusing research objectives for the community.</p>
<p>Keywords:
activism; climate change; psychological barriers; supply; sustainability</p>
<h2 id="Location-based services and navigation    5">Location-based services and navigation    5</h2>
<h3 id="401. HaptiMoto: turn-by-turn haptic route guidance interface for motorcyclists.">401. HaptiMoto: turn-by-turn haptic route guidance interface for motorcyclists.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557404">Paper Link</a>    Pages:3597-3606</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Prasad:Manoj">Manoj Prasad</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Taele:Paul">Paul Taele</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Goldberg:Daniel_W=">Daniel W. Goldberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hammond:Tracy_Anne">Tracy Anne Hammond</a></p>
<p>Abstract:
A national study by the Australian Transport Safety Bureau revealed that motorcyclist deaths were nearly thirty times more prevalent than that of drivers of other vehicles. These fatalities represent approximately 5% of all highway deaths each year, yet motorcycles account for only 2% of all registered vehicles in the USA. Motorcyclists are highly exposed on the road, so maintaining situational awareness at all times is crucial. Route guidance systems enable users to efficiently navigate between locations using dynamic visual maps and audio directions, and have been well tested with motorists, but remain unsafe for use by motorcyclists. Audio/visual routing systems decrease motorcyclists' situational awareness and vehicle control, and thus elevate chances of an accident. To enable motorcyclists to take advantage of route guidance while maintaining situational awareness, we created HaptiMoto, a wearable haptic route guidance system. HaptiMoto uses tactile signals to encode the distance and direction of approaching turns, thus avoiding interference with audio/visual awareness. Our evaluations demonstrate that HaptiMoto is both intuitive and a safer alternative for motorcyclists compared to existing solutions.</p>
<p>Keywords:
advanced traveler information system; route guidance; tactile interface; vibro-tactile</p>
<h3 id="402. Experimental evaluation of user interfaces for visual indoor navigation.">402. Experimental evaluation of user interfaces for visual indoor navigation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557003">Paper Link</a>    Pages:3607-3616</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/M=ouml=ller:Andreas">Andreas Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kranz:Matthias">Matthias Kranz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Diewald:Stefan">Stefan Diewald</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roalter:Luis">Luis Roalter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huitl:Robert">Robert Huitl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Stockinger:Tobias">Tobias Stockinger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Koelle:Marion">Marion Koelle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lindemann:Patrick">Patrick Lindemann</a></p>
<p>Abstract:
Mobile location recognition by capturing images of the environment (visual localization) is a promising technique for indoor navigation in arbitrary surroundings. However, it has barely been investigated so far how the user interface (UI) can cope with the challenges of the vision-based localization technique, such as varying quality of the query images. We implemented a novel UI for visual localization, consisting of Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and ensure localization accuracy. If necessary, the system encourages the user to point the smartphone at distinctive regions to improve localization quality. We evaluated the UI in a experimental navigation task with a prototype, informed by initial evaluation results using design mockups. We found that VR can contribute to efficient and effective indoor navigation even at unreliable location and orientation accuracy. We discuss identified challenges and share lessons learned as recommendations for future work.</p>
<p>Keywords:
augmented reality; indoor navigation; mobile interaction; virtual reality; visual localization</p>
<h3 id="403. Digitally driven: how location based services impact the work practices of London bus drivers.">403. Digitally driven: how location based services impact the work practices of London bus drivers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557156">Paper Link</a>    Pages:3617-3626</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pritchard:Gary_W=">Gary W. Pritchard</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vines:John">John Vines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Briggs:Pamela">Pamela Briggs</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thomas:Lisa_A=">Lisa A. Thomas</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Olivier:Patrick">Patrick Olivier</a></p>
<p>Abstract:
This paper examines how an occupational group has adapted to the demands of working with a Location Based Service (LBS). Instead of following a rigid timetable, London's bus drivers are now required to maintain an equal distance between the bus in front and the one behind. Our qualitative study employs ethnographic fieldwork and in-depth semi-structured interviews to elicit drivers' perspectives of the new system and show how it has modified their driving and general work conditions. We explore how passengers influence the movement of the bus and how the technology frames bus drivers' relationships to their managers and commuters. This work contributes to our understanding of the impact of LBS in the workplace and shows how technological imperatives can be established that cause unanticipated consequences and gradually undermine human relationships.</p>
<p>Keywords:
auto ethnography; ethnography; lbd; lbs; location based devices; location based services; public transport</p>
<h3 id="404. Smart flashlight: map navigation using a bike-mounted projector.">404. Smart flashlight: map navigation using a bike-mounted projector.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557289">Paper Link</a>    Pages:3627-3630</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/d/Dancu:Alexandru">Alexandru Dancu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Franjcic:Zlatko">Zlatko Franjcic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fjeld:Morten">Morten Fjeld</a></p>
<p>Abstract:
While mobile phones affect our behavior and tend to separate us from our physical environment, this very environment could instead become a responsive part of the information domain. For navigation using a map while cycling in an urban environment, we studied two alternative solutions: smartphone display and projection on the road. This paper firstly demonstrates by proof-of-concept a GPS-based map navigation using a bike-mounted projector. Secondly, it implements a prototype using both a projector and a smartphone mounted on a bike, comparing them for use in a navigation system for nighttime cycling. Thirdly, it examines how visuo-spatial factors influence navigation. We believe that our findings will be useful for designing navigation systems for bikes and even for cars, helping cyclists and drivers be more attentive to their environment while navigating, and to provide useful information while moving.</p>
<p>Keywords:
bike; field of view; gps; navigation; pico-projector; smartphone; visuo-spatial</p>
<h3 id="405. Partially intelligent automobiles and driving experience at the moment of system transition.">405. Partially intelligent automobiles and driving experience at the moment of system transition.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557370">Paper Link</a>    Pages:3631-3634</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Key_Jung">Key Jung Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Joo:Yeon_Kyoung">Yeon Kyoung Joo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nass:Clifford">Clifford Nass</a></p>
<p>Abstract:
The current study (N = 49) took a user-centered approach to explore how level of automation (pedal automated, wheel automated or fully automated driving) and the interface modality (switching automation on or off via touch or voice control) in automated vehicles influence drivers' perceived experience and performance. The results found that full or wheel automation in vehicles was perceived significantly more intelligent than pedal automation. Furthermore, drivers in the pedal automation condition reported greater nervousness when using the touch interface than the voice interface. This tendency was not found among drivers in the full and wheel automation conditions. Drivers who used the voice interface to control automated driving had fewer driving mistakes than those who operated the touch interface. Our findings have important psychological and practical implications for designing a user interface for automated vehicles.</p>
<p>Keywords:
automated car; in-car interfaces; partial automation; safe driving; situational awareness</p>
<h2 id="Crowdsourcing    4">Crowdsourcing    4</h2>
<h3 id="406. Slide to X: unlocking the potential of smartphone unlocking.">406. Slide to X: unlocking the potential of smartphone unlocking.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557044">Paper Link</a>    Pages:3635-3644</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/t/Truong:Khai_N=">Khai N. Truong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shihipar:Thariq">Thariq Shihipar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wigdor:Daniel_J=">Daniel J. Wigdor</a></p>
<p>Abstract:
Unlock gestures are performed by billions of users across the world multiple times a day. Beyond preventing accidental input on mobile devices, they currently serve little to no other purpose. In this paper, we explore how replacing the regular unlock screen with one that asks the user to perform a simple, optional task, can benefit a wealth of application domains, including data collection, personal-health metrics collection, and human intelligence tasks. We evaluate this concept, which we refer to as Slide to X. Further, we show that people are willing to perform microtasks presented through this interface and continue to do so throughout the day while they visit different locations as part of their daily routines. We then discuss how to implement this concept and demonstrate three applications.</p>
<p>Keywords:
dual-purpose interaction; microtasks; phone unlock</p>
<h3 id="407. Twitch crowdsourcing: crowd contributions in short bursts of time.">407. Twitch crowdsourcing: crowd contributions in short bursts of time.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556996">Paper Link</a>    Pages:3645-3654</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vaish:Rajan">Rajan Vaish</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wyngarden:Keith">Keith Wyngarden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Jingshu">Jingshu Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cheung:Brandon">Brandon Cheung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bernstein:Michael_S=">Michael S. Bernstein</a></p>
<p>Abstract:
To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing: crowdsourcing via quick contributions that can be completed in one or two seconds. We introduce Twitch, a mobile phone application that asks users to make a micro-contribution each time they unlock their phone. Twitch takes advantage of the common habit of turning to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such as authoring a census of local human activity, rating stock photos, and extracting structured data from Wikipedia pages. We report a field deployment of Twitch where 82 users made 11,240 crowdsourcing contributions as they used their phone in the course of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock interface.</p>
<p>Keywords:
crowdsourcing; microtasking; mobile crowdsourcing</p>
<h3 id="408. Crowdsourcing the future: predictions made with a social network.">408. Crowdsourcing the future: predictions made with a social network.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556967">Paper Link</a>    Pages:3655-3664</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Forlines:Clifton">Clifton Forlines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Sarah">Sarah Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guelcher:Leslie">Leslie Guelcher</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bruzzi:Robert">Robert Bruzzi</a></p>
<p>Abstract:
Researchers have long known that aggregate estimations built from the collected opinions of a large group of people often outperform the estimations of individual experts. This phenomenon is generally described as the "Wisdom of Crowds". This approach has shown promise with respect to the task of accurately forecasting future events. Previous research has demonstrated the value of utilizing meta-forecasts (forecasts about what others in the group will predict) when aggregating group predictions. In this paper, we describe an extension to meta-forecasting and demonstrate the value of modeling the familiarity among a population's members (its social network) and applying this model to forecast aggregation. A pair of studies demonstrates the value of taking this model into account, and the described technique produces aggregate forecasts for future events that are significantly better than the standard Wisdom of Crowds approach as well as previous meta-forecasting techniques.</p>
<p>Keywords:
aggregation; bayesian truth serum; crowd-sourcing; forecasting; meta-forecast; social network</p>
<h3 id="409. Cognitively inspired task design to improve user performance on crowdsourcing platforms.">409. Cognitively inspired task design to improve user performance on crowdsourcing platforms.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557155">Paper Link</a>    Pages:3665-3674</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sampath:Harini_Alagarai">Harini Alagarai Sampath</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rajeshuni:Rajeev">Rajeev Rajeshuni</a> ; <a href="http://dblp.uni-trier.de/pers/hd/i/Indurkhya:Bipin">Bipin Indurkhya</a></p>
<p>Abstract:
Recent research in human computation has focused on improving the quality of work done by crowd workers on crowdsourcing platforms. Multiple approaches have been adopted like filtering crowd workers through qualification tasks, and aggregating responses from multiple crowd workers to obtain consensus. We investigate here how improving the presentation of the task itself by using cognitively inspired features affects the performance of crowd workers. We illustrate this with a case-study for the task of extracting text from scanned images. We generated six task-presentation designs by modifying two parameters - visual saliency of the target fields and working memory requirements - and conducted experiments on Amazon Mechanical Turk (AMT) and with an eye-tracker in the lab setting. Our results identify which task-design parameters (e.g. highlighting target fields) result in improved performance, and which ones do not (e.g. reducing the number of distractors). In conclusion, we claim that the use of cognitively inspired features for task design is a powerful technique for maximizing the performance of crowd workers.</p>
<p>Keywords:
cognitive psychology; crowdsourcing; eye tracking; mechanical turk; task design; visual saliency; working memory</p>
<h2 id="Desktop search and history    4">Desktop search and history    4</h2>
<h3 id="410. Searching for myself: motivations and strategies for self-search.">410. Searching for myself: motivations and strategies for self-search.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557356">Paper Link</a>    Pages:3675-3684</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Marshall:Catherine_C=">Catherine C. Marshall</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lindley:Si=acirc=n_E=">Sin E. Lindley</a></p>
<p>Abstract:
We present findings from a qualitative study of self-search, also known as ego or vanity search. In the context of a broader study about personal online content, participants were asked to search for themselves using their own computers and the browsers and queries they would normally adopt. Our analysis highlights five motivations for self-search: as a form of identity management; to discover reactions to and reuse of user-generated media; to re-find personal content; as a form of entertainment; and to reveal lost or forgotten content. Strategies vary according to motivation, and may differ markedly from typical information-seeking, with users looking deep into the results and using image search to identify content about themselves. We argue that two dimensions underpin ways of improving self-search: controllability and expectedness, and discuss what these dimensions imply for design.</p>
<p>Keywords:
aggregation; archive; autosurveillance; doppelganger; ego search; identity; self-search; vanity search</p>
<h3 id="411. Finder highlights: field evaluation and design of an augmented file browser.">411. Finder highlights: field evaluation and design of an augmented file browser.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557014">Paper Link</a>    Pages:3685-3694</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Fitchett:Stephen">Stephen Fitchett</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cockburn:Andy">Andy Cockburn</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a></p>
<p>Abstract:
Navigating to files through a hierarchy is often a slow, laborious, and repetitive task. Recent lab studies showed that file browser interface augmentations, such as Icon Highlights and Search Directed Navigation, have the potential to reduce file retrieval times. However, for this potential to be realised in actual systems, further study is necessary to address two important issues. First, there are important design and implementation challenges in advancing the research prototypes previously evaluated into complete interactive systems that can be used for real work. Second, it is unknown how real users would employ these systems while engaged in actual work; would the potential performance improvements suggested by the earlier lab studies be realised? We therefore describe the design, implementation, and longitudinal field study evaluation of Finder Highlights, a file browser plugin for the OS X 'Finder' that adds support for Icon Highlights and Search Directed Navigation. Study results confirm that the augmentations are effective in reducing real-world file retrieval times, with retrieval times 13% faster when using Finder Highlights compared to the standard tool (10.6 s versus 12.2 s), while also emphasising important differences between lab and field studies. In summary, the paper strongly suggests that large-scale deployment of interface augmentations to file browsers, particularly Icon Highlights, will have a marked effect in improving users' real-world file retrieval.</p>
<p>Keywords:
file navigation; file retrieval; prediction; revisitation</p>
<h3 id="412. PIM and personality: what do our personal file systems say about us?">412. PIM and personality: what do our personal file systems say about us?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557023">Paper Link</a>    Pages:3695-3704</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Massey:Charlotte">Charlotte Massey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/TenBrook:Sean">Sean TenBrook</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tatum:Chaconne">Chaconne Tatum</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Whittaker:Steve">Steve Whittaker</a></p>
<p>Abstract:
Individual differences are prevalent in personal information management (PIM). There is large variation between individuals in how they structure and retrieve information from personal archives. These differences make it hard to develop general PIM tools. However we know little about the origins of these differences. We present two studies evaluating whether differences arise from personality traits, by exploring whether different personalities structure personal archives differently. The first exploratory study asks participants to identify PIM cues that signal personality traits. While the aim was to identify cues, these cues also proved surprisingly accurate indicators of personality. In a second study, to evaluate these cues, we directly measure relations between structure and traits. We demonstrate that Conscientiousness predicts file organization, particularly PC users' desktops. Neurotic people may also keep more desktop files. One implication is that systems might be customized for different personalities. We also advance personality theory, showing that personal digital artifacts signal personality.</p>
<p>Keywords:
file systems; individual differences; personal information management; personality</p>
<h3 id="413. Show me the invisible: visualizing hidden content.">413. Show me the invisible: visualizing hidden content.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557032">Paper Link</a>    Pages:3705-3714</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Geymayer:Thomas">Thomas Geymayer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Steinberger:Markus">Markus Steinberger</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lex:Alexander">Alexander Lex</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Streit:Marc">Marc Streit</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schmalstieg:Dieter">Dieter Schmalstieg</a></p>
<p>Abstract:
Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked. In search tasks, the efficient retrieval of sought content is important. Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries. To remedy this situation, we introduce two novel visualization methods to guide users to hidden content. Our first method generates awareness for occluded or out-of-viewport content using see-through visualization. For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview. To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content. We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.</p>
<p>Keywords:
hidden content; occluded content; off-screen content; visual linking</p>
<h2 id="Lost and found in translation    5">Lost and found in translation    5</h2>
<h3 id="414. "Maybe it was a joke": emotion detection in text-only communication by non-native english speakers.">414. "Maybe it was a joke": emotion detection in text-only communication by non-native english speakers.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557215">Paper Link</a>    Pages:3715-3724</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hautasaari:Ari_M=_J=">Ari M. J. Hautasaari</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yamashita:Naomi">Naomi Yamashita</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gao:Ge">Ge Gao</a></p>
<p>Abstract:
Previous studies have shown that people can effectively detect emotions in text-only messages written in their native languages. But is this the same for non-native speakers' In this paper, we conduct an experiment where native English speakers (NS) and Japanese non-native English speakers (NNS) rate the emotional valence in text-only messages written by native English-speaking authors. They also annotate all emotional cues (words, symbols and emoticons) that affected their rating. Accuracy of NS and NNS ratings and annotations are calculated by comparing their average correlations with author ratings and annotations used as a gold standard. Our results conclude that NNS are significantly less accurate at detecting the emotional valence of messages, especially when the messages include highly negative words. Although NNS are as accurate as NS at detecting emotional cues, they are not able to make use of symbols (exclamation marks) and emoticons to detect the emotional valence of text-only messages.</p>
<p>Keywords:
computer-mediated communication; emotion; non-native speaker; text-only communication</p>
<h3 id="415. TransPhoner: automated mnemonic keyword generation.">415. TransPhoner: automated mnemonic keyword generation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556985">Paper Link</a>    Pages:3725-3734</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Savva:Manolis">Manolis Savva</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chang:Angel_X=">Angel X. Chang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Manning:Christopher_D=">Christopher D. Manning</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hanrahan:Pat">Pat Hanrahan</a></p>
<p>Abstract:
We present TransPhoner: a system that generates keywords for a variety of scenarios including vocabulary learning, phonetic transliteration, and creative word plays. We select effective keywords by considering phonetic, orthographic and semantic word similarity, and word concept imageability. We show that keywords provided by TransPhoner improve learner performance in an online vocabulary learning study, with the improvement being more pronounced for harder words. Participants rated TransPhoner keywords as more helpful than a random keyword baseline, and almost as helpful as manually selected keywords. Comments also indicated higher engagement in the learning task, and more desire to continue learning. We demonstrate additional applications to tasks such as pure phonetic transliteration, generation of mnemonics for complex vocabulary, and topic-based transformation of song lyrics.</p>
<p>Keywords:
mnemonic keywords</p>
<h3 id="416. AudioCanvas: internet-free interactive audio photos.">416. AudioCanvas: internet-free interactive audio photos.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556993">Paper Link</a>    Pages:3735-3738</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Robinson:Simon">Simon Robinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pearson:Jennifer_S=">Jennifer S. Pearson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jones:Matt">Matt Jones</a></p>
<p>Abstract:
In this paper we present a novel interaction technique that helps to make textual information more accessible to those with low or no textual literacy skills. AudioCanvas allows cameraphone users to interact directly with their own photos of printed media to receive audio feedback or narration. The use of a remote telephone-based service also allows our design to be used over a standard phone line, removing the need for data connections, which can be problematic in developing regions. We show the value of the technique via user evaluations in both a rural Indian village and a South African township.</p>
<p>Keywords:
audio; camera phones; developing regions; qr codes</p>
<h3 id="417. The impact of visual contextualization on UI localization.">417. The impact of visual contextualization on UI localization.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556982">Paper Link</a>    Pages:3739-3742</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Leiva:Luis_A=">Luis A. Leiva</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Alabau:Vicent">Vicent Alabau</a></p>
<p>Abstract:
Translating the text in an interface is a challenging task. Besides the jargon and technical terms, many of the strings are often very short, such as those shown in buttons and pull-down menus. Then, as a result of the lack of visual context in the traditional localization process, an important ambiguity problem arises. We study three approaches to solve this problem: using plain gettext (baseline condition), using gettext plus being able to operate the UI, and translating the UI in-place. We found that translators are substantially faster with plain gettext but commit a significantly higher number of errors in comparison to the other approaches. Unexpectedly, the mixed condition was slower and more error-prone than in-place translation. The latter was found to be comparable to plain gettext in terms of time, although some strings passed unnoticed as the UI was operated. Based on our results, we arrive at a set of recommendations to augment localization tools to improve translator's productivity.</p>
<p>Keywords:
i18n; internationalization; l10n; localization; translation</p>
<h3 id="418. Improving machine translation by showing two outputs.">418. Improving machine translation by showing two outputs.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557171">Paper Link</a>    Pages:3743-3746</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/x/Xu_0002:Bin">Bin Xu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gao:Ge">Ge Gao</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fussell:Susan_R=">Susan R. Fussell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cosley:Dan">Dan Cosley</a></p>
<p>Abstract:
We propose to improve real-time communication between people who do not share a common language by foregrounding potential problems in machine translation. We developed a prototype chat tool that displays two parallel translations of each chat turn, with the thought that comparing the translations might both highlight problems and provide resources for resolving them. We conducted a user study to investigate how people use and like such an interface compared to a standard one-translation interface. On balance, users preferred two translations to one, using them to both notice differences and infer meaning from uncertain translations, with no increase in workload. This suggests that this interface may help improve cross-lingual communication in practical applications and lays the groundwork for a larger design space around systems that highlight possible errors to support communication.</p>
<p>Keywords:
machine translation; multiple translations</p>
<h2 id="Participatory design    4">Participatory design    4</h2>
<h3 id="419. Diversity for design: a framework for involving neurodiverse children in the technology design process.">419. Diversity for design: a framework for involving neurodiverse children in the technology design process.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557244">Paper Link</a>    Pages:3747-3756</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Benton:Laura">Laura Benton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vasalou:Asimina">Asimina Vasalou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Khaled:Rilla">Rilla Khaled</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Johnson:Hilary">Hilary Johnson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gooch:Daniel">Daniel Gooch</a></p>
<p>Abstract:
The neurodiversity movement seeks to positively reframe certain neurological conditions, such as autism spectrum disorders (ASD) and dyslexia, by concentrating on their strengths. In recent years, neurodiverse children have increasingly been involved in the technology design process, but the design approaches adopted have focused mostly on overcoming difficulties of working with these children, leaving their strengths untapped. We present a new participatory design (PD) framework, Diversity for Design (D4D), which provides guidance for technology designers working with neurodiverse children in establishing PD methods that capitalize on children's strengths and also support potential difficulties. We present two case studies of use of the D4D framework, involving children with ASD and dyslexia, showing how it informed the development and refinement of PD methods tailored to these populations. In addition, we show how to apply the D4D framework to other neurodiverse populations.</p>
<p>Keywords:
autism; children; dyslexia; neurodiversity; participatory design</p>
<h3 id="420. Canine-centered interface design: supporting the work of diabetes alert dogs.">420. Canine-centered interface design: supporting the work of diabetes alert dogs.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557396">Paper Link</a>    Pages:3757-3766</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Robinson:Charlotte_L=">Charlotte L. Robinson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mancini:Clara">Clara Mancini</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Linden:Janet_van_der">Janet van der Linden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guest:Claire">Claire Guest</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Harris:Robert">Robert Harris</a></p>
<p>Abstract:
Many people with Diabetes live with the continuous threat of hypoglycemic attacks and the danger of going into coma. Diabetes Alert Dogs are trained to detect the onset of an attack before the condition of the human handler they are paired with deteriorates, giving them time to take action. We investigated requirements for designing an alarm system allowing dogs to remotely call for help when their human falls unconscious before being able to react to an alert. Through a multispecies ethnographic approach we focus on the requirements for a physical canine user interface, involving dogs, their handlers and specialist dog trainers in the design process. We discuss tensions between the requirements for canine and the human users, argue the need for increased sensitivity towards the needs of individual dogs that goes beyond breed specific physical characteristics, and reflect on how we can move from designing for dogs to designing with dogs.</p>
<p>Keywords:
animal-computer interaction; diabetes alert dog; human-animal interaction; multispecies ethnography; user-centered design</p>
<h3 id="421. Co-constructing child personas for health-promoting services with vulnerable children.">421. Co-constructing child personas for health-promoting services with vulnerable children.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557115">Paper Link</a>    Pages:3767-3776</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/W=auml=rnest=aring=l:Pontus">Pontus Wrnestl</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Svedberg:Petra">Petra Svedberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nygren:Jens">Jens Nygren</a></p>
<p>Abstract:
The availability of health-promoting resources for young children diagnosed with cancer who are transitioning from intensive care to everyday life is limited. In the context of designing digital peer support services for children who are considered vulnerable due to clinical and age-related aspects, there are several challenges that put critical requirements on a user-centered design process. This paper reports on a new method for co-constructing child-personas that are tailored for developing health-promoting services where empirical data is restricted due to practical and ethical reasons. In particular, we are proposing to focus children design workshop sessions on salutogenesis, and complement this with a pathogenic perspective by interviewing healthcare professionals and parents. We also introduce the use of proxy personas, and redemption scenarios in the form of comicboards, both collaboratively constructed by children and designers through storytelling. By applying four progressive steps of data collection and analysis we arrive at authentic child-personas that can be used to design and develop health-promoting services for children in vulnerable life stages.</p>
<p>Keywords:
digital peer support; interaction design; methodology; participatory design; personas; social interaction; user experience; vulnerable children</p>
<h3 id="422. Balancing design tensions: iterative display design to support ad hoc and multidisciplinary medical teamwork.">422. Balancing design tensions: iterative display design to support ad hoc and multidisciplinary medical teamwork.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557301">Paper Link</a>    Pages:3777-3786</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kusunoki:Diana_S=">Diana S. Kusunoki</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sarcevic:Aleksandra">Aleksandra Sarcevic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weibel:Nadir">Nadir Weibel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marsic:Ivan">Ivan Marsic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Zhan">Zhan Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Tuveson:Genevieve">Genevieve Tuveson</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Burd:Randall_S=">Randall S. Burd</a></p>
<p>Abstract:
In this paper, we describe how we developed an information display prototype for trauma resuscitation teams based on design ideas and feedback from clinicians. Our approach is grounded in participatory design, emphasizing the importance of gaining long-term commitment from clinicians in system development. Through a series of participatory design workshops, heuristic evaluation, and simulated resuscitation sessions, we identified the main information features to include on our display. Our results focus on how we balanced the design tensions that emerged when addressing the ad hoc, hierarchical, and multidisciplinary nature of trauma teamwork. We discuss the implications of balancing role-based differences for each information feature, as well as two major design tensions: process-based vs. state-based designs and role-based vs. team-based displays.</p>
<p>Keywords:
design tensions; healthcare; information displays; participatory design; teamwork; trauma resuscitation</p>
<h2 id="Brain computer interfaces    4">Brain computer interfaces    4</h2>
<h3 id="423. Error related negativity in observing interactive tasks.">423. Error related negativity in observing interactive tasks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557015">Paper Link</a>    Pages:3787-3796</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Vi:Chi_Thanh">Chi Thanh Vi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jamil:Izdihar">Izdihar Jamil</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Coyle:David">David Coyle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Subramanian:Sriram">Sriram Subramanian</a></p>
<p>Abstract:
Error Related Negativity is triggered when a user either makes a mistake or the application behaves differently from their expectation. It can also appear while observing another user making a mistake. This paper investigates ERN in collaborative settings where observing another user (the executer) perform a task is typical and then explores its applicability to HCI. We first show that ERN can be detected on signals captured by commodity EEG headsets like an Emotiv headset when observing another person perform a typical multiple-choice reaction time task. We then investigate the anticipation effects by detecting ERN in the time interval when an executer is reaching towards an answer. We show that we can detect this signal with both a clinical EEG device and with an Emotiv headset. Our results show that online single trial detection is possible using both headsets during tasks that are typical of collaborative interactive applications. However there is a trade-off between the detection speed and the quality/prices of the headsets. Based on the results, we discuss and present several HCI scenarios for use of ERN in observing tasks and collaborative settings.</p>
<p>Keywords:
brain computer interface; eeg; electroencephalography; error related negativity; tabletop</p>
<h3 id="424. Dynamic difficulty using brain metrics of workload.">424. Dynamic difficulty using brain metrics of workload.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557230">Paper Link</a>    Pages:3797-3806</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/a/Afergan:Daniel">Daniel Afergan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Peck:Evan_M=">Evan M. Peck</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Solovey:Erin_Treacy">Erin Treacy Solovey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jenkins:Andrew">Andrew Jenkins</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hincks:Samuel_W=">Samuel W. Hincks</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brown:Eli_T=">Eli T. Brown</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chang:Remco">Remco Chang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jacob:Robert_J=_K=">Robert J. K. Jacob</a></p>
<p>Abstract:
Dynamic difficulty adjustments can be used in human-computer systems in order to improve user engagement and performance. In this paper, we use functional near-infrared spectroscopy (fNIRS) to obtain passive brain sensing data and detect extended periods of boredom or overload. From these physiological signals, we can adapt a simulation in order to optimize workload in real-time, which allows the system to better fit the task to the user from moment to moment. To demonstrate this idea, we ran a laboratory study in which participants performed path planning for multiple unmanned aerial vehicles (UAVs) in a simulation. Based on their state, we varied the difficulty of the task by adding or removing UAVs and found that we were able to decrease error by 35% over a baseline condition. Our results show that we can use fNIRS brain sensing to detect task difficulty in real-time and construct an interface that improves user performance through dynamic difficulty adjustment.</p>
<p>Keywords:
bci; dynamic difficulty; fnirs; near-infrared spectroscopy; passive brain-computer interface; uav; workload</p>
<h3 id="425. Measuring the effect of think aloud protocols on workload using fNIRS.">425. Measuring the effect of think aloud protocols on workload using fNIRS.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556974">Paper Link</a>    Pages:3807-3816</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Pike:Matthew_F=">Matthew F. Pike</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Maior:Horia_A=">Horia A. Maior</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Porcheron:Martin">Martin Porcheron</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sharples:Sarah_C=">Sarah C. Sharples</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wilson:Max_L=">Max L. Wilson</a></p>
<p>Abstract:
The Think Aloud Protocol (TAP) is a verbalisation technique widely employed in HCI user studies to give insight into user experience, yet little work has explored the impact that TAPs have on participants during user studies. This paper utilises a brain sensing technique, fNIRS, to observe the effect that TAPs have on participants. Functional Near-Infrared Spectroscopy (fNIRS) is a brain sensing technology that offers the potential to provide continuous, detailed insight into brain activity, enabling an objective view of cognitive processes during complex tasks. Participants were asked to perform a mathematical task under 4 conditions: nonsense verbalisations, passive concurrent think aloud protocol, invasive concurrent think aloud protocol, and a baseline of silence. Subjective ratings and performance measures were collected during the study. Our results provide a novel view into the effect that different forms of verbalisation have on workload during tasks. Further, the results provide a means for estimating the effect of spoken artefacts when measuring workload, which is another step towards our goal of proactively involving fNIRS analysis in ecologically valid user studies.</p>
<p>Keywords:
bci; fnirs; functional near-infrared spectroscopy; hci; human cognition; think aloud protocol</p>
<h3 id="426. An EEG-based approach for evaluating audio notifications under ambient sounds.">426. An EEG-based approach for evaluating audio notifications under ambient sounds.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557076">Paper Link</a>    Pages:3817-3826</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lee:Yi=Chieh">Yi-Chieh Lee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lin:Wen=Chieh">Wen-Chieh Lin</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/King:Jung=Tai">Jung-Tai King</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Ko:Li=Wei">Li-Wei Ko</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Huang:Yu=Ting">Yu-Ting Huang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cherng:Fu=Yin">Fu-Yin Cherng</a></p>
<p>Abstract:
Audio notifications are an important means of prompting users of electronic products. Although useful in most environments, audio notifications are ineffective in certain situations, especially against particular auditory backgrounds or when the user is distracted. Several studies have used behavioral performance to evaluate audio notifications, but these studies failed to achieve consistent results due to factors including user subjectivity and environmental differences; thus, a new method and more objective indicators are necessary. In this study, we propose an approach based on electroencephalography (EEG) to evaluate audio notifications by measuring users' auditory perceptual responses (mismatch negativity) and attention shifting (P3a). We demonstrate our approach by applying it to the usability testing of audio notifications in realistic scenarios, such as users performing a major task amid ambient noises. Our results open a new perspective for evaluating the design of the audio notifications.</p>
<p>Keywords:
audio notifications; electroencephalography (eeg); human cognition; mismatch negativity; usability testing</p>
<h2 id="3D printing and fabrication    4">3D printing and fabrication    4</h2>
<h3 id="427. faBrickation: fast 3D printing of functional objects by integrating construction kit building blocks.">427. faBrickation: fast 3D printing of functional objects by integrating construction kit building blocks.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557005">Paper Link</a>    Pages:3827-3834</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mueller:Stefanie">Stefanie Mueller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mohr:Tobias">Tobias Mohr</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guenther:Kerstin">Kerstin Guenther</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Frohnhofen:Johannes">Johannes Frohnhofen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Baudisch:Patrick">Patrick Baudisch</a></p>
<p>Abstract:
We present a new approach to rapid prototyping of functional objects, such as the body of a head-mounted display. The key idea is to save 3D printing time by automatically substituting sub-volumes with standard building blocks'in our case Lego bricks. When making the body for a head-mounted display, for example, getting the optical path right is paramount. Users thus mark the lens mounts as "high-resolution" to indicate that these should later be 3D printed. faBrickator then 3D prints these parts. It also generates instructions that show users how to create everything else from Lego bricks. If users iterate on the design later, faBrickator offers even greater benefit as it allows re-printing only the elements that changed. We validated our system at the example of three 3D models of functional objects. On average, our system fabricates objects 2.44 times faster than traditional 3D printing while requiring only 14 minutes of manual assembly.</p>
<p>Keywords:
3d printing; building blocks; design iteration; physical prototyping; rapid prototyping</p>
<h3 id="428. Understanding physical activity through 3D printed material artifacts.">428. Understanding physical activity through 3D printed material artifacts.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557144">Paper Link</a>    Pages:3835-3844</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Khot:Rohit_Ashok">Rohit Ashok Khot</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hjorth:Larissa">Larissa Hjorth</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mueller:Florian_=Floyd=">Florian 'Floyd' Mueller</a></p>
<p>Abstract:
In this paper, we advocate a novel approach of representing physical activity in the form of material artifacts. By designing such material representations, we aim to understand what these artifacts might offer in terms of reflecting upon physical activity. For example, what types of affect do material artifacts, representing ones' physical activity create for the user' In order to advance this understanding, we designed a system called SweatAtoms that transforms the physical activity data based on heart rate into 3D printed material artifacts. We conducted an 'in the wild study' by deploying our system in six households where participants were experiencing five different material representations of their physical activity for a period of two weeks each. We found that the material artifacts made participants more conscious about their involvement in physical activity and illustrated different levels of engagement with the artifacts. Along with reporting the gained insights from the deployments, we offer reflections on designing material representations for physical activity. We hope that our work will inspire designers to consider new possibilities afforded by digital fabrication to support user's experience with physical activity by utilizing interactive technologies at our disposal.</p>
<p>Keywords:
3d printing; digital fabrication; entertainment; personal informatics; physical exercise; quantifiable self</p>
<h3 id="429. Supporting the design and fabrication of physical visualizations.">429. Supporting the design and fabrication of physical visualizations.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557310">Paper Link</a>    Pages:3845-3854</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Swaminathan:Saiganesh">Saiganesh Swaminathan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shi:Conglei">Conglei Shi</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jansen:Yvonne">Yvonne Jansen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dragicevic:Pierre">Pierre Dragicevic</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oehlberg:Lora">Lora Oehlberg</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fekete:Jean=Daniel">Jean-Daniel Fekete</a></p>
<p>Abstract:
Physical visualizations come in increasingly diverse forms, and are used in domains including art and entertainment, business analytics, and scientific research. However, creating physical visualizations requires laborious craftsmanship and demands expertise in both data visualization and digital fabrication. We present three case studies that illustrate limitations of current visualization fabrication workflows. We then present MakerVis, a prototype tool that integrates the entire process of creating physical visualizations, from data filtering to physical fabrication. Design sessions with three end users demonstrate how tools such as MakerVis can dramatically lower the barriers to producing physical visualizations. Observations and interviews from these sessions highlighted future research areas, including customization support, using material properties to represent data variables, and allowing the reuse of physical data objects in new visualizations.</p>
<p>Keywords:
digital fabrication; infovis; physical visualization</p>
<h3 id="430. MixFab: a mixed-reality environment for personal fabrication.">430. MixFab: a mixed-reality environment for personal fabrication.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557090">Paper Link</a>    Pages:3855-3864</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Weichel:Christian">Christian Weichel</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lau:Manfred">Manfred Lau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kim:David">David Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Villar:Nicolas">Nicolas Villar</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gellersen:Hans=Werner">Hans-Werner Gellersen</a></p>
<p>Abstract:
Personal fabrication machines, such as 3D printers and laser cutters, are becoming increasingly ubiquitous. However, designing objects for fabrication still requires 3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group. In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication that lowers the barrier for users to engage in personal fabrication. Users design objects in an immersive augmented reality environment, interact with virtual objects in a direct gestural manner and can introduce existing physical objects effortlessly into their designs. We describe the design and implementation of MixFab, a user-defined gesture study that informed this design, show artifacts designed with the system and describe a user study evaluating the system's prototype.</p>
<p>Keywords:
3d modeling; 3d printing; direct manipulation; mixed-reality; personal fabrication</p>
<h2 id="Modeling users and interaction    5">Modeling users and interaction    5</h2>
<h3 id="431. Model of visual search and selection time in linear menus.">431. Model of visual search and selection time in linear menus.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557093">Paper Link</a>    Pages:3865-3874</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bailly:Gilles">Gilles Bailly</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brumby:Duncan_P=">Duncan P. Brumby</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Howes:Andrew">Andrew Howes</a></p>
<p>Abstract:
This paper presents a novel mathematical model for visual search and selection time in linear menus. Assuming two visual search strategies, serial and directed, and a pointing sub-task, it captures the change of performance with five fac- tors: 1) menu length, 2) menu organization, 3) target position, 4) absence/presence of target, and 5) practice. The novel aspect is that the model is expressed as probability density distribution of gaze, which allows for deriving total selection time. We present novel data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking and mouse tracking to confirm model predictions. The same parametrization yielded a high fit to both menu selection time and gaze distributions. The model has the potential to improve menu designs by helping designers identify more effective solutions without conducting empirical studies.</p>
<p>Keywords:
eye-tracking; linear menus; mathematical predictive models; user performance; visual search</p>
<h3 id="432. Towards accurate and practical predictive models of active-vision-based visual search.">432. Towards accurate and practical predictive models of active-vision-based visual search.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557324">Paper Link</a>    Pages:3875-3884</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kieras:David_E=">David E. Kieras</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornof:Anthony_J=">Anthony J. Hornof</a></p>
<p>Abstract:
Being able to predict the performance of interface designs using models of human cognition and performance is a long-standing goal of HCI research. This paper presents recent advances in cognitive modeling which permit increasingly realistic and accurate predictions for visual human-computer interaction tasks such as icon search by incorporating an "active vision" approach which emphasizes eye movements to visual features based on the availability of features in relationship to the point of gaze. A high fidelity model of a classic visual search task demonstrates the value of incorporating visual acuity functions into models of visual performance. The features captured by the high-fidelity model are then used to formulate a model simple enough for practical use, which is then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models for complex visual search are thus feasible and should be further developed.</p>
<p>Keywords:
cognitive architecture; goms; human performance modeling; visual acuity; visual search</p>
<h3 id="433. Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling.">433. Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557351">Paper Link</a>    Pages:3885-3894</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Yunfeng">Yunfeng Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hornof:Anthony_J=">Anthony J. Hornof</a></p>
<p>Abstract:
Human multitasking often involves complex task interactions and subtle tradeoffs which might be best understood through detailed computational cognitive modeling, yet traditional cognitive modeling approaches may not explore a sufficient range of task strategies to reveal the true complexity of multitasking behavior. This study proposes a systematic approach for exploring a large number of strategies using a computer-cluster-based parallelized modeling system. The paper demonstrates the efficacy of the approach for investigating and revealing the effects of different microstrategies on human performance, both within and across individuals, for a time-pressured multimodal dual task. The modeling results suggest that multitasking performance is not simply a matter of interleaving cognitive and sensorimotor processing but is instead heavily influenced by the selection of subtask microstrategies.</p>
<p>Keywords:
cognitive modeling; high performance computing; model comparison; multimodal; multitasking; task strategies.</p>
<h3 id="434. How does knowing what you are looking for change visual search behavior?">434. How does knowing what you are looking for change visual search behavior?</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557064">Paper Link</a>    Pages:3895-3898</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brumby:Duncan_P=">Duncan P. Brumby</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cox:Anna_Louise">Anna Louise Cox</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chung:Jacqueline">Jacqueline Chung</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fernandes:Byron">Byron Fernandes</a></p>
<p>Abstract:
When searching a display, users sometimes know what the target is but sometimes do not. It has generally been assumed that for this latter case people must engage in a deeper semantic evaluation of items during the search process. This idea is central to Information Foraging theory. But do people actually spend longer assessing items when engaged in a semantically demanding search task' We investigate this by having participants locate target items in 16-item menus. Participants were either told exactly what to look for (known-item search) or they were told the category that the target belonged to (semantic search). Participants were faster and more accurate at known-item searches. Eye-movement data show that this was because participants were more likely to skip over items when performing known-item searches. Contrary to expectation, we found limited empirical evidence to support the idea that deeper semantic evaluations of items lead to longer gaze durations (this occurred only when items were arranged very close together). This finding is important because it reveals how people adopt different eye gaze strategies depending on the kind of search activity they are engaged in.</p>
<p>Keywords:
eye-tracking; information foraging; menus; visual search</p>
<h3 id="435. Automated nonlinear regression modeling for HCI.">435. Automated nonlinear regression modeling for HCI.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556999">Paper Link</a>    Pages:3899-3902</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/o/Oulasvirta:Antti">Antti Oulasvirta</a></p>
<p>Abstract:
Predictive models in HCI, such as models of user performance, are often expressed as multivariate nonlinear regressions. This approach has been preferred, because it is compact and allows scrutiny. However, existing modeling tools in HCI, along with the common statistical packages, are limited to predefined nonlinear models or support linear models only. To assist researchers in the task of identifying novel nonlinear models, we propose a stochastic local search method that constructs equations iteratively. Instead of predefining a model equation, the researcher defines constraints that guide the search process. Comparison of outputs to published baselines in HCI shows improvements in model fit in seven out of 11 cases. We present a few ways in which the method can help HCI researchers explore modeling problems. We conclude that the approach is particularly suitable for complex datasets that have many predictor variables.</p>
<p>Keywords:
model selection; multivariate nonlinear regression models; predictive modeling in human--computer interaction</p>
<h2 id="Engaging older adults through technology    4">Engaging older adults through technology    4</h2>
<h3 id="436. Understanding digital and material social communications for older adults.">436. Understanding digital and material social communications for older adults.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557133">Paper Link</a>    Pages:3903-3912</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hope:Alexis">Alexis Hope</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwaba:Ted">Ted Schwaba</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Piper:Anne_Marie">Anne Marie Piper</a></p>
<p>Abstract:
Online technologies are promising for helping older adults maintain social connectedness, particularly with younger people, yet many older adults resist or participate minimally in the mainstream technologies used by younger members of their social network. We present results from an interview study involving 22 older adults (age 71-92) to understand communication preferences and values related to social media. Seniors articulate many concerns with online social media, including the time required for legitimate participation, the loss of deeper communication, content irrelevance, and privacy. Additionally, older adults engage in social practices that could be supported by online social technologies, but they rarely use such tools. The theme of material social communications emerges from our data, and we examine this in context of online social media. We conclude with design considerations for the development of social media for older adults, and as part of this we describe the notion of bridging technologies as a framework for intergenerational communication design.</p>
<p>Keywords:
materiality.; older adults; social media; social network sites</p>
<h3 id="437. Never too old: engaging retired people inventing the future with MaKey MaKey.">437. Never too old: engaging retired people inventing the future with MaKey MaKey.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557184">Paper Link</a>    Pages:3913-3922</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Rogers:Yvonne">Yvonne Rogers</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Paay:Jeni">Jeni Paay</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brereton:Margot">Margot Brereton</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vaisutis:Kate">Kate Vaisutis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Marsden:Gary">Gary Marsden</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vetere:Frank">Frank Vetere</a></p>
<p>Abstract:
Within HCI, aging is often viewed in terms of designing assistive technologies to improve the lives of older people, such as those who are suffering from frailty or memory loss. Our research adopts a very different approach, reframing the relationship in terms of wisdom, creativity and invention. We ran a series of workshops where groups of retirees, aged between early 60s and late 80s, used the MaKey MaKey inventor's toolkit. We asked them to think about inventing the future and suggest ideas for new technologies. Our findings showed that they not only rose to the challenge but also mastered the technology, collaborated intensely together while using it and freely and at length discussed their own, their family's and others' relationship with technology. We discuss the value of empowering people in this way and consider what else could be invented to enable more people to be involved in the design and use of creative technologies.</p>
<p>Keywords:
aging; creativity; future technology; invention; makey makey; retired people; toolkits</p>
<h3 id="438. What's on your mind?: investigating recommendations for inclusive social networking and older adults.">438. What's on your mind?: investigating recommendations for inclusive social networking and older adults.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556992">Paper Link</a>    Pages:3923-3932</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/n/Norval:Chris">Chris Norval</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Arnott:John_L=">John L. Arnott</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hanson:Vicki_L=">Vicki L. Hanson</a></p>
<p>Abstract:
Social networking sites (SNSs) are becoming increasingly popular as a method for social interaction. While research has reported benefits associated with components of SNS usage, a digital divide has emerged between younger and older users. SNSs can be useful for communicating with family members and helping one feel digitally included; however, there are a wide range of reasons why many older adults choose not to use this kind of technology. We present a series of user studies investigating the barriers and challenges that SNSs can present to older users. These user studies led to the derivation of user recommendations to mitigate these barriers. The recommendations were then evaluated within a comparative evaluation which involved 25 older adults completing tasks on two interface versions of a simulation SNS. We present the recommendations and the methods of their creation and evaluation. Implications for developers of SNSs are discussed.</p>
<p>Keywords:
comparative evaluation; inclusive design; older adults; recommendations; social networking sites</p>
<h3 id="439. Being senior and ICT: a study of seniors using ICT in China.">439. Being senior and ICT: a study of seniors using ICT in China.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557248">Paper Link</a>    Pages:3933-3942</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Sun:Yuling">Yuling Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Ding:Xianghua">Xianghua Ding</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lindtner:Silvia">Silvia Lindtner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lu:Tun">Tun Lu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gu:Ning">Ning Gu</a></p>
<p>Abstract:
System design for seniors often focuses on the decline of their biological capabilities and social connectedness. This approach has been challenged as too simplistic to capture what it really means to be senior. This paper presents a qualitative study of 17 seniors in urban China (age ranging from 50s to 70s), who have adopted and incorporated ICT into their daily lives. Findings from this study show that the ways in which seniors attend to ICT are not simply shaped by changes in health or other wellbeing, but also by their life attitudes, value systems, relationships to younger generations as well as historical specifics during their coming of age. This paper contributes by showing that 1) what it means to be senior is shaped from within a whole social ecology of past and current experiences, values and interactions; 2) senior identities are not fixed, but continuously negotiated, articulated and enacted through ICT; 3) social interaction and access of technologies are highly intertwined.</p>
<p>Keywords:
companionship; cross-generational communication; elders; ict; qualitative study; seniors; values</p>
<h2 id="Computer mediated intimacy and romance    4">Computer mediated intimacy and romance    4</h2>
<h3 id="440. The lonely raccoon at the ball: designing for intimacy, sociability, and selfhood.">440. The lonely raccoon at the ball: designing for intimacy, sociability, and selfhood.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557127">Paper Link</a>    Pages:3943-3952</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Jeffrey">Jeffrey Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Bardzell:Shaowen">Shaowen Bardzell</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zhang:Guo">Guo Zhang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pace:Tyler">Tyler Pace</a></p>
<p>Abstract:
Designing for sociable systems requires, among other abilities, a sensitivity to the meanings, structures, and nuances of technology-mediated experiences that are simultaneously felt by users to be intimate and also social. Such a sensitivity is not easily acquired, and design researchers have recommended the use of social theories to guide designers' readings of technology-mediated social experiences. We use philosopher Michel Foucault's theory of identity (and social power, discourse, sexuality, creativity, and style) known as "the care of the self," as a scaffold with which to produce a sensitive interpretation of the intimacy (and expert social creative) practices of adult users of the virtual world Second Life (SL). This reading sheds light on several skilled and creative intimacy practices in SL. It also offers a philosophically grounded hermeneutic strategy for designers interested in analyzing intimate experiences.</p>
<p>Keywords:
amateurs; creativity; design; hci; identity; intimacy; maker culture; making; sexuality; sociability; user experience</p>
<h3 id="441. Room for interpretation: the role of self-esteem and CMC in romantic couple conflict.">441. Room for interpretation: the role of self-esteem and CMC in romantic couple conflict.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557177">Paper Link</a>    Pages:3953-3962</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Scissors:Lauren_E=">Lauren E. Scissors</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Roloff:Michael_E=">Michael E. Roloff</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gergle:Darren">Darren Gergle</a></p>
<p>Abstract:
This work explores the role of communication technologies during romantic couple conflict, and the impact that self-esteem has on behavior, preferences for communication channels, and attitudes about mediated communication during conflict. Results revealed that lower levels of self-esteem and communicating via text messaging (vs. face-to-face) were associated with increased distancing and perceived partner distancing behaviors. Lower levels of self-esteem and using mediated communication were also associated with a greater likelihood of thinking that a conflict had a negative impact on the relationship. Yet, there was no evidence to suggest that individuals with lower levels of self-esteem exhibited more negative behaviors and perceptions in text-based communication than in FtF communication. In addition, lower levels of self-esteem were associated with increased use of and preferences for text-based mediated communication over FtF communication during conflict. Overall, this study suggests that both self-esteem and communication channel impact the nature of romantic couple conflict.</p>
<p>Keywords:
computer-mediated communication (cmc); conflict; cscw; relationships; romantic couples; self-esteem</p>
<h3 id="442. Exploring affective communication through variable-friction surface haptics.">442. Exploring affective communication through variable-friction surface haptics.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557343">Paper Link</a>    Pages:3963-3972</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/m/Mullenbach:Joe">Joe Mullenbach</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shultz:Craig_D=">Craig D. Shultz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Colgate:J=_Edward">J. Edward Colgate</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Piper:Anne_Marie">Anne Marie Piper</a></p>
<p>Abstract:
This paper explores the use of variable friction surface haptics enabled by the TPad Tablet to support affective communication between pairs of users. We introduce three haptic applications for the TPad Tablet (text messaging, image sharing, and virtual touch) and evaluate the applications with 24 users, including intimate couples and strangers. Participants used haptics to communicate literal texture, denote action within a scene, convey emotional information, highlight content, express and engage in physical playfulness, and to provide one's partner with an experience or sensation. We conclude that users readily associate haptics with emotional expression and that the intimacy of touch in the contexts we study is best suited for communications with close social partners.</p>
<p>Keywords:
communication; surface haptics; tablet; touchscreen; variable friction</p>
<h3 id="443. Wrigglo: shape-changing peripheral for interpersonal mobile communication.">443. Wrigglo: shape-changing peripheral for interpersonal mobile communication.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557166">Paper Link</a>    Pages:3973-3976</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Park:Joohee">Joohee Park</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Park:Youngwoo">Youngwoo Park</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nam:Tek=Jin">Tek-Jin Nam</a></p>
<p>Abstract:
We introduce Wrigglo, a shape-changing smart phone peripheral that allows pairs of users to share wriggling movements with one another. Attached to a smart phone, Wrigglo captures the sender's motions and activates the receiver's Wrigglo which repeats the motion simultaneously. The result of our in-lab use observation with twelve couples showed that Wrigglo supported emotional and functional roles of body gestures and postures, creating vocabularies related to the motion of specific body parts and, to some extent, reflected the connected user's presence through the device's movement. Through its peripheral anthropomorphization, Wrigglo can deliver new forms of telepresence by embodied posturing and gesturing in mobile communication.</p>
<p>Keywords:
mobile peripheral; remote communication; shape-changing</p>
<h2 id="Network of care    3">Network of care    3</h2>
<h3 id="444. Recreating living experiences from past memories through virtual worlds for people with dementia.">444. Recreating living experiences from past memories through virtual worlds for people with dementia.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557035">Paper Link</a>    Pages:3977-3986</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Siriaraya:Panote">Panote Siriaraya</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Ang:Chee_Siang">Chee Siang Ang</a></p>
<p>Abstract:
This paper describes a study aimed to understand the use of 3D virtual world (VW) technology to support life engagement for people with dementia in long-term care. Three versions of VW prototypes (reminiscence room, virtual tour and gardening) utilising gestured-base interaction were developed iteratively. These prototypes were tested with older residents (80+) with dementia in care homes and their caregivers. Data collection was based on observations of how the residents and care staff interacted collaboratively with the VW. We discussed in depth the use of VWs in stimulating past memories and how this technology could help enhance their sense of self through various means. We also highlighted key approaches in designing VWs to sustain attention, create ludic experiences and facilitate interaction for older people with dementia.</p>
<p>Keywords:
3d virtual worlds; care home; dementia; gesture-based interaction; older people</p>
<h3 id="445. Addressing the subtleties in dementia care: pre-study & evaluation of a GPS monitoring system.">445. Addressing the subtleties in dementia care: pre-study &amp; evaluation of a GPS monitoring system.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557307">Paper Link</a>    Pages:3987-3996</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wan:Lin">Lin Wan</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller_0002:Claudia">Claudia Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Wulf:Volker">Volker Wulf</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Randall:David_William">David William Randall</a></p>
<p>Abstract:
In this work we present a user-centered development process for a GPS-based monitoring system to be used in dementia care. Our research covers a full design process including a qualitative-empirical pre-study, the prototyping process and the investigation of long-term appropriation processes of the stable prototypes in three different practice environments. Specifically, we deal with the problem of 'wandering' by persons suffering from late-phase dementia. Although GPS tracking is not a novel technological objective, the usage of those systems in dementia care remains very low. The paper therefore takes a socio-technical stance on development and appropriation of GPS technology in dementia care and assesses the practical and ideological issues surrounding care to understand why. We additionally provide design research in two different settings, familial and institutional care, and report on the design of a GPS-based tracking system reflecting these considerations. What comes to the fore is the need for ICT to reflect complex organizational, ideological and practical issues that form part of a moral universe where sensitivity is crucial.</p>
<p>Keywords:
autonomy; dementia; evaluation; gps monitoring system; privacy</p>
<h3 id="446. Sweet Home: understanding diabetes management via a chinese online community.">446. Sweet Home: understanding diabetes management via a chinese online community.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557344">Paper Link</a>    Pages:3997-4006</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/z/Zhou:Xiaomu">Xiaomu Zhou</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Sun:Si">Si Sun</a> ; <a href="http://dblp.uni-trier.de/pers/hd/y/Yang:Jiang">Jiang Yang</a></p>
<p>Abstract:
China has overtaken India and the U.S. as host to the largest diabetic population in the world. Many problems exist in the Chinese healthcare system and very small number of diabetes patients receives treatment. Our paper reports on a case study through the lens of an online diabetes patient community, Sweet Home. We conducted participant observations, text analysis, and interviews, to understand the health management of patients at Sweet Home. Our findings reveal that patients' understanding of diabetes, their choice of treatments, their routine management, and their interactions with others (in the physical world) and among themselves (in the online world) are influenced by many factors: belief in traditional Chinese versus western medicine, cultural and social norms regarding social eating and drinking, conflicts over self-images, and responses to comments and pressures of coworkers. That is, social context may significantly affect patients' behaviors and each individual patient's actions may also help reshape the social context. We draw out implications for how our society as a whole may respond to these issues, from the perspective of public health, education, and information technology design.</p>
<p>Keywords:
chinese medicine; chinese table culture; chronic disease management; diabetes; online community; social eating</p>
<h2 id="Tutorials    4">Tutorials    4</h2>
<h3 id="447. Investigating the feasibility of extracting tool demonstrations from in-situ video content.">447. Investigating the feasibility of extracting tool demonstrations from in-situ video content.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557142">Paper Link</a>    Pages:4007-4016</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Lafreniere:Ben">Ben Lafreniere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grossman:Tovi">Tovi Grossman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Matejka:Justin">Justin Matejka</a> ; <a href="http://dblp.uni-trier.de/pers/hd/f/Fitzmaurice:George_W=">George W. Fitzmaurice</a></p>
<p>Abstract:
Short video demonstrations are effective resources for helping users to learn tools in feature-rich software. However manually creating demonstrations for the hundreds (or thousands) of individual features in these programs would be impractical. In this paper, we investigate the potential for identifying good tool demonstrations from within screen recordings of users performing real-world tasks. Using an instrumented image-editing application, we collected workflow video content and log data from actual end users. We then developed a heuristic for identifying demonstration clips, and had the quality of a sample set of clips evaluated by both domain experts and end users. This multi-step approach allowed us to characterize the quality of 'naturally occurring' tool demonstrations, and to derive a list of good and bad features of these videos. Finally, we conducted an initial investigation into using machine learning techniques to distinguish between good and bad demonstrations.</p>
<p>Keywords:
feature-rich software; help; in-situ usage data; learning; toolclips; video tooltips</p>
<h3 id="448. Crowdsourcing step-by-step information extraction to enhance existing how-to videos.">448. Crowdsourcing step-by-step information extraction to enhance existing how-to videos.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556986">Paper Link</a>    Pages:4017-4026</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/k/Kim:Juho">Juho Kim</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Nguyen:Phu_Tran">Phu Tran Nguyen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/w/Weir:Sarah_A=">Sarah A. Weir</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Guo:Philip_J=">Philip J. Guo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Miller:Robert_C=">Robert C. Miller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gajos:Krzysztof_Z=">Krzysztof Z. Gajos</a></p>
<p>Abstract:
Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of existing how-to videos with step-by-step annotations. We first performed a formative study to verify that annotations are actually useful to learners. We created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player. To add the needed step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all three domains with 77% precision and 81% recall.</p>
<p>Keywords:
crowdsourcing; how-to videos; video annotation.</p>
<h3 id="449. EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration.">449. EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557407">Paper Link</a>    Pages:4027-4036</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Wang:Cheng=Yao">Cheng-Yao Wang</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chu:Wei=Chen">Wei-Chen Chu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Hou=Ren">Hou-Ren Chen</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hsu:Chun=Yen">Chun-Yen Hsu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chen:Mike_Y=">Mike Y. Chen</a></p>
<p>Abstract:
We present EverTutor, a system that automatically generates interactive tutorials on smartphone from user demonstration. For tutorial authors, it simplifies the tutorial creation. For tutorial users, it provides contextual step-by-step guidance and avoids the frequent context switching between tutorials and users' primary tasks. In order to generate the tutorials automatically, EverTutor records low-level touch events to detect gestures and identify on-screen targets. When a tutorial is browsed, the system uses vision-based techniques to locate the target regions and overlays the corresponding input prompt contextually. It also identifies the correctness of users' interaction to guide the users step by step. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, and we compared EverTutor's interactive tutorials to static and video ones. Study results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials. Also, when using the tutorials, the task completion time for interactive tutorials were 3-6 times faster than static and video tutorials regardless of age group. In terms of user preference, 83% of the users chose interactive type as the preferred tutorial type and rated it easiest to follow and easiest to understand.</p>
<p>Keywords:
contextual help; smartphone; touchscreen gesture; tutorials</p>
<h3 id="450. TaggedComments: promoting and integrating user comments in online application tutorials.">450. TaggedComments: promoting and integrating user comments in online application tutorials.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557118">Paper Link</a>    Pages:4037-4046</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Bunt:Andrea">Andrea Bunt</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dubois:Patrick">Patrick Dubois</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lafreniere:Ben">Ben Lafreniere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Terry:Michael_A=">Michael A. Terry</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Cormack:David_T=">David T. Cormack</a></p>
<p>Abstract:
User comments posted to popular online tutorials constitute a rich additional source of information for readers, yet current designs for displaying user comments on tutorial webpages do little to support their use. Instead, comments are separated from the tutorial content they reference and tend to be ordered according to post date. We propose and evaluate the TaggedComments system, a new approach to displaying comments that users post to online tutorials. Using tags supplied by commenters, TaggedComments seeks to enhance the role of user comments by 1) improving their visibility, 2) allowing users to personalize their use of the comments according to their particular information needs, and 3) providing direct access to potentially helpful comments from the tutorial content. A laboratory evaluation with 16 participants shows that, in comparison to the standard comment layout, TaggedComments significantly improves users' subjective impressions of comment utility when interacting with Photoshop tutorials.</p>
<p>Keywords:
feature-rich software; tagging; web-based tutorials</p>
<h2 id="Driving interfaces and evaluations    3">Driving interfaces and evaluations    3</h2>
<h3 id="451. A smartphone-based sensing platform to model aggressive driving behaviors.">451. A smartphone-based sensing platform to model aggressive driving behaviors.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557321">Paper Link</a>    Pages:4047-4056</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/h/Hong:Jin=Hyuk">Jin-Hyuk Hong</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Margines:Ben">Ben Margines</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dey:Anind_K=">Anind K. Dey</a></p>
<p>Abstract:
Driving aggressively increases the risk of accidents. Assessing a person's driving style is a useful way to guide aggressive drivers toward having safer driving behaviors. A number of studies have investigated driving style, but they often rely on the use of self-reports or simulators, which are not suitable for the real-time, continuous, automated assessment and feedback on the road. In order to understand and model aggressive driving style, we construct an in-vehicle sensing platform that uses a smartphone instead of using heavyweight, expensive systems. Utilizing additional cheap sensors, our sensing platform can collect useful information about vehicle movement, maneuvering and steering wheel movement. We use this data and apply machine learning to build a driver model that evaluates drivers' driving styles based on a number of driving-related features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed the characteristics of drivers who have an aggressive driving style. Our model classified those drivers with an accuracy of 90.5% (violation-class) and 81% (questionnaire-class). We describe how, in future work, our model can be used to provide real-time feedback to drivers using only their current smartphone.</p>
<p>Keywords:
driving assessment; in-vehicle sensing platform; smartphone</p>
<h3 id="452. Classifying driver workload using physiological and driving performance data: two field studies.">452. Classifying driver workload using physiological and driving performance data: two field studies.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557068">Paper Link</a>    Pages:4057-4066</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/s/Solovey:Erin_Treacy">Erin Treacy Solovey</a> ; <a href="http://dblp.uni-trier.de/pers/hd/z/Zec:Marin">Marin Zec</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perez:Enrique_Abdon_Garcia">Enrique Abdon Garcia Perez</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reimer:Bryan">Bryan Reimer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mehler:Bruce">Bruce Mehler</a></p>
<p>Abstract:
Understanding the driver's cognitive load is important for evaluating in-vehicle user interfaces. This paper describes experiments to assess machine learning classification algorithms on their ability to automatically identify elevated cognitive workload levels in drivers, leading towards the development of robust tools for automobile user interface evaluation. We look at using both driver performance as well as physiological data. These measures can be collected in real-time and do not interfere with the primary task of driving the vehicle. We report classification accuracies of up to 90% for detecting elevated levels of cognitive load, and show that the inclusion of physiological data leads to higher classification accuracy than vehicle sensor data evaluated alone. Finally, we show results suggesting that models can be built to classify cognitive load across individuals, instead of building individual models for each per-son. By collecting data from drivers in two large field studies on the highway (20 drivers and 99 drivers), this work extends prior work and demonstrates feasibility and potential of such measures for HCI research in vehicles.</p>
<p>Keywords:
cognitive workload; driving; heart rate; machine learning; physiological computing; skin conductance</p>
<h3 id="453. Evaluating multimodal driver displays under varying situational urgency.">453. Evaluating multimodal driver displays under varying situational urgency.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2556988">Paper Link</a>    Pages:4067-4076</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Politis:Ioannis">Ioannis Politis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Brewster:Stephen_A=">Stephen A. Brewster</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Pollick:Frank_E=">Frank E. Pollick</a></p>
<p>Abstract:
Previous studies have investigated audio, visual and tactile driver warnings, indicating the importance of communicating the appropriate level of urgency to the drivers. However, these modalities have never been combined exhaustively and tested under conditions of varying situational urgency to assess their effectiveness both in the presence and absence of critical driving events. This paper describes an experiment evaluating all multimodal combinations of such warnings under two contexts of situational urgency: a lead car braking and not braking. The results showed that participants responded quicker to more urgent warnings, especially in the presence of a car braking. They also responded faster to the multimodal as opposed to unimodal signals. Driving behaviour improved in the presence of the warnings and the absence of a car braking. These results highlight the influence of urgency and number of modalities in warning design and indicate the utility of non-visual warnings in driving.</p>
<p>Keywords:
audio; lateral deviation; multimodal interaction; response time; simulator; situational urgency; steering angle; tactile; visual; warnings</p>
<h2 id="Gesture-based interaction    4">Gesture-based interaction    4</h2>
<h3 id="454. Multi-viewer gesture-based interaction for omni-directional video.">454. Multi-viewer gesture-based interaction for omni-directional video.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557113">Paper Link</a>    Pages:4077-4086</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Ruiz:Gustavo_Alberto_Rovelo">Gustavo Alberto Rovelo Ruiz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vanacken:Davy">Davy Vanacken</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Luyten:Kris">Kris Luyten</a> ; <a href="http://dblp.uni-trier.de/pers/hd/a/Abad:Francisco">Francisco Abad</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Camahort:Emilio">Emilio Camahort</a></p>
<p>Abstract:
Omni-directional video (ODV) is a novel medium that offers viewers a 360 panoramic recording. This type of content will become more common within our living rooms in the near future, seeing that immersive displaying technologies such as 3D television are on the rise. However, little attention has been given to how to interact with ODV content. We present a gesture elicitation study in which we asked users to perform mid-air gestures that they consider to be appropriate for ODV interaction, both for individual as well as collocated settings. We are interested in the gesture variations and adaptations that come forth from individual and collocated usage. To this end, we gathered quantitative and qualitative data by means of observations, motion capture, questionnaires and interviews. This data resulted in a user-defined gesture set for ODV, alongside an in-depth analysis of the variation in gestures we observed during the study.</p>
<p>Keywords:
gesture elicitation; multi-user interaction; omni-directional video; user-defined gestures</p>
<h3 id="455. Making big gestures: effects of gesture size on observability and identification for co-located group awareness.">455. Making big gestures: effects of gesture size on observability and identification for co-located group awareness.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557219">Paper Link</a>    Pages:4087-4096</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/Reetz:Adrian">Adrian Reetz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gutwin:Carl">Carl Gutwin</a></p>
<p>Abstract:
Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.</p>
<p>Keywords:
consequential communication; gestures; group awareness</p>
<h3 id="456. A chair as ubiquitous input device: exploring semaphoric chair gestures for focused and peripheral interaction.">456. A chair as ubiquitous input device: exploring semaphoric chair gestures for focused and peripheral interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557051">Paper Link</a>    Pages:4097-4106</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/p/Probst:Kathrin">Kathrin Probst</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lindlbauer:David">David Lindlbauer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Haller:Michael">Michael Haller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schwartz:Bernhard">Bernhard Schwartz</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Schrempf:Andreas">Andreas Schrempf</a></p>
<p>Abstract:
During everyday office work we are used to controlling our computers with keyboard and mouse, while the majority of our body remains unchallenged and the physical workspace around us stays largely unattended. Addressing this untapped potential, we explore the concept of turning a flexible office chair into a ubiquitous input device. To facilitate daily desktop work, we propose the utilization of semaphoric chair gestures that can be assigned to specific application functionalities. The exploration of two usage scenarios in the context of focused and peripheral interaction demonstrates high potential of chair gestures as additional input modality for opportunistic, hands-free interaction.</p>
<p>Keywords:
gestural interaction; input technologies; interactive chair</p>
<h3 id="457. Exploring the design space of gestural interaction with active tokens through user-defined gestures.">457. Exploring the design space of gestural interaction with active tokens through user-defined gestures.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557373">Paper Link</a>    Pages:4107-4116</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/v/Valdes:Consuelo">Consuelo Valdes</a> ; <a href="http://dblp.uni-trier.de/pers/hd/e/Eastman:Diana">Diana Eastman</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Grote:Casey">Casey Grote</a> ; <a href="http://dblp.uni-trier.de/pers/hd/t/Thatte:Shantanu">Shantanu Thatte</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Shaer:Orit">Orit Shaer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mazalek:Ali">Ali Mazalek</a> ; <a href="http://dblp.uni-trier.de/pers/hd/u/Ullmer:Brygg">Brygg Ullmer</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Konkel:Miriam">Miriam Konkel</a></p>
<p>Abstract:
Multi-touch and tangible interfaces provide unique opportunities for enhancing learning and discovery with big data. However, existing interaction techniques have limitations when manipulating large data sets. Our goal is to define novel interaction techniques for multi-touch and tangible interfaces, which support the construction of complex queries for big data. In this paper, we present results from a study which investigates the use of gestural interaction with active tokens for manipulating large data sets. In particular, we studied user expectations of a hybrid tangible and gestural language engaging this space. Our main results include a vocabulary of user-defined gestures for interaction with active tokens, which extends beyond familiar multi-touch gestures; characterization of the design space of gestural interaction with active tokens; and insight into participants' mental models, including common metaphors. We also present implications for the design of multi-touch and tangible interfaces with active tokens.</p>
<p>Keywords:
cross-device interaction; gestures; multi-display environments; physical tokens.; queries; tabletop</p>
<h2 id="Interactive surfaces and pervasive displays    4">Interactive surfaces and pervasive displays    4</h2>
<h3 id="458. Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D).">458. Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D).</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557365">Paper Link</a>    Pages:4117-4126</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Winkler:Christian">Christian Winkler</a> ; <a href="http://dblp.uni-trier.de/pers/hd/s/Seifert:Julian">Julian Seifert</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dobbelstein:David">David Dobbelstein</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rukzio:Enrico">Enrico Rukzio</a></p>
<p>Abstract:
The vision of pervasive ambient information displays which show relevant information has not yet come true. One of the main reasons is the limited number of available displays in the environment which is a fundamental requirement of the original vision. We introduce the concept of an Ambient Mobile Pervasive Display AMP-D which is a wearable projector system that constantly projects an ambient information display in front of the user. The floor display provides serendipitous access to public and personal information. The display is combined with a projected display on the user's hand, forming a continuous interaction space that is controlled by hand gestures. The paper introduces this novel device concept, discusses its interaction design, and explores its advantages through various implemented application examples. Furthermore, we present the AMP-D prototype which illustrates the involved challenges concerning hardware, sensing, and visualization.</p>
<p>Keywords:
ambient displays; augmented reality; personal projection; pervasive displays</p>
<h3 id="459. Bigger is not always better: display size, performance, and task load during peephole map navigation.">459. Bigger is not always better: display size, performance, and task load during peephole map navigation.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557071">Paper Link</a>    Pages:4127-4136</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/r/R=auml=dle:Roman">Roman Rdle</a> ; <a href="http://dblp.uni-trier.de/pers/hd/j/Jetter:Hans=Christian">Hans-Christian Jetter</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/M=uuml=ller:Jens">Jens Mller</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Reiterer:Harald">Harald Reiterer</a></p>
<p>Abstract:
Dynamic peephole navigation is an increasingly popular technique for navigating large information spaces such as maps. Users can view the map through handheld, spatially aware displays that serve as peepholes and navigate the map by moving these displays in physical space. We conducted a controlled experiment of peephole map navigation with 16 participants to better understand the effect of a peephole's size on users' map navigation behavior, navigation performance, and task load. Simulating different peephole sizes from 4' (smartphone) up to 120' (control condition), we confirmed that larger peepholes significantly improve learning speed, navigation speed, and reduce task load; however, this added benefit diminishes with growing sizes. Our data shows that a relatively small, tablet-sized peephole can serve as a 'sweet spot' between peephole size and both user navigation performance and user task load.</p>
<p>Keywords:
display size; experimentation; map navigation; navigation performance; peephole navigation; user study</p>
<h3 id="460. Mechanical force redistribution: enabling seamless, large-format, high-accuracy surface interaction.">460. Mechanical force redistribution: enabling seamless, large-format, high-accuracy surface interaction.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557172">Paper Link</a>    Pages:4137-4146</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/g/Grau:Alex_M=">Alex M. Grau</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hendee:Charles">Charles Hendee</a> ; <a href="http://dblp.uni-trier.de/pers/hd/r/Rizzo:John=Ross">John-Ross Rizzo</a> ; <a href="http://dblp.uni-trier.de/pers/hd/p/Perlin:Ken">Ken Perlin</a></p>
<p>Abstract:
We present Mechanical Force Redistribution (MFR): a method of sensing which creates an anti-aliased image of forces applied to a surface. This technique mechanically focuses the force from a surface onto adjacent discrete forcels (force sensing cells) by way of protrusions (small bumps or pegs), allowing for high-accuracy interpolation between adjacent discrete forcels. MFR works with any force transducing technique or material, including force variable resistive inks, piezoelectric materials and capacitive force plates. MFR sensors can be tiled such that the signal is continuous across contiguous tiles. By minimizing active materials and computational complexity, MFR makes large-format interactive walls, collaborative tabletops and high-resolution floor tiles possible and economically feasible.</p>
<p>Keywords:
floors; force; input device; large format; mechanical force redistribution; pressure; sensor; tabletop; walls</p>
<h3 id="461. Effects of display size and navigation type on a classification task.">461. Effects of display size and navigation type on a classification task.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557020">Paper Link</a>    Pages:4147-4156</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/l/Liu:Can">Can Liu</a> ; <a href="http://dblp.uni-trier.de/pers/hd/c/Chapuis:Olivier">Olivier Chapuis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/b/Beaudouin=Lafon:Michel">Michel Beaudouin-Lafon</a> ; <a href="http://dblp.uni-trier.de/pers/hd/l/Lecolinet:Eric">Eric Lecolinet</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Mackay:Wendy_E=">Wendy E. Mackay</a></p>
<p>Abstract:
The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.</p>
<p>Keywords:
classification task; lenses; overview+detail; pan-and-zoom; physical navigation; wall-size display</p>
<h2 id="Social Media for Relationships    4">Social Media for Relationships    4</h2>
<h3 id="462. Stewarding a legacy: responsibilities and relationships in the management of post-mortem data.">462. Stewarding a legacy: responsibilities and relationships in the management of post-mortem data.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557059">Paper Link</a>    Pages:4157-4166</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Brubaker:Jed_R=">Jed R. Brubaker</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Dombrowski:Lynn">Lynn Dombrowski</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gilbert:Anita_M=">Anita M. Gilbert</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kusumakaulika:Nafiri">Nafiri Kusumakaulika</a> ; <a href="http://dblp.uni-trier.de/pers/hd/h/Hayes:Gillian_R=">Gillian R. Hayes</a></p>
<p>Abstract:
This paper extends research on the giving and inheriting of digital artifacts by examining social network site accounts post-mortem. Given the important role that social network sites play in online bereavement practices, we conducted a series of in-depth qualitative interviews to explore issues around inheritance and post-mortem data management of Facebook accounts. We found that participants focused less on ownership of the data, and instead on the duties and potential conflicts associated with maintaining an account post-mortem. Subsequently, we argue for 'stewardship' as an alternative to inheritance for framing post-mortem data management practices. Analysis of post-mortem data management activities highlights how stewards are accountable and responsible to the deceased and various survivors. However, weighing competing responsibilities is complicated by varied relationships with disparate survivors, as well as the inability to consult with the deceased. Based on our findings, we claim that post-mortem solutions need to account for the needs of stewards in addition to those of the deceased and survivors. We suggest that a model of stewardship better accounts for the interpersonal responsibilities that accompany online data than inheritance alone.</p>
<p>Keywords:
death; digital legacy; facebook; inheritance; qualitative study; social network sites; stewardship</p>
<h3 id="463. Captioned photographs in psychosocial aged care: relationship building and boundary work.">463. Captioned photographs in psychosocial aged care: relationship building and boundary work.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557290">Paper Link</a>    Pages:4167-4176</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/w/Waycott:Jenny">Jenny Waycott</a> ; <a href="http://dblp.uni-trier.de/pers/hd/d/Davis:Hilary">Hilary Davis</a> ; <a href="http://dblp.uni-trier.de/pers/hd/v/Vetere:Frank">Frank Vetere</a> ; <a href="http://dblp.uni-trier.de/pers/hd/m/Morgans:Amee">Amee Morgans</a> ; <a href="http://dblp.uni-trier.de/pers/hd/g/Gruner:Alan">Alan Gruner</a> ; <a href="http://dblp.uni-trier.de/pers/hd/o/Ozanne:Elizabeth">Elizabeth Ozanne</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kulik:Lars">Lars Kulik</a></p>
<p>Abstract:
In this paper we examine the use of a novel social technology to support the provision of formal aged care services to clients who live in their own homes. Social technologies offer enormous potential for enhancing aged care, but research on their use in aged care has largely focused on institutional or informal care settings, rather than formal care in the home. Meanwhile, technologies for aging in place typically focus on monitoring and security, rather than psychosocial support. We conducted a field study in which aged care managers used a photo and message-sharing tool to communicate with clients living in their own homes. Our findings demonstrate that visual and social forms of communication are valuable for supporting psychosocial care-giving, but there are barriers to effectively adopting new communication tools in this setting. Time constraints inhibited care managers' use of the technology, which was also influenced by their efforts to carefully maintain boundaries between their personal and professional lives.</p>
<p>Keywords:
aged care; ipad; photo-sharing; social technologies</p>
<h3 id="464. The routines and needs of grandparents and parents for grandparent-grandchild conversations over distance.">464. The routines and needs of grandparents and parents for grandparent-grandchild conversations over distance.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557255">Paper Link</a>    Pages:4177-4186</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/f/Forghani:Azadeh">Azadeh Forghani</a> ; <a href="http://dblp.uni-trier.de/pers/hd/n/Neustaedter:Carman">Carman Neustaedter</a></p>
<p>Abstract:
A variety of systems have been designed to support communication between distance-separated grandparents and grandchildren. Yet there are few studies of the actual conversational routines of these groups as well as the social challenges that might arise as a result of technology usage. To address this gap, we conducted an interview and diary study that explores the conversational practices of distance-separated grandparents and young grandchildren (aged 3-10) from the perspective of the grandparents and parents of the children. Our results describe the focus of grandparent-grandchild conversations and show that grandparent-grandchild communication is not without its challenges: grandparents sometimes feel self-conscious, perceive that parents or children will be annoyed if they ask too many questions, and do not want to interfere too much in their grandchildren's lives. The implication is that designs should attempt to support the conversation routines and needs of grandparents and grandchildren while attempting to mitigate the social challenges.</p>
<p>Keywords:
design; family communication; grandparent and grandchild communication</p>
<h3 id="465. Growing closer on facebook: changes in tie strength through social network site use.">465. Growing closer on facebook: changes in tie strength through social network site use.</h3>
<p><a href="http://doi.acm.org/10.1145/2556288.2557094">Paper Link</a>    Pages:4187-4196</p>
<p>Authors:
<a href="http://dblp.uni-trier.de/pers/hd/b/Burke:Moira">Moira Burke</a> ; <a href="http://dblp.uni-trier.de/pers/hd/k/Kraut:Robert_E=">Robert E. Kraut</a></p>
<p>Abstract:
Scientists debate whether people grow closer to their friends through social networking sites like Facebook, whether those sites displace more meaningful interaction, or whether they simply reflect existing ties. Combining server log analysis and longitudinal surveys of 3,649 Facebook users reporting on relationships with 26,134 friends, we find that communication on the site is associated with changes in reported relationship closeness, over and above effects attributable to their face-to-face, phone, and email contact. Tie strength increases with both one-on-one communication, such as posts, comments, and messages, and through reading friends' broadcasted content, such as status updates and photos. The effect is greater for composed pieces, such as comments, posts, and messages than for 'one-click' actions such as 'likes.' Facebook has a greater impact on non-family relationships and ties who do not frequently communicate via other channels.</p>
<p>Keywords:
facebook; families; friendship; relational closeness; social network sites; social relationships; tie strength</p>
 

<div class="home">
<i title='' onclick="location.href='../index.html'"><i class="fa fa-home fa-lg"></i></i>
</div>

<div class="toc">
<i id="showLeftPush" title=''><i class="fa fa-list fa-lg"></i></i>
</div>

<!-- Classie - class helper functions by @desandro https://github.com/desandro/classie -->
<script>
	var menuLeft = document.getElementById( 'menu-s1' ),
		showLeftPush = document.getElementById( 'showLeftPush' ),
		body = document.body;

	showLeftPush.onclick = function() {
		classie.toggle( this, 'active' );
		classie.toggle( body, 'cbp-spmenu-push-toright' );
		classie.toggle( menuLeft, 'cbp-spmenu-open' );
		disableOther( 'showLeftPush' );
	};
</script>

<div class="go-top" >
<i title='' onclick="window.scrollTo('0', '0')"><i class="fa fa-angle-double-up fa-2x"></i></i>
</div>

<div class="theme" >
<i title='' onclick="change_css()"><i class="fa fa-adjust fa-lg"></i></i>
</div>

<div id="footer">

  <p> <i class="fa fa-envelope-o fa-1x"></i>:&nbsp huntercmd@163.com &nbsp Published under<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh"> (CC) BY-NC-SA 3.0</a></p>

  <p>&copy; 2013 HunterCmd &nbsp <a href="https://github.com/huntercmd/ccf"><i class="fa fa-github fa-1x"></i>
  </p>
</div>

</body>
