 
<head>
<meta name="HunterCmd" charset="utf-8">

<link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
<link id="cssfile" rel="stylesheet" type="text/css" href="https://rawcdn.githack.com/huntercmd/blog/master/config/css/light.css">
<script src="https://rawcdn.githack.com/huntercmd/blog/d9beff1/config/css/skin.js"></script>
<script src="https://rawcdn.githack.com/huntercmd/blog/master/config/css/classie.js"></script>

<title>HunterCmd</title>
</head>

<body class="cbp-spmenu-push">

<nav class="cbp-spmenu cbp-spmenu-vertical cbp-spmenu-left" id="menu-s1" style="width: 320px;overflow: auto;
">

<h1>Table of contents</h1>
<ul>
<li><a href="#29th CIKM 2020:Virtual Event, Ireland">29th CIKM 2020:Virtual Event, Ireland</a><ul>
<li><a href="#Paper Num: 494 || Session Num: 10">Paper Num: 494 || Session Num: 10</a></li>
<li><a href="#Keynote Talks    2">Keynote Talks    2</a><ul>
<li><a href="#1. Ceres: Harvesting Knowledge from the Semi-structured Web.">1. Ceres: Harvesting Knowledge from the Semi-structured Web.</a></li>
<li><a href="#2. Accelerating Discovery Science with an Internet of FAIR Data and Services.">2. Accelerating Discovery Science with an Internet of FAIR Data and Services.</a></li>
</ul>
</li>
<li><a href="#Full Paper Track    193">Full Paper Track    193</a><ul>
<li><a href="#3. Ensemble Block Co-clustering: A Unified Framework for Text Data.">3. Ensemble Block Co-clustering: A Unified Framework for Text Data.</a></li>
<li><a href="#4. Learning to Personalize for Web Search Sessions.">4. Learning to Personalize for Web Search Sessions.</a></li>
<li><a href="#5. Optimization of Answer Set Programs for Consistent Query Answering by Means of First-Order Rewriting.">5. Optimization of Answer Set Programs for Consistent Query Answering by Means of First-Order Rewriting.</a></li>
<li><a href="#6. Spectral Relaxations and Fair Densest Subgraphs.">6. Spectral Relaxations and Fair Densest Subgraphs.</a></li>
<li><a href="#7. The Impact of Negative Triple Generation Strategies and Anomalies on Knowledge Graph Completion.">7. The Impact of Negative Triple Generation Strategies and Anomalies on Knowledge Graph Completion.</a></li>
<li><a href="#8. tdGraphEmbed: Temporal Dynamic Graph-Level Embedding.">8. tdGraphEmbed: Temporal Dynamic Graph-Level Embedding.</a></li>
<li><a href="#9. Learning to Match Jobs with Resumes from Sparse Interaction Data using Multi-View Co-Teaching Network.">9. Learning to Match Jobs with Resumes from Sparse Interaction Data using Multi-View Co-Teaching Network.</a></li>
<li><a href="#10. Incremental and Parallel Computation of Structural Graph Summaries for Evolving Graphs.">10. Incremental and Parallel Computation of Structural Graph Summaries for Evolving Graphs.</a></li>
<li><a href="#11. Do People and Neural Nets Pay Attention to the Same Words: Studying Eye-tracking Data for Non-factoid QA Evaluation.">11. Do People and Neural Nets Pay Attention to the Same Words: Studying Eye-tracking Data for Non-factoid QA Evaluation.</a></li>
<li><a href="#12. Fast and Scalable Outlier Detection with Sorted Hypercubes.">12. Fast and Scalable Outlier Detection with Sorted Hypercubes.</a></li>
<li><a href="#13. SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis.">13. SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis.</a></li>
<li><a href="#14. Laconic Image Classification: Human vs. Machine Performance.">14. Laconic Image Classification: Human vs. Machine Performance.</a></li>
<li><a href="#15. Retrievability based Document Selection for Relevance Feedback with Automatically Generated Query Variants.">15. Retrievability based Document Selection for Relevance Feedback with Automatically Generated Query Variants.</a></li>
<li><a href="#16. Learning Graph-Based Geographical Latent Representation for Point-of-Interest Recommendation.">16. Learning Graph-Based Geographical Latent Representation for Point-of-Interest Recommendation.</a></li>
<li><a href="#17. Continuous-Time Dynamic Graph Learning via Neural Interaction Processes.">17. Continuous-Time Dynamic Graph Learning via Neural Interaction Processes.</a></li>
<li><a href="#18. TGCN: Tag Graph Convolutional Network for Tag-Aware Recommendation.">18. TGCN: Tag Graph Convolutional Network for Tag-Aware Recommendation.</a></li>
<li><a href="#19. An Adaptive Embedding Framework for Heterogeneous Information Networks.">19. An Adaptive Embedding Framework for Heterogeneous Information Networks.</a></li>
<li><a href="#20. Improving End-to-End Sequential Recommendations with Intent-aware Diversification.">20. Improving End-to-End Sequential Recommendations with Intent-aware Diversification.</a></li>
<li><a href="#21. Unsupervised Cyberbullying Detection via Time-Informed Gaussian Mixture Model.">21. Unsupervised Cyberbullying Detection via Time-Informed Gaussian Mixture Model.</a></li>
<li><a href="#22. Product Quality Prediction with Convolutional Encoder-Decoder Architecture and Transfer Learning.">22. Product Quality Prediction with Convolutional Encoder-Decoder Architecture and Transfer Learning.</a></li>
<li><a href="#23. Matching in Selective and Balanced Representation Space for Treatment Effects Estimation.">23. Matching in Selective and Balanced Representation Space for Treatment Effects Estimation.</a></li>
<li><a href="#24. TPR: Text-aware Preference Ranking for Recommender Systems.">24. TPR: Text-aware Preference Ranking for Recommender Systems.</a></li>
<li><a href="#25. Offline Evaluation by Maximum Similarity to an Ideal Ranking.">25. Offline Evaluation by Maximum Similarity to an Ideal Ranking.</a></li>
<li><a href="#26. EPNet: Learning to Exit with Flexible Multi-Branch Network.">26. EPNet: Learning to Exit with Flexible Multi-Branch Network.</a></li>
<li><a href="#27. Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction.">27. Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction.</a></li>
<li><a href="#28. Opinion-aware Answer Generation for Review-driven Question Answering in E-Commerce.">28. Opinion-aware Answer Generation for Review-driven Question Answering in E-Commerce.</a></li>
<li><a href="#29. UPON: User Profile Transferring across Networks.">29. UPON: User Profile Transferring across Networks.</a></li>
<li><a href="#30. Evaluating Stochastic Rankings with Expected Exposure.">30. Evaluating Stochastic Rankings with Expected Exposure.</a></li>
<li><a href="#31. Towards Plausible Differentially Private ADMM Based Distributed Machine Learning.">31. Towards Plausible Differentially Private ADMM Based Distributed Machine Learning.</a></li>
<li><a href="#32. Graph Prototypical Networks for Few-shot Learning on Attributed Networks.">32. Graph Prototypical Networks for Few-shot Learning on Attributed Networks.</a></li>
<li><a href="#33. Neural Formatting for Spreadsheet Tables.">33. Neural Formatting for Spreadsheet Tables.</a></li>
<li><a href="#34. Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters.">34. Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters.</a></li>
<li><a href="#35. Towards Generalizable Deepfake Detection with Locality-aware AutoEncoder.">35. Towards Generalizable Deepfake Detection with Locality-aware AutoEncoder.</a></li>
<li><a href="#36. Quality-Aware Ranking of Arguments.">36. Quality-Aware Ranking of Arguments.</a></li>
<li><a href="#37. RelSen: An Optimization-based Framework for Simultaneously Sensor Reliability Monitoring and Data Cleaning.">37. RelSen: An Optimization-based Framework for Simultaneously Sensor Reliability Monitoring and Data Cleaning.</a></li>
<li><a href="#38. Critically Examining the Claimed Value of Convolutions over User-Item Embedding Maps for Recommender Systems.">38. Critically Examining the Claimed Value of Convolutions over User-Item Embedding Maps for Recommender Systems.</a></li>
<li><a href="#39. Query-to-Session Matching: Do NOT Forget History and Future during Response Selection for Multi-Turn Dialogue Systems.">39. Query-to-Session Matching: Do NOT Forget History and Future during Response Selection for Multi-Turn Dialogue Systems.</a></li>
<li><a href="#40. Learning from Textual Data in Database Systems.">40. Learning from Textual Data in Database Systems.</a></li>
<li><a href="#41. Rotate3D: Representing Relations as Rotations in Three-Dimensional Space for Knowledge Graph Embedding.">41. Rotate3D: Representing Relations as Rotations in Three-Dimensional Space for Knowledge Graph Embedding.</a></li>
<li><a href="#42. Set-Sequence-Graph: A Multi-View Approach Towards Exploiting Reviews for Recommendation.">42. Set-Sequence-Graph: A Multi-View Approach Towards Exploiting Reviews for Recommendation.</a></li>
<li><a href="#43. How and Why is An Answer (Still">43. How and Why is An Answer (Still) Correct? Maintaining Provenance in Dynamic Knowledge Graphs.</a> Correct? Maintaining Provenance in Dynamic Knowledge Graphs.)</li>
<li><a href="#44. MICK: A Meta-Learning Framework for Few-shot Relation Classification with Small Training Data.">44. MICK: A Meta-Learning Framework for Few-shot Relation Classification with Small Training Data.</a></li>
<li><a href="#45. Knowledge Graph Embedding Preserving Soft Logical Regularity.">45. Knowledge Graph Embedding Preserving Soft Logical Regularity.</a></li>
<li><a href="#46. GraSeq: Graph and Sequence Fusion Learning for Molecular Property Prediction.">46. GraSeq: Graph and Sequence Fusion Learning for Molecular Property Prediction.</a></li>
<li><a href="#47. Modelling User Behavior Dynamics with Embeddings.">47. Modelling User Behavior Dynamics with Embeddings.</a></li>
<li><a href="#48. Genetic Meta-Structure Search for Recommendation on Heterogeneous Information Network.">48. Genetic Meta-Structure Search for Recommendation on Heterogeneous Information Network.</a></li>
<li><a href="#49. Ranking Enhanced Dialogue Generation.">49. Ranking Enhanced Dialogue Generation.</a></li>
<li><a href="#50. Privacy-Preserving Classification with Secret Vector Machines.">50. Privacy-Preserving Classification with Secret Vector Machines.</a></li>
<li><a href="#51. Learning to Selectively Update State Neurons in Recurrent Networks.">51. Learning to Selectively Update State Neurons in Recurrent Networks.</a></li>
<li><a href="#52. Hypergraph Random Walks, Laplacians, and Clustering.">52. Hypergraph Random Walks, Laplacians, and Clustering.</a></li>
<li><a href="#53. VN Network: Embedding Newly Emerging Entities with Virtual Neighbors.">53. VN Network: Embedding Newly Emerging Entities with Virtual Neighbors.</a></li>
<li><a href="#54. WMEgo: Willingness Maximization for Ego Network Data Extraction in Online Social Networks.">54. WMEgo: Willingness Maximization for Ego Network Data Extraction in Online Social Networks.</a></li>
<li><a href="#55. Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems.">55. Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems.</a></li>
<li><a href="#56. Image Captioning with Internal and External Knowledge.">56. Image Captioning with Internal and External Knowledge.</a></li>
<li><a href="#57. GNNVis: Visualize Large-Scale Data by Learning a Graph Neural Network Representation.">57. GNNVis: Visualize Large-Scale Data by Learning a Graph Neural Network Representation.</a></li>
<li><a href="#58. Predicting Economic Growth by Region Embedding: A Multigraph Convolutional Network Approach.">58. Predicting Economic Growth by Region Embedding: A Multigraph Convolutional Network Approach.</a></li>
<li><a href="#59. Sequential Recommender via Time-aware Attentive Memory Network.">59. Sequential Recommender via Time-aware Attentive Memory Network.</a></li>
<li><a href="#60. MARU: Meta-context Aware Random Walks for Heterogeneous Network Representation Learning.">60. MARU: Meta-context Aware Random Walks for Heterogeneous Network Representation Learning.</a></li>
<li><a href="#61. Partial Relationship Aware Influence Diffusion via a Multi-channel Encoding Scheme for Social Recommendation.">61. Partial Relationship Aware Influence Diffusion via a Multi-channel Encoding Scheme for Social Recommendation.</a></li>
<li><a href="#62. Social Factors in Closed-Network Content Consumption.">62. Social Factors in Closed-Network Content Consumption.</a></li>
<li><a href="#63. DE-RRD: A Knowledge Distillation Framework for Recommender System.">63. DE-RRD: A Knowledge Distillation Framework for Recommender System.</a></li>
<li><a href="#64. Collective Embedding with Feature Importance: A Unified Approach for Spatiotemporal Network Embedding.">64. Collective Embedding with Feature Importance: A Unified Approach for Spatiotemporal Network Embedding.</a></li>
<li><a href="#65. AutoFeature: Searching for Feature Interactions and Their Architectures for Click-through Rate Prediction.">65. AutoFeature: Searching for Feature Interactions and Their Architectures for Click-through Rate Prediction.</a></li>
<li><a href="#66. Selecting Influential Features by a Learnable Content-Aware Linear Threshold Model.">66. Selecting Influential Features by a Learnable Content-Aware Linear Threshold Model.</a></li>
<li><a href="#67. Describing and Predicting Online Items with Reshare Cascades via Dual Mixture Self-exciting Processes.">67. Describing and Predicting Online Items with Reshare Cascades via Dual Mixture Self-exciting Processes.</a></li>
<li><a href="#68. Extracting N-ary Facts from Wikipedia Table Clusters.">68. Extracting N-ary Facts from Wikipedia Table Clusters.</a></li>
<li><a href="#69. Live Multi-Streaming and Donation Recommendations via Coupled Donation-Response Tensor Factorization.">69. Live Multi-Streaming and Donation Recommendations via Coupled Donation-Response Tensor Factorization.</a></li>
<li><a href="#70. MERL: Multi-View Edge Representation Learning in Social Networks.">70. MERL: Multi-View Edge Representation Learning in Social Networks.</a></li>
<li><a href="#71. Towards Temporal Knowledge Graph Embeddings with Arbitrary Time Precision.">71. Towards Temporal Knowledge Graph Embeddings with Arbitrary Time Precision.</a></li>
<li><a href="#72. News Recommendation with Topic-Enriched Knowledge Graphs.">72. News Recommendation with Topic-Enriched Knowledge Graphs.</a></li>
<li><a href="#73. Cross-sentence N-ary Relation Extraction using Entity Link and Discourse Relation.">73. Cross-sentence N-ary Relation Extraction using Entity Link and Discourse Relation.</a></li>
<li><a href="#74. Knowledge Adaption for Demand Prediction based on Multi-task Memory Neural Network.">74. Knowledge Adaption for Demand Prediction based on Multi-task Memory Neural Network.</a></li>
<li><a href="#75. Learning with Noisy Partial Labels by Simultaneously Leveraging Global and Local Consistencies.">75. Learning with Noisy Partial Labels by Simultaneously Leveraging Global and Local Consistencies.</a></li>
<li><a href="#76. Knowledge-Enhanced Personalized Review Generation with Capsule Graph Neural Network.">76. Knowledge-Enhanced Personalized Review Generation with Capsule Graph Neural Network.</a></li>
<li><a href="#77. Seed-free Graph De-anonymiztiation with Adversarial Learning.">77. Seed-free Graph De-anonymiztiation with Adversarial Learning.</a></li>
<li><a href="#78. Generate Neural Template Explanations for Recommendation.">78. Generate Neural Template Explanations for Recommendation.</a></li>
<li><a href="#79. A Topic and Concept Integrated Model for Thread Recommendation in Online Health Communities.">79. A Topic and Concept Integrated Model for Thread Recommendation in Online Health Communities.</a></li>
<li><a href="#80. Trapping Malicious Crawlers in Social Networks.">80. Trapping Malicious Crawlers in Social Networks.</a></li>
<li><a href="#81. Deep Time-Aware Item Evolution Network for Click-Through Rate Prediction.">81. Deep Time-Aware Item Evolution Network for Click-Through Rate Prediction.</a></li>
<li><a href="#82. Learning Better Representations for Neural Information Retrieval with Graph Information.">82. Learning Better Representations for Neural Information Retrieval with Graph Information.</a></li>
<li><a href="#83. Cooperative Multi-Agent Reinforcement Learning in Express System.">83. Cooperative Multi-Agent Reinforcement Learning in Express System.</a></li>
<li><a href="#84. Meta-Learning for Neural Relation Classification with Distant Supervision.">84. Meta-Learning for Neural Relation Classification with Distant Supervision.</a></li>
<li><a href="#85. Aspect-invariant Sentiment Features Learning: Adversarial Multi-task Learning for Aspect-based Sentiment Analysis.">85. Aspect-invariant Sentiment Features Learning: Adversarial Multi-task Learning for Aspect-based Sentiment Analysis.</a></li>
<li><a href="#86. Attributed Network Embedding based on Mutual Information Estimation.">86. Attributed Network Embedding based on Mutual Information Estimation.</a></li>
<li><a href="#87. STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation.">87. STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation.</a></li>
<li><a href="#88. Attacking Recommender Systems with Augmented User Profiles.">88. Attacking Recommender Systems with Augmented User Profiles.</a></li>
<li><a href="#89. Jointly Modeling Individual Student Behaviors and Social Influence for Prediction Tasks.">89. Jointly Modeling Individual Student Behaviors and Social Influence for Prediction Tasks.</a></li>
<li><a href="#90. Fusing Parallel Social Contexts within Flexible-Order Proximity for Microblog Topic Detection.">90. Fusing Parallel Social Contexts within Flexible-Order Proximity for Microblog Topic Detection.</a></li>
<li><a href="#91. Cross Domain Recommendation via Bi-directional Transfer Graph Collaborative Filtering Networks.">91. Cross Domain Recommendation via Bi-directional Transfer Graph Collaborative Filtering Networks.</a></li>
<li><a href="#92. Explainable Recommender Systems via Resolving Learning Representations.">92. Explainable Recommender Systems via Resolving Learning Representations.</a></li>
<li><a href="#93. Deep Spatio-Temporal Multiple Domain Fusion Network for Urban Anomalies Detection.">93. Deep Spatio-Temporal Multiple Domain Fusion Network for Urban Anomalies Detection.</a></li>
<li><a href="#94. Structural Relationship Representation Learning with Graph Embedding for Personalized Product Search.">94. Structural Relationship Representation Learning with Graph Embedding for Personalized Product Search.</a></li>
<li><a href="#95. Personalized Re-ranking with Item Relationships for E-commerce.">95. Personalized Re-ranking with Item Relationships for E-commerce.</a></li>
<li><a href="#96. An NVM SSD-Optimized Query Processing Framework.">96. An NVM SSD-Optimized Query Processing Framework.</a></li>
<li><a href="#97. Shapley Values and Meta-Explanations for Probabilistic Graphical Model Inference.">97. Shapley Values and Meta-Explanations for Probabilistic Graphical Model Inference.</a></li>
<li><a href="#98. Recommending Inferior Results: A General and Feature-Free Model for Spam Detection.">98. Recommending Inferior Results: A General and Feature-Free Model for Spam Detection.</a></li>
<li><a href="#99. Towards Locality-Aware Meta-Learning of Tail Node Embeddings on Networks.">99. Towards Locality-Aware Meta-Learning of Tail Node Embeddings on Networks.</a></li>
<li><a href="#100. Feature Fusion Based Subgraph Classification for Link Prediction.">100. Feature Fusion Based Subgraph Classification for Link Prediction.</a></li>
<li><a href="#101. Fast Attributed Multiplex Heterogeneous Network Embedding.">101. Fast Attributed Multiplex Heterogeneous Network Embedding.</a></li>
<li><a href="#102. Dynamic Representation Learning for Large-Scale Attributed Networks.">102. Dynamic Representation Learning for Large-Scale Attributed Networks.</a></li>
<li><a href="#103. Dual Head-wise Coattention Network for Machine Comprehension with Multiple-Choice Questions.">103. Dual Head-wise Coattention Network for Machine Comprehension with Multiple-Choice Questions.</a></li>
<li><a href="#104. Spatiotemporal Adaptive Gated Graph Convolution Network for Urban Traffic Flow Forecasting.">104. Spatiotemporal Adaptive Gated Graph Convolution Network for Urban Traffic Flow Forecasting.</a></li>
<li><a href="#105. Probabilistic Dynamic Non-negative Group Factor Model for Multi-source Text Mining.">105. Probabilistic Dynamic Non-negative Group Factor Model for Multi-source Text Mining.</a></li>
<li><a href="#106. Hierarchical Active Learning with Overlapping Regions.">106. Hierarchical Active Learning with Overlapping Regions.</a></li>
<li><a href="#107. Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification.">107. Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification.</a></li>
<li><a href="#108. Feature Selection on Data Stream via Multi-Cluster Structure Preservation.">108. Feature Selection on Data Stream via Multi-Cluster Structure Preservation.</a></li>
<li><a href="#109. PSTIE: Time Information Enhanced Personalized Search.">109. PSTIE: Time Information Enhanced Personalized Search.</a></li>
<li><a href="#110. Examining the Additivity of Top-k Query Processing Innovations.">110. Examining the Additivity of Top-k Query Processing Innovations.</a></li>
<li><a href="#111. Relational Reflection Entity Alignment.">111. Relational Reflection Entity Alignment.</a></li>
<li><a href="#112. CSNE: Conditional Signed Network Embedding.">112. CSNE: Conditional Signed Network Embedding.</a></li>
<li><a href="#113. Learning to Distract: A Hierarchical Multi-Decoder Network for Automated Generation of Long Distractors for Multiple-Choice Questions for Reading Comprehension.">113. Learning to Distract: A Hierarchical Multi-Decoder Network for Automated Generation of Long Distractors for Multiple-Choice Questions for Reading Comprehension.</a></li>
<li><a href="#114. "Keep it Simple, Lazy" - MetaLazy: A New MetaStrategy for Lazy Text Classification.">114. "Keep it Simple, Lazy" - MetaLazy: A New MetaStrategy for Lazy Text Classification.</a></li>
<li><a href="#115. A Methodology Based on Deep Q-Learning/Genetic Algorithms for Optimizing COVID-19 Pandemic Government Actions.">115. A Methodology Based on Deep Q-Learning/Genetic Algorithms for Optimizing COVID-19 Pandemic Government Actions.</a></li>
<li><a href="#116. SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection.">116. SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection.</a></li>
<li><a href="#117. Deep Generative Positive-Unlabeled Learning under Selection Bias.">117. Deep Generative Positive-Unlabeled Learning under Selection Bias.</a></li>
<li><a href="#118. FANG: Leveraging Social Context for Fake News Detection Using Graph Representation.">118. FANG: Leveraging Social Context for Fake News Detection Using Graph Representation.</a></li>
<li><a href="#119. Uncovering Semantic Bias in Neural Network Models Using a Knowledge Graph.">119. Uncovering Semantic Bias in Neural Network Models Using a Knowledge Graph.</a></li>
<li><a href="#120. STP-TrellisNets: Spatial-Temporal Parallel TrellisNets for Metro Station Passenger Flow Prediction.">120. STP-TrellisNets: Spatial-Temporal Parallel TrellisNets for Metro Station Passenger Flow Prediction.</a></li>
<li><a href="#121. Star Graph Neural Networks for Session-based Recommendation.">121. Star Graph Neural Networks for Session-based Recommendation.</a></li>
<li><a href="#122. RKT: Relation-Aware Self-Attention for Knowledge Tracing.">122. RKT: Relation-Aware Self-Attention for Knowledge Tracing.</a></li>
<li><a href="#123. ST-GRAT: A Novel Spatio-temporal Graph Attention Networks for Accurately Forecasting Dynamically Changing Road Speed.">123. ST-GRAT: A Novel Spatio-temporal Graph Attention Networks for Accurately Forecasting Dynamically Changing Road Speed.</a></li>
<li><a href="#124. Minimal Edit-Based Diffs for Large Trees.">124. Minimal Edit-Based Diffs for Large Trees.</a></li>
<li><a href="#125. Efficient Detection of Data Dependency Violations.">125. Efficient Detection of Data Dependency Violations.</a></li>
<li><a href="#126. EnDeA: Ensemble based Decoupled Adversarial Learning for Identifying Infrastructure Damage during Disasters.">126. EnDeA: Ensemble based Decoupled Adversarial Learning for Identifying Infrastructure Damage during Disasters.</a></li>
<li><a href="#127. G-CREWE: Graph CompREssion With Embedding for Network Alignment.">127. G-CREWE: Graph CompREssion With Embedding for Network Alignment.</a></li>
<li><a href="#128. Diversifying Search Results using Self-Attention Network.">128. Diversifying Search Results using Self-Attention Network.</a></li>
<li><a href="#129. Time-Efficient Geo-Obfuscation to Protect Worker Location Privacy over Road Networks in Spatial Crowdsourcing.">129. Time-Efficient Geo-Obfuscation to Protect Worker Location Privacy over Road Networks in Spatial Crowdsourcing.</a></li>
<li><a href="#130. Hierarchical Query Graph Generation for Complex Question Answering over Knowledge Graph.">130. Hierarchical Query Graph Generation for Complex Question Answering over Knowledge Graph.</a></li>
<li><a href="#131. Robust Irregular Tensor Factorization and Completion for Temporal Health Data Analysis.">131. Robust Irregular Tensor Factorization and Completion for Temporal Health Data Analysis.</a></li>
<li><a href="#132. The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation Objectively?">132. The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation Objectively?</a></li>
<li><a href="#133. ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot Retrieval of Images from Textual Descriptions.">133. ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot Retrieval of Images from Textual Descriptions.</a></li>
<li><a href="#134. Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models.">134. Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models.</a></li>
<li><a href="#135. A GAN-based Framework for Modeling Hashtag Popularity Dynamics Using Assistive Information.">135. A GAN-based Framework for Modeling Hashtag Popularity Dynamics Using Assistive Information.</a></li>
<li><a href="#136. Index Obfuscation for Oblivious Document Retrieval in a Trusted Execution Environment.">136. Index Obfuscation for Oblivious Document Retrieval in a Trusted Execution Environment.</a></li>
<li><a href="#137. Auxiliary-task Based Deep Reinforcement Learning for Participant Selection Problem in Mobile Crowdsourcing.">137. Auxiliary-task Based Deep Reinforcement Learning for Participant Selection Problem in Mobile Crowdsourcing.</a></li>
<li><a href="#138. Neural Logic Reasoning.">138. Neural Logic Reasoning.</a></li>
<li><a href="#139. METEOR: Learning Memory and Time Efficient Representations from Multi-modal Data Streams.">139. METEOR: Learning Memory and Time Efficient Representations from Multi-modal Data Streams.</a></li>
<li><a href="#140. Carpe Diem, Seize the Samples Uncertain "at the Moment" for Adaptive Batch Selection.">140. Carpe Diem, Seize the Samples Uncertain "at the Moment" for Adaptive Batch Selection.</a></li>
<li><a href="#141. Continual Domain Adaptation for Machine Reading Comprehension.">141. Continual Domain Adaptation for Machine Reading Comprehension.</a></li>
<li><a href="#142. Multi-modal Knowledge Graphs for Recommender Systems.">142. Multi-modal Knowledge Graphs for Recommender Systems.</a></li>
<li><a href="#143. Anomaly Subgraph Detection with Feature Transfer.">143. Anomaly Subgraph Detection with Feature Transfer.</a></li>
<li><a href="#144. OHEA: Secure Data Aggregation in Wireless Sensor Networks against Untrusted Sensors.">144. OHEA: Secure Data Aggregation in Wireless Sensor Networks against Untrusted Sensors.</a></li>
<li><a href="#145. Investigating and Mitigating Degree-Related Biases in Graph Convoltuional Networks.">145. Investigating and Mitigating Degree-Related Biases in Graph Convoltuional Networks.</a></li>
<li><a href="#146. QSAN: A Quantum-probability based Signed Attention Network for Explainable False Information Detection.">146. QSAN: A Quantum-probability based Signed Attention Network for Explainable False Information Detection.</a></li>
<li><a href="#147. Quaternion-Based Self-Attentive Long Short-term User Preference Encoding for Recommendation.">147. Quaternion-Based Self-Attentive Long Short-term User Preference Encoding for Recommendation.</a></li>
<li><a href="#148. E-Commerce Dispute Resolution Prediction.">148. E-Commerce Dispute Resolution Prediction.</a></li>
<li><a href="#149. When Inverse Propensity Scoring does not Work: Affine Corrections for Unbiased Learning to Rank.">149. When Inverse Propensity Scoring does not Work: Affine Corrections for Unbiased Learning to Rank.</a></li>
<li><a href="#150. A Graph Matching Attack on Privacy-Preserving Record Linkage.">150. A Graph Matching Attack on Privacy-Preserving Record Linkage.</a></li>
<li><a href="#151. Semi-Supervised Max-Sum Clustering.">151. Semi-Supervised Max-Sum Clustering.</a></li>
<li><a href="#152. Efficient Sampling Algorithms for Approximate Temporal Motif Counting.">152. Efficient Sampling Algorithms for Approximate Temporal Motif Counting.</a></li>
<li><a href="#153. Streaming Graph Neural Networks via Continual Learning.">153. Streaming Graph Neural Networks via Continual Learning.</a></li>
<li><a href="#154. Soap: Soaking Capacity Optimization for Multi-Document Summarization.">154. Soap: Soaking Capacity Optimization for Multi-Document Summarization.</a></li>
<li><a href="#155. Mining Infrequent High-Quality Phrases from Domain-Specific Corpora.">155. Mining Infrequent High-Quality Phrases from Domain-Specific Corpora.</a></li>
<li><a href="#156. Graph Few-shot Learning with Attribute Matching.">156. Graph Few-shot Learning with Attribute Matching.</a></li>
<li><a href="#157. Multi-task Adversarial Spatial-Temporal Networks for Crowd Flow Prediction.">157. Multi-task Adversarial Spatial-Temporal Networks for Crowd Flow Prediction.</a></li>
<li><a href="#158. Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification.">158. Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification.</a></li>
<li><a href="#159. Fast Graph Convolution Network Based Multi-label Image Recognition via Cross-modal Fusion.">159. Fast Graph Convolution Network Based Multi-label Image Recognition via Cross-modal Fusion.</a></li>
<li><a href="#160. Bringing Order to Network Embedding: A Relative Ranking based Approach.">160. Bringing Order to Network Embedding: A Relative Ranking based Approach.</a></li>
<li><a href="#161. Efficient Knowledge Graph Validation via Cross-Graph Representation Learning.">161. Efficient Knowledge Graph Validation via Cross-Graph Representation Learning.</a></li>
<li><a href="#162. DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation.">162. DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation.</a></li>
<li><a href="#163. Succinct Adaptive Manifold Transfer.">163. Succinct Adaptive Manifold Transfer.</a></li>
<li><a href="#164. Personalized Imputation on Wearable-Sensory Time Series via Knowledge Transfer.">164. Personalized Imputation on Wearable-Sensory Time Series via Knowledge Transfer.</a></li>
<li><a href="#165. Providing Direct Answers in Search Results: A Study of User Behavior.">165. Providing Direct Answers in Search Results: A Study of User Behavior.</a></li>
<li><a href="#166. CAFE: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation.">166. CAFE: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation.</a></li>
<li><a href="#167. OPHiForest: Order Preserving Hashing Based Isolation Forest for Robust and Scalable Anomaly Detection.">167. OPHiForest: Order Preserving Hashing Based Isolation Forest for Robust and Scalable Anomaly Detection.</a></li>
<li><a href="#168. Deep Graph Convolutional Networks for Incident-Driven Traffic Speed Prediction.">168. Deep Graph Convolutional Networks for Incident-Driven Traffic Speed Prediction.</a></li>
<li><a href="#169. Controllable Multi-Character Psychology-Oriented Story Generation.">169. Controllable Multi-Character Psychology-Oriented Story Generation.</a></li>
<li><a href="#170. Schema2QA: High-Quality and Low-Cost Q&A Agents for the Structured Web.">170. Schema2QA: High-Quality and Low-Cost Q&amp;A Agents for the Structured Web.</a></li>
<li><a href="#171. E-commerce Recommendation with Weighted Expected Utility.">171. E-commerce Recommendation with Weighted Expected Utility.</a></li>
<li><a href="#172. NHP: Neural Hypergraph Link Prediction.">172. NHP: Neural Hypergraph Link Prediction.</a></li>
<li><a href="#173. Fair Class Balancing: Enhancing Model Fairness without Observing Sensitive Attributes.">173. Fair Class Balancing: Enhancing Model Fairness without Observing Sensitive Attributes.</a></li>
<li><a href="#174. Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching.">174. Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching.</a></li>
<li><a href="#175. NagE: Non-Abelian Group Embedding for Knowledge Graphs.">175. NagE: Non-Abelian Group Embedding for Knowledge Graphs.</a></li>
<li><a href="#176. LB-CGM: Latent Based Conditional Generative Model with Reliable Distribution Prediction.">176. LB-CGM: Latent Based Conditional Generative Model with Reliable Distribution Prediction.</a></li>
<li><a href="#177. LSAN: Modeling Long-term Dependencies and Short-term Correlations with Hierarchical Attention for Risk Prediction.">177. LSAN: Modeling Long-term Dependencies and Short-term Correlations with Hierarchical Attention for Risk Prediction.</a></li>
<li><a href="#178. Logic Enhanced Commonsense Inference with Chain Transformer.">178. Logic Enhanced Commonsense Inference with Chain Transformer.</a></li>
<li><a href="#179. Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering.">179. Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering.</a></li>
<li><a href="#180. GeneraLight: Improving Environment Generalization of Traffic Signal Control via Meta Reinforcement Learning.">180. GeneraLight: Improving Environment Generalization of Traffic Signal Control via Meta Reinforcement Learning.</a></li>
<li><a href="#181. TOMATO: A Topic-Wise Multi-Task Sparsity Model.">181. TOMATO: A Topic-Wise Multi-Task Sparsity Model.</a></li>
<li><a href="#182. More Than One: A Cluster-Prototype Matching Framework for Zero-Shot Learning.">182. More Than One: A Cluster-Prototype Matching Framework for Zero-Shot Learning.</a></li>
<li><a href="#183. A Feature-Importance-Aware and Robust Aggregator for GCN.">183. A Feature-Importance-Aware and Robust Aggregator for GCN.</a></li>
<li><a href="#184. Query Understanding via Intent Description Generation.">184. Query Understanding via Intent Description Generation.</a></li>
<li><a href="#185. Generating Categories for Sets of Entities.">185. Generating Categories for Sets of Entities.</a></li>
<li><a href="#186. CommDGI: Community Detection Oriented Deep Graph Infomax.">186. CommDGI: Community Detection Oriented Deep Graph Infomax.</a></li>
<li><a href="#187. Spatial-Temporal Convolutional Graph Attention Networks for Citywide Traffic Flow Forecasting.">187. Spatial-Temporal Convolutional Graph Attention Networks for Citywide Traffic Flow Forecasting.</a></li>
<li><a href="#188. Semi-Supervised Graph-to-Graph Translation.">188. Semi-Supervised Graph-to-Graph Translation.</a></li>
<li><a href="#189. Error-Bounded Graph Anomaly Loss for GNNs.">189. Error-Bounded Graph Anomaly Loss for GNNs.</a></li>
<li><a href="#190. Whole-Chain Recommendations.">190. Whole-Chain Recommendations.</a></li>
<li><a href="#191. S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization.">191. S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization.</a></li>
<li><a href="#192. Top-k Graph Summarization on Hierarchical DAGs.">192. Top-k Graph Summarization on Hierarchical DAGs.</a></li>
<li><a href="#193. When Structure Meets Keywords: Cohesive Attributed Community Search.">193. When Structure Meets Keywords: Cohesive Attributed Community Search.</a></li>
<li><a href="#194. LRHNE: A Latent-Relation Enhanced Embedding Method for Heterogeneous Information Networks.">194. LRHNE: A Latent-Relation Enhanced Embedding Method for Heterogeneous Information Networks.</a></li>
<li><a href="#195. Corpus Bootstrapping for Assessment of the Properties of Effectiveness Measures.">195. Corpus Bootstrapping for Assessment of the Properties of Effectiveness Measures.</a></li>
</ul>
</li>
<li><a href="#Short Paper Track    102">Short Paper Track    102</a><ul>
<li><a href="#196. Building Test Collections using Bandit Techniques: A Reproducibility Study.">196. Building Test Collections using Bandit Techniques: A Reproducibility Study.</a></li>
<li><a href="#197. FDCM: Towards Balanced and Generalizable Concept-based Models for Effective Medical Ranking.">197. FDCM: Towards Balanced and Generalizable Concept-based Models for Effective Medical Ranking.</a></li>
<li><a href="#198. Application Performance Anomaly Detection with LSTM on Temporal Irregularities in Logs.">198. Application Performance Anomaly Detection with LSTM on Temporal Irregularities in Logs.</a></li>
<li><a href="#199. Automatic Gaussian Process Model Retrieval for Big Data.">199. Automatic Gaussian Process Model Retrieval for Big Data.</a></li>
<li><a href="#200. Query Abandonment Prediction with Recurrent Neural Models of Mouse Cursor Movements.">200. Query Abandonment Prediction with Recurrent Neural Models of Mouse Cursor Movements.</a></li>
<li><a href="#201. NumClaim: Investor's Fine-grained Claim Detection.">201. NumClaim: Investor's Fine-grained Claim Detection.</a></li>
<li><a href="#202. Label-Aware Graph Convolutional Networks.">202. Label-Aware Graph Convolutional Networks.</a></li>
<li><a href="#203. Graph Unfolding Networks.">203. Graph Unfolding Networks.</a></li>
<li><a href="#204. CONE-Align: Consistent Network Alignment with Proximity-Preserving Node Embedding.">204. CONE-Align: Consistent Network Alignment with Proximity-Preserving Node Embedding.</a></li>
<li><a href="#205. Generative Adversarial Attributed Network Anomaly Detection.">205. Generative Adversarial Attributed Network Anomaly Detection.</a></li>
<li><a href="#206. Joint Estimation of User And Publisher Credibility for Fake News Detection.">206. Joint Estimation of User And Publisher Credibility for Fake News Detection.</a></li>
<li><a href="#207. Learning Discriminative Virtual Sequences for Time Series Classification.">207. Learning Discriminative Virtual Sequences for Time Series Classification.</a></li>
<li><a href="#208. DECWA: Density-Based Clustering using Wasserstein Distance.">208. DECWA: Density-Based Clustering using Wasserstein Distance.</a></li>
<li><a href="#209. Why is That a Background Article: A Qualitative Analysis of Relevance for News Background Linking.">209. Why is That a Background Article: A Qualitative Analysis of Relevance for News Background Linking.</a></li>
<li><a href="#210. Hybrid Dynamic Pruning for Efficient and Effective Query Processing.">210. Hybrid Dynamic Pruning for Efficient and Effective Query Processing.</a></li>
<li><a href="#211. Sample Optimization For Display Advertising.">211. Sample Optimization For Display Advertising.</a></li>
<li><a href="#212. A Reinforced Semi-supervised Neural Network for Helpful Review Identification.">212. A Reinforced Semi-supervised Neural Network for Helpful Review Identification.</a></li>
<li><a href="#213. A View-Adversarial Framework for Multi-View Network Embedding.">213. A View-Adversarial Framework for Multi-View Network Embedding.</a></li>
<li><a href="#214. Can Adversarial Weight Perturbations Inject Neural Backdoors.">214. Can Adversarial Weight Perturbations Inject Neural Backdoors.</a></li>
<li><a href="#215. Estimating Topic Difficulty Using Normalized Discounted Cumulated Gain.">215. Estimating Topic Difficulty Using Normalized Discounted Cumulated Gain.</a></li>
<li><a href="#216. The Impact of Negative Relevance Judgments on NDCG.">216. The Impact of Negative Relevance Judgments on NDCG.</a></li>
<li><a href="#217. Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots.">217. Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots.</a></li>
<li><a href="#218. Subsampled Randomized Hadamard Transform for Regression of Dynamic Graphs.">218. Subsampled Randomized Hadamard Transform for Regression of Dynamic Graphs.</a></li>
<li><a href="#219. Learning to Form Skill-based Teams of Experts.">219. Learning to Form Skill-based Teams of Experts.</a></li>
<li><a href="#220. GAEAT: Graph Auto-Encoder Attention Networks for Knowledge Graph Completion.">220. GAEAT: Graph Auto-Encoder Attention Networks for Knowledge Graph Completion.</a></li>
<li><a href="#221. Learning to Re-Rank with Contextualized Stopwords.">221. Learning to Re-Rank with Contextualized Stopwords.</a></li>
<li><a href="#222. DATSING: Data Augmented Time Series Forecasting with Adversarial Domain Adaptation.">222. DATSING: Data Augmented Time Series Forecasting with Adversarial Domain Adaptation.</a></li>
<li><a href="#223. Homogenization with Explicit Semantics Preservation for Heterogeneous Information Network.">223. Homogenization with Explicit Semantics Preservation for Heterogeneous Information Network.</a></li>
<li><a href="#224. DistilSum: : Distilling the Knowledge for Extractive Summarization.">224. DistilSum: : Distilling the Knowledge for Extractive Summarization.</a></li>
<li><a href="#225. T-REX: A Topic-Aware Relation Extraction Model.">225. T-REX: A Topic-Aware Relation Extraction Model.</a></li>
<li><a href="#226. CR-Graph: Community Reinforcement for Accurate Community Detection.">226. CR-Graph: Community Reinforcement for Accurate Community Detection.</a></li>
<li><a href="#227. What Rankers Can be Statistically Distinguished in Multileaved Comparisons?">227. What Rankers Can be Statistically Distinguished in Multileaved Comparisons?</a></li>
<li><a href="#228. A Synopses Data Engine for Interactive Extreme-Scale Analytics.">228. A Synopses Data Engine for Interactive Extreme-Scale Analytics.</a></li>
<li><a href="#229. NASE: : Learning Knowledge Graph Embedding for Link Prediction via Neural Architecture Search.">229. NASE: : Learning Knowledge Graph Embedding for Link Prediction via Neural Architecture Search.</a></li>
<li><a href="#230. Ranking Clarification Questions via Natural Language Inference.">230. Ranking Clarification Questions via Natural Language Inference.</a></li>
<li><a href="#231. MetaTPOT: Enhancing A Tree-based Pipeline Optimization Tool Using Meta-Learning.">231. MetaTPOT: Enhancing A Tree-based Pipeline Optimization Tool Using Meta-Learning.</a></li>
<li><a href="#232. Rethinking Operators Placement of Stream Data Application in the Edge.">232. Rethinking Operators Placement of Stream Data Application in the Edge.</a></li>
<li><a href="#233. An Index Advisor Using Deep Reinforcement Learning.">233. An Index Advisor Using Deep Reinforcement Learning.</a></li>
<li><a href="#234. Bridging the Gap between Click and Relevance for Learning-to-Rank with Minimal Supervision.">234. Bridging the Gap between Click and Relevance for Learning-to-Rank with Minimal Supervision.</a></li>
<li><a href="#235. Are Negative Links Really Beneficial to Network Embedding?: In-Depth Analysis and Interesting Results.">235. Are Negative Links Really Beneficial to Network Embedding?: In-Depth Analysis and Interesting Results.</a></li>
<li><a href="#236. Non-local Self-attentive Autoencoder for Genetic Functionality Prediction.">236. Non-local Self-attentive Autoencoder for Genetic Functionality Prediction.</a></li>
<li><a href="#237. Recursive Balanced k-Subset Sum Partition for Rule-constrained Resource Allocation.">237. Recursive Balanced k-Subset Sum Partition for Rule-constrained Resource Allocation.</a></li>
<li><a href="#238. Alike and Unlike: Resolving Class Imbalance Problem in Financial Credit Risk Assessment.">238. Alike and Unlike: Resolving Class Imbalance Problem in Financial Credit Risk Assessment.</a></li>
<li><a href="#239. Active Query of Private Demographic Data for Learning Fair Models.">239. Active Query of Private Demographic Data for Learning Fair Models.</a></li>
<li><a href="#240. Neural Relation Extraction on Wikipedia Tables for Augmenting Knowledge Graphs.">240. Neural Relation Extraction on Wikipedia Tables for Augmenting Knowledge Graphs.</a></li>
<li><a href="#241. Fairness-Aware Learning with Prejudice Free Representations.">241. Fairness-Aware Learning with Prejudice Free Representations.</a></li>
<li><a href="#242. A Comparison of Top-k Threshold Estimation Techniques for Disjunctive Query Processing.">242. A Comparison of Top-k Threshold Estimation Techniques for Disjunctive Query Processing.</a></li>
<li><a href="#243. Feedback Loop and Bias Amplification in Recommender Systems.">243. Feedback Loop and Bias Amplification in Recommender Systems.</a></li>
<li><a href="#244. Diversifying Top-k Point-of-Interest Queries via Collective Social Reach.">244. Diversifying Top-k Point-of-Interest Queries via Collective Social Reach.</a></li>
<li><a href="#245. Transformer Models for Recommending Related Questions in Web Search.">245. Transformer Models for Recommending Related Questions in Web Search.</a></li>
<li><a href="#246. Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models.">246. Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models.</a></li>
<li><a href="#247. Deep Metric Learning Based on Rank-sensitive Optimization of Top-k Precision.">247. Deep Metric Learning Based on Rank-sensitive Optimization of Top-k Precision.</a></li>
<li><a href="#248. Gated Heterogeneous Graph Representation Learning for Shop Search in E-commerce.">248. Gated Heterogeneous Graph Representation Learning for Shop Search in E-commerce.</a></li>
<li><a href="#249. A Reproducibility Study of Deep and Surface Machine Learning Methods for Human-related Trajectory Prediction.">249. A Reproducibility Study of Deep and Surface Machine Learning Methods for Human-related Trajectory Prediction.</a></li>
<li><a href="#250. CGTR: Convolution Graph Topology Representation for Document Ranking.">250. CGTR: Convolution Graph Topology Representation for Document Ranking.</a></li>
<li><a href="#251. Representative Negative Instance Generation for Online Ad Targeting.">251. Representative Negative Instance Generation for Online Ad Targeting.</a></li>
<li><a href="#252. Training Sensitivity in Graph Isomorphism Network.">252. Training Sensitivity in Graph Isomorphism Network.</a></li>
<li><a href="#253. Securing Bloom Filters for Privacy-preserving Record Linkage.">253. Securing Bloom Filters for Privacy-preserving Record Linkage.</a></li>
<li><a href="#254. Product Insights: Analyzing Product Intents in Web Search.">254. Product Insights: Analyzing Product Intents in Web Search.</a></li>
<li><a href="#255. Muse: Multi-query Event Trend Aggregation.">255. Muse: Multi-query Event Trend Aggregation.</a></li>
<li><a href="#256. Distant Supervision in BERT-based Adhoc Document Retrieval.">256. Distant Supervision in BERT-based Adhoc Document Retrieval.</a></li>
<li><a href="#257. Modelling Regional Crime Risk using Directed Graph of Check-ins.">257. Modelling Regional Crime Risk using Directed Graph of Check-ins.</a></li>
<li><a href="#258. Relation Extraction with Self-determined Graph Convolutional Network.">258. Relation Extraction with Self-determined Graph Convolutional Network.</a></li>
<li><a href="#259. A Framework for Analyzing the Impact of Missing Data in Predictive Models.">259. A Framework for Analyzing the Impact of Missing Data in Predictive Models.</a></li>
<li><a href="#260. Deep Adaptive Feature Aggregation in Multi-task Convolutional Neural Networks.">260. Deep Adaptive Feature Aggregation in Multi-task Convolutional Neural Networks.</a></li>
<li><a href="#261. GGDs: Graph Generating Dependencies.">261. GGDs: Graph Generating Dependencies.</a></li>
<li><a href="#262. Do You Really Like Her Post?: Network-Based Analysis for Understanding Like Activities in SNS.">262. Do You Really Like Her Post?: Network-Based Analysis for Understanding Like Activities in SNS.</a></li>
<li><a href="#263. DREAM: A Dynamic Relation-Aware Model for Social Recommendation.">263. DREAM: A Dynamic Relation-Aware Model for Social Recommendation.</a></li>
<li><a href="#264. LogBug: Generating Adversarial System Logs in Real Time.">264. LogBug: Generating Adversarial System Logs in Real Time.</a></li>
<li><a href="#265. TABLE: A Task-Adaptive BERT-based ListwisE Ranking Model for Document Retrieval.">265. TABLE: A Task-Adaptive BERT-based ListwisE Ranking Model for Document Retrieval.</a></li>
<li><a href="#266. DynamicRec: A Dynamic Convolutional Network for Next Item Recommendation.">266. DynamicRec: A Dynamic Convolutional Network for Next Item Recommendation.</a></li>
<li><a href="#267. Schema-Agnostic Entity Matching using Pre-trained Language Models.">267. Schema-Agnostic Entity Matching using Pre-trained Language Models.</a></li>
<li><a href="#268. Denoising Individual Bias for Fairer Binary Submatrix Detection.">268. Denoising Individual Bias for Fairer Binary Submatrix Detection.</a></li>
<li><a href="#269. Dual Autoencoder Network with Swap Reconstruction for Cold-Start Recommendation.">269. Dual Autoencoder Network with Swap Reconstruction for Cold-Start Recommendation.</a></li>
<li><a href="#270. Embedding Node Structural Role Identity into Hyperbolic Space.">270. Embedding Node Structural Role Identity into Hyperbolic Space.</a></li>
<li><a href="#271. Calibration of Google Trends Time Series.">271. Calibration of Google Trends Time Series.</a></li>
<li><a href="#272. Tolerant Markov Boundary Discovery for Feature Selection.">272. Tolerant Markov Boundary Discovery for Feature Selection.</a></li>
<li><a href="#273. Deep Multi-Interest Network for Click-through Rate Prediction.">273. Deep Multi-Interest Network for Click-through Rate Prediction.</a></li>
<li><a href="#274. Learning to Generate Reformulation Actions for Scalable Conversational Query Understanding.">274. Learning to Generate Reformulation Actions for Scalable Conversational Query Understanding.</a></li>
<li><a href="#275. Enhance Prototypical Network with Text Descriptions for Few-shot Relation Classification.">275. Enhance Prototypical Network with Text Descriptions for Few-shot Relation Classification.</a></li>
<li><a href="#276. Analysis of Multivariate Scoring Functions for Automatic Unbiased Learning to Rank.">276. Analysis of Multivariate Scoring Functions for Automatic Unbiased Learning to Rank.</a></li>
<li><a href="#277. Time-aware Graph Relational Attention Network for Stock Recommendation.">277. Time-aware Graph Relational Attention Network for Stock Recommendation.</a></li>
<li><a href="#278. Deep Interaction Machine: A Simple but Effective Model for High-order Feature Interactions.">278. Deep Interaction Machine: A Simple but Effective Model for High-order Feature Interactions.</a></li>
<li><a href="#279. Few-shot Insider Threat Detection.">279. Few-shot Insider Threat Detection.</a></li>
<li><a href="#280. Leveraging User Email Actions to Improve Ad-Close Prediction.">280. Leveraging User Email Actions to Improve Ad-Close Prediction.</a></li>
<li><a href="#281. Event-Driven Network for Cross-Modal Retrieval.">281. Event-Driven Network for Cross-Modal Retrieval.</a></li>
<li><a href="#282. Integrating Diagnosis Rules into Deep Neural Networks for Bladder Cancer Staging.">282. Integrating Diagnosis Rules into Deep Neural Networks for Bladder Cancer Staging.</a></li>
<li><a href="#283. Hyper-Substructure Enhanced Link Predictor.">283. Hyper-Substructure Enhanced Link Predictor.</a></li>
<li><a href="#284. Seasonal-Periodic Subgraph Mining in Temporal Networks.">284. Seasonal-Periodic Subgraph Mining in Temporal Networks.</a></li>
<li><a href="#285. Multiplex Graph Neural Networks for Multi-behavior Recommendation.">285. Multiplex Graph Neural Networks for Multi-behavior Recommendation.</a></li>
<li><a href="#286. Robust Normalized Squares Maximization for Unsupervised Domain Adaptation.">286. Robust Normalized Squares Maximization for Unsupervised Domain Adaptation.</a></li>
<li><a href="#287. Community Identification in Signed Networks: A K-Truss Based Model.">287. Community Identification in Signed Networks: A K-Truss Based Model.</a></li>
<li><a href="#288. An Event-Oriented Neural Ranking Model for News Retrieval.">288. An Event-Oriented Neural Ranking Model for News Retrieval.</a></li>
<li><a href="#289. Revisiting Alternative Experimental Settings for Evaluating Top-N Item Recommendation Algorithms.">289. Revisiting Alternative Experimental Settings for Evaluating Top-N Item Recommendation Algorithms.</a></li>
<li><a href="#290. Dimension Relation Modeling for Click-Through Rate Prediction.">290. Dimension Relation Modeling for Click-Through Rate Prediction.</a></li>
<li><a href="#291. On-demand Influencer Discovery on Social Media.">291. On-demand Influencer Discovery on Social Media.</a></li>
<li><a href="#292. Data Augmentation for Graph Classification.">292. Data Augmentation for Graph Classification.</a></li>
<li><a href="#293. Diversifying Multi-aspect Search Results Using Simpson's Diversity Index.">293. Diversifying Multi-aspect Search Results Using Simpson's Diversity Index.</a></li>
<li><a href="#294. Leveraging Historical Interaction Data for Improving Conversational Recommender System.">294. Leveraging Historical Interaction Data for Improving Conversational Recommender System.</a></li>
<li><a href="#295. Behavior-driven Student Performance Prediction with Tri-branch Convolutional Neural Network.">295. Behavior-driven Student Performance Prediction with Tri-branch Convolutional Neural Network.</a></li>
<li><a href="#296. Multimodal Clustering via Deep Commonness and Uniqueness Mining.">296. Multimodal Clustering via Deep Commonness and Uniqueness Mining.</a></li>
<li><a href="#297. An Empirical Study on Clarifying Question-Based Systems.">297. An Empirical Study on Clarifying Question-Based Systems.</a></li>
</ul>
</li>
<li><a href="#Applied Research Track    73">Applied Research Track    73</a><ul>
<li><a href="#298. AutoADR: Automatic Model Design for Ad Relevance.">298. AutoADR: Automatic Model Design for Ad Relevance.</a></li>
<li><a href="#299. U-rank: Utility-oriented Learning to Rank with Implicit Feedback.">299. U-rank: Utility-oriented Learning to Rank with Implicit Feedback.</a></li>
<li><a href="#300. Personalized Bundle Recommendation in Online Games.">300. Personalized Bundle Recommendation in Online Games.</a></li>
<li><a href="#301. Learning Formatting Style Transfer and Structure Extraction for Spreadsheet Tables with a Hybrid Neural Network Architecture.">301. Learning Formatting Style Transfer and Structure Extraction for Spreadsheet Tables with a Hybrid Neural Network Architecture.</a></li>
<li><a href="#302. The Utility of Context When Extracting Entities From Legal Documents.">302. The Utility of Context When Extracting Entities From Legal Documents.</a></li>
<li><a href="#303. Learning to Rank in the Position Based Model with Bandit Feedback.">303. Learning to Rank in the Position Based Model with Bandit Feedback.</a></li>
<li><a href="#304. Fusing Global Domain Information and Local Semantic Information to Classify Financial Documents.">304. Fusing Global Domain Information and Local Semantic Information to Classify Financial Documents.</a></li>
<li><a href="#305. MTBRN: Multiplex Target-Behavior Relation Enhanced Network for Click-Through Rate Prediction.">305. MTBRN: Multiplex Target-Behavior Relation Enhanced Network for Click-Through Rate Prediction.</a></li>
<li><a href="#306. Fine-Tuned Compressed Representations of Vessel Trajectories.">306. Fine-Tuned Compressed Representations of Vessel Trajectories.</a></li>
<li><a href="#307. Intent-Driven Similarity in E-Commerce Listings.">307. Intent-Driven Similarity in E-Commerce Listings.</a></li>
<li><a href="#308. Impression Pacing for Jobs Marketplace at LinkedIn.">308. Impression Pacing for Jobs Marketplace at LinkedIn.</a></li>
<li><a href="#309. Bid Shading in The Brave New World of First-Price Auctions.">309. Bid Shading in The Brave New World of First-Price Auctions.</a></li>
<li><a href="#310. Prospective Modeling of Users for Online Display Advertising via Deep Time-Aware Model.">310. Prospective Modeling of Users for Online Display Advertising via Deep Time-Aware Model.</a></li>
<li><a href="#311. Learning to Profile: User Meta-Profile Network for Few-Shot Learning.">311. Learning to Profile: User Meta-Profile Network for Few-Shot Learning.</a></li>
<li><a href="#312. EdgeRec: Recommender System on Edge in Mobile Taobao.">312. EdgeRec: Recommender System on Edge in Mobile Taobao.</a></li>
<li><a href="#313. Price Forecast with High-Frequency Finance Data: An Autoregressive Recurrent Neural Network Model with Technical Indicators.">313. Price Forecast with High-Frequency Finance Data: An Autoregressive Recurrent Neural Network Model with Technical Indicators.</a></li>
<li><a href="#314. Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems.">314. Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems.</a></li>
<li><a href="#315. A Deep Prediction Network for Understanding Advertiser Intent and Satisfaction.">315. A Deep Prediction Network for Understanding Advertiser Intent and Satisfaction.</a></li>
<li><a href="#316. DeText: A Deep Text Ranking Framework with BERT.">316. DeText: A Deep Text Ranking Framework with BERT.</a></li>
<li><a href="#317. P-Companion: A Principled Framework for Diversified Complementary Product Recommendation.">317. P-Companion: A Principled Framework for Diversified Complementary Product Recommendation.</a></li>
<li><a href="#318. Loan Default Analysis with Multiplex Graph Learning.">318. Loan Default Analysis with Multiplex Graph Learning.</a></li>
<li><a href="#319. Imbalanced Time Series Classification for Flight Data Analyzing with Nonlinear Granger Causality Learning.">319. Imbalanced Time Series Classification for Flight Data Analyzing with Nonlinear Granger Causality Learning.</a></li>
<li><a href="#320. Personalized Flight Itinerary Ranking at Fliggy.">320. Personalized Flight Itinerary Ranking at Fliggy.</a></li>
<li><a href="#321. Learning Effective Representations for Person-Job Fit by Feature Fusion.">321. Learning Effective Representations for Person-Job Fit by Feature Fusion.</a></li>
<li><a href="#322. Incorporating User Feedback into Sequence to Sequence Model Training.">322. Incorporating User Feedback into Sequence to Sequence Model Training.</a></li>
<li><a href="#323. Magellan: A Personalized Travel Recommendation System Using Transaction Data.">323. Magellan: A Personalized Travel Recommendation System Using Transaction Data.</a></li>
<li><a href="#324. ART (Attractive Recommendation Tailor">324. ART (Attractive Recommendation Tailor): How the Diversity of Product Recommendations Affects Customer Purchase Preference in Fashion Industry?</a>: How the Diversity of Product Recommendations Affects Customer Purchase Preference in Fashion Industry?)</li>
<li><a href="#325. AliMeKG: Domain Knowledge Graph Construction and Application in E-commerce.">325. AliMeKG: Domain Knowledge Graph Construction and Application in E-commerce.</a></li>
<li><a href="#326. Peer-inspired Student Performance Prediction in Interactive Online Question Pools with Graph Neural Network.">326. Peer-inspired Student Performance Prediction in Interactive Online Question Pools with Graph Neural Network.</a></li>
<li><a href="#327. Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection.">327. Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection.</a></li>
<li><a href="#328. Improving Multi-Scenario Learning to Rank in E-commerce by Exploiting Task Relationships in the Label Space.">328. Improving Multi-Scenario Learning to Rank in E-commerce by Exploiting Task Relationships in the Label Space.</a></li>
<li><a href="#329. Graph Neural Network for Tag Ranking in Tag-enhanced Video Recommendation.">329. Graph Neural Network for Tag Ranking in Tag-enhanced Video Recommendation.</a></li>
<li><a href="#330. Decoupled Graph Convolution Network for Inferring Substitutable and Complementary Items.">330. Decoupled Graph Convolution Network for Inferring Substitutable and Complementary Items.</a></li>
<li><a href="#331. Two-Stage Audience Expansion for Financial Targeting in Marketing.">331. Two-Stage Audience Expansion for Financial Targeting in Marketing.</a></li>
<li><a href="#332. Efficiently Training Intelligible Models for Global Explanations.">332. Efficiently Training Intelligible Models for Global Explanations.</a></li>
<li><a href="#333. TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval.">333. TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval.</a></li>
<li><a href="#334. Learning to Create Better Ads: Generation and Ranking Approaches for Ad Creative Refinement.">334. Learning to Create Better Ads: Generation and Ranking Approaches for Ad Creative Refinement.</a></li>
<li><a href="#335. Personalizing Natural Language Understanding using Multi-armed Bandits and Implicit Feedback.">335. Personalizing Natural Language Understanding using Multi-armed Bandits and Implicit Feedback.</a></li>
<li><a href="#336. MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction.">336. MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction.</a></li>
<li><a href="#337. Learning to Infer User Hidden States for Online Sequential Advertising.">337. Learning to Infer User Hidden States for Online Sequential Advertising.</a></li>
<li><a href="#338. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction.">338. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction.</a></li>
<li><a href="#339. Category-aware Graph Neural Networks for Improving E-commerce Review Helpfulness Prediction.">339. Category-aware Graph Neural Networks for Improving E-commerce Review Helpfulness Prediction.</a></li>
<li><a href="#340. Expert-in-the-loop AI for Polymer Discovery.">340. Expert-in-the-loop AI for Polymer Discovery.</a></li>
<li><a href="#341. An Extensive Investigation of Machine Learning Techniques for Sleep Apnea Screening.">341. An Extensive Investigation of Machine Learning Techniques for Sleep Apnea Screening.</a></li>
<li><a href="#342. Continuous Improvement of Medical Diagnostic Systems with Large Scale Patient Vignette Simulation.">342. Continuous Improvement of Medical Diagnostic Systems with Large Scale Patient Vignette Simulation.</a></li>
<li><a href="#343. Detection of Novel Social Bots by Ensembles of Specialized Classifiers.">343. Detection of Novel Social Bots by Ensembles of Specialized Classifiers.</a></li>
<li><a href="#344. ITAD: Integrative Tensor-based Anomaly Detection System for Reducing False Positives of Satellite Systems.">344. ITAD: Integrative Tensor-based Anomaly Detection System for Reducing False Positives of Satellite Systems.</a></li>
<li><a href="#345. Helix: DGA Domain Embeddings for Tracking and Exploring Botnets.">345. Helix: DGA Domain Embeddings for Tracking and Exploring Botnets.</a></li>
<li><a href="#346. Crime Linkage Based on Textual Hebrew Police Reports Utilizing Behavioral Patterns.">346. Crime Linkage Based on Textual Hebrew Police Reports Utilizing Behavioral Patterns.</a></li>
<li><a href="#347. AGATHA: Automatic Graph Mining And Transformer based Hypothesis Generation Approach.">347. AGATHA: Automatic Graph Mining And Transformer based Hypothesis Generation Approach.</a></li>
<li><a href="#348. Query Understanding for Surfacing Under-served Music Content.">348. Query Understanding for Surfacing Under-served Music Content.</a></li>
<li><a href="#349. LiFT: A Scalable Framework for Measuring Fairness in ML Applications.">349. LiFT: A Scalable Framework for Measuring Fairness in ML Applications.</a></li>
<li><a href="#350. Match Tracing: A Unified Framework for Real-time Win Prediction and Quantifiable Performance Evaluation.">350. Match Tracing: A Unified Framework for Real-time Win Prediction and Quantifiable Performance Evaluation.</a></li>
<li><a href="#351. Masked-field Pre-training for User Intent Prediction.">351. Masked-field Pre-training for User Intent Prediction.</a></li>
<li><a href="#352. Efficient Neural Query Auto Completion.">352. Efficient Neural Query Auto Completion.</a></li>
<li><a href="#353. A Joint Inverse Reinforcement Learning and Deep Learning Model for Drivers' Behavioral Prediction.">353. A Joint Inverse Reinforcement Learning and Deep Learning Model for Drivers' Behavioral Prediction.</a></li>
<li><a href="#354. Deep Behavior Tracing with Multi-level Temporality Preserved Embedding.">354. Deep Behavior Tracing with Multi-level Temporality Preserved Embedding.</a></li>
<li><a href="#355. Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to Cold-Start Search Retrieval.">355. Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to Cold-Start Search Retrieval.</a></li>
<li><a href="#356. Relevance Ranking for Real-Time Tweet Search.">356. Relevance Ranking for Real-Time Tweet Search.</a></li>
<li><a href="#357. Generating Full Spatiotemporal Vehicular Paths: A Data Fusion Approach.">357. Generating Full Spatiotemporal Vehicular Paths: A Data Fusion Approach.</a></li>
<li><a href="#358. Multi-Channel Sellers Traffic Allocation in Large-scale E-commerce Promotion.">358. Multi-Channel Sellers Traffic Allocation in Large-scale E-commerce Promotion.</a></li>
<li><a href="#359. aDMSCN: A Novel Perspective for User Intent Prediction in Customer Service Bots.">359. aDMSCN: A Novel Perspective for User Intent Prediction in Customer Service Bots.</a></li>
<li><a href="#360. GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems.">360. GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems.</a></li>
<li><a href="#361. Ranking User Attributes for Fast Candidate Selection in Recommendation Systems.">361. Ranking User Attributes for Fast Candidate Selection in Recommendation Systems.</a></li>
<li><a href="#362. Learning to Build User-tag Profile in Recommendation System.">362. Learning to Build User-tag Profile in Recommendation System.</a></li>
<li><a href="#363. You Are How You Use: Catching Gas Theft Suspects among Diverse Restaurant Users.">363. You Are How You Use: Catching Gas Theft Suspects among Diverse Restaurant Users.</a></li>
<li><a href="#364. Query-aware Tip Generation for Vertical Search.">364. Query-aware Tip Generation for Vertical Search.</a></li>
<li><a href="#365. BotSpot: A Hybrid Learning Framework to Uncover Bot Install Fraud in Mobile Advertising.">365. BotSpot: A Hybrid Learning Framework to Uncover Bot Install Fraud in Mobile Advertising.</a></li>
<li><a href="#366. Community Mitigation: A Data-driven System for COVID-19 Risk Assessment in a Hierarchical Manner.">366. Community Mitigation: A Data-driven System for COVID-19 Risk Assessment in a Hierarchical Manner.</a></li>
<li><a href="#367. Who is Delivering My Food?: Detecting Food Delivery Abusers using Variational Reward Inference Networks.">367. Who is Delivering My Food?: Detecting Food Delivery Abusers using Variational Reward Inference Networks.</a></li>
<li><a href="#368. Elevated Road Network: A Metric Learning Method for Recognizing Whether a Vehicle is on an Elevated Road.">368. Elevated Road Network: A Metric Learning Method for Recognizing Whether a Vehicle is on an Elevated Road.</a></li>
<li><a href="#369. Predicting Quality of Automated Welding with Machine Learning and Semantics: A Bosch Case Study.">369. Predicting Quality of Automated Welding with Machine Learning and Semantics: A Bosch Case Study.</a></li>
<li><a href="#370. Ensembled CTR Prediction via Knowledge Distillation.">370. Ensembled CTR Prediction via Knowledge Distillation.</a></li>
</ul>
</li>
<li><a href="#Resource Track    32">Resource Track    32</a><ul>
<li><a href="#371. GeoLink Cruises: A Non-Synthetic Benchmark for Co-Reference Resolution on Knowledge Graphs.">371. GeoLink Cruises: A Non-Synthetic Benchmark for Co-Reference Resolution on Knowledge Graphs.</a></li>
<li><a href="#372. MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages and Modalities.">372. MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages and Modalities.</a></li>
<li><a href="#373. MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings.">373. MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings.</a></li>
<li><a href="#374. ORCAS: 20 Million Clicked Query-Document Pairs for Analyzing Search.">374. ORCAS: 20 Million Clicked Query-Document Pairs for Analyzing Search.</a></li>
<li><a href="#375. TweetsCOV19 - A Knowledge Base of Semantically Annotated Tweets about the COVID-19 Pandemic.">375. TweetsCOV19 - A Knowledge Base of Semantically Annotated Tweets about the COVID-19 Pandemic.</a></li>
<li><a href="#376. LensKit for Python: Next-Generation Software for Recommender Systems Experiments.">376. LensKit for Python: Next-Generation Software for Recommender Systems Experiments.</a></li>
<li><a href="#377. A Multidimensional Dataset Based on Crowdsourcing for Analyzing and Detecting News Bias.">377. A Multidimensional Dataset Based on Crowdsourcing for Analyzing and Detecting News Bias.</a></li>
<li><a href="#378. Feature Extraction for Large-Scale Text Collections.">378. Feature Extraction for Large-Scale Text Collections.</a></li>
<li><a href="#379. CauseNet: Towards a Causality Graph Extracted from the Web.">379. CauseNet: Towards a Causality Graph Extracted from the Web.</a></li>
<li><a href="#380. Fine-Grained Relevance Annotations for Multi-Task Document Ranking and Question Answering.">380. Fine-Grained Relevance Annotations for Multi-Task Document Ranking and Question Answering.</a></li>
<li><a href="#381. SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs.">381. SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs.</a></li>
<li><a href="#382. Web Page Segmentation Revisited: Evaluation Framework and Dataset.">382. Web Page Segmentation Revisited: Evaluation Framework and Dataset.</a></li>
<li><a href="#383. The Newspaper Navigator Dataset: Extracting Headlines and Visual Content from 16 Million Historic Newspaper Pages in Chronicling America.">383. The Newspaper Navigator Dataset: Extracting Headlines and Visual Content from 16 Million Historic Newspaper Pages in Chronicling America.</a></li>
<li><a href="#384. MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction.">384. MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction.</a></li>
<li><a href="#385. Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers.">385. Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers.</a></li>
<li><a href="#386. CC-News-En: A Large English News Corpus.">386. CC-News-En: A Large English News Corpus.</a></li>
<li><a href="#387. PrivacyFL: A Simulator for Privacy-Preserving and Secure Federated Learning.">387. PrivacyFL: A Simulator for Privacy-Preserving and Secure Federated Learning.</a></li>
<li><a href="#388. ContentWise Impressions: An Industrial Dataset with Impressions Included.">388. ContentWise Impressions: An Industrial Dataset with Impressions Included.</a></li>
<li><a href="#389. Profiling Entity Matching Benchmark Tasks.">389. Profiling Entity Matching Benchmark Tasks.</a></li>
<li><a href="#390. A Large Test Collection for Entity Aspect Linking.">390. A Large Test Collection for Entity Aspect Linking.</a></li>
<li><a href="#391. A Dataset of Journalists' Interactions with Their Readership: When Should Article Authors Reply to Reader Comments?">391. A Dataset of Journalists' Interactions with Their Readership: When Should Article Authors Reply to Reader Comments?</a></li>
<li><a href="#392. Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on Graphs.">392. Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on Graphs.</a></li>
<li><a href="#393. Little Ball of Fur: A Python Library for Graph Sampling.">393. Little Ball of Fur: A Python Library for Graph Sampling.</a></li>
<li><a href="#394. Falcon 2.0: An Entity and Relation Linking Tool over Wikidata.">394. Falcon 2.0: An Entity and Relation Linking Tool over Wikidata.</a></li>
<li><a href="#395. GeoFlink: A Distributed and Scalable Framework for the Real-time Processing of Spatial Streams.">395. GeoFlink: A Distributed and Scalable Framework for the Real-time Processing of Spatial Streams.</a></li>
<li><a href="#396. Event-QA: A Dataset for Event-Centric Question Answering over Knowledge Graphs.">396. Event-QA: A Dataset for Event-Centric Question Answering over Knowledge Graphs.</a></li>
<li><a href="#397. ReQue: A Configurable Workflow and Dataset Collection for Query Refinement.">397. ReQue: A Configurable Workflow and Dataset Collection for Query Refinement.</a></li>
<li><a href="#398. BioKG: A Knowledge Graph for Relational Learning On Biological Data.">398. BioKG: A Knowledge Graph for Relational Learning On Biological Data.</a></li>
<li><a href="#399. Flexible IR Pipelines with Capreolus.">399. Flexible IR Pipelines with Capreolus.</a></li>
<li><a href="#400. MIMICS: A Large-Scale Data Collection for Search Clarification.">400. MIMICS: A Large-Scale Data Collection for Search Clarification.</a></li>
<li><a href="#401. The Enslaved Dataset: A Real-world Complex Ontology Alignment Benchmark using Wikibase.">401. The Enslaved Dataset: A Real-world Complex Ontology Alignment Benchmark using Wikibase.</a></li>
<li><a href="#402. ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research.">402. ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research.</a></li>
</ul>
</li>
<li><a href="#Doctoral Consortium    12">Doctoral Consortium    12</a><ul>
<li><a href="#403. Detecting and Measuring the Exposure of Children and Adolescents to Inappropriate Comments in YouTube.">403. Detecting and Measuring the Exposure of Children and Adolescents to Inappropriate Comments in YouTube.</a></li>
<li><a href="#404. Tailoring Entity Matching for Industrial Settings.">404. Tailoring Entity Matching for Industrial Settings.</a></li>
<li><a href="#405. Embedding based Link Prediction for Knowledge Graph Completion.">405. Embedding based Link Prediction for Knowledge Graph Completion.</a></li>
<li><a href="#406. Computational Approaches for Drug Repositioning: Towards a Holistic Perspective based on Knowledge Graphs.">406. Computational Approaches for Drug Repositioning: Towards a Holistic Perspective based on Knowledge Graphs.</a></li>
<li><a href="#407. Synthesis of Dependent Multichannel ECG using Generative Adversarial Networks.">407. Synthesis of Dependent Multichannel ECG using Generative Adversarial Networks.</a></li>
<li><a href="#408. Some Issues for Location Dependent Information System Query in Mobile Environment.">408. Some Issues for Location Dependent Information System Query in Mobile Environment.</a></li>
<li><a href="#409. Approximate Event Pattern Matching over Heterogeneous and Dirty Sources.">409. Approximate Event Pattern Matching over Heterogeneous and Dirty Sources.</a></li>
<li><a href="#410. Controlling Patent Text Generation by Structural Metadata.">410. Controlling Patent Text Generation by Structural Metadata.</a></li>
<li><a href="#411. Neural (Knowledge Graph">411. Neural (Knowledge Graph) Question Answering Using Synthetic Training Data.</a> Question Answering Using Synthetic Training Data.)</li>
<li><a href="#412. Automatic Contextual Storytelling in a Natural Language Corpus.">412. Automatic Contextual Storytelling in a Natural Language Corpus.</a></li>
<li><a href="#413. Generating Clarifying Questions in Conversational Search Systems.">413. Generating Clarifying Questions in Conversational Search Systems.</a></li>
<li><a href="#414. How the Quantum-inspired Framework Supports Keyword Searches on Multi-model Databases.">414. How the Quantum-inspired Framework Supports Keyword Searches on Multi-model Databases.</a></li>
</ul>
</li>
<li><a href="#Poster Presentations    25">Poster Presentations    25</a><ul>
<li><a href="#415. Optimal End-Biased Histograms for Hierarchical Data.">415. Optimal End-Biased Histograms for Hierarchical Data.</a></li>
<li><a href="#416. Two Test Collections for Retrieval Using Named Entity Markup.">416. Two Test Collections for Retrieval Using Named Entity Markup.</a></li>
<li><a href="#417. Improving Anchor-based Explanations.">417. Improving Anchor-based Explanations.</a></li>
<li><a href="#418. Towards Inferring Queries from Simple and Partial Provenance Examples.">418. Towards Inferring Queries from Simple and Partial Provenance Examples.</a></li>
<li><a href="#419. Enhanced Story Representation by ConceptNet for Predicting Story Endings.">419. Enhanced Story Representation by ConceptNet for Predicting Story Endings.</a></li>
<li><a href="#420. Empirical Analysis of Impact of Query-Specific Customization of nDCG: A Case-Study with Learning-to-Rank Methods.">420. Empirical Analysis of Impact of Query-Specific Customization of nDCG: A Case-Study with Learning-to-Rank Methods.</a></li>
<li><a href="#421. Autonomous Predictive Modeling via Reinforcement Learning.">421. Autonomous Predictive Modeling via Reinforcement Learning.</a></li>
<li><a href="#422. A Human-in-the-Loop Approach to Malware Author Classification.">422. A Human-in-the-Loop Approach to Malware Author Classification.</a></li>
<li><a href="#423. Deriving Geolocations in Wikipedia.">423. Deriving Geolocations in Wikipedia.</a></li>
<li><a href="#424. A Cost Estimation Technique for Recursive Relational Algebra.">424. A Cost Estimation Technique for Recursive Relational Algebra.</a></li>
<li><a href="#425. User Taste-Aware Image Search.">425. User Taste-Aware Image Search.</a></li>
<li><a href="#426. RotaryDS: Fast Storage for Massive Data Streams via a Rotation Storage Model.">426. RotaryDS: Fast Storage for Massive Data Streams via a Rotation Storage Model.</a></li>
<li><a href="#427. ALEX: Active Learning based Enhancement of a Classification Model's EXplainability.">427. ALEX: Active Learning based Enhancement of a Classification Model's EXplainability.</a></li>
<li><a href="#428. A Capsule Network-based Model for Learning Node Embeddings.">428. A Capsule Network-based Model for Learning Node Embeddings.</a></li>
<li><a href="#429. Structured Knowledge: Have we made progress? An extrinsic study of KB coverage over 19 years.">429. Structured Knowledge: Have we made progress? An extrinsic study of KB coverage over 19 years.</a></li>
<li><a href="#430. Diverse Enumeration of Maximal Cliques.">430. Diverse Enumeration of Maximal Cliques.</a></li>
<li><a href="#431. Truth be Told: Fake News Detection Using User Reactions on Reddit.">431. Truth be Told: Fake News Detection Using User Reactions on Reddit.</a></li>
<li><a href="#432. Ranking Multiple Choice Question Distractors using Semantically Informed Neural Networks.">432. Ranking Multiple Choice Question Distractors using Semantically Informed Neural Networks.</a></li>
<li><a href="#433. Exploiting Common Neighbor Graph for Link Prediction.">433. Exploiting Common Neighbor Graph for Link Prediction.</a></li>
<li><a href="#434. Maximum Signed (k, r">434. Maximum Signed (k, r)-Truss Identification in Signed Networks.</a>-Truss Identification in Signed Networks.)</li>
<li><a href="#435. Semi-supervised Consensus Clustering Based on Frequent Closed Itemsets.">435. Semi-supervised Consensus Clustering Based on Frequent Closed Itemsets.</a></li>
<li><a href="#436. Smarter and Safer Traffic Signal Controlling via Deep Reinforcement Learning.">436. Smarter and Safer Traffic Signal Controlling via Deep Reinforcement Learning.</a></li>
<li><a href="#437. OFFER: A Motif Dimensional Framework for Network Representation Learning.">437. OFFER: A Motif Dimensional Framework for Network Representation Learning.</a></li>
<li><a href="#438. Large Scale Long-tailed Product Recognition System at Alibaba.">438. Large Scale Long-tailed Product Recognition System at Alibaba.</a></li>
<li><a href="#439. Exploiting Class Labels to Boost Performance on Embedding-based Text Classification.">439. Exploiting Class Labels to Boost Performance on Embedding-based Text Classification.</a></li>
</ul>
</li>
<li><a href="#Demonstrations    35">Demonstrations    35</a><ul>
<li><a href="#440. Gtensor: Fast and Accurate Tensor Analysis System using GPUs.">440. Gtensor: Fast and Accurate Tensor Analysis System using GPUs.</a></li>
<li><a href="#441. CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine for COVID-19 Information.">441. CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine for COVID-19 Information.</a></li>
<li><a href="#442. Nebula: A Scalable Privacy-Preserving Machine Learning System in Ant Financial.">442. Nebula: A Scalable Privacy-Preserving Machine Learning System in Ant Financial.</a></li>
<li><a href="#443. IDEAL: IDEntifying the User's IdeAL Tuple via Sorting in the Database.">443. IDEAL: IDEntifying the User's IdeAL Tuple via Sorting in the Database.</a></li>
<li><a href="#444. PandaSQL: Parallel Randomized Triangle Enumeration with SQL Queries.">444. PandaSQL: Parallel Randomized Triangle Enumeration with SQL Queries.</a></li>
<li><a href="#445. Semantic Search over Structured Data.">445. Semantic Search over Structured Data.</a></li>
<li><a href="#446. STREAMER: A Powerful Framework for Continuous Learning in Data Streams.">446. STREAMER: A Powerful Framework for Continuous Learning in Data Streams.</a></li>
<li><a href="#447. INforE: Interactive Cross-platform Analytics for Everyone.">447. INforE: Interactive Cross-platform Analytics for Everyone.</a></li>
<li><a href="#448. ArXivDigest: A Living Lab for Personalized Scientific Literature Recommendation.">448. ArXivDigest: A Living Lab for Personalized Scientific Literature Recommendation.</a></li>
<li><a href="#449. Vallum-Med: Protecting Medical Data in Cloud Environments.">449. Vallum-Med: Protecting Medical Data in Cloud Environments.</a></li>
<li><a href="#450. Weaving Text into Tables.">450. Weaving Text into Tables.</a></li>
<li><a href="#451. IAI MovieBot: A Conversational Movie Recommender System.">451. IAI MovieBot: A Conversational Movie Recommender System.</a></li>
<li><a href="#452. Exploration of Dynamic Query-Based Load Balancing for Partially Replicated Database Systems with Node Failures.">452. Exploration of Dynamic Query-Based Load Balancing for Partially Replicated Database Systems with Node Failures.</a></li>
<li><a href="#453. TiCCo: Time-Centric Content Exploration.">453. TiCCo: Time-Centric Content Exploration.</a></li>
<li><a href="#454. Multimodal Knowledge Graph for Deep Learning Papers and Code.">454. Multimodal Knowledge Graph for Deep Learning Papers and Code.</a></li>
<li><a href="#455. UWKGM: A Modular Platform for Knowledge Graph Management.">455. UWKGM: A Modular Platform for Knowledge Graph Management.</a></li>
<li><a href="#456. WebLens: Towards Interactive Large-scale Structured Data Profiling.">456. WebLens: Towards Interactive Large-scale Structured Data Profiling.</a></li>
<li><a href="#457. Visualet: Visualizing Shapelets for Time Series Classification.">457. Visualet: Visualizing Shapelets for Time Series Classification.</a></li>
<li><a href="#458. M-Cypher: A GQL Framework Supporting Motifs.">458. M-Cypher: A GQL Framework Supporting Motifs.</a></li>
<li><a href="#459. AURORA: An Information Extraction System of Domain-specific Business Documents with Limited Data.">459. AURORA: An Information Extraction System of Domain-specific Business Documents with Limited Data.</a></li>
<li><a href="#460. PrivacyCheck v2: A Tool that Recaps Privacy Policies for You.">460. PrivacyCheck v2: A Tool that Recaps Privacy Policies for You.</a></li>
<li><a href="#461. Inside Quasimodo: Exploring Construction and Usage of Commonsense Knowledge.">461. Inside Quasimodo: Exploring Construction and Usage of Commonsense Knowledge.</a></li>
<li><a href="#462. Computing and Illustrating Query Rewritings on Path Views with Binding Patterns.">462. Computing and Illustrating Query Rewritings on Path Views with Binding Patterns.</a></li>
<li><a href="#463. A Toolkit for Managing Multiple Crowdsourced Top-K Queries.">463. A Toolkit for Managing Multiple Crowdsourced Top-K Queries.</a></li>
<li><a href="#464. User and Context Integrated Experience Mining in Online Health Communities.">464. User and Context Integrated Experience Mining in Online Health Communities.</a></li>
<li><a href="#465. Attribution IQ: Scalable Game Theoretic Attribution in Web Analytics.">465. Attribution IQ: Scalable Game Theoretic Attribution in Web Analytics.</a></li>
<li><a href="#466. April: An Automatic Graph Data Management System Based on Reinforcement Learning.">466. April: An Automatic Graph Data Management System Based on Reinforcement Learning.</a></li>
<li><a href="#467. Active Hazard Observation via Human in the Loop Social Media Analytics System.">467. Active Hazard Observation via Human in the Loop Social Media Analytics System.</a></li>
<li><a href="#468. UI-FAME.">468. UI-FAME.</a></li>
<li><a href="#469. InterNet: Multistep Traffic Forecasting by Interacting Spatial and Temporal Features.">469. InterNet: Multistep Traffic Forecasting by Interacting Spatial and Temporal Features.</a></li>
<li><a href="#470. Sample Driven Data Mapping for Linked Data and Web APIs.">470. Sample Driven Data Mapping for Linked Data and Web APIs.</a></li>
<li><a href="#471. EasyGML: A Fully-functional and Easy-to-use Platform for Industrial Graph Machine Learning.">471. EasyGML: A Fully-functional and Easy-to-use Platform for Industrial Graph Machine Learning.</a></li>
<li><a href="#472. SemFE: Facilitating ML Pipeline Development with Semantics.">472. SemFE: Facilitating ML Pipeline Development with Semantics.</a></li>
<li><a href="#473. Active Search using Meta-Bandits.">473. Active Search using Meta-Bandits.</a></li>
<li><a href="#474. Towards Rich Qery Blockchain Database.">474. Towards Rich Qery Blockchain Database.</a></li>
</ul>
</li>
<li><a href="#Tutorials    11">Tutorials    11</a><ul>
<li><a href="#475. Neural Bayesian Information Processing.">475. Neural Bayesian Information Processing.</a></li>
<li><a href="#476. The Battle Against Online Harmful Information: The Cases of Fake News and Hate Speech.">476. The Battle Against Online Harmful Information: The Cases of Fake News and Hate Speech.</a></li>
<li><a href="#477. Multi-Model Data Query Languages and Processing Paradigms.">477. Multi-Model Data Query Languages and Processing Paradigms.</a></li>
<li><a href="#478. Compression of Deep Learning Models for NLP.">478. Compression of Deep Learning Models for NLP.</a></li>
<li><a href="#479. Knowledge Graphs: A Tutorial on the History of Knowledge Graph's Main Ideas.">479. Knowledge Graphs: A Tutorial on the History of Knowledge Graph's Main Ideas.</a></li>
<li><a href="#480. Fairness in Unsupervised Learning.">480. Fairness in Unsupervised Learning.</a></li>
<li><a href="#481. Challenges and Solutions to the Student Dropout Prediction Problem in Online Courses.">481. Challenges and Solutions to the Student Dropout Prediction Problem in Online Courses.</a></li>
<li><a href="#482. Introduction to Computer Vision and Realtime Deep Learning-based Object Detection.">482. Introduction to Computer Vision and Realtime Deep Learning-based Object Detection.</a></li>
<li><a href="#483. IoT Data Quality.">483. IoT Data Quality.</a></li>
<li><a href="#484. Mining User Interests from Social Media.">484. Mining User Interests from Social Media.</a></li>
<li><a href="#485. Network Alignment: Recent Advances and Future Directions.">485. Network Alignment: Recent Advances and Future Directions.</a></li>
</ul>
</li>
<li><a href="#Workshop Summaries    9">Workshop Summaries    9</a><ul>
<li><a href="#486. CSSA'20: Workshop on Combining Symbolic and Sub-Symbolic Methods and their Applications.">486. CSSA'20: Workshop on Combining Symbolic and Sub-Symbolic Methods and their Applications.</a></li>
<li><a href="#487. SKG4J 2020: 1st International Workshop on Semantic and Knowledge Graph Advances for Journalism.">487. SKG4J 2020: 1st International Workshop on Semantic and Knowledge Graph Advances for Journalism.</a></li>
<li><a href="#488. The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020">488. The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020): Special Edition on Dis/Misinformation Mining from Social media.</a>: Special Edition on Dis/Misinformation Mining from Social media.)</li>
<li><a href="#489. AIMLAI'20: Third Workshop on Advances in Interpretable Machine Learning and Artificial Intelligence.">489. AIMLAI'20: Third Workshop on Advances in Interpretable Machine Learning and Artificial Intelligence.</a></li>
<li><a href="#490. DataMod2020: 9th International Symposium "From Data to Models and Back".">490. DataMod2020: 9th International Symposium "From Data to Models and Back".</a></li>
<li><a href="#491. 3rd International Workshop on EntitY Retrieval and lEarning (EYRE 2020">491. 3rd International Workshop on EntitY Retrieval and lEarning (EYRE 2020).</a>.)</li>
<li><a href="#492. IWILDS'20: The 1st International Workshop on Investigating Learning during Web Search.">492. IWILDS'20: The 1st International Workshop on Investigating Learning during Web Search.</a></li>
<li><a href="#493. DTMBIO 2020: The Fourteenth International Workshop on Data and Text Mining in Biomedical Informatics.">493. DTMBIO 2020: The Fourteenth International Workshop on Data and Text Mining in Biomedical Informatics.</a></li>
<li><a href="#494. On the Knowledge-Driven Analytics and Systems Impacting Human Quality of Life.">494. On the Knowledge-Driven Analytics and Systems Impacting Human Quality of Life.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav><h1 id="29th CIKM 2020:Virtual Event, Ireland">29th CIKM 2020:Virtual Event, Ireland</h1>
<p><a href="https://doi.org/10.1145/3340531">CIKM '20: The 29th ACM International Conference on Information and Knowledge Management, Virtual Event, Ireland, October 19-23, 2020.</a> ACM
<a href="https://dblp.uni-trier.de/db/conf/cikm/cikm2020.html">DBLP Link</a></p>
<h2 id="Paper Num: 494 || Session Num: 10">Paper Num: 494 || Session Num: 10</h2>
<ul>
<li><a href="#Applied Research Track    73">Applied Research Track    73</a></li>
<li><a href="#Demonstrations    35">Demonstrations    35</a></li>
<li><a href="#Doctoral Consortium    12">Doctoral Consortium    12</a></li>
<li><a href="#Full Paper Track    193">Full Paper Track    193</a></li>
<li><a href="#Keynote Talks    2">Keynote Talks    2</a></li>
<li><a href="#Poster Presentations    25">Poster Presentations    25</a></li>
<li><a href="#Resource Track    32">Resource Track    32</a></li>
<li><a href="#Short Paper Track    102">Short Paper Track    102</a></li>
<li><a href="#Tutorials    11">Tutorials    11</a></li>
<li><a href="#Workshop Summaries    9">Workshop Summaries    9</a></li>
</ul>
<h2 id="Keynote Talks    2">Keynote Talks    2</h2>
<h3 id="1. Ceres: Harvesting Knowledge from the Semi-structured Web.">1. Ceres: Harvesting Knowledge from the Semi-structured Web.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417406">Paper Link</a>    Pages:1</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/d/XinLunaDong.html">Xin Luna Dong</a></p>
<p>Abstract:
Knowledge graphs have been used to support a wide range of applications and enhance search and QA for Google, Bing, Amazon Alexa, etc. However, we often miss long-tail knowledge, including unpopular entities, unpopular relations, and unpopular verticals. In this talk we describe our efforts in harvesting knowledge from semi-structured websites, which are often populated according to some templates using vast volume of data stored in underlying databases.</p>
<p>Keywords:</p>
<h3 id="2. Accelerating Discovery Science with an Internet of FAIR Data and Services.">2. Accelerating Discovery Science with an Internet of FAIR Data and Services.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417407">Paper Link</a>    Pages:3</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/d/MichelDumontier.html">Michel Dumontier</a></p>
<p>Abstract:
Biomedicine has always been a fertile and challenging domain for computational discovery science. Indeed, the existence of millions of scientific articles, thousands of databases, and hundreds of ontologies offer exciting opportunities to mine our collective knowledge, were we not stymied by incompatible formats, incomplete and overlapping vocabularies, confusing licensing policies, and heterogeneous data access points.</p>
<p>Keywords:</p>
<h2 id="Full Paper Track    193">Full Paper Track    193</h2>
<h3 id="3. Ensemble Block Co-clustering: A Unified Framework for Text Data.">3. Ensemble Block Co-clustering: A Unified Framework for Text Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412058">Paper Link</a>    Pages:5-14</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/147/0407.html">Sverine Affeldt</a> ; <a href="https://dblp.uni-trier.de/pid/24/8729.html">Lazhar Labiod</a> ; <a href="https://dblp.uni-trier.de/pid/63/1468.html">Mohamed Nadif</a></p>
<p>Abstract:
In this paper, we propose a unified framework for Ensemble Block Co-clustering (EBCO), which aims to fuse multiple basic co-clusterings into a consensus structured affinity matrix. Each co-clustering to be fused is obtained by applying a co-clustering method on the same document-term dataset. This fusion process reinforces the individual quality of the multiple basic data co-clusterings within a single consensus matrix. Besides, the proposed framework enables a completely unsupervised co-clustering where the number of co-clusters is automatically inferred based on the non trivial generalized modularity. We first define an explicit objective function which allows the joint learning of the basic co-clusterings aggregation and the consensus block co-clustering. Then, we show that EBCO generalizes the one side ensemble clustering to an ensemble block co-clustering context. We also establish theoretical equivalence to spectral co-clustering and weighted double spherical k-means clustering for textual data. Experimental results on various real-world document-term datasets demonstrate that EBCO is an efficient competitor to some state-of-the-art ensemble and co-clustering methods.</p>
<p>Keywords:</p>
<h3 id="4. Learning to Personalize for Web Search Sessions.">4. Learning to Personalize for Web Search Sessions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412050">Paper Link</a>    Pages:15-24</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/141/4302.html">Saad Aloteibi</a> ; <a href="https://dblp.uni-trier.de/pid/12/336.html">Stephen Clark</a></p>
<p>Abstract:
The task of session search focuses on using interaction data to improve relevance for the user's next query at the session level. In this paper, we formulate session search as a personalization task under the framework of learning to rank. Personalization approaches re-rank results to match a user model. Such user models are usually accumulated over time based on the user's browsing behaviour. We use a pre-computed and transparent set of user models based on concepts from the social science literature. Interaction data are used to map each session to these user models. Novel features are then estimated based on such models as well as sessions' interaction data. Extensive experiments on test collections from the TREC session track show statistically significant improvements over current session search algorithms.</p>
<p>Keywords:</p>
<h3 id="5. Optimization of Answer Set Programs for Consistent Query Answering by Means of First-Order Rewriting.">5. Optimization of Answer Set Programs for Consistent Query Answering by Means of First-Order Rewriting.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411911">Paper Link</a>    Pages:25-34</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5074.html">Aziz Amezian El Khalfioui</a> ; <a href="https://dblp.uni-trier.de/pid/276/5115.html">Jonathan Joertz</a> ; <a href="https://dblp.uni-trier.de/pid/276/5119.html">Dorian Labeeuw</a> ; <a href="https://dblp.uni-trier.de/pid/276/5060.html">Gatan Staquet</a> ; <a href="https://dblp.uni-trier.de/pid/w/JefWijsen.html">Jef Wijsen</a></p>
<p>Abstract:
Consistent Query Answering (CQA) with respect to primary keys is the following problem. Given a database instance that is possibly inconsistent with respect to its primary key constraints, define a repair as an inclusion-maximal consistent subinstance. Given a Boolean query q, the problem CERTAINTY(q) takes a database instance as input, and asks whether q is true in every repair. For every Boolean conjunctive query q, the complement of CERTAINTY(q) can be straightforwardly implemented in Answer Set Programming (ASP) by means of a generate-and-test approach: first generate a repair, and then test whether it falsifies the query. Theoretical research has recently revealed that for every self-join-free Boolean conjunctive query q, the complexity class of CERTAINTY(q) is one of FO, L-complete, or coNP-complete. Faced with this complexity trichotomy, one can hypothesize that in practice, the full power of generate-and-test is a computational overkill when CERTAINTY(q) is in the low complexity classes FO or L. We investigate part of this hypothesis within the context of ASP, by asking the following question: whenever CERTAINTY(q) is in FO, does a dedicated first-order algorithm exhibit significant performance gains compared to a generic generate-and-test implementation? We first elaborate on the construction of such dedicated first-order algorithms in ASP, and then empirically address this question.</p>
<p>Keywords:</p>
<h3 id="6. Spectral Relaxations and Fair Densest Subgraphs.">6. Spectral Relaxations and Fair Densest Subgraphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412036">Paper Link</a>    Pages:35-44</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/54/3951.html">Aris Anagnostopoulos</a> ; <a href="https://dblp.uni-trier.de/pid/b/LucaBecchetti.html">Luca Becchetti</a> ; <a href="https://dblp.uni-trier.de/pid/163/0451.html">Adriano Fazzone</a> ; <a href="https://dblp.uni-trier.de/pid/228/2522.html">Cristina Menghini</a> ; <a href="https://dblp.uni-trier.de/pid/48/7183.html">Chris Schwiegelshohn</a></p>
<p>Abstract:
Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we address the problem of identifying a densest subgraph, while ensuring that none of one binary protected attribute is disparately impacted.</p>
<p>Keywords:</p>
<h3 id="7. The Impact of Negative Triple Generation Strategies and Anomalies on Knowledge Graph Completion.">7. The Impact of Negative Triple Generation Strategies and Anomalies on Knowledge Graph Completion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412023">Paper Link</a>    Pages:45-54</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/262/0588.html">Iti Bansal</a> ; <a href="https://dblp.uni-trier.de/pid/265/0838.html">Sudhanshu Tiwari</a> ; <a href="https://dblp.uni-trier.de/pid/02/9016.html">Carlos R. Rivero</a></p>
<p>Abstract:
Even though knowledge graphs have proven very useful for several tasks, they are marked by incompleteness. Completion algorithms aim to extend knowledge graphs by predicting missing (subject, predicate, object) triples, usually by training a model to discern between correct (positive) and incorrect (negative) triples. However, under the open-world assumption in which a missing triple is not negative but unknown, negative triple generation is challenging. Although negative triples are known to drive the accuracy of completion models, its impact has not been thoroughly examined yet. To evaluate accuracy, test triples are considered positive and negative triples are derived from them. The evaluation protocol is thus impacted by the generation of negative triples, which remains to be analyzed. Another issue is that the knowledge graphs available for evaluation contain anomalies like severe redundancy, and it is unclear how anomalies affect the accuracy of completion models. In this paper, we analyze the impact of negative triple generation during both training and testing on translation-based completion models. We examine four negative triple generation strategies, which are also used to evaluate the models when anomalies in the test split are included and discarded. In addition to previously-studied anomalies like near-same predicates, we include another anomaly: knowledge present in the test that is missing from the training split. Our main conclusion is that the most common strategy for negative triple generation (local-closed world assumption) can be mimicked by a combination of a naive and a immediate neighborhood strategies. This result suggests that completion models can be learned independently for certain subgraphs, which would render completion models useful in the context of knowledge graph evolution. Although anomalies are considered harmful since they artificially increase the accuracy of completion models, our results show otherwise for certain knowledge graphs, which calls for further research efforts.</p>
<p>Keywords:</p>
<h3 id="8. tdGraphEmbed: Temporal Dynamic Graph-Level Embedding.">8. tdGraphEmbed: Temporal Dynamic Graph-Level Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411953">Paper Link</a>    Pages:55-64</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/168/1230.html">Moran Beladev</a> ; <a href="https://dblp.uni-trier.de/pid/r/LiorRokach.html">Lior Rokach</a> ; <a href="https://dblp.uni-trier.de/pid/54/10321.html">Gilad Katz</a> ; <a href="https://dblp.uni-trier.de/pid/46/650.html">Ido Guy</a> ; <a href="https://dblp.uni-trier.de/pid/08/6560.html">Kira Radinsky</a></p>
<p>Abstract:
Temporal dynamic graphs are graphs whose topology evolves over time, with nodes and edges added and removed between different time snapshots. Embedding such graphs in a low-dimensional space is important for a variety of tasks, including graphs' similarities, time series trends analysis and anomaly detection, graph visualization, graph classification, and clustering. Despite the importance of the temporal element in these tasks, existing graph embedding methods focus on capturing the graph's nodes in a static mode and/or do not model the graph in its entirety in temporal dynamic mode. In this study, we present tdGraphEmbed, a novel temporal graph-level embedding approach that extend the random-walk based node embedding methods to globally embed both the nodes of the graph and its representation at each time step, thus creating representation of the entire graph at each step. Our approach was applied to graph similarity ranking, temporal anomaly detection, trend analysis, and graph visualizations tasks, where we leverage our temporal embedding in a fast and scalable way for each of the tasks. An evaluation of tdGraphEmbed on five real-world datasets shows that our approach can outperform state-of-the-art approaches used for graph embedding and node embedding in temporal graphs.</p>
<p>Keywords:</p>
<h3 id="9. Learning to Match Jobs with Resumes from Sparse Interaction Data using Multi-View Co-Teaching Network.">9. Learning to Match Jobs with Resumes from Sparse Interaction Data using Multi-View Co-Teaching Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411929">Paper Link</a>    Pages:65-74</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/217/1794.html">Shuqing Bian</a> ; <a href="https://dblp.uni-trier.de/pid/83/6331-17.html">Xu Chen</a> ; <a href="https://dblp.uni-trier.de/pid/52/8700.html">Wayne Xin Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/48/3927.html">Kun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/255/2277.html">Yupeng Hou</a> ; <a href="https://dblp.uni-trier.de/pid/24/4470.html">Yang Song</a> ; <a href="https://dblp.uni-trier.de/pid/15/4777.html">Tao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
With the ever-increasing growth of online recruitment data, job-resume matching has become an important task to automatically match jobs with suitable resumes. This task is typically casted as a supervised text matching problem. Supervised learning is powerful when the labeled data is sufficient. However, on online recruitment platforms, job-resume interaction data is sparse and noisy, which affects the performance of job-resume match algorithms.</p>
<p>Keywords:</p>
<h3 id="10. Incremental and Parallel Computation of Structural Graph Summaries for Evolving Graphs.">10. Incremental and Parallel Computation of Structural Graph Summaries for Evolving Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411878">Paper Link</a>    Pages:75-84</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/222/6353.html">Till Blume</a> ; <a href="https://dblp.uni-trier.de/pid/r/DavidRicherby.html">David Richerby</a> ; <a href="https://dblp.uni-trier.de/pid/06/2380.html">Ansgar Scherp</a></p>
<p>Abstract:
Graph summarization is the task of finding condensed representations of graphs such that a chosen set of (structural) subgraph features in the graph summary are equivalent to the input graph. Existing graph summarization algorithms are tailored to specific graph summary models, only support one-time batch computation, are designed and implemented for a specific task, or evaluated using static graphs. Our novel, incremental, parallel algorithm addresses all these shortcomings. We support various structural graph summary models defined in our formal language FLUID. All graph summaries defined with FLUID can be updated in time O(  dk), where  is the number of additions, deletions, and modifications to the input graph, d is its maximum degree, and k is the maximum distance in the subgraphs considered. We empirically evaluate the performance of our algorithm on benchmark and real-world datasets. Our experiments show that, for commonly used summary models and datasets, the incremental summarization algorithm almost always outperforms their batch counterpart, even when about $50%$ of the graph database changes. The source code and the experimental results are openly available for reproducibility and extensibility.</p>
<p>Keywords:</p>
<h3 id="11. Do People and Neural Nets Pay Attention to the Same Words: Studying Eye-tracking Data for Non-factoid QA Evaluation.">11. Do People and Neural Nets Pay Attention to the Same Words: Studying Eye-tracking Data for Non-factoid QA Evaluation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412043">Paper Link</a>    Pages:85-94</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/205/1978.html">Valeria Bolotova</a> ; <a href="https://dblp.uni-trier.de/pid/205/1964.html">Vladislav Blinov</a> ; <a href="https://dblp.uni-trier.de/pid/204/0083.html">Yukun Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/c/WBruceCroft.html">W. Bruce Croft</a> ; <a href="https://dblp.uni-trier.de/pid/98/1631.html">Falk Scholer</a> ; <a href="https://dblp.uni-trier.de/pid/s/MarkSanderson.html">Mark Sanderson</a></p>
<p>Abstract:
We investigated how users evaluate passage-length answers for non-factoid questions. We conduct a study where answers were presented to users, sometimes shown with automatic word highlighting. Users were tasked with evaluating answer quality, correctness, completeness, and conciseness. Words in the answer were also annotated, both explicitly through user mark up and implicitly through user gaze data obtained from eye-tracking. Our results show that the correctness of an answer strongly depends on its completeness, conciseness is less important.</p>
<p>Keywords:</p>
<h3 id="12. Fast and Scalable Outlier Detection with Sorted Hypercubes.">12. Fast and Scalable Outlier Detection with Sorted Hypercubes.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412033">Paper Link</a>    Pages:95-104</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5000.html">Eugnio F. Cabral</a> ; <a href="https://dblp.uni-trier.de/pid/84/5092.html">Robson L. F. Cordeiro</a></p>
<p>Abstract:
Outlier detection is the task responsible for finding novel or rare phenomena that provide valuable insights in many areas of the industry. The neighborhood-based algorithms are largely used to tackle this problem due to the intuitive interpretation and wide applicability in different domains. Their major drawback is the intensive neighborhood search that takes hours or even days to complete in large data, thus being impractical in many real-world scenarios. This paper proposes HySortOD -- a novel algorithm that uses an efficient hypercube-ordering-and-searching strategy for fast outlier detection. Its main focus is the analysis of data with many instances and a low-to-moderate number of dimensions. We performed comprehensive experiments using real data with up to ~500k instances and ~120 dimensions, where our new algorithm outperformed 7 state-of-the-art competitors in runtime, being up to 4 orders of magnitude faster in large data. Specifically, 12 well-known benchmark datasets were deeply investigated and one case study in the crucial task of breast cancer detection was also performed to demonstrate that our approach can be successfully used as an out-of-the-box solution for real-world, non-benchmark problems. Based on our experiments, we also identified default parameter values that allow us to be parameter-free and yet report high-quality results.</p>
<p>Keywords:</p>
<h3 id="13. SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis.">13. SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412003">Paper Link</a>    Pages:105-114</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/80/7421.html">Erik Cambria</a> ; <a href="https://dblp.uni-trier.de/pid/37/4190-55.html">Yang Li</a> ; <a href="https://dblp.uni-trier.de/pid/191/2446.html">Frank Z. Xing</a> ; <a href="https://dblp.uni-trier.de/pid/116/4904.html">Soujanya Poria</a> ; <a href="https://dblp.uni-trier.de/pid/03/9813.html">Kenneth Kwok</a></p>
<p>Abstract:
Deep learning has unlocked new paths towards the emulation of the peculiarly-human capability of learning from examples. While this kind of bottom-up learning works well for tasks such as image classification or object detection, it is not as effective when it comes to natural language processing. Communication is much more than learning a sequence of letters and words: it requires a basic understanding of the world and social norms, cultural awareness, commonsense knowledge, etc.; all things that we mostly learn in a top-down manner. In this work, we integrate top-down and bottom-up learning via an ensemble of symbolic and subsymbolic AI tools, which we apply to the interesting problem of polarity detection from text. In particular, we integrate logical reasoning within deep learning architectures to build a new version of SenticNet, a commonsense knowledge base for sentiment analysis.</p>
<p>Keywords:</p>
<h3 id="14. Laconic Image Classification: Human vs. Machine Performance.">14. Laconic Image Classification: Human vs. Machine Performance.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411984">Paper Link</a>    Pages:115-124</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/228/0400.html">Javier Carrasco</a> ; <a href="https://dblp.uni-trier.de/pid/h/AidanHogan.html">Aidan Hogan</a> ; <a href="https://dblp.uni-trier.de/pid/12/6407-1.html">Jorge Prez</a></p>
<p>Abstract:
We propose laconic classification as a novel way to understand and compare the performance of diverse image classifiers. The goal in this setting is to minimise the amount of information (aka. entropy) required in individual test images to maintain correct classification. Given a classifier and a test image, we compute an approximate minimal-entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalising similar methods explored in previous works. Proposing two complementary frameworks for computing the minimal-entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test-set, we find that machine classifiers are more sensitive entropy-wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans), supporting recent results suggesting a texture bias in the ILSVRC-trained models used. We also find, in the evaluated setting, that humans classify the minimal-entropy positive images of machine models with higher precision than machines classify those of humans.</p>
<p>Keywords:</p>
<h3 id="15. Retrievability based Document Selection for Relevance Feedback with Automatically Generated Query Variants.">15. Retrievability based Document Selection for Relevance Feedback with Automatically Generated Query Variants.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412032">Paper Link</a>    Pages:125-134</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/73/2286.html">Anirban Chakraborty</a> ; <a href="https://dblp.uni-trier.de/pid/41/7272.html">Debasis Ganguly</a> ; <a href="https://dblp.uni-trier.de/pid/70/1905.html">Owen Conlan</a></p>
<p>Abstract:
To mitigate the problem of over-dependence of a pseudo-relevance feedback algorithm on the top-M document set, we make use of a set of equivalence classes of queries rather than one single query. These query equivalents are automatically constructed either from a) a knowledge base of prior distributions of terms with respect to the given query terms, or b) iteratively generated from a relevance model of term distributions in the absence of such priors. These query variants are then used to estimate the retrievability of each document with the hypothesis that documents that are more likely to be retrieved at top-ranks for a larger number of these query variants are more likely to be effective for relevance feedback. Results of our experiments show that our proposed method is able to achieve substantially better precision at top-ranks (e.g. higher [email protected] and [email protected] values) for ad-hoc IR and points-of-interest (POI) recommendation tasks.</p>
<p>Keywords:</p>
<h3 id="16. Learning Graph-Based Geographical Latent Representation for Point-of-Interest Recommendation.">16. Learning Graph-Based Geographical Latent Representation for Point-of-Interest Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411905">Paper Link</a>    Pages:135-144</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/221/3390.html">Buru Chang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5091.html">Gwanghoon Jang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5041.html">Seoyoon Kim</a> ; <a href="https://dblp.uni-trier.de/pid/k/JaewooKang.html">Jaewoo Kang</a></p>
<p>Abstract:
Several geographical latent representation models that capture geographical influences among points-of-interest (POIs) have been proposed. Although the models improve POI recommendation performance, they depend on shallow methods that cannot effectively capture highly non-linear geographical influences from complex user-POI networks. In this paper, we propose a new graph-based geographical latent representation model (GGLR) which can capture highly non-linear geographical influences from complex user-POI networks. Our proposed GGLR considers two types of geographical influences: ingoing influences and outgoing influences. Based on a graph auto-encoder, geographical latent representations of ingoing and outgoing influences are trained to increase geographical influences between two consecutive POIs that frequently appear in check-in histories. Furthermore, we propose a graph neural network-based POI recommendation model (GPR) that uses the trained geographical latent representations of ingoing and outgoing influences for the estimation of user preferences. In the experimental evaluation on real-world datasets, we show that GGLR effectively captures highly non-linear geographical influences and GPR achieves state-of-the-art performance.</p>
<p>Keywords:</p>
<h3 id="17. Continuous-Time Dynamic Graph Learning via Neural Interaction Processes.">17. Continuous-Time Dynamic Graph Learning via Neural Interaction Processes.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411946">Paper Link</a>    Pages:145-154</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/24/10000.html">Xiaofu Chang</a> ; <a href="https://dblp.uni-trier.de/pid/172/1079.html">Xuqin Liu</a> ; <a href="https://dblp.uni-trier.de/pid/09/7677.html">Jianfeng Wen</a> ; <a href="https://dblp.uni-trier.de/pid/43/6294-2.html">Shuang Li</a> ; <a href="https://dblp.uni-trier.de/pid/234/2760.html">Yanming Fang</a> ; <a href="https://dblp.uni-trier.de/pid/94/3481.html">Le Song</a> ; <a href="https://dblp.uni-trier.de/pid/57/2210.html">Yuan Qi</a></p>
<p>Abstract:
Dynamic graphs such as the user-item interactions graphs and financial transaction networks are ubiquitous nowadays. While numerous representation learning methods for static graphs have been proposed, the study of dynamic graphs is still in its infancy. A main challenge of modeling dynamic graphs is how to effectively encode temporal and structural information into nonlinear and compact dynamic embeddings. To achieve this, we propose a principled graph-neural-based approach to learn continuous-time dynamic embeddings. We first define a temporal dependency interaction graph(TDIG) that is induced from sequences of interaction data. Based on the topology of this TDIG, we develop a dynamic message passing neural network named TDIG-MPNN, which can capture the fine-grained global and local information on TDIG. In addition, to enhance the quality of continuous-time dynamic embeddings, a novel selection mechanism comprised of two successive steps, i.e., co-attention and gating, is applied before the above TDIG-MPNN layer to adjust the importance of the nodes by considering high-order correlation between interactive nodes' k-depth neighbors on TDIG. Finally, we cast our learning problem in the framework of temporal point processes (TPPs) where we use TDIG-MPNN to design a neural intensity function for the dynamic interaction processes. Our model achieves superior performance over alternatives on temporal interaction prediction (including tranductive and inductive tasks) on multiple datasets.</p>
<p>Keywords:</p>
<h3 id="18. TGCN: Tag Graph Convolutional Network for Tag-Aware Recommendation.">18. TGCN: Tag Graph Convolutional Network for Tag-Aware Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411927">Paper Link</a>    Pages:155-164</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/89/5615.html">Bo Chen</a> ; <a href="https://dblp.uni-trier.de/pid/71/6601.html">Wei Guo</a> ; <a href="https://dblp.uni-trier.de/pid/24/10003.html">Ruiming Tang</a> ; <a href="https://dblp.uni-trier.de/pid/35/1895.html">Xin Xin</a> ; <a href="https://dblp.uni-trier.de/pid/39/10049.html">Yue Ding</a> ; <a href="https://dblp.uni-trier.de/pid/11/5357.html">Xiuqiang He</a> ; <a href="https://dblp.uni-trier.de/pid/40/3934.html">Dong Wang</a></p>
<p>Abstract:
Tag-aware recommender systems (TRS) utilize rich tagging records to better depict user portraits and item features. Recently, many efforts have been done to improve TRS with neural networks. However, these solutions rustically rely on the tag-based features for recommendation, which is insufficient to ease the sparsity, ambiguity and redundancy issues introduced by tags, thus hindering the recommendation performance. In this paper, we propose a novel tag-aware recommendation model named Tag Graph Convolutional Network (TGCN), which leverages the contextual semantics of multi-hop neighbors in the user-tag-item graph to alleviate the above issues. Specifically, TGCN first employs type-aware neighbor sampling and aggregation operation to learn the type-specific neighborhood representations. Then we leverage attention mechanism to discriminate the importance of different node types and creatively employ Convolutional Neural Network (CNN) as type-level aggregator to perform vertical and horizontal convolutions for modeling multi-granular feature interactions. Besides, a TransTag regularization function is proposed to accurately identify user's substantive preference. Extensive experiments on three public datasets and a real industrial dataset show that TGCN significantly outperforms state-of-the-art baselines for tag-aware top-N recommendation.</p>
<p>Keywords:</p>
<h3 id="19. An Adaptive Embedding Framework for Heterogeneous Information Networks.">19. An Adaptive Embedding Framework for Heterogeneous Information Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411989">Paper Link</a>    Pages:165-174</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/217/4891.html">Daoyuan Chen</a> ; <a href="https://dblp.uni-trier.de/pid/127/6999.html">Yaliang Li</a> ; <a href="https://dblp.uni-trier.de/pid/46/3522.html">Bolin Ding</a> ; <a href="https://dblp.uni-trier.de/pid/01/8558.html">Ying Shen</a></p>
<p>Abstract:
Heterogeneous information networks (HINs) have been ubiquitous in the real-world. HIN embeddings, which encode various information of the networks into low-dimensional vectors, can facilitate a wide range of applications on graph-structured data. Existing HIN embedding methods include random walk based methods that may not fully utilize the edge semantics and knowledge graph embedding methods that restrict the expression ability of topological information. In this paper, we propose a novel adaptive embedding framework, which integrates these two kinds of methods to preserve both topological information and relational information. By incorporating an assistant knowledge graph embedding model, the proposed framework performs efficient biased random walk under the guidance of edge semantics.</p>
<p>Keywords:</p>
<h3 id="20. Improving End-to-End Sequential Recommendations with Intent-aware Diversification.">20. Improving End-to-End Sequential Recommendations with Intent-aware Diversification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411897">Paper Link</a>    Pages:175-184</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/204/0075.html">Wanyu Chen</a> ; <a href="https://dblp.uni-trier.de/pid/168/4596.html">Pengjie Ren</a> ; <a href="https://dblp.uni-trier.de/pid/71/2935.html">Fei Cai</a> ; <a href="https://dblp.uni-trier.de/pid/51/394-1.html">Fei Sun</a> ; <a href="https://dblp.uni-trier.de/pid/r/MdRijke.html">Maarten de Rijke</a></p>
<p>Abstract:
Sequential recommenders that capture users' dynamic intents by modeling sequential behavior, are able to accurately recommend items to users. Previous studies on sequential recommendations (SRs) mostly focus on optimizing the recommendation accuracy, thus ignoring the diversity of recommended items. Many existing methods for improving the diversity of recommended items are not applicable to SRs because they assume that user intents are static and rely on post-processing the list of recommended items to promote diversity. We consider both accuracy and diversity by reformulating SRs as a list generation task, and propose an integrated approach with an end-to-end neural model, called intent-aware diversified sequential recommendation (IDSR). Specifically, we introduce an implicit intent mining (IIM) module for SR to capture multiple user intents reflected in sequences of user behavior. We design an intent-aware diversity promoting (IDP) loss function to supervise the learning of the IIM module and guide the model to take diversity into account during training. Extensive experiments on four datasets show that IDSR significantly outperforms state-of-the-art methods in terms of recommendation diversity while yielding comparable or superior recommendation accuracy.</p>
<p>Keywords:</p>
<h3 id="21. Unsupervised Cyberbullying Detection via Time-Informed Gaussian Mixture Model.">21. Unsupervised Cyberbullying Detection via Time-Informed Gaussian Mixture Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411934">Paper Link</a>    Pages:185-194</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/17/4969.html">Lu Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/153/5265.html">Kai Shu</a> ; <a href="https://dblp.uni-trier.de/pid/180/3252.html">Siqi Wu</a> ; <a href="https://dblp.uni-trier.de/pid/s/YasinNSilva.html">Yasin N. Silva</a> ; <a href="https://dblp.uni-trier.de/pid/190/5228.html">Deborah L. Hall</a> ; <a href="https://dblp.uni-trier.de/pid/92/309-1.html">Huan Liu</a></p>
<p>Abstract:
Social media is a vital means for information-sharing due to its easy access, low cost, and fast dissemination characteristics. However, increases in social media usage have corresponded with a rise in the prevalence of cyberbullying. Most existing cyberbullying detection methods aresupervised and, thus, have two key drawbacks: (1) The data labeling process is often time-consuming and labor-intensive; (2) Current labeling guidelines may not be generalized to future instances because of different language usage and evolving social networks. To address these limitations, this work introduces a principled approach forunsupervised cyberbullying detection. The proposed model consists of two main components: (1) Arepresentation learning network that encodes the social media session by exploiting multi-modal features, e.g., text, network, and time. (2) Amulti-task learning network that simultaneously fits the comment inter-arrival times and estimates the bullying likelihood based on a Gaussian Mixture Model. The proposed model jointly optimizes the parameters of both components to overcome the shortcomings of decoupled training. Our core contribution is an unsupervised cyberbullying detection model that not only experimentally outperforms the state-of-the-art unsupervised models, but also achieves competitive performance compared to supervised models.</p>
<p>Keywords:</p>
<h3 id="22. Product Quality Prediction with Convolutional Encoder-Decoder Architecture and Transfer Learning.">22. Product Quality Prediction with Convolutional Encoder-Decoder Architecture and Transfer Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412007">Paper Link</a>    Pages:195-204</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/194/4213.html">Hao-Yi Chih</a> ; <a href="https://dblp.uni-trier.de/pid/85/6913.html">Yao-Chung Fan</a> ; <a href="https://dblp.uni-trier.de/pid/92/1623.html">Wen-Chih Peng</a> ; <a href="https://dblp.uni-trier.de/pid/276/5090.html">Hai-Yuan Kuo</a></p>
<p>Abstract:
Mining data collected from industrial manufacturing process plays an important role for intelligent manufacturing in Industry 4.0. In this paper, we propose a deep convolutional model for predicting wafer fabrication quality in an intelligent integrated-circuit manufacturing application. The wafer fabrication quality prediction is motivated by the need for improving product line efficiency and reducing manufacturing cost by detecting potential defective work-in-process (WIP) wafers. This work considers the following two crucial data characteristics for wafer fabrication. First, our model is designed to learn spatial correlation between quality measurements on WIP wafers and fabrication results through an encoder-decoder neural network. Second, we leverage the fact that different products share the same raw manufacturing process to enable the knowledge transferring between prediction models of different products. Performance evaluation on real data sets is conducted to validate the strengths of our model on quality prediction, model interpretability, and feasibility of transferring knowledge.</p>
<p>Keywords:</p>
<h3 id="23. Matching in Selective and Balanced Representation Space for Treatment Effects Estimation.">23. Matching in Selective and Balanced Representation Space for Treatment Effects Estimation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412037">Paper Link</a>    Pages:205-214</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/258/1233.html">Zhixuan Chu</a> ; <a href="https://dblp.uni-trier.de/pid/136/7508.html">Stephen L. Rathbun</a> ; <a href="https://dblp.uni-trier.de/pid/23/3439-1.html">Sheng Li</a></p>
<p>Abstract:
The dramatically growing availability of observational data is being witnessed in various domains of science and technology, which facilitates the study of causal inference. However, estimating treatment effects from observational data is faced with two major challenges, missing counterfactual outcomes and treatment selection bias. Matching methods are among the mostly widely used and fundamental approaches to estimating treatment effects, but existing matching methods have poor performance when facing data with high dimensional and complicated variables. We propose a feature selection representation matching (FSRM) method based on deep representation learning and matching, which maps the original covariate space into a selective, nonlinear, and balanced representation space, and then conducts matching in the learned representation space. FSRM adopts deep feature selection to minimize the influence of irrelevant variables for estimating treatment effects and incorporates a regularizer based on the Wasserstein distance to learn balanced representations. We evaluate the performance of our FSRM method on three datasets, and the results demonstrate superiority over the state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="24. TPR: Text-aware Preference Ranking for Recommender Systems.">24. TPR: Text-aware Preference Ranking for Recommender Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411969">Paper Link</a>    Pages:215-224</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/207/7875.html">Yu-Neng Chuang</a> ; <a href="https://dblp.uni-trier.de/pid/59/5631-3.html">Chih-Ming Chen</a> ; <a href="https://dblp.uni-trier.de/pid/03/5904.html">Chuan-Ju Wang</a> ; <a href="https://dblp.uni-trier.de/pid/16/3313.html">Ming-Feng Tsai</a> ; <a href="https://dblp.uni-trier.de/pid/22/981.html">Yuan Fang</a> ; <a href="https://dblp.uni-trier.de/pid/l/EePengLim.html">Ee-Peng Lim</a></p>
<p>Abstract:
Textual data is common and informative auxiliary information for recommender systems. Most prior art utilizes text for rating prediction, but rare work connects it to top-recommendation. Moreover, although advanced recommendation models capable of incorporating auxiliary information have been developed, none of these are specifically designed to model textual information, yielding a limited usage scenario for typical user-to-item recommendation. In this work, we present a framework of text-aware preference ranking (TPR) for top- recommendation, in which we comprehensively model the joint association of user-item interaction and relations between items and associated text. Using the TPR framework, we construct a joint likelihood function that explicitly describes two ranking structures: 1) item preference ranking (IPR) and 2) word relatedness ranking (WRR), where the former captures the item preference of each user and the latter captures the word relatedness of each item. As these two explicit structures are by nature mutually dependent, we propose TPR-OPT, a simple yet effective learning criterion that additionally includes implicit structures, such as relatedness between items and relatedness between words for each user for model optimization. Such a design not only successfully describes the joint association among users, words, and text comprehensively but also naturally yields powerful representations that are suitable for a range of recommendation tasks, including user-to-item, item-to-item, and user-to-word recommendation, as well as item-to-word reconstruction. In this paper, extensive experiments have been conducted on eight recommendation datasets, the results of which demonstrate that by including textual information from item descriptions, the proposed TPR model consistently outperforms state-of-the-art baselines on various recommendation tasks.</p>
<p>Keywords:</p>
<h3 id="25. Offline Evaluation by Maximum Similarity to an Ideal Ranking.">25. Offline Evaluation by Maximum Similarity to an Ideal Ranking.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411915">Paper Link</a>    Pages:225-234</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/96/3666.html">Charles L. A. Clarke</a> ; <a href="https://dblp.uni-trier.de/pid/07/801.html">Mark D. Smucker</a> ; <a href="https://dblp.uni-trier.de/pid/178/4375.html">Alexandra Vtyurina</a></p>
<p>Abstract:
NDCG and similar measures remain standard for the offline evaluation of search, recommendation, question answering and similar systems. These measures require definitions for two or more relevance levels, which human assessors then apply to judge individual documents. Due to this dependence on a definition of relevance, it can be difficult to extend these measures to account for factors beyond relevance. Rather than propose extensions to these measures, we instead propose a radical simplification to replace them. For each query, we define a set of ideal rankings and compute the maximum rank similarity between members of this set and an actual ranking generated by a system. This maximum similarity to an ideal ranking becomes our effectiveness measure, replacing NDCG and similar measures. We propose rank biased overlap (RBO) to compute this rank similarity, since it was specifically created to address the requirements of rank similarity between search results. As examples, we explore ideal rankings that account for document length, diversity, and correctness.</p>
<p>Keywords:</p>
<h3 id="26. EPNet: Learning to Exit with Flexible Multi-Branch Network.">26. EPNet: Learning to Exit with Flexible Multi-Branch Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411973">Paper Link</a>    Pages:235-244</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/98/2150.html">Xin Dai</a> ; <a href="https://dblp.uni-trier.de/pid/06/8315.html">Xiangnan Kong</a> ; <a href="https://dblp.uni-trier.de/pid/55/3523.html">Tian Guo</a></p>
<p>Abstract:
Dynamic inference is an emerging technique that reduces the computational cost of deep neural network under resource-constrained scenarios, such as inference on mobile devices. One way to achieve dynamic inference is to leverage multi-branch neural networks that apply different computation on input data by following different branches. Conventional research on multi-branch neural networks mainly targeted at improving the accuracy of each branch, and use manually designed rules to decide which input follows which branch of the network. Furthermore, these networks often provide a small number of exits, limiting their ability to adapt to external changes. In this paper, we investigate the problem of designing a flexible multi-branch network and early-exiting policies that can adapt to the resource consumption to individual inference request without impacting the inference accuracy. We propose a lightweight branch structure that also provides fine-grained flexibility for early-exiting and leverage Markov decision process (MDP) to automatically learn the early-exiting policies. Our proposed model, EPNet, was effective in reducing inference cost without impacting accuracy by choosing the most suitable branch exit. We also observe that EPNet achieved 3% higher accuracy with an inference budget, compared to state-of-the-art approaches.</p>
<p>Keywords:</p>
<h3 id="27. Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction.">27. Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411975">Paper Link</a>    Pages:245-254</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/241/4844.html">Songgaojun Deng</a> ; <a href="https://dblp.uni-trier.de/pid/77/9625.html">Shusen Wang</a> ; <a href="https://dblp.uni-trier.de/pid/30/444.html">Huzefa Rangwala</a> ; <a href="https://dblp.uni-trier.de/pid/48/6248.html">Lijing Wang</a> ; <a href="https://dblp.uni-trier.de/pid/74/9990.html">Yue Ning</a></p>
<p>Abstract:
Forecasting influenza-like illness (ILI) is of prime importance to epidemiologists and health-care providers. Early prediction of epidemic outbreaks plays a pivotal role in disease intervention and control. Most existing work has either limited long-term prediction performance or fails to capture spatio-temporal dependencies in data. In this paper, we design a cross-location attention based graph neural network (Cola-GNN) for learning time series embeddings in long-term ILI predictions. We propose a graph message passing framework to combine graph structures (e.g., geolocations) and time-series features (e.g., temporal sequences) in a dynamic propagation process. We compare the proposed method with state-of-the-art statistical approaches and deep learning models. We conducted a set of extensive experiments on real-world epidemic-related datasets from the United States and Japan. The proposed method demonstrated strong predictive performance and leads to interpretable results for long-term epidemic predictions.</p>
<p>Keywords:</p>
<h3 id="28. Opinion-aware Answer Generation for Review-driven Question Answering in E-Commerce.">28. Opinion-aware Answer Generation for Review-driven Question Answering in E-Commerce.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411904">Paper Link</a>    Pages:255-264</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/115/6282.html">Yang Deng</a> ; <a href="https://dblp.uni-trier.de/pid/85/1177.html">Wenxuan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/48/1707.html">Wai Lam</a></p>
<p>Abstract:
Product-related question answering (QA) is an important but challenging task in E-Commerce. It leads to a great demand on automatic review-driven QA, which aims at providing instant responses towards user-posted questions based on diverse product reviews. Nevertheless, the rich information about personal opinions in product reviews, which is essential to answer those product-specific questions, is underutilized in current generation-based review-driven QA studies. There are two main challenges when exploiting the opinion information from the reviews to facilitate the opinion-aware answer generation: (i) jointly modeling opinionated and interrelated information between the question and reviews to capture important information for answer generation, (ii) aggregating diverse opinion information to uncover the common opinion towards the given question. In this paper, we tackle opinion-aware answer generation by jointly learning answer generation and opinion mining tasks with a unified model. Two kinds of opinion fusion strategies, namely, static and dynamic fusion, are proposed to distill and aggregate important opinion information learned from the opinion mining task into the answer generation process. Then a multi-view pointer-generator network is employed to generate opinion-aware answers for a given product-related question. Experimental results show that our method achieves superior performance in real-world E-Commerce QA datasets, and effectively generate opinionated and informative answers.</p>
<p>Keywords:</p>
<h3 id="29. UPON: User Profile Transferring across Networks.">29. UPON: User Profile Transferring across Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411964">Paper Link</a>    Pages:265-274</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/4994.html">Mengting Diao</a> ; <a href="https://dblp.uni-trier.de/pid/95/9457.html">Zhongbao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/63/2499.html">Sen Su</a> ; <a href="https://dblp.uni-trier.de/pid/03/4179.html">Shuai Gao</a> ; <a href="https://dblp.uni-trier.de/pid/181/3748.html">Huafeng Cao</a></p>
<p>Abstract:
User profiling has very important applications for many downstream tasks, such as recommender system, behavior prediction and market strategy. Most existing methods only focus on modeling user profiles of one social network with plenty of data. However, user profiles are difficult to acquire, especially when the data is scarce. Modeling user profiles under such conditions often leads to poor performance. Fortunately, we observed that not only user attributes but also user relationships are useful for user profiling and benefit the results. Meanwhile, similar users have similar behavior in different social networks. Finding user dependencies between social networks will help to infer user profiles. Motivated by such observations, in this paper, we for the first time propose to study the user profiling problem from the transfer learning perspective. We design an efficient User Profile transferring acrOss Networks (UPON) framework, which transfers knowledge of user relationship from one social network with plenty of data to facilitate the user profiling on the other social network with scarce data. In UPON, we first design a novel graph convolutional networks based characteristic-aware domain attention model (GCN-CDAM) to find user dependencies within and between domains (referring to social networks). We then design a dual-domain weighted adversarial learning method to solve the domain shift problem existing in the transferring procedure. Experimental results on Twitter-Foursquare dataset demonstrate that UPON outperforms the state-of-the-art models.</p>
<p>Keywords:</p>
<h3 id="30. Evaluating Stochastic Rankings with Expected Exposure.">30. Evaluating Stochastic Rankings with Expected Exposure.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411962">Paper Link</a>    Pages:275-284</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/38/2451-1.html">Fernando Diaz</a> ; <a href="https://dblp.uni-trier.de/pid/147/9120.html">Bhaskar Mitra</a> ; <a href="https://dblp.uni-trier.de/pid/69/7949.html">Michael D. Ekstrand</a> ; <a href="https://dblp.uni-trier.de/pid/130/0373.html">Asia J. Biega</a> ; <a href="https://dblp.uni-trier.de/pid/61/5238.html">Ben Carterette</a></p>
<p>Abstract:
We introduce the concept of expected exposure as the average attention ranked items receive from users over repeated samples of the same query. Furthermore, we advocate for the adoption of the principle of equal expected exposure: given a fixed information need, no item should receive more or less expected exposure than any other item of the same relevance grade. We argue that this principle is desirable for many retrieval objectives and scenarios, including topical diversity and fair ranking. %Leveraging user models from existing retrieval metrics, we propose a general evaluation methodology based on expected exposure and draw connections to related metrics in information retrieval evaluation. Importantly, this methodology relaxes classic information retrieval assumptions, allowing a system, in response to a query, to produce a distribution over rankings instead of a single fixed ranking. We study the behavior of the expected exposure metric and stochastic rankers across a variety of information access conditions, including ad hoc retrieval and recommendation. %We believe that measuring and optimizing expected exposure metrics using randomization opens a new area for retrieval algorithm development and progress.</p>
<p>Keywords:</p>
<h3 id="31. Towards Plausible Differentially Private ADMM Based Distributed Machine Learning.">31. Towards Plausible Differentially Private ADMM Based Distributed Machine Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411860">Paper Link</a>    Pages:285-294</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/234/6210.html">Jiahao Ding</a> ; <a href="https://dblp.uni-trier.de/pid/18/3178.html">Jingyi Wang</a> ; <a href="https://dblp.uni-trier.de/pid/191/6694.html">Guannan Liang</a> ; <a href="https://dblp.uni-trier.de/pid/26/3430.html">Jinbo Bi</a> ; <a href="https://dblp.uni-trier.de/pid/16/1033.html">Miao Pan</a></p>
<p>Abstract:
The Alternating Direction Method of Multipliers (ADMM) and its distributed version have been widely used in machine learning. In the iterations of ADMM, model updates using local private data and model exchanges among agents impose critical privacy concerns. Despite some pioneering works to relieve such concerns, differentially private ADMM still confronts many research challenges. For example, the guarantee of differential privacy (DP) relies on the premise that the optimality of each local problem can be perfectly attained in each ADMM iteration, which may never happen in practice. The model trained by DP ADMM may have low prediction accuracy. In this paper, we address these concerns by proposing a novel (Improved) Plausible differentially Private ADMM algorithm, called PP-ADMM and IPP-ADMM. In PP-ADMM, each agent approximately solves a perturbed optimization problem that is formulated from its local private data in an iteration, and then perturbs the approximate solution with Gaussian noise to provide the DP guarantee. To further improve the model accuracy and convergence, an improved version IPP-ADMM adopts sparse vector technique (SVT) to determine if an agent should update its neighbors with the current perturbed solution. The agent calculates the difference of the current solution from that in the last iteration, and if the difference is larger than a threshold, it passes the solution to neighbors; or otherwise the solution will be discarded. Moreover, we propose to track the total privacy loss under the zero-concentrated DP (zCDP) and provide a generalization performance analysis. Experiments on real-world datasets demonstrate that under the same privacy guarantee, the proposed algorithms are superior to the state of the art in terms of model accuracy and convergence rate.</p>
<p>Keywords:</p>
<h3 id="32. Graph Prototypical Networks for Few-shot Learning on Attributed Networks.">32. Graph Prototypical Networks for Few-shot Learning on Attributed Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411922">Paper Link</a>    Pages:295-304</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/234/6878.html">Kaize Ding</a> ; <a href="https://dblp.uni-trier.de/pid/50/8201.html">Jianling Wang</a> ; <a href="https://dblp.uni-trier.de/pid/144/7997.html">Jundong Li</a> ; <a href="https://dblp.uni-trier.de/pid/153/5265.html">Kai Shu</a> ; <a href="https://dblp.uni-trier.de/pid/65/6164.html">Chenghao Liu</a> ; <a href="https://dblp.uni-trier.de/pid/92/309-1.html">Huan Liu</a></p>
<p>Abstract:
Attributed networks nowadays are ubiquitous in a myriad of high-impact applications, such as social network analysis, financial fraud detection, and drug discovery. As a central analytical task on attributed networks, node classification has received much attention in the research community. In real-world attributed networks, a large portion of node classes only contains limited labeled instances, rendering a long-tail node class distribution. Existing node classification algorithms are unequipped to handle the few-shot node classes. As a remedy, few-shot learning has attracted a surge of attention in the research community. Yet, few-shot node classification remains a challenging problem as we need to address the following questions: (i) How to extract meta-knowledge from an attributed network for few-shot node classification? (ii) How to identify the informativeness of each labeled instance for building a robust and effective model? To answer these questions, in this paper, we propose a graph meta-learning framework -- Graph Prototypical Networks (GPN). By constructing a pool of semi-supervised node classification tasks to mimic the real test environment, GPN is able to perform meta-learning on an attributed network and derive a highly generalizable model for handling the target classification task. Extensive experiments demonstrate the superior capability of GPN in few-shot node classification.</p>
<p>Keywords:</p>
<h3 id="33. Neural Formatting for Spreadsheet Tables.">33. Neural Formatting for Spreadsheet Tables.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411943">Paper Link</a>    Pages:305-314</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5055.html">Haoyu Dong Dong</a> ; <a href="https://dblp.uni-trier.de/pid/63/6030.html">Jinyu Wang</a> ; <a href="https://dblp.uni-trier.de/pid/63/3161.html">Zhouyu Fu</a> ; <a href="https://dblp.uni-trier.de/pid/23/3395.html">Shi Han</a> ; <a href="https://dblp.uni-trier.de/pid/87/461.html">Dongmei Zhang</a></p>
<p>Abstract:
Spreadsheets are popular and widely used for data presentation and management, where users create tables in various structures to organize and present data. Table formatting is an important yet tedious task for better exhibiting table structures and data relationships. However, without the aid of intelligent tools, manual formatting remains a tedious and time-consuming task. In this paper, we propose CellGAN, a neural formatting model for learning and recommending formats of spreadsheet tables. Based on a novel conditional generative adversarial network (cGAN) architecture, CellGAN learns table formatting from real-world spreadsheet tables in a self-supervised fashion without requiring human labeling. In CellGAN we devise two mechanisms, row/column-wise pooling and local refinement network, to address challenges from the spreadsheet domain. We evaluate the effectiveness of CellGAN against real-world datasets using both quantitative metrics and human perception studies. The results indicate remarkable performance gains over rule-based methods, graphical models or direct application of the state-of-the-art cGANs used in visual synthesis tasks. Neural Formatting is the first step towards auto-formatting for spreadsheet tables with promising results.</p>
<p>Keywords:</p>
<h3 id="34. Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters.">34. Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411903">Paper Link</a>    Pages:315-324</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/193/5689.html">Yingtong Dou</a> ; <a href="https://dblp.uni-trier.de/pid/90/9499.html">Zhiwei Liu</a> ; <a href="https://dblp.uni-trier.de/pid/57/2405-8.html">Li Sun</a> ; <a href="https://dblp.uni-trier.de/pid/264/4737.html">Yutong Deng</a> ; <a href="https://dblp.uni-trier.de/pid/69/7742.html">Hao Peng</a> ; <a href="https://dblp.uni-trier.de/pid/y/PhilipSYu.html">Philip S. Yu</a></p>
<p>Abstract:
Graph Neural Networks (GNNs) have been widely applied to fraud detection problems in recent years, revealing the suspiciousness of nodes by aggregating their neighborhood information via different relations. However, few prior works have noticed the camouflage behavior of fraudsters, which could hamper the performance of GNN-based fraud detectors during the aggregation process. In this paper, we introduce two types of camouflages based on recent empirical studies, i.e., the feature camouflage and the relation camouflage. Existing GNNs have not addressed these two camouflages, which results in their poor performance in fraud detection problems. Alternatively, we propose a new model named CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation process with three unique modules against camouflages. Concretely, we first devise a label-aware similarity measure to find informative neighboring nodes. Then, we leverage reinforcement learning (RL) to find the optimal amounts of neighbors to be selected. Finally, the selected neighbors across different relations are aggregated together. Comprehensive experiments on two real-world fraud datasets demonstrate the effectiveness of the RL algorithm. The proposed CARE-GNN also outperforms state-of-the-art GNNs and GNN-based fraud detectors. We integrate all GNN-based fraud detectors as an opensource toolbox <a href="https://github.com/safe-graph/DGFraud">https://github.com/safe-graph/DGFraud</a>. The CARE-GNN code and datasets are available at <a href="https://github.com/YingtongDou/CARE-GNN">https://github.com/YingtongDou/CARE-GNN</a>.</p>
<p>Keywords:</p>
<h3 id="35. Towards Generalizable Deepfake Detection with Locality-aware AutoEncoder.">35. Towards Generalizable Deepfake Detection with Locality-aware AutoEncoder.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411892">Paper Link</a>    Pages:325-334</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/183/5606.html">Mengnan Du</a> ; <a href="https://dblp.uni-trier.de/pid/240/9336.html">Shiva K. Pentyala</a> ; <a href="https://dblp.uni-trier.de/pid/241/9779.html">Yuening Li</a> ; <a href="https://dblp.uni-trier.de/pid/24/7536.html">Xia Hu</a></p>
<p>Abstract:
With advancements of deep learning techniques, it is now possible to generate super-realistic images and videos, i.e., deepfakes. These deepfakes could reach mass audience and result in adverse impacts on our society. Although lots of efforts have been devoted to detect deepfakes, their performance drops significantly on previously unseen but related manipulations and the detection generalization capability remains a problem. Motivated by the fine-grained nature and spatial locality characteristics of deepfakes, we propose Locality-Aware AutoEncoder (LAE) to bridge the generalization gap. In the training process, we use a pixel-wise mask to regularize local interpretation of LAE to enforce the model to learn intrinsic representation from the forgery region, instead of capturing artifacts in the training set and learning superficial correlations to perform detection. We further propose an active learning framework to select the challenging candidates for labeling, which requires human masks for less than 3% of the training data, dramatically reducing the annotation efforts to regularize interpretations. Experimental results on three deepfake detection tasks indicate that LAE could focus on the forgery regions to make decisions. The analysis further shows that LAE outperforms the state-of-the-arts by 6.52%, 12.03%, and 3.08% respectively on three deepfake detection tasks in terms of generalization accuracy on previously unseen manipulations.</p>
<p>Keywords:</p>
<h3 id="36. Quality-Aware Ranking of Arguments.">36. Quality-Aware Ranking of Arguments.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411960">Paper Link</a>    Pages:335-344</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/217/2512.html">Lorik Dumani</a> ; <a href="https://dblp.uni-trier.de/pid/s/RalfSchenkel.html">Ralf Schenkel</a></p>
<p>Abstract:
Argument search engines identify, extract, and rank the most important arguments for and against a given controversial topic. A number of such systems have recently been developed, usually focusing on classic information retrieval ranking methods that are based on frequency information. An important aspect that has been ignored so far by search engines is the quality of arguments. We present a quality-aware ranking framework for arguments already extracted from texts and represented as argument graphs, considering multiple established quality measures. An extensive evaluation with a standard benchmark collection demonstrates that taking quality into account significantly helps to improve retrieval quality for argument search. We also publish a dataset in which arguments with respect to topics were tediously annotated by humans with three widely accepted argument quality dimensions.</p>
<p>Keywords:</p>
<h3 id="37. RelSen: An Optimization-based Framework for Simultaneously Sensor Reliability Monitoring and Data Cleaning.">37. RelSen: An Optimization-based Framework for Simultaneously Sensor Reliability Monitoring and Data Cleaning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411942">Paper Link</a>    Pages:345-354</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/149/7966.html">Cheng Feng</a> ; <a href="https://dblp.uni-trier.de/pid/06/4676.html">Xiao Liang</a> ; <a href="https://dblp.uni-trier.de/pid/06/1905.html">Daniel Schneegass</a> ; <a href="https://dblp.uni-trier.de/pid/00/1921.html">Pengwei Tian</a></p>
<p>Abstract:
Recent advances in the Internet of Things (IoT) technology have led to a surge on the popularity of sensing applications. As a result, people increasingly rely on information obtained from sensors to make decisions in their daily life. Unfortunately, in most sensing applications, sensors are known to be error-prone and their measurements can become misleading at any unexpected time. Therefore, in order to enhance the reliability of sensing applications, apart from the physical phenomena/processes of interest, we believe it is also highly important to monitor the reliability of sensors and clean the sensor data before analysis on them being conducted. Existing studies often regard sensor reliability monitoring and sensor data cleaning as separate problems. In this work, we propose RelSen, a novel optimization-based framework to address the two problems simultaneously via utilizing the mutual dependence between them. Furthermore, RelSen is not application-specific as its implementation assumes a minimal prior knowledge of the process dynamics under monitoring. This significantly improves its generality and applicability in practice. In our experiments, we apply RelSen on an outdoor air pollution monitoring system and a condition monitoring system for a cement rotary kiln. Experimental results show that our framework can timely identify unreliable sensors and remove sensor measurement errors caused by three types of most commonly observed sensor faults.</p>
<p>Keywords:</p>
<h3 id="38. Critically Examining the Claimed Value of Convolutions over User-Item Embedding Maps for Recommender Systems.">38. Critically Examining the Claimed Value of Convolutions over User-Item Embedding Maps for Recommender Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411901">Paper Link</a>    Pages:355-363</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/225/7792.html">Maurizio Ferrari Dacrema</a> ; <a href="https://dblp.uni-trier.de/pid/271/0414.html">Federico Parroni</a> ; <a href="https://dblp.uni-trier.de/pid/03/3233.html">Paolo Cremonesi</a> ; <a href="https://dblp.uni-trier.de/pid/j/DietmarJannach.html">Dietmar Jannach</a></p>
<p>Abstract:
In recent years, algorithm research in the area of recommender systems has shifted from matrix factorization techniques and their latent factor models to neural approaches. However, given the proven power of latent factor models, some newer neural approaches incorporate them within more complex network architectures. One specific idea, recently put forward by several researchers, is to consider potential correlations between the latent factors, i.e., embeddings, by applying convolutions over the user-item interaction map. However, contrary to what is claimed in these articles, such interaction maps do not share the properties of images where Convolutional Neural Networks (CNNs) are particularly useful. In this work, we show through analytical considerations and empirical evaluations that the claimed gains reported in the literature cannot be attributed to the ability of CNNs to model embedding correlations, as argued in the original papers. Moreover, additional performance evaluations show that all of the examined recent CNN-based models are outperformed by existing non-neural machine learning techniques or traditional nearest-neighbor approaches. On a more general level, our work points to major methodological issues in recommender systems research.</p>
<p>Keywords:</p>
<h3 id="39. Query-to-Session Matching: Do NOT Forget History and Future during Response Selection for Multi-Turn Dialogue Systems.">39. Query-to-Session Matching: Do NOT Forget History and Future during Response Selection for Multi-Turn Dialogue Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411938">Paper Link</a>    Pages:365-374</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/209/8408.html">Zhenxin Fu</a> ; <a href="https://dblp.uni-trier.de/pid/209/4930.html">Shaobo Cui</a> ; <a href="https://dblp.uni-trier.de/pid/50/6349.html">Feng Ji</a> ; <a href="https://dblp.uni-trier.de/pid/86/1953.html">Ji Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/34/6243.html">Haiqing Chen</a> ; <a href="https://dblp.uni-trier.de/pid/63/1870.html">Dongyan Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/19/2405-1.html">Rui Yan</a></p>
<p>Abstract:
Given a user query, traditional multi-turn retrieval-based dialogue systems first retrieve a set of candidate responses from the historical dialogue sessions. Then the response selection models select the most appropriate response to the given query. However, previous work only considers the matching between the query and the response but ignores the informative dialogue session in which the response is located. Nevertheless, this session, composed of the response, the response's history and the response's future, always contains valuable contextual information which can help the response selection task. More specifically, if the current query and a response's history both refer to the same question, we can conclude that this response is quite likely to answer this query. As for the response's future, it can always provide contextual hints and supplementary information that might be omitted in the response. Inspired by such motivation, we propose a query-to-session matching (QSM) framework to make full use of the session information: matching the query with the candidate session instead of the response only. Different from the previous work which ranks response directly, the response in the session with the highest query-to-session matching score will be selected as the desired response. In our proposed framework, the query, history, and future are all sequences of utterances, which makes it necessary to model the relationships among the utterances. So we propose a novel dialogue flow aware query-to-session matching (DF-QSM) model. The dialogue flows model the relationships among the utterances through a memory network. To our best knowledge, our paper is the first work to utilize both the response's history and future in the response selection task. The experimental results on three multi-turn response selection benchmarks show that our proposed model outperforms existing state-of-the-art methods by a large margin.</p>
<p>Keywords:</p>
<h3 id="40. Learning from Textual Data in Database Systems.">40. Learning from Textual Data in Database Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412056">Paper Link</a>    Pages:375-384</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/56/1310-2.html">Michael Gnther</a> ; <a href="https://dblp.uni-trier.de/pid/130/0313.html">Philipp Oehme</a> ; <a href="https://dblp.uni-trier.de/pid/48/2949.html">Maik Thiele</a> ; <a href="https://dblp.uni-trier.de/pid/l/WLehner.html">Wolfgang Lehner</a></p>
<p>Abstract:
Relational database systems hold massive amounts of text, valuable for many machine learning (ML) tasks. Since ML techniques depend on numerical input representations, pre-trained word embeddings are increasingly utilized to convert text values into meaningful numbers. However, a nave one-to-one mapping of each word in a database to a word embedding vector misses incorporating rich context information given by the database schema. Thus, we propose a novel relational retrofitting framework Retro to learn numerical representations of text values in databases, capturing the rich information encoded by pre-trained word embedding models as well as context information provided by tabular and foreign key relations in the database. We defined relation retrofitting as an optimization problem, present an efficient algorithm solving it, and investigate the influence of various hyperparameters. Further, we develop simple feed-forward and complex graph convolutional neural network architectures to operate on those representations. Our evaluation shows that the proposed embeddings and models are ready-to-use for many ML tasks, such as text classification, imputation, and link prediction, and even outperform state-of-the-art techniques.</p>
<p>Keywords:</p>
<h3 id="41. Rotate3D: Representing Relations as Rotations in Three-Dimensional Space for Knowledge Graph Embedding.">41. Rotate3D: Representing Relations as Rotations in Three-Dimensional Space for Knowledge Graph Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411889">Paper Link</a>    Pages:385-394</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/11/8376.html">Chang Gao</a> ; <a href="https://dblp.uni-trier.de/pid/92/5589.html">Chengjie Sun</a> ; <a href="https://dblp.uni-trier.de/pid/120/9007.html">Lili Shan</a> ; <a href="https://dblp.uni-trier.de/pid/17/2654-1.html">Lei Lin</a> ; <a href="https://dblp.uni-trier.de/pid/165/7729.html">Mingjiang Wang</a></p>
<p>Abstract:
Knowledge graph embedding, which aims to learn low-dimensional embeddings of entities and relations, plays a vital role in a wide range of applications. It is crucial for knowledge graph embedding models to model and infer various relation patterns, such as symmetry/antisymmetry, inversion, and composition. However, most existing methods fail to model the non-commutative composition pattern, which is essential, especially for multi-hop reasoning. To address this issue, we propose a new model called Rotate3D, which maps entities to the three-dimensional space and defines relations as rotations from head entities to tail entities. By using the non-commutative composition property of rotations in the three-dimensional space, Rotate3D can naturally preserve the order of the composition of relations. Experiments show that Rotate3D outperforms existing state-of-the-art models for link prediction and path query answering. Further case studies demonstrate that Rotate3D can effectively capture various relation patterns with a marked improvement in modeling the composition pattern.</p>
<p>Keywords:</p>
<h3 id="42. Set-Sequence-Graph: A Multi-View Approach Towards Exploiting Reviews for Recommendation.">42. Set-Sequence-Graph: A Multi-View Approach Towards Exploiting Reviews for Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411939">Paper Link</a>    Pages:395-404</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/206/6520.html">Jingyue Gao</a> ; <a href="https://dblp.uni-trier.de/pid/59/5166.html">Yang Lin</a> ; <a href="https://dblp.uni-trier.de/pid/70/2725.html">Yasha Wang</a> ; <a href="https://dblp.uni-trier.de/pid/134/4020.html">Xiting Wang</a> ; <a href="https://dblp.uni-trier.de/pid/21/2326.html">Zhao Yang</a> ; <a href="https://dblp.uni-trier.de/pid/151/5258.html">Yuanduo He</a> ; <a href="https://dblp.uni-trier.de/pid/131/4767.html">Xu Chu</a></p>
<p>Abstract:
Existing review-based recommendation models mainly learn long- term user and item representations from a set of reviews. Due to the ignorance of rich side information of reviews, these models suffer from two drawbacks: 1) they fail to capture short-term changes of user preferences and item features reflected in reviews and 2) they cannot accurately model high-order user-item collaborative signals from reviews. To overcome these limitations, we propose a multi-view approach named Set-Sequence-Graph (SSG), to augment existing single-view (i.e., view of set) methods by introducing two additional views of exploiting reviews: sequence and graph. In particular, with reviews organized in forms of set, sequence, and graph respectively, we design a three-way encoder architecture that jointly captures long-term (set), short-term (sequence), and collaborative (graph) features of users and items for recommendation. For the sequence encoder, we propose a short-term priority attention network that explicitly takes the order and personalized time intervals of reviews into consideration. For the graph encoder, we design a novel review-aware graph attention network to model high-order multi-aspect relations in the user-item graph. To combat the potential redundancy in captured features, our fusion module employs a cross-view decorrelation mechanism to encourage diverse representations from multiple views for integration. Experiments on public datasets demonstrate that SSG significantly outperforms state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="43. How and Why is An Answer (Still) Correct? Maintaining Provenance in Dynamic Knowledge Graphs.">43. How and Why is An Answer (Still) Correct? Maintaining Provenance in Dynamic Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411958">Paper Link</a>    Pages:405-414</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/207/9943.html">Garima Gaur</a> ; <a href="https://dblp.uni-trier.de/pid/48/2626-1.html">Arnab Bhattacharya</a> ; <a href="https://dblp.uni-trier.de/pid/b/SrikantaJBedathur.html">Srikanta Bedathur</a></p>
<p>Abstract:
Knowledge graphs (KGs), that have become the backbone of many critical knowledge-centric applications, are mostly automatically constructed based on an ensemble of extraction techniques applied over diverse data sources. It is, therefore, important to establish the provenance of results for a query to determine how these were computed. Provenance is shown to be useful for assigning confidence scores to the results, for debugging the KG generation itself, and for providing answer explanations. In many such applications, certain queries are registered as standing queries since their answers are needed often. However, KGs keep continuously changing due to reasons such as changes in the source data, improvements to the extraction techniques, refinement/enrichment of information, and so on. This raises the issue of efficiently maintaining the provenance polynomials of complex graph pattern queries for dynamic and large KGs instead of having to recompute them from scratch each time the KG is updated. Addressing this issue, we present a framework HUKA that uses provenance polynomials for tracking the derivation of query results over knowledge graphs by encoding the edges involved in generating the answer. More importantly, HUKA also maintains these provenance polynomials in the face of updates---insertions as well as deletions of facts---in the underlying KG. Experimental results over large real-world KGs such as YAGO and DBpedia with various benchmark SPARQL query workloads reveals that HUKA can be almost 50 times faster than existing systems for provenance computation on dynamic KGs.</p>
<p>Keywords:</p>
<h3 id="44. MICK: A Meta-Learning Framework for Few-shot Relation Classification with Small Training Data.">44. MICK: A Meta-Learning Framework for Few-shot Relation Classification with Small Training Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411858">Paper Link</a>    Pages:415-424</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/263/9984.html">Xiaoqing Geng</a> ; <a href="https://dblp.uni-trier.de/pid/262/2611.html">Xiwen Chen</a> ; <a href="https://dblp.uni-trier.de/pid/z/KennyQiliZhu.html">Kenny Q. Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/06/5089.html">Libin Shen</a> ; <a href="https://dblp.uni-trier.de/pid/25/9282.html">Yinggong Zhao</a></p>
<p>Abstract:
Few-shot relation classification seeks to classify incoming query instances after meeting only few support instances. This ability is gained by training with large amount of in-domain annotated data. In this paper, we tackle an even harder problem by further limiting the amount of data available at training time. We propose a few-shot learning framework for relation classification, which is particularly powerful when the training data is very small. In this framework, models not only strive to classify query instances, but also seek underlying knowledge about the support instances to obtain better instance representations. The framework also includes a method for aggregating cross-domain knowledge into models by open-source task enrichment. Additionally, we construct a brand new dataset: the TinyRel-CM dataset, a few-shot relation classification dataset in health domain with purposely small training data and challenging relation classes. Experimental results demonstrate that our framework brings performance gains for most underlying classification models, outperforms the state-of-the-art results given small training data, and achieves competitive results with sufficiently large training data.</p>
<p>Keywords:</p>
<h3 id="45. Knowledge Graph Embedding Preserving Soft Logical Regularity.">45. Knowledge Graph Embedding Preserving Soft Logical Regularity.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412055">Paper Link</a>    Pages:425-434</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/121/2156.html">Shu Guo</a> ; <a href="https://dblp.uni-trier.de/pid/73/2252.html">Lin Li</a> ; <a href="https://dblp.uni-trier.de/pid/267/7290.html">Zhen Hui</a> ; <a href="https://dblp.uni-trier.de/pid/256/2554.html">Lingshuai Meng</a> ; <a href="https://dblp.uni-trier.de/pid/235/7038.html">Bingnan Ma</a> ; <a href="https://dblp.uni-trier.de/pid/49/3283.html">Wei Liu</a> ; <a href="https://dblp.uni-trier.de/pid/17/1495.html">Lihong Wang</a> ; <a href="https://dblp.uni-trier.de/pid/30/9718.html">Haibin Zhai</a> ; <a href="https://dblp.uni-trier.de/pid/24/6914.html">Hong Zhang</a></p>
<p>Abstract:
Embedding knowledge graphs (KGs) into continuous vector spaces is currently an active research area. Soft rules, despite their uncertainty, are highly beneficial to KG embedding. However, they have not been studied enough in recent methods. A major challenge here is how to devise a principled framework, which efficiently and effectively integrates such soft logical information into embedding models. This paper proposes a highly scalable and effective method for preserving soft logical regularities by imposing soft rule constraints on relation representations. Specifically, we first represent relations as bilinear forms and map entity representations into a non-negative and bounded space. Then we derive a rule-based regularization that merely enforces relation representations to satisfy constraints introduced by soft rules. The proposed method has the following advantages: 1) it regularizes relations directly with the complexity of rule learning independent of entity set size, improving scalability; 2) it imposes prior logical information upon the structure of the embedding space, and would be beneficial to knowledge reasoning. Evaluation in link prediction on Freebase and DBpedia shows the effectiveness of our approach over many competitive baselines. Code and datasets are available at <a href="https://github.com/StudyGroup-lab/SLRE">https://github.com/StudyGroup-lab/SLRE</a>.</p>
<p>Keywords:</p>
<h3 id="46. GraSeq: Graph and Sequence Fusion Learning for Molecular Property Prediction.">46. GraSeq: Graph and Sequence Fusion Learning for Molecular Property Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411981">Paper Link</a>    Pages:435-443</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/254/0545.html">Zhichun Guo</a> ; <a href="https://dblp.uni-trier.de/pid/159/8117.html">Wenhao Yu</a> ; <a href="https://dblp.uni-trier.de/pid/133/8537.html">Chuxu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/69/339-1.html">Meng Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/c/NiteshVChawla.html">Nitesh V. Chawla</a></p>
<p>Abstract:
With the recent advancement of deep learning, molecular representation learning -- automating the discovery of feature representation of molecular structure, has attracted significant attention from both chemists and machine learning researchers. Deep learning can facilitate a variety of downstream applications, including bio-property prediction, chemical reaction prediction, etc. Despite the fact that current SMILES string or molecular graph molecular representation learning algorithms (via sequence modeling and graph neural networks, respectively) have achieved promising results, there is no work to integrate the capabilities of both approaches in preserving molecular characteristics (e.g, atomic cluster, chemical bond) for further improvement. In this paper, we propose GraSeq, a joint graph and sequence representation learning model for molecular property prediction. Specifically, GraSeq makes a complementary combination of graph neural networks and recurrent neural networks for modeling two types of molecular inputs, respectively. In addition, it is trained by the multitask loss of unsupervised reconstruction and various downstream tasks, using limited size of labeled datasets. In a variety of chemical property prediction tests, we demonstrate that our GraSeq model achieves better performance than state-of-the-art approaches.</p>
<p>Keywords:</p>
<h3 id="47. Modelling User Behavior Dynamics with Embeddings.">47. Modelling User Behavior Dynamics with Embeddings.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411985">Paper Link</a>    Pages:445-454</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/75/2307-3.html">Lei Han</a> ; <a href="https://dblp.uni-trier.de/pid/72/10821.html">Alessandro Checco</a> ; <a href="https://dblp.uni-trier.de/pid/09/10814.html">Djellel Eddine Difallah</a> ; <a href="https://dblp.uni-trier.de/pid/05/3422.html">Gianluca Demartini</a> ; <a href="https://dblp.uni-trier.de/pid/s/SWSadiq.html">Shazia Wasim Sadiq</a></p>
<p>Abstract:
Understanding user interaction behaviors remains a challenging problem. Quantifying behavior dynamics over time as users complete tasks has only been done in specific domains. In this paper, we present a user behavior model built using behavior embeddings to compare behaviors and their change over time. To this end, we first define the formal model and train the model using both action (e.g., copy/paste) embeddings and user interaction feature (e.g., length of the copied text) embeddings. Having obtained vector representations of user behaviors, we then define three measurements to model behavior dynamics over time, namely: behavior position, displacement, and velocity. To evaluate the proposed methodology, we use three real world datasets: (i) tens of users completing complex data curation tasks in a lab setting, (ii) hundreds of crowd workers completing structured tasks in a crowdsourcing setting, and (iii) thousands of editors completing unstructured editing tasks on Wikidata. Through these datasets, we show that the proposed methodology can: (i) surface behavioral differences among users; (ii) recognize relative behavioral changes; and (iii) discover directional deviations of user behaviors. Our approach can be used (i) to capture behavioral semantics from data in a consistent way, (ii) to quantify behavioral diversity for a task and among different users, and (iii) to explore the temporal behavior evolution with respect to various task properties (e.g., structure and difficulty).</p>
<p>Keywords:</p>
<h3 id="48. Genetic Meta-Structure Search for Recommendation on Heterogeneous Information Network.">48. Genetic Meta-Structure Search for Recommendation on Heterogeneous Information Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412015">Paper Link</a>    Pages:455-464</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/210/0308.html">Zhenyu Han</a> ; <a href="https://dblp.uni-trier.de/pid/169/8818.html">Fengli Xu</a> ; <a href="https://dblp.uni-trier.de/pid/274/1352.html">Jinghan Shi</a> ; <a href="https://dblp.uni-trier.de/pid/28/5630.html">Yu Shang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5023.html">Haorui Ma</a> ; <a href="https://dblp.uni-trier.de/pid/62/1272.html">Pan Hui</a> ; <a href="https://dblp.uni-trier.de/pid/93/2334.html">Yong Li</a></p>
<p>Abstract:
In the past decade, the heterogeneous information network (HIN) has become an important methodology for modern recommender systems. To fully leverage its power, manually designed network templates, i.e., meta-structures, are introduced to filter out semantic-aware information. The hand-crafted meta-structure rely on intense expert knowledge, which is both laborious and data-dependent. On the other hand, the number of meta-structures grows exponentially with its size and the number of node types, which prohibits brute-force search. To address these challenges, we propose Genetic Meta-Structure Search (GEMS) to automatically optimize meta-structure designs for recommendation on HINs. Specifically, GEMS adopts a parallel genetic algorithm to search meaningful meta-structures for recommendation, and designs dedicated rules and a meta-structure predictor to efficiently explore the search space. Finally, we propose an attention based multi-view graph convolutional network module to dynamically fuse information from different meta-structures. Extensive experiments on three real-world datasets suggest the effectiveness of GEMS, which consistently outperforms all baseline methods in HIN recommendation. Compared with simplified GEMS which utilizes hand-crafted meta-paths, GEMS achieves over 6% performance gain on most evaluation metrics. More importantly, we conduct an in-depth analysis on the identified meta-structures, which sheds light on the HIN based recommender system design.</p>
<p>Keywords:</p>
<h3 id="49. Ranking Enhanced Dialogue Generation.">49. Ranking Enhanced Dialogue Generation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411918">Paper Link</a>    Pages:465-474</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/260/2038.html">Changying Hao</a> ; <a href="https://dblp.uni-trier.de/pid/37/11078.html">Liang Pang</a> ; <a href="https://dblp.uni-trier.de/pid/00/6040.html">Yanyan Lan</a> ; <a href="https://dblp.uni-trier.de/pid/51/394-1.html">Fei Sun</a> ; <a href="https://dblp.uni-trier.de/pid/02/146.html">Jiafeng Guo</a> ; <a href="https://dblp.uni-trier.de/pid/44/912.html">Xueqi Cheng</a></p>
<p>Abstract:
How to effectively utilize the dialogue history is a crucial problem in multi-turn dialogue generation. Previous works usually employ various neural network architectures (e.g., recurrent neural networks, attention mechanisms, and hierarchical structures) to model the history. However, a recent empirical study by Sankar et al. has shown that these architectures lack the ability of understanding and modeling the dynamics of the dialogue history. For example, the widely used architectures are insensitive to perturbations of the dialogue history, such as words shuffling, utterances missing, and utterances reordering. To tackle this problem, we propose a Ranking Enhanced Dialogue generation framework in this paper. Despite the traditional representation encoder and response generation modules, an additional ranking module is introduced to model the ranking relation between the former utterance and consecutive utterances. Specifically, the former utterance and consecutive utterances are treated as query and corresponding documents, and both local and global ranking losses are designed in the learning process. In this way, the dynamics in the dialogue history can be explicitly captured. To evaluate our proposed models, we conduct extensive experiments on three public datasets, i.e., bAbI, PersonaChat, and JDC. Experimental results show that our models produce better responses in terms of both quantitative measures and human judgments, as compared with the state-of-the-art dialogue generation models. Furthermore, we give some detailed experimental analysis to show where and how the improvements come from.</p>
<p>Keywords:</p>
<h3 id="50. Privacy-Preserving Classification with Secret Vector Machines.">50. Privacy-Preserving Classification with Secret Vector Machines.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412051">Paper Link</a>    Pages:475-484</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/243/6943.html">Valentin Hartmann</a> ; <a href="https://dblp.uni-trier.de/pid/178/3634.html">Konark Modi</a> ; <a href="https://dblp.uni-trier.de/pid/p/JosepMPujol.html">Josep M. Pujol</a> ; <a href="https://dblp.uni-trier.de/pid/142/8100.html">Robert West</a></p>
<p>Abstract:
Today, large amounts of valuable data are distributed among millions of user-held devices, such as personal computers, phones, or Internet-of-things devices. Many companies collect such data with the goal of using it for training machine learning models allowing them to improve their services. User-held data is, however, often sensitive, and collecting it is problematic in terms of privacy. We address this issue by proposing a novel way of training a supervised classifier in a distributed setting akin to the recently proposed federated learning paradigm, but under the stricter privacy requirement that the server that trains the model is assumed to be untrusted and potentially malicious. We thus preserve user privacy by design, rather than by trust. In particular, our framework, called secret vector machine (SecVM), provides an algorithm for training linear support vector machines (SVM) in a setting in which data-holding clients communicate with an untrusted server by exchanging messages designed to not reveal any personally identifiable information. We evaluate our model in two ways. First, in an offline evaluation, we train SecVM to predict user gender from tweets, showing that we can preserve user privacy without sacrificing classification performance. Second, we implement SecVM's distributed framework for the Cliqz web browser and deploy it for predicting user gender in a large-scale online evaluation with thousands of clients, outperforming baselines by a large margin and thus showcasing that SecVM is suitable for production environments.</p>
<p>Keywords:</p>
<h3 id="51. Learning to Selectively Update State Neurons in Recurrent Networks.">51. Learning to Selectively Update State Neurons in Recurrent Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412018">Paper Link</a>    Pages:485-494</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/211/5752.html">Thomas Hartvigsen</a> ; <a href="https://dblp.uni-trier.de/pid/167/6611.html">Cansu Sen</a> ; <a href="https://dblp.uni-trier.de/pid/06/8315.html">Xiangnan Kong</a> ; <a href="https://dblp.uni-trier.de/pid/r/EARundensteiner.html">Elke A. Rundensteiner</a></p>
<p>Abstract:
Recurrent Neural Networks (RNNs) are the state-of-the-art approach to sequential learning. However, standard RNNs use the same amount of computation to generate their hidden states at each timestep, regardless of the input data. Recent works have begun to tackle this rigid assumption by imposing a priori-determined patterns for updating the states at each step. These approaches could lend insights into the dynamics of RNNs and possibly speed up inference. However, the pre-determined nature of the current update strategies limits their application. To overcome this, we instead design the first fully-learned approach, SA-RNN, that augments any RNN by predicting discrete update patterns at the fine granularity of individual hidden state neurons. This is achieved through the parameterization of a distribution of update-likelihoods driven by the input data. Unlike related methods, our approach imposes no assumptions on the structure of the update patterns. Better yet, our method adapts its update patterns online, allowing different dimensions to be updated conditionally based on the input. To learn which dimensions to update, the model solves a multi-objective optimization problem, maximizing task performance while minimizing the number of updates based on a unified control. Using five publicly-available datasets spanning three sequential learning settings, we demonstrate that our method consistently achieves higher accuracy with fewer updates compared to state-of-the-art alternatives. We also show the benefits of learning to sparsely-update a large hidden state as opposed to densely-update a small hidden state. As an added benefit, our method can be directly applied to a wide variety of models containing RNN architectures.</p>
<p>Keywords:</p>
<h3 id="52. Hypergraph Random Walks, Laplacians, and Clustering.">52. Hypergraph Random Walks, Laplacians, and Clustering.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412034">Paper Link</a>    Pages:495-504</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/205/2992.html">Koby Hayashi</a> ; <a href="https://dblp.uni-trier.de/pid/210/2558.html">Sinan G. Aksoy</a> ; <a href="https://dblp.uni-trier.de/pid/00/191.html">Cheong Hee Park</a> ; <a href="https://dblp.uni-trier.de/pid/78/5322.html">Haesun Park</a></p>
<p>Abstract:
We propose a flexible framework for clustering hypergraph-structured data based on recently proposed random walks utilizing edge-dependent vertex weights. When incorporating edge-dependent vertex weights (EDVW), a weight is associated with each vertex-hyperedge pair, yielding a weighted incidence matrix of the hypergraph. Such weightings have been utilized in term-document representations of text data sets. We explain how random walks with EDVW serve to construct different hypergraph Laplacian matrices, and then develop a suite of clustering methods that use these incidence matrices and Laplacians for hypergraph clustering. Using several data sets from real-life applications, we compare the performance of these clustering algorithms experimentally against a variety of existing hypergraph clustering methods. We show that the proposed methods produce high-quality clusters and conclude by highlighting avenues for future work.</p>
<p>Keywords:</p>
<h3 id="53. VN Network: Embedding Newly Emerging Entities with Virtual Neighbors.">53. VN Network: Embedding Newly Emerging Entities with Virtual Neighbors.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411865">Paper Link</a>    Pages:505-514</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5095.html">Yongquan He</a> ; <a href="https://dblp.uni-trier.de/pid/272/8221.html">Zhihan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/21/1048.html">Peng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/71/9281.html">Zhaopeng Tu</a> ; <a href="https://dblp.uni-trier.de/pid/58/10440.html">Zhaochun Ren</a></p>
<p>Abstract:
Embedding entities and relations into continuous vector spaces has attracted a surge of interest in recent years. Most embedding methods assume that all test entities are available during training, which makes it time-consuming to retrain embeddings for newly emerging entities. To address this issue, recent works apply the graph neural network on the existing neighbors of the unseen entities. In this paper, we propose a novel framework, namely Virtual Neighbor (VN) network, to address three key challenges. Firstly, to reduce the neighbor sparsity problem, we introduce the concept of the virtual neighbors inferred by rules. And we assign soft labels to these neighbors by solving a rule-constrained problem, rather than simply regarding them as unquestionably true. Secondly, many existing methods only use one-hop or two-hop neighbors for aggregation and ignore the distant information that may be helpful. Instead, we identify both logic and symmetric path rules to capture complex patterns. Finally, instead of one-time injection of rules, we employ an iterative learning scheme between the embedding method and virtual neighbor prediction to capture the interactions within. Experimental results on two knowledge graph completion tasks demonstrate that our VN network significantly outperforms state-of-the-art baselines. Furthermore, results on Subject/Object-R show that our proposed VN network is highly robust to the neighbor sparsity problem.</p>
<p>Keywords:</p>
<h3 id="54. WMEgo: Willingness Maximization for Ego Network Data Extraction in Online Social Networks.">54. WMEgo: Willingness Maximization for Ego Network Data Extraction in Online Social Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411867">Paper Link</a>    Pages:515-524</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/70/9915.html">Bay-Yuan Hsu</a> ; <a href="https://dblp.uni-trier.de/pid/38/8845.html">Chih-Ya Shen</a> ; <a href="https://dblp.uni-trier.de/pid/248/8819.html">Ming-Yi Chang</a></p>
<p>Abstract:
The data of egocentric networks (ego networks) are very important for evaluating and validating the algorithms and machine learning approaches in Online Social Networks (OSNs). Nevertheless, obtaining the ego network data from OSNs is not a trivial task. Conventional manual approaches are time-consuming, and only a small number of users would agree to contribute their data. This is because there are two important factors that should be considered simultaneously for this data acquisition task: i) users' willingness to contribute their data, and ii) the structure of the ego network. However, addressing the above two factors to obtain the more complete ego network data has not received much research attention. Therefore, in this paper, we make our first attempt to address this issue by proposing a new research problem, named Willingness Maximization for Ego Network Extraction in Online Social Networks (WMEgo), to identify a set of ego networks from the OSN such that the willingness of the users to contribute their data is maximized. We prove that WMEgo is NP-hard and propose a 1/2*(1 1/e)-approximation algorithm, named Ego Network Identification with Maximum Willingness (EIMW). We conduct an evaluation study with 672 volunteers to validate the proposed WMEgo and EIMW, and perform extensive experiments on multiple real datasets to demonstrate the effectiveness and efficiency of our approach.</p>
<p>Keywords:</p>
<h3 id="55. Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems.">55. Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411967">Paper Link</a>    Pages:525-534</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/162/1097.html">Kai Hua</a> ; <a href="https://dblp.uni-trier.de/pid/276/5038.html">Zhiyuan Feng</a> ; <a href="https://dblp.uni-trier.de/pid/194/2515.html">Chongyang Tao</a> ; <a href="https://dblp.uni-trier.de/pid/19/2405.html">Rui Yan</a> ; <a href="https://dblp.uni-trier.de/pid/z/LuZhang1.html">Lu Zhang</a></p>
<p>Abstract:
Recently, knowledge-grounded conversations in the open domain gain great attention from researchers. Existing works on retrieval-based dialogue systems have paid tremendous efforts to utilize neural networks to build a matching model, where all of the context and knowledge contents are used to match the response candidate with various representation methods.</p>
<p>Keywords:</p>
<h3 id="56. Image Captioning with Internal and External Knowledge.">56. Image Captioning with Internal and External Knowledge.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411948">Paper Link</a>    Pages:535-544</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5075.html">Feicheng Huang</a> ; <a href="https://dblp.uni-trier.de/pid/82/7406.html">Zhixin Li</a> ; <a href="https://dblp.uni-trier.de/pid/276/5017.html">Shengjia Chen</a> ; <a href="https://dblp.uni-trier.de/pid/78/10949.html">Canlong Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/37/7406.html">Huifang Ma</a></p>
<p>Abstract:
Automatically generating a human-like description for a given image is a potential research in artificial intelligence, which has attracted a great of attention recently. Most of the existing attention methods explore the mapping relationships between words in sentence and regions in image, such unpredictable matching manner sometimes causes inharmonious alignments that may reduce the quality of generated captions. In this paper, we make our efforts to reason about more accurate and meaningful captions. We first propose word attention to improve the correctness of visual attention when generating sequential descriptions word-by-word. The special word attention emphasizes on word importance when focusing on different regions of the input image, and makes full use of the internal annotation knowledge to assist the calculation of visual attention. Then, in order to reveal those incomprehensible intentions that cannot be expressed straightforwardly by machines, we inject external knowledge extracted from knowledge graph into the encoder-decoder framework to facilitate meaningful captioning. We validate our model on two freely available captioning benchmarks: Microsoft COCO dataset and Flickr30k dataset. The results demonstrate that our approach achieves state-of-the-art performance and outperforms many of the existing approaches.</p>
<p>Keywords:</p>
<h3 id="57. GNNVis: Visualize Large-Scale Data by Learning a Graph Neural Network Representation.">57. GNNVis: Visualize Large-Scale Data by Learning a Graph Neural Network Representation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411987">Paper Link</a>    Pages:545-554</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/157/4739.html">Yajun Huang</a> ; <a href="https://dblp.uni-trier.de/pid/73/5227.html">Jingbin Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/67/9902.html">Yiyang Yang</a> ; <a href="https://dblp.uni-trier.de/pid/95/6295.html">Zhiguo Gong</a> ; <a href="https://dblp.uni-trier.de/pid/94/6214.html">Zhifeng Hao</a></p>
<p>Abstract:
Many achievements have been made by studying how to visualize large-scale and high-dimensional data in typically 2D or 3D space. Normally, such a process is performed through a non-parametric (unsupervised) approach which is limited in handling the unseen data. In this work, we study the parametric (supervised) model which is capable to learn a mapping between high-dimensional data space Rd and low-dimensional latent space Rs with similarity structure in Rd preserved where s l d. The GNNVis is proposed, a framework that applies the idea of Graph Neural Networks (GNNs) to the parametric learning process and the learned mapping serves as a Visualizer (Vis) to compute the low-dimensional embeddings of unseen data online. In our framework, the features of data nodes, as well as the (hidden) information of their neighbors are fused to conduct Dimension Reduction. To the best of our knowledge, none of the existing visualization works have studied how to combine such information into the learning representation. Moreover, the learning process of GNNVis is designed as an end-to-end manner and can easily be extended to arbitrary Dimension Reduction methods if the corresponding objective function is given. Based on GNNVis, several typical dimension reduction methods t-SNE, LargeVis, and UMAP are investigated. As a parametric framework, GNNVis is an inherently efficient Visualizer capable of computing the embeddings of large-scale unseen data. To guarantee its scalability in the Training Stage, a novel training strategy with Subgraph Negative Sampling (SNS) is conducted to reduce the corresponding cost. Experimental results in real datasets demonstrate the advantages of GNNVis. The visualization quality of GNNVis outperforms the state-of-the-art parametric models, and is comparable to that of the non-parametric models.</p>
<p>Keywords:</p>
<h3 id="58. Predicting Economic Growth by Region Embedding: A Multigraph Convolutional Network Approach.">58. Predicting Economic Growth by Region Embedding: A Multigraph Convolutional Network Approach.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411882">Paper Link</a>    Pages:555-564</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/260/4200.html">Bo Hui</a> ; <a href="https://dblp.uni-trier.de/pid/81/9436-1.html">Da Yan</a> ; <a href="https://dblp.uni-trier.de/pid/21/1694.html">Wei-Shinn Ku</a> ; <a href="https://dblp.uni-trier.de/pid/196/1399.html">Wenlu Wang</a></p>
<p>Abstract:
With the rapid progress of global urbanization and function division among different geographical regions, it is of urgent need to develop methods that can find regions of desired future function distributions in applications. For example, a company tends to open a new branch in a region where the growth trend of industrial sectors fits its strategic goals, or is similar to that of an existing company location; while a job hunter tends to search regions where his/her expertise aligns with the industrial growth trend providing sufficient job opportunities to sustain future employment and job-hopping.</p>
<p>Keywords:</p>
<h3 id="59. Sequential Recommender via Time-aware Attentive Memory Network.">59. Sequential Recommender via Time-aware Attentive Memory Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411869">Paper Link</a>    Pages:565-574</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/185/6815.html">Wendi Ji</a> ; <a href="https://dblp.uni-trier.de/pid/01/10613.html">Keqiang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/92/6206.html">Xiaoling Wang</a> ; <a href="https://dblp.uni-trier.de/pid/02/2895.html">Tingwei Chen</a> ; <a href="https://dblp.uni-trier.de/pid/265/5754.html">Alexandra Cristea</a></p>
<p>Abstract:
Recommendation systems aim to assist users to discover most preferred contents from an ever-growing corpus of items. Although recommenders have been greatly improved by deep learning, they still face several challenges: (1) Behaviors are much more com- plex than words in sentences, so traditional attentive and recurrent models have limitations capturing the temporal dynamics of user preferences. (2) The preferences of users are multiple and evolving, so it is difficult to integrate long-term memory and short-term intent.</p>
<p>Keywords:</p>
<h3 id="60. MARU: Meta-context Aware Random Walks for Heterogeneous Network Representation Learning.">60. MARU: Meta-context Aware Random Walks for Heterogeneous Network Representation Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412040">Paper Link</a>    Pages:575-584</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/130/8167.html">Jyun-Yu Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/25/287.html">Zeyu Li</a> ; <a href="https://dblp.uni-trier.de/pid/161/5741.html">Chelsea J.-T. Ju</a> ; <a href="https://dblp.uni-trier.de/pid/w/WeiWang.html">Wei Wang</a></p>
<p>Abstract:
Information networks, such as social and citation networks, are ubiquitous in the real world so that network analysis plays an important role in data mining and knowledge discovery. To alleviate the sparsity problem of network analysis, it is common to capture the network semantics by projecting nodes onto a vector space as network embeddings. Moreover, random walks are usually exploited to efficiently learn node embeddings and preserve network proximity. In addition to proximity structure, heterogeneous networks have more knowledge about the types of nodes. However, to profit from heterogeneous knowledge, most of the existing approaches guide the random walks through predefined meta-paths or specific strategies, which can distort the understanding of network structures. Furthermore, traditional random walk-based approaches much favor the nodes with higher degrees while other nodes are equivalently important for the downstream applications. In this paper, we propose Meta-context Aware Random Walks (MARU) to overcome these challenges, thereby learning richer and more unbiased representations for heterogeneous networks. To reduce the bias in classical random walks, the algorithm of bidirectional extended random walks is introduced to improve the fairness of representation learning. Based on the enhanced random walks, the meta-context aware skip-gram model is then presented to learn robust network embeddings with dynamic meta-contexts. Therefore, MARU can not only fairly understand the overall network structures but also leverage the sophisticated heterogeneous knowledge in the networks. Extensive experiments have been conducted on three real-world large-scale publicly available datasets. The experimental results demonstrate that MARU significantly outperforms state-of-the-art heterogeneous network embedding methods across three general machine learning tasks, including multi-label node classification, node clustering, and link prediction.</p>
<p>Keywords:</p>
<h3 id="61. Partial Relationship Aware Influence Diffusion via a Multi-channel Encoding Scheme for Social Recommendation.">61. Partial Relationship Aware Influence Diffusion via a Multi-channel Encoding Scheme for Social Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412016">Paper Link</a>    Pages:585-594</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/74/3468-1.html">Bo Jin</a> ; <a href="https://dblp.uni-trier.de/pid/81/3800.html">Ke Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/50/6759.html">Liang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/134/3987.html">Yanjie Fu</a> ; <a href="https://dblp.uni-trier.de/pid/13/3656.html">Minghao Yin</a> ; <a href="https://dblp.uni-trier.de/pid/22/752.html">Lu Jiang</a></p>
<p>Abstract:
Social recommendation tasks exploit social connections to enhance recommendation performance. To fully utilize each user's first-order and high-order neighborhood preferences, recent approaches incorporate influence diffusion process for better user preference modeling. Despite the superior performance of these models, they either neglect the latent individual interests hidden in the user-item interactions or rely on computationally expensive graph attention models to uncover the item-induced sub-relations, which essentially determine the influence propagation passages. Considering the sparse substructures are derived from original social network, we name them as partial relationships between users. We argue such relationships can be directly modeled such that both personal interests and shared interests can propagate along a few channels (or dimensions) of latent users' embeddings. To this end, we propose a partial relationship aware influence diffusion structure via a computationally efficient multi-channel encoding scheme. Specifically, the encoding scheme first simplifies graph attention operation based on a channel-wise sparsity assumption, and then adds an InfluenceNorm function to maintain such sparsity. Moreover, ChannelNorm is designed to alleviate the oversmoothing problem in graph neural network models. Extensive experiments on two benchmark datasets show that our method is comparable to state-of-the-art graph attention-based social recommendation models while capturing user interests according to partial relationships more efficiently.</p>
<p>Keywords:</p>
<h3 id="62. Social Factors in Closed-Network Content Consumption.">62. Social Factors in Closed-Network Content Consumption.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411935">Paper Link</a>    Pages:595-604</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/194/3463.html">Parisa Kaghazgaran</a> ; <a href="https://dblp.uni-trier.de/pid/207/5897.html">Maarten Bos</a> ; <a href="https://dblp.uni-trier.de/pid/180/2571.html">Leonardo Neves</a> ; <a href="https://dblp.uni-trier.de/pid/71/7771.html">Neil Shah</a></p>
<p>Abstract:
How do users on social platforms consume content shared by their friends? Is this consumption socially motivated, and can we predict it? Considerable prior work has focused on inferring and learning user preferences with respect to broadcasted, or open-network content in public spheres like webpages or public videos. However, user engagement with narrowcasted, closed-network content shared by their friends is considerably under-explored, despite being a commonplace activity. Here we bridge this gap by focusing on consumption of visual media content in closed-network settings, using data from Snapchat, a large multimedia-driven social sharing service with over 200M daily active users. Broadly, we answer questions around content consumption patterns, social factors that are associated with such consumption habits, and predictability of consumption time. We propose models for patterns in users' time-spending behaviors across friends, and observe that viewers preferentially and consistently spend more time on content from certain friends, even without considering any explicit notion of intrinsic content value. We also find that consumption time is highly correlated with several engagement-based social factors, suggesting a large social role in closed-network content consumption. Finally, we propose a novel approach of modeling future consumption time as a learning-to-rank task over users? friends. Our results demonstrate significant predictive value (0.815 [email protected], 0.650 [email protected]) using only social factors. We expect our work to motivate additional research in modeling consumption and ranking of online closed-network content.</p>
<p>Keywords:</p>
<h3 id="63. DE-RRD: A Knowledge Distillation Framework for Recommender System.">63. DE-RRD: A Knowledge Distillation Framework for Recommender System.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412005">Paper Link</a>    Pages:605-614</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/251/9613.html">SeongKu Kang</a> ; <a href="https://dblp.uni-trier.de/pid/246/3153.html">Junyoung Hwang</a> ; <a href="https://dblp.uni-trier.de/pid/264/2604.html">Wonbin Kweon</a> ; <a href="https://dblp.uni-trier.de/pid/80/6889.html">Hwanjo Yu</a></p>
<p>Abstract:
Recent recommender systems have started to employ knowledge distillation, which is a model compression technique distilling knowledge from a cumbersome model (teacher) to a compact model (student), to reduce inference latency while maintaining performance. The state-of-the-art methods have only focused on making the student model to accurately imitate the predictions of the teacher model. They have a limitation in that the prediction results incompletely reveal the teacher's knowledge. In this paper, we propose a novel knowledge distillation framework for recommender system, called DE-RRD, which enables the student model to learn from the latent knowledge encoded in the teacher model as well as from the teacher's predictions. Concretely, DE-RRD consists of two methods: 1) Distillation Experts (DE) that directly transfers the latent knowledge from the teacher model. DE exploits "experts" and a novel expert selection strategy for effectively distilling the vast teacher's knowledge to the student with limited capacity. 2) Relaxed Ranking Distillation (RRD) that transfers the knowledge revealed from the teacher's prediction with consideration of the relaxed ranking orders among items. Our extensive experiments show that DE-RRD outperforms the state-of-the-art competitors and achieves comparable or even better performance to that of the teacher model with faster inference time.</p>
<p>Keywords:</p>
<h3 id="64. Collective Embedding with Feature Importance: A Unified Approach for Spatiotemporal Network Embedding.">64. Collective Embedding with Feature Importance: A Unified Approach for Spatiotemporal Network Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412030">Paper Link</a>    Pages:615-624</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/230/4705.html">Dakshak Keerthi Chandra</a> ; <a href="https://dblp.uni-trier.de/pid/219/1752.html">Pengyang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/68/6646.html">Jennifer Leopold</a> ; <a href="https://dblp.uni-trier.de/pid/134/3987.html">Yanjie Fu</a></p>
<p>Abstract:
In the last decade, there has been great progress in the field of machine learning and deep learning. These models have been instrumental in addressing a great number of problems. However, they have struggled when it comes to dealing with high dimensional data. In recent years, representation learning models have proven to be quite efficient in addressing this problem as they are capable of capturing effective lower-dimensional representations of the data. However, most of the existing models are quite ineffective when it comes to dealing with high dimensional spatiotemporal data as they encapsulate complex spatial and temporal relationships that exist among real-world objects. High-dimensional spatiotemporal data of cities represent urban communities. By learning their social structure we can better quantitatively depict them and understand factors influencing rapid growth, expansion, and changes.</p>
<p>Keywords:</p>
<h3 id="65. AutoFeature: Searching for Feature Interactions and Their Architectures for Click-through Rate Prediction.">65. AutoFeature: Searching for Feature Interactions and Their Architectures for Click-through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411912">Paper Link</a>    Pages:625-634</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/145/1172.html">Farhan Khawar</a> ; <a href="https://dblp.uni-trier.de/pid/272/1013.html">Xu Hang</a> ; <a href="https://dblp.uni-trier.de/pid/24/10003.html">Ruiming Tang</a> ; <a href="https://dblp.uni-trier.de/pid/35/837.html">Bin Liu</a> ; <a href="https://dblp.uni-trier.de/pid/23/6479.html">Zhenguo Li</a> ; <a href="https://dblp.uni-trier.de/pid/11/5357.html">Xiuqiang He</a></p>
<p>Abstract:
Click-through rate prediction is an important task in commercial recommender systems and it aims to predict the probability of a user clicking on an item. The event of a user clicking on an item is accompanied by several user and item features. As modelling the feature interactions effectively can lead to better predictions, it has been the focus of many recent approaches including deep learning-based models. However, the existing approaches either (i) model all possible feature interactions for a given order, or (ii) manually select which feature interactions to model. Besides, they use the same network structure or function to model all the feature interactions while ignoring the difference of complexity among them. To address these issues, we propose a neural architecture search based approach called AutoFeature that automatically finds essential feature interactions and selects an appropriate structure to model each of these interactions. Specifically, we first define a flexible architecture search space for the CTR prediction task which covers many popular designs such as PIN, PNN and DeepFM, etc., and enables higher-order interactions. Then we propose an efficient neural architecture search algorithm that recursively refines the search space by partitioning it into several subspaces and samples from higher quality ones. Extensive experiments on multiple CTR prediction benchmarks show the superiority of our AutoFeature over the state-of-the-art baselines. In addition, our experiments show that the learned architectures use fewer flops/parameters and hence can efficiently incorporate higher-order feature interactions. This further boosts the performance. Finally, we show that AutoFeature can find meaningful feature interactions.</p>
<p>Keywords:</p>
<h3 id="66. Selecting Influential Features by a Learnable Content-Aware Linear Threshold Model.">66. Selecting Influential Features by a Learnable Content-Aware Linear Threshold Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411886">Paper Link</a>    Pages:635-644</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5065.html">Ansh Khurana</a> ; <a href="https://dblp.uni-trier.de/pid/228/6073.html">Alvis Logins</a> ; <a href="https://dblp.uni-trier.de/pid/08/5342.html">Panagiotis Karras</a></p>
<p>Abstract:
Consider a network in which items propagate in a manner determined by their inherent characteristics or features. How should we select such inherent content features of a message emanating from a given set of nodes, so as to engender high influence spread over the network? This influential feature set selection problem has received scarce attention, contrary to its dual, influential node set selection counterpart, which calls to select the initial adopter nodes from which a fixed message emanates, so as to reach high influence. However, the influential feature set selection problem arises in many practical settings, where initial adopters are given, while propagation depends on the perception of certain malleable message features. We study this problem for a diffusion governed by a content-aware linear threshold (CALT) model, by which, once the aggregate weight of influence on a node exceeds a randomly chosen threshold, the item goes through. We show that the influence spread function is not submodular, hence a greedy algorithm with approximation guarantees is inadmissible. We propose a method that learns the parameters of the CALT model and adapt the SimPath diffusion estimation method to build a heuristic for the influential feature selection problem. Our experimental study demonstrates the efficacy and efficiency of our technique over synthetic and real data.</p>
<p>Keywords:</p>
<h3 id="67. Describing and Predicting Online Items with Reshare Cascades via Dual Mixture Self-exciting Processes.">67. Describing and Predicting Online Items with Reshare Cascades via Dual Mixture Self-exciting Processes.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411861">Paper Link</a>    Pages:645-654</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/209/9882.html">Quyu Kong</a> ; <a href="https://dblp.uni-trier.de/pid/34/7832.html">Marian-Andrei Rizoiu</a> ; <a href="https://dblp.uni-trier.de/pid/59/4002.html">Lexing Xie</a></p>
<p>Abstract:
It is well-known that online behavior is long-tailed, with most cascaded actions being short and a few being very long. A prominent drawback in generative models for online events is the inability to describe unpopular items well. This work addresses these shortcomings by proposing dual mixture self-exciting processes to jointly learn from groups of cascades. We first start from the observation that maximum likelihood estimates for content virality and influence decay are separable in a Hawkes process. Next, our proposed model, which leverages a Borel mixture model and a kernel mixture model, jointly models the unfolding of a heterogeneous set of cascades. When applied to cascades of the same online items, the model directly characterizes their spread dynamics and supplies interpretable quantities, such as content virality and content influence decay, as well as methods for predicting the final content popularities. On two retweet cascade datasets --- one relating to YouTube videos and the second relating to controversial news articles --- we show that our models capture the differences between online items at the granularity of items, publishers and categories. In particular, we are able to distinguish between far-right, conspiracy, controversial and reputable online news articles based on how they diffuse through social media, achieving an F1 score of 0.945. On holdout datasets, we show that the dual mixture model provides, for reshare diffusion cascades especially unpopular ones, better generalization performance and, for online items, accurate item popularity predictions.</p>
<p>Keywords:</p>
<h3 id="68. Extracting N-ary Facts from Wikipedia Table Clusters.">68. Extracting N-ary Facts from Wikipedia Table Clusters.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412027">Paper Link</a>    Pages:655-664</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/148/4547.html">Benno Kruit</a> ; <a href="https://dblp.uni-trier.de/pid/b/PeterABoncz.html">Peter A. Boncz</a> ; <a href="https://dblp.uni-trier.de/pid/15/7454.html">Jacopo Urbani</a></p>
<p>Abstract:
Tables in Wikipedia articles contain a wealth of knowledge that would be useful for many applications if it were structured in a more coherent, queryable form. An important problem is that many of such tables contain the same type of knowledge, but have different layouts and/or schemata. Moreover, some tables refer to entities that we can link to Knowledge Bases (KBs), while others do not. Finally, some tables express entity-attribute relations, while others contain more complex n-ary relations. We propose a novel knowledge extraction technique that tackles these problems. Our method first transforms and clusters similar tables into fewer unified ones to overcome the problem of table diversity. Then, the unified tables are linked to the KB so that knowledge about popular entities propagates to the unpopular ones. Finally, our method applies a technique that relies on functional dependencies to judiciously interpret the table and extract n-ary relations. Our experiments over 1.5M Wikipedia tables show that our clustering can group many semantically similar tables. This leads to the extraction of many novel n-ary relations.</p>
<p>Keywords:</p>
<h3 id="69. Live Multi-Streaming and Donation Recommendations via Coupled Donation-Response Tensor Factorization.">69. Live Multi-Streaming and Donation Recommendations via Coupled Donation-Response Tensor Factorization.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411925">Paper Link</a>    Pages:665-674</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/194/7730.html">Hsu-Chao Lai</a> ; <a href="https://dblp.uni-trier.de/pid/177/0974.html">Jui-Yi Tsai</a> ; <a href="https://dblp.uni-trier.de/pid/86/10294.html">Hong-Han Shuai</a> ; <a href="https://dblp.uni-trier.de/pid/52/2437.html">Jiun-Long Huang</a> ; <a href="https://dblp.uni-trier.de/pid/14/716.html">Wang-Chien Lee</a> ; <a href="https://dblp.uni-trier.de/pid/85/318.html">De-Nian Yang</a></p>
<p>Abstract:
In contrast to traditional online videos, live multi-streaming supports real-time social interactions between multiple streamers and viewers, such as donations. However, donation and multi-streaming channel recommendations are challenging due to complicated streamer and viewer relations, asymmetric communications, and the tradeoff between personal interests and group interactions. In this paper, we introduce Multi-Stream Party (MSP) and formulate a new multi-streaming recommendation problem, called Donation and MSP Recommendation (DAMRec). We propose Multi-stream Party Recommender System (MARS) to extract latent features via socio-temporal coupled donation-response tensor factorization for donation and MSP recommendations. Experimental results on Twitch and Douyu manifest that MARS significantly outperforms existing recommenders by at least 38.8% in terms of hit ratio and mean average precision.</p>
<p>Keywords:</p>
<h3 id="70. MERL: Multi-View Edge Representation Learning in Social Networks.">70. MERL: Multi-View Edge Representation Learning in Social Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412049">Paper Link</a>    Pages:675-684</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/143/4576.html">Yi-Yu Lai</a> ; <a href="https://dblp.uni-trier.de/pid/n/JenniferNeville.html">Jennifer Neville</a></p>
<p>Abstract:
Network embedding models aim to learn low-dimensional representations for nodes and/or edges in graphs. For social networks, learning edge representations is especially beneficial as we need to describe or explain the relationships, activities, and interactions between users. Existing approaches that learn stand-alone node embeddings, and represent edges as pairs of node embeddings, are limited in their applicability because nodes participate in multiple relationships, which should be considered. In addition, social networks often contain multiple types of edges, which yields multi-view contexts that need to be considered in the representation. In this paper, we propose a new methodology, MERL, that (1) captures asymmetry in multiple views by learning well-defined edge representations that are responsive to the difference between the source and destination node roles, and (2) incorporates textual communications to identify multiple source of social signals (e.g. strength and affinity) that moderate the impact of different views between users. Our experiments show that MERL outperforms alternative state-of-the-art embedding models on link prediction and multilabel classification tasks across multiple views in social network datasets. We further analyze the learned embeddings of MERL and demonstrate they are more correlated with the existence of view-based edges compared to previous methods.</p>
<p>Keywords:</p>
<h3 id="71. Towards Temporal Knowledge Graph Embeddings with Arbitrary Time Precision.">71. Towards Temporal Knowledge Graph Embeddings with Arbitrary Time Precision.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412028">Paper Link</a>    Pages:685-694</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/35/8398.html">Julien Leblay</a> ; <a href="https://dblp.uni-trier.de/pid/116/4883.html">Melisachew Wudage Chekol</a> ; <a href="https://dblp.uni-trier.de/pid/76/1820-20.html">Xin Liu</a></p>
<p>Abstract:
Acknowledging the dynamic nature of knowledge graphs, the problem of learning temporal knowledge graph embeddings has recently gained attention. Essentially, the goal is to learn vector representation for the nodes and edges of a knowledge graph taking time into account. These representations must preserve certain properties of the original graph, so as to allow not only classification or clustering tasks, as for classical graph embeddings, but also approximate time-dependent query answering or link predictions over knowledge graphs. For instance, "who was the leader of Germany in 1994?'' or "when was Bonn the capital of Germany?''</p>
<p>Keywords:</p>
<h3 id="72. News Recommendation with Topic-Enriched Knowledge Graphs.">72. News Recommendation with Topic-Enriched Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411932">Paper Link</a>    Pages:695-704</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/47/2932.html">Dongho Lee</a> ; <a href="https://dblp.uni-trier.de/pid/170/0446.html">Byungkook Oh</a> ; <a href="https://dblp.uni-trier.de/pid/170/0544.html">Seungmin Seo</a> ; <a href="https://dblp.uni-trier.de/pid/27/5926.html">Kyong-Ho Lee</a></p>
<p>Abstract:
News recommendation systems? purpose is to tackle the immense amount of news and offer personalized recommendations to users. A major issue in news recommendation is to capture the precise news representations for the efficacy of recommended items. Commonly, news contents are filled with well-known entities of different types. However, existing recommendation systems overlook exploiting external knowledge about entities and topical relatedness among the news. To cope with the above problem, in this paper, we propose Topic-Enriched Knowledge Graph Recommendation System(TEKGR). Three encoders in TEKGR handle news titles in two perspectives to obtain news representation embedding: (1) to extract meaning of news words without considering latent knowledge features in the news and (2) to extract semantic knowledge of news through topic information and contextual information from a knowledge graph. After obtaining news representation vectors, an attention network compares clicked news to the candidate news in order to get the user's final embedding. Our TEKGR model is superior to existing news recommendation methods by manipulating topical relations among entities and contextual features of entities. Experimental results on two public datasets show that our approach outperforms state-of-the-art deep recommendation approaches.</p>
<p>Keywords:</p>
<h3 id="73. Cross-sentence N-ary Relation Extraction using Entity Link and Discourse Relation.">73. Cross-sentence N-ary Relation Extraction using Entity Link and Discourse Relation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412011">Paper Link</a>    Pages:705-714</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/87/8442.html">Sanghak Lee</a> ; <a href="https://dblp.uni-trier.de/pid/170/0544.html">Seungmin Seo</a> ; <a href="https://dblp.uni-trier.de/pid/170/0446.html">Byungkook Oh</a> ; <a href="https://dblp.uni-trier.de/pid/27/5926.html">Kyong-Ho Lee</a> ; <a href="https://dblp.uni-trier.de/pid/03/4568.html">Dong-Hoon Shin</a> ; <a href="https://dblp.uni-trier.de/pid/08/4568.html">Yeonsoo Lee</a></p>
<p>Abstract:
This paper presents an efficient method of extracting n-ary relations from multiple sentences which is called Entity-path and Discourse relation-centric Relation Extractor (EDCRE). Unlike previous approaches, the proposed method focuses on an entity link, which consists of dependency edges between entities, and discourse relations between sentences. Specifically, the proposed model consists of two main sub-models. The first one encodes sentences with a higher weight on the entity link while considering the other edges with an attention mechanism. To consider various latent discourse relations between sentences, the second sub-model encodes discourse relations between adjacent sentences considering the contents of each sentence. Experiment results on the cross-sentence relation extraction dataset, PubMed, and the document-level relation extraction dataset, DocRED, show that the proposed model outperforms state-of-the-art methods of extracting relations across sentences. Furthermore, ablation study proves that both the two main sub-models have noticeable effect on the relation extraction task.</p>
<p>Keywords:</p>
<h3 id="74. Knowledge Adaption for Demand Prediction based on Multi-task Memory Neural Network.">74. Knowledge Adaption for Demand Prediction based on Multi-task Memory Neural Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411965">Paper Link</a>    Pages:715-724</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/94/10021.html">Can Li</a> ; <a href="https://dblp.uni-trier.de/pid/119/1223-1.html">Lei Bai</a> ; <a href="https://dblp.uni-trier.de/pid/49/3283.html">Wei Liu</a> ; <a href="https://dblp.uni-trier.de/pid/56/6651.html">Lina Yao</a> ; <a href="https://dblp.uni-trier.de/pid/55/4916.html">S. Travis Waller</a></p>
<p>Abstract:
Accurate demand forecasting of different public transport modes (e.g., buses and light rails) is essential for public service operation. However, the development level of various modes often varies significantly, which makes it hard to predict the demand of the modes with insufficient knowledge and sparse station distribution (i.e., station-sparse mode). Intuitively, different public transit modes may exhibit shared demand patterns temporally and spatially in a city. As such, we propose to enhance the demand prediction of station-sparse modes with the data from station-intensive mode and design a Memory-Augmented Multi-task Re current Network (MATURE) to derive the transferable demand patterns from each mode and boost the prediction of station-sparse modes through adapting the relevant patterns from the station-intensive mode. Specifically, MATURE comprises three components: 1) a memory-augmented recurrent network for strengthening the ability to capture the long-short term information and storing temporal knowledge of each transit mode; 2) a knowledge adaption module to adapt the relevant knowledge from a station-intensive source to station-sparse sources; 3) a multi-task learning framework to incorporate all the information and forecast the demand of multiple modes jointly. The experimental results on a real-world dataset covering four public transport modes demonstrate that our model can promote the demand forecasting performance for the station-sparse modes.</p>
<p>Keywords:</p>
<h3 id="75. Learning with Noisy Partial Labels by Simultaneously Leveraging Global and Local Consistencies.">75. Learning with Noisy Partial Labels by Simultaneously Leveraging Global and Local Consistencies.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411885">Paper Link</a>    Pages:725-734</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/73/7819.html">Changchun Li</a> ; <a href="https://dblp.uni-trier.de/pid/130/1013.html">Ximing Li</a> ; <a href="https://dblp.uni-trier.de/pid/46/3783.html">Jihong Ouyang</a></p>
<p>Abstract:
In real-world scenarios, the data are widespread that are annotated with a set of candidate labels but a single ground-truth label per-instance. The learning paradigm with such data, formally referred to as Partial Label (PL) learning, has recently drawn much attention. The traditional PL methods estimate the confidences being the ground-truth label of candidate labels with various regularizations and constraints, however, they only consider the local information, resulting in potentially less accurate estimations as well as worse classification performance. To alleviate this problem, we propose a novel PL method, namely PArtial label learNing by simultaneously leveraging GlObal and Local consIsteNcies (Pangolin). Specifically, we design a global consistency regularization term to pull instances associated with similar labeling confidences together by minimizing the distances between instances and label prototypes, and a local consistency term to push instances marked with no same candidate labels away by maximizing their distances. We further propose a nonlinear kernel extension of Pangolin, and employ the Taylor approximation trick for efficient optimization. Empirical results demonstrate that Pangolin significantly outperforms the existing PL baseline methods.</p>
<p>Keywords:</p>
<h3 id="76. Knowledge-Enhanced Personalized Review Generation with Capsule Graph Neural Network.">76. Knowledge-Enhanced Personalized Review Generation with Capsule Graph Neural Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411893">Paper Link</a>    Pages:735-744</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/28/6612.html">Junyi Li</a> ; <a href="https://dblp.uni-trier.de/pid/240/0322.html">Siqing Li</a> ; <a href="https://dblp.uni-trier.de/pid/52/8700.html">Wayne Xin Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/224/0314.html">Gaole He</a> ; <a href="https://dblp.uni-trier.de/pid/22/2720.html">Zhicheng Wei</a> ; <a href="https://dblp.uni-trier.de/pid/131/4855.html">Nicholas Jing Yuan</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
Personalized review generation (PRG) aims to automatically produce review text reflecting user preference, which is a challenging natural language generation task. Most of previous studies do not explicitly model factual description of products, tending to generate uninformative content. Moreover, they mainly focus on word-level generation, but cannot accurately reflect more abstractive user preference in multiple aspects. To address the above issues, we propose a novel knowledgeenhanced PRG model based on capsule graph neural network (CapsGNN). We first construct a heterogeneous knowledge graph (HKG) for utilizing rich item attributes. We adopt Caps-GNN to learn graph capsules for encoding underlying characteristics from the HKG. Our generation process contains two major steps, namely aspect sequence generation and sentence generation. First, based on graph capsules, we adaptively learn aspect capsules for inferring the aspect sequence. Then, conditioned on the inferred aspect label, we design a graph-based copy mechanism to generate sentences by incorporating related entities or words from HKG. To our knowledge, we are the first to utilize knowledge graph for the PRG task. The incorporated KG information is able to enhance user preference at both aspect and word levels. Extensive experiments on three real-world datasets have demonstrated the effectiveness of our model on the PRG task.</p>
<p>Keywords:</p>
<h3 id="77. Seed-free Graph De-anonymiztiation with Adversarial Learning.">77. Seed-free Graph De-anonymiztiation with Adversarial Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411970">Paper Link</a>    Pages:745-754</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/00/4848.html">Kaiyang Li</a> ; <a href="https://dblp.uni-trier.de/pid/132/1723.html">Guoming Lu</a> ; <a href="https://dblp.uni-trier.de/pid/65/8410.html">Guangchun Luo</a> ; <a href="https://dblp.uni-trier.de/pid/14/5155-1.html">Zhipeng Cai</a></p>
<p>Abstract:
The huge amount of graph data are published and shared for research and business purposes, which brings great benefit for our society. However, user privacy is badly undermined even though user identity can be anonymized. Graph de-anonymization to identify nodes from an anonymized graph is widely adopted to evaluate users' privacy risks. Most existing de-anonymization methods which are heavily reliant on side information (e.g., seeds, user profiles, community labels) are unrealistic due to the difficulty of collecting this side information. A few graph de-anonymization methods only using structural information, called seed-free methods, have been proposed recently, which mainly take advantage of the local and manual features of nodes while overlooking the global structural information of the graph for de-anonymization.</p>
<p>Keywords:</p>
<h3 id="78. Generate Neural Template Explanations for Recommendation.">78. Generate Neural Template Explanations for Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411992">Paper Link</a>    Pages:755-764</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/13/7007.html">Lei Li</a> ; <a href="https://dblp.uni-trier.de/pid/82/7829.html">Yongfeng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/c/LiChen.html">Li Chen</a></p>
<p>Abstract:
Personalized recommender systems are important to assist user decision-making in the era of information overload. Meanwhile, explanations of the recommendations further help users to better understand the recommended items so as to make informed choices, which gives rise to the importance of explainable recommendation research. Textual sentence-based explanation has been an important form of explanations for recommender systems due to its advantage in communicating rich information to users. However, current approaches to generating sentence explanations are either limited to predefined sentence templates, which restricts the sentence expressiveness, or opt for free-style sentence generation, which makes it difficult for sentence quality control. In an attempt to benefit both sentence expressiveness and quality, we propose a Neural Template (NETE) explanation generation framework, which brings the best of both worlds by learning sentence templates from data and generating template-controlled sentences that comment about specific features. Experimental results on real-world datasets show that NETE consistently outperforms state-of-the-art explanation generation approaches in terms of sentence quality and expressiveness. Further analysis on case study also shows the advantages of NETE on generating diverse and controllable explanations.</p>
<p>Keywords:</p>
<h3 id="79. A Topic and Concept Integrated Model for Thread Recommendation in Online Health Communities.">79. A Topic and Concept Integrated Model for Thread Recommendation in Online Health Communities.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411933">Paper Link</a>    Pages:765-774</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/32/10146.html">Mingda Li</a> ; <a href="https://dblp.uni-trier.de/pid/151/7891.html">Weiting Gao</a> ; <a href="https://dblp.uni-trier.de/pid/88/6466-1.html">Yi Chen</a></p>
<p>Abstract:
Online health communities (OHCs) provide a popular channel for users to seek information, suggestions and support during their medical treatment and recovery processes. To help users find relevant information easily, we present CLIR, an effective system for recommending relevant discussion threads to users in OHCs. We identify that thread content and user interests can be categorized in two dimensions: topics and concepts. CLIR leverages Latent Dirichlet Allocation model to summarize the topic dimension and uses Convolutional Neural Network to encode the concept dimension. It then builds a thread neural network to capture thread characteristics and builds a user neural network to capture user interests by integrating these two dimensions and their interactions. Finally, it matches the target thread's characteristics with candidate users' interests to make recommendations. Experimental evaluation with multiple OHC datasets demonstrates the performance advantage of CLIR over the state-of-the-art recommender systems on various evaluation metrics.</p>
<p>Keywords:</p>
<h3 id="80. Trapping Malicious Crawlers in Social Networks.">80. Trapping Malicious Crawlers in Social Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412004">Paper Link</a>    Pages:775-784</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/32/1755.html">Shiju Li</a> ; <a href="https://dblp.uni-trier.de/pid/70/1627.html">Chul-Ho Lee</a> ; <a href="https://dblp.uni-trier.de/pid/65/2878.html">Do Young Eun</a></p>
<p>Abstract:
In this paper, we study a problem of trapping malicious web crawlers in social networks to minimize the attacks from crawlers with malicious intents to steal personal/private information. The problem is to find where to place a given set of traps over a graph so as to minimize the expected number of users who possibly fall prey to a (possibly random) set of malicious crawlers, each of which traverses the graph in a random-walk fashion for a random finite time. We first show that this problem is NP-hard and also a monotone submodular maximization problem. We then present a greedy algorithm that achieves a ($1-1/e$)-approximation. We also develop an $(,)$-approximation Monte Carlo estimator to ease the computation of the greedy algorithm and thus make the algorithm scalable for large graphs. We finally present extensive simulation results to show that our algorithm significantly outperforms other baseline algorithms based on various centrality measures.</p>
<p>Keywords:</p>
<h3 id="81. Deep Time-Aware Item Evolution Network for Click-Through Rate Prediction.">81. Deep Time-Aware Item Evolution Network for Click-Through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411952">Paper Link</a>    Pages:785-794</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/40/1491.html">Xiang Li</a> ; <a href="https://dblp.uni-trier.de/pid/188/7759.html">Chao Wang</a> ; <a href="https://dblp.uni-trier.de/pid/78/1232.html">Bin Tong</a> ; <a href="https://dblp.uni-trier.de/pid/136/8684.html">Jiwei Tan</a> ; <a href="https://dblp.uni-trier.de/pid/245/6049.html">Xiaoyi Zeng</a> ; <a href="https://dblp.uni-trier.de/pid/04/3077.html">Tao Zhuang</a></p>
<p>Abstract:
For better user satisfaction and business effectiveness, Click-Through Rate (CTR) prediction is one of the most important tasks in E-commerce. It is often the case that users' interests different from their past routines may emerge or impressions such as promotional items may burst in a very short period. In essence, such changes relate to item evolution problem, which has not been investigated by previous studies. The state-of-the-art methods in the sequential recommendation, which use simple user behaviors, are incapable of modeling these changes sufficiently. It is because, in the user behaviors, outdated interests may exist and the popularity of an item over time is not well represented. To address these limitations, we introduce time-aware item behaviors for addressing the recommendation of emerging preference. The time-aware item behavior for an item is a set of users who interact with this item with timestamps. The rich interaction information of users for an item may help to model its evolution. In this work, we propose a CTR prediction model TIEN based on the time-aware item behavior. In TIEN, by leveraging the interaction time intervals, information of similar users in a short time interval helps identify the emerging user interest of the target user. By using the sequential time intervals, the item's popularity over time can be captured in evolutionary item dynamics. Noisy users who interact with items accidentally are further eliminated thus learning robust personalized item dynamics. To the best of our knowledge, this is the first study to the item evolution problem for E-commerce CTR prediction. We conduct extensive experiments on five real-world CTR prediction datasets. The results show that the TIEN model consistently achieves remarkable improvements to the state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="82. Learning Better Representations for Neural Information Retrieval with Graph Information.">82. Learning Better Representations for Neural Information Retrieval with Graph Information.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411957">Paper Link</a>    Pages:795-804</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/125/7007.html">Xiangsheng Li</a> ; <a href="https://dblp.uni-trier.de/pid/r/MdRijke.html">Maarten de Rijke</a> ; <a href="https://dblp.uni-trier.de/pid/49/1579-1.html">Yiqun Liu</a> ; <a href="https://dblp.uni-trier.de/pid/174/8367.html">Jiaxin Mao</a> ; <a href="https://dblp.uni-trier.de/pid/169/1390.html">Weizhi Ma</a> ; <a href="https://dblp.uni-trier.de/pid/83/5342-6.html">Min Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/40/1949.html">Shaoping Ma</a></p>
<p>Abstract:
Neural ranking models have recently gained much attention in Information Retrieval community and obtain good ranking performance. However, most of these retrieval models focus on capturing the textual matching signals between query and document but do not consider user behavior information that may be helpful for the retrieval task. Specifically, users' click and query reformulation behavior can be represented by a click-through bipartite graph and a session-flow graph, respectively. Such graph representations contain rich user behavior information and may help us better understand users' search intent beyond the textual information. In this study, we aim to incorporate this rich information encoded in these two graphs into existing neural ranking models.</p>
<p>Keywords:</p>
<h3 id="83. Cooperative Multi-Agent Reinforcement Learning in Express System.">83. Cooperative Multi-Agent Reinforcement Learning in Express System.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411871">Paper Link</a>    Pages:805-814</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/176/1477.html">Yexin Li</a> ; <a href="https://dblp.uni-trier.de/pid/87/1585.html">Yu Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/140/7598.html">Qiang Yang</a></p>
<p>Abstract:
Express systems are widely deployed in many major cities. One type of important tasks in the system is to pick up packages from customers in time. As pick-up requests come in real time and there are many couriers picking up packages, how to dispatch couriers to ensure the cooperation among them and to complete more pick-up tasks in a long time, is very important but challenging. In this paper, we propose a reinforcement learning based framework to learn courier dispatching policies. At first, we divide the city into independent regions, inner each of which a constant number of couriers pick up packages at the same time. Besides reducing problem complexity, city division has practical operation benefits. Afterwards, we focus on each region separately. For each region, we propose a Cooperative Multi-Agent Reinforcement Learning model, i.e. CMARL, to learn the optimal courier dispatching policy in it. CMARL tries to maximize the total number of completed pick-up tasks by all couriers in a long time. Our model achieves this target by combining two Markov Decision Processes, one to guarantee the cooperation among couriers, and the other one to ensure the long-term optimization. After obtaining the value functions of these two MDPs, a new value function is designed to trade off them, based on which we can infer the courier dispatching policy. Experiments based on real-world road network data and historical express data from Beijing are conducted, to confirm the superiority of our model compared with nine baselines.</p>
<p>Keywords:</p>
<h3 id="84. Meta-Learning for Neural Relation Classification with Distant Supervision.">84. Meta-Learning for Neural Relation Classification with Distant Supervision.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412039">Paper Link</a>    Pages:815-824</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/117/3061.html">Zhenzhen Li</a> ; <a href="https://dblp.uni-trier.de/pid/n/JianYunNie.html">Jian-Yun Nie</a> ; <a href="https://dblp.uni-trier.de/pid/169/1793.html">Benyou Wang</a> ; <a href="https://dblp.uni-trier.de/pid/74/5694.html">Pan Du</a> ; <a href="https://dblp.uni-trier.de/pid/06/7406.html">Yuhan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/193/4216.html">Lixin Zou</a> ; <a href="https://dblp.uni-trier.de/pid/254/0830-1.html">Dongsheng Li</a></p>
<p>Abstract:
Distant supervision provides a means to create a large number of weakly labeled data at low cost for relation classification. However, the resulting labeled instances are very noisy, containing data with wrong labels. Many approaches have been proposed to select a subset of reliable instances for neural model training, but they still suffer from noisy labeling problem or underutilization of the weakly-labeled data. To better select more reliable training instances, we introduce a small amount of manually labeled data as reference to guide the selection process. In this paper, we propose a meta-learning based approach, which learns to reweight noisy training data under the guidance of reference data. As the clean reference data is usually very small, we propose to augment it by dynamically distilling the most reliable elite instances from the noisy data. Experiments on several datasets demonstrate that the reference data can effectively guide the selection of training data, and our augmented approach consistently improves the performance of relation classification comparing to the existing state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="85. Aspect-invariant Sentiment Features Learning: Adversarial Multi-task Learning for Aspect-based Sentiment Analysis.">85. Aspect-invariant Sentiment Features Learning: Adversarial Multi-task Learning for Aspect-based Sentiment Analysis.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411868">Paper Link</a>    Pages:825-834</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/71/6053.html">Bin Liang</a> ; <a href="https://dblp.uni-trier.de/pid/266/0682.html">Rongdi Yin</a> ; <a href="https://dblp.uni-trier.de/pid/34/8605-3.html">Lin Gui</a> ; <a href="https://dblp.uni-trier.de/pid/172/9266.html">Jiachen Du</a> ; <a href="https://dblp.uni-trier.de/pid/75/5430.html">Yulan He</a> ; <a href="https://dblp.uni-trier.de/pid/93/5407.html">Ruifeng Xu</a></p>
<p>Abstract:
In most previous studies, the aspect-related text is considered an important clue for the Aspect-based Sentiment Analysis (ABSA) task, and thus various attention mechanisms have been proposed to leverage the interactions between aspects and context. However, it is observed that some sentiment expressions carry the same polarity regardless of the aspects they are associated with. In such cases, it is not necessary to incorporate aspect information for ABSA. More observations on the experimental results show that blindly leveraging interactions between aspects and context as features may introduce noises when analyzing those aspect-invariant sentiment expressions, especially when the aspect-related annotated data is insufficient. Hence, in this paper, we propose an Adversarial Multi-task Learning framework to identify the aspect-invariant/dependent sentiment expressions without extra annotations. In addition, we adopt a gating mechanism to control the contribution of representations derived from aspect-invariant and aspect-dependent hidden states when generating the final contextual sentiment representations for the given aspect. This essentially allows the exploitation of aspect-invariant sentiment features for better ABSA results. Experimental results on two benchmark datasets show that extending existing neural models using our proposed framework achieves superior performance. In addition, the aspect-invariant data extracted by the proposed framework can be considered as pivot features for better transfer learning of the ABSA models on unseen aspects.</p>
<p>Keywords:</p>
<h3 id="86. Attributed Network Embedding based on Mutual Information Estimation.">86. Attributed Network Embedding based on Mutual Information Estimation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412008">Paper Link</a>    Pages:835-844</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/262/3410.html">Xiaomin Liang</a> ; <a href="https://dblp.uni-trier.de/pid/06/988.html">Daifeng Li</a> ; <a href="https://dblp.uni-trier.de/pid/219/6593.html">Andrew Madden</a></p>
<p>Abstract:
Attributed network embedding (ANE) attempts to represent a network in short code, while retaining information about node topological structures and node attributes. A node's feature and topological structure information could be divided into different local aspects, while in many cases, not all the information but part of the information contained in several local aspects determine the relations among different nodes. Most of the existing works barely concern and identify the aspect influence from network embedding to our knowledge. We attempt to use local embeddings to represent local aspect information and propose InfomaxANE which encodes both global and local embeddings from the perspective of mutual information. The local aspect embeddings are forced to learn and extract different aspect information from nodes' features and topological structures by using orthogonal constraint. A theoretical analysis is also provided to further confirm its correctness and rationality. Besides, to provide complete and refined information for local encoders, we also optimize feature aggregation in SAGE with different structures: feature similarities are concerned and aggregator is seperated from encoder. InfomaxANE is evaluated on both node clustering and node classification tasks (including both transductive and inductive settings) with several benchmark datasets, the results show the outperformance of InfomaxANE over competitive baselines. We also verify the significance of each module in our proposed InfomaxANE in the additional experiment.</p>
<p>Keywords:</p>
<h3 id="87. STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation.">87. STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411876">Paper Link</a>    Pages:845-854</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5027.html">Nicholas Lim</a> ; <a href="https://dblp.uni-trier.de/pid/169/9975.html">Bryan Hooi</a> ; <a href="https://dblp.uni-trier.de/pid/00/5480.html">See-Kiong Ng</a> ; <a href="https://dblp.uni-trier.de/pid/120/7192.html">Xueou Wang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5015.html">Yong Liang Goh</a> ; <a href="https://dblp.uni-trier.de/pid/276/5083.html">Renrong Weng</a> ; <a href="https://dblp.uni-trier.de/pid/30/8937.html">Jagannadan Varadarajan</a></p>
<p>Abstract:
Next Point-of-Interest (POI) recommendation is a longstanding problem across the domains of Location-Based Social Networks (LBSN) and transportation. Recent Recurrent Neural Network (RNN) based approaches learn POI-POI relationships in a local view based on independent user visit sequences. This limits the model's ability to directly connect and learn across users in a global view to recommend semantically trained POIs. In this work, we propose a Spatial-Temporal-Preference User Dimensional Graph Attention Network (STP-UDGAT), a novel explore-exploit model that concurrently exploits personalized user preferences and explores new POIs in global spatial-temporal-preference (STP) neighbourhoods, while allowing users to selectively learn from other users. In addition, we propose random walks as a masked self-attention option to leverage the STP graphs' structures and find new higher-order POI neighbours during exploration. Experimental results on six real-world datasets show that our model significantly outperforms baseline and state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="88. Attacking Recommender Systems with Augmented User Profiles.">88. Attacking Recommender Systems with Augmented User Profiles.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411884">Paper Link</a>    Pages:855-864</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/37/3102.html">Chen Lin</a> ; <a href="https://dblp.uni-trier.de/pid/93/5439.html">Si Chen</a> ; <a href="https://dblp.uni-trier.de/pid/66/3387-57.html">Hui Li</a> ; <a href="https://dblp.uni-trier.de/pid/96/999.html">Yanghua Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/265/6372.html">Lianyun Li</a> ; <a href="https://dblp.uni-trier.de/pid/15/3199.html">Qian Yang</a></p>
<p>Abstract:
Recommendation Systems (RS) have become an essential part of many online services. Due to its pivotal role in guiding customers towards purchasing, there is a natural motivation for unscrupulous parties to spoof RS for profits. In this paper, we study the shilling attack: a subsistent and profitable attack where an adversarial party injects a number of user profiles to promote or demote a target item. Conventional shilling attack models are based on simple heuristics that can be easily detected, or directly adopt adversarial attack methods without a special design for RS. Moreover, the study on the attack impact on deep learning based RS is missing in the literature, making the effects of shilling attack against real RS doubtful. We present a novel Augmented Shilling Attack framework (AUSH) and implement it with the idea of Generative Adversarial Network. AUSH is capable of tailoring attacks against RS according to budget and complex attack goals, such as targeting a specific user group. We experimentally show that the attack impact of AUSH is noticeable on a wide range of RS including both classic and modern deep learning based RS, while it is virtually undetectable by the state-of-the-art attack detection model.</p>
<p>Keywords:</p>
<h3 id="89. Jointly Modeling Individual Student Behaviors and Social Influence for Prediction Tasks.">89. Jointly Modeling Individual Student Behaviors and Social Influence for Prediction Tasks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411961">Paper Link</a>    Pages:865-874</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/230/7127.html">Haobing Liu</a> ; <a href="https://dblp.uni-trier.de/pid/02/6595.html">Yanmin Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5093.html">Tianzi Zang</a> ; <a href="https://dblp.uni-trier.de/pid/85/3615.html">Jiadi Yu</a> ; <a href="https://dblp.uni-trier.de/pid/60/1377.html">Haibin Cai</a></p>
<p>Abstract:
Prediction tasks about students such as predicting students' academic performances have practical real-world significance at both the student level and the college level. With the rapid construction of smart campuses, colleges not only offer residence and academic programs but also record students' daily life. The digital footprints provide an opportunity to offer better solutions for prediction tasks. In this paper, we aim to propose a general deep neural network which can jointly model student heterogeneous daily behaviors generated from digital footprints and social influence to deal with prediction tasks. To this end, we design a variant of LSTM and a novel attention mechanism to model the daily behavior sequence. The proposed LSTM is able to consider context information (e.g., weather conditions) while modeling the daily behavior sequence. The proposed attention mechanism can dynamically learn the different importance degrees of different days for every student. Based on behavior information, we propose an unsupervised way to construct a social network to model social influence. Moreover, we design a residual network based decoder to model the complex interactions between the features and get the predicted values such as future academic performances. Qualitative and quantitative experiments on two real-world datasets collected from a college have demonstrated the effectiveness of our model.</p>
<p>Keywords:</p>
<h3 id="90. Fusing Parallel Social Contexts within Flexible-Order Proximity for Microblog Topic Detection.">90. Fusing Parallel Social Contexts within Flexible-Order Proximity for Microblog Topic Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412024">Paper Link</a>    Pages:875-884</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/07/706.html">Hongyu Liu</a> ; <a href="https://dblp.uni-trier.de/pid/96/9018.html">Ruifang He</a> ; <a href="https://dblp.uni-trier.de/pid/150/8245.html">Haocheng Wang</a> ; <a href="https://dblp.uni-trier.de/pid/72/6811.html">Bo Wang</a></p>
<p>Abstract:
Topic detection in social media is a challenging task due to large-scale short, noisy and informal nature of messages. Most existing methods only consider textual content or simultaneously model the posts and the first-order structural characteristics of social networks. They ignore the impact of larger neighborhoods in microblog conversations on topics. Moreover, the simple combination of separated content and structure representations fails to capture their nonlinear correlation and different importance in topic inference. To this end, we propose a novel random walk based Parallel Social Contexts Fusion Topic Model (PCFTM) for weibo conversations. Firstly, a user-level conversation network with content information is built by the reposting and commenting relationships among users. Through random walks of different lengths on network, we obtain the user sequences containing the parallel content and structure contexts, which are used to acquire the flexible-order proximity of users. Then we propose a self-fusion network embedding to capture the nonlinear correlation between parallel social contexts. It is achieved by taking the content embedding sequence processed by CNN as the initial value of structure embedding sequence fed to Bi-LSTM. Meanwhile, a user-level self-attention is further used to mine the different importance of users to topics. Lastly, the user sequence embedding is incorporated into neural variational inference for detecting topics, which adaptively balances the intrinsic complementarity between content and structure, and fully uses both local and global social contexts in topic inference. Extensive experiments on three real-world weibo datasets demonstrate the effectiveness of our proposed model.</p>
<p>Keywords:</p>
<h3 id="91. Cross Domain Recommendation via Bi-directional Transfer Graph Collaborative Filtering Networks.">91. Cross Domain Recommendation via Bi-directional Transfer Graph Collaborative Filtering Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412012">Paper Link</a>    Pages:885-894</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/41/7841.html">Meng Liu</a> ; <a href="https://dblp.uni-trier.de/pid/34/780.html">Jianjun Li</a> ; <a href="https://dblp.uni-trier.de/pid/05/10612.html">Guohui Li</a> ; <a href="https://dblp.uni-trier.de/pid/03/4293.html">Peng Pan</a></p>
<p>Abstract:
Data sparsity is a challenge problem that most modern recommender systems are confronted with. By leveraging the knowledge from relevant domains, the cross-domain recommendation technique can be an effective way of alleviating the data sparsity problem. In this paper, we propose a novel Bi-directional Transfer learning method for cross-domain recommendation by using Graph Collaborative Filtering network as the base model (BiTGCF). BiTGCF not only exploits the high-order connectivity in user-item graph of single domain through a novel feature propagation layer, but also realizes the two-way transfer of knowledge across two domains by using the common user as the bridge. Moreover, distinct from previous cross-domain collaborative filtering methods, BiTGCF fuses users' common features and domain-specific features during transfer. Experimental results on four couple benchmark datasets verify the effectiveness of BiTGCF over state-of-the-art models in terms of bi-directional cross domain recommendation.</p>
<p>Keywords:</p>
<h3 id="92. Explainable Recommender Systems via Resolving Learning Representations.">92. Explainable Recommender Systems via Resolving Learning Representations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411919">Paper Link</a>    Pages:895-904</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/145/4489.html">Ninghao Liu</a> ; <a href="https://dblp.uni-trier.de/pid/39/844.html">Yong Ge</a> ; <a href="https://dblp.uni-trier.de/pid/53/2189.html">Li Li</a> ; <a href="https://dblp.uni-trier.de/pid/24/7536.html">Xia Hu</a> ; <a href="https://dblp.uni-trier.de/pid/02/1003.html">Rui Chen</a> ; <a href="https://dblp.uni-trier.de/pid/185/1826.html">Soo-Hyun Choi</a></p>
<p>Abstract:
Recommender systems play a fundamental role in web applications in filtering massive information and matching user interests. While many efforts have been devoted to developing more effective models in various scenarios, the exploration on the explainability of recommender systems is running behind. Explanations could help improve user experience and discover system defects. In this paper, after formally introducing the elements that are related to model explainability, we propose a novel explainable recommendation model through improving the transparency of the representation learning process. Specifically, to overcome the representation entangling problem in traditional models, we revise traditional graph convolution to discriminate information from different layers. Also, each representation vector is factorized into several segments, where each segment relates to one semantic aspect in data. Different from previous work, in our model, factor discovery and representation learning are simultaneously conducted, and we are able to handle extra attribute information and knowledge. In this way, the proposed model can learn interpretable and meaningful representations for users and items. Unlike traditional methods that need to make a trade-off between explainability and effectiveness, the performance of our proposed explainable model is not negatively affected after considering explainability. Finally, comprehensive experiments are conducted to validate the performance of our model as well as explanation faithfulness.</p>
<p>Keywords:</p>
<h3 id="93. Deep Spatio-Temporal Multiple Domain Fusion Network for Urban Anomalies Detection.">93. Deep Spatio-Temporal Multiple Domain Fusion Network for Urban Anomalies Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411920">Paper Link</a>    Pages:905-914</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/11/8456.html">Ruiqiang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/116/8682-1.html">Shuai Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/05/2700-1.html">Bo Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/54/4089.html">Hao Yang</a> ; <a href="https://dblp.uni-trier.de/pid/41/7868.html">Haina Tang</a> ; <a href="https://dblp.uni-trier.de/pid/40/2765.html">Taoyu Li</a></p>
<p>Abstract:
Multiple domain fusion has been widely used for urban anomalies forecasting problem, as urban anomalies such as traffic accidents or illegal assembly are usually caused by many complex factors and they would affect many fields. Although many efforts have been devoted to fusing multiple datasets for anomalies detection, most of the work is to extract the spatio-temporal features one by one from multiple datasets and then fuse to get the result or anomaly score. However, the correlation between data from multiple domains at each moment is ignored, which is especially important when detecting anomalies by analyzing the impacts from multiple datasets. In this paper, we propose a novel end-to-end deep learning based framework, namely deep spatio-temporal multiple domain fusion network to collect the impacts of urban anomalies on multiple datasets and detect anomalies in each region of the city at next time interval in turn. We formulate the problem on a weighted graph and obtain spatiotemporal features with adaptive graph convolution and temporal convolution. In addition, a cross-domain convolution network is applied to fully obtain connection between multiple domains. We evaluate our method with real-world dataset collected in New York City and experiments on our model show the advantages nearly 10% beyond the state-of-the-art urban anomalies detection methods.</p>
<p>Keywords:</p>
<h3 id="94. Structural Relationship Representation Learning with Graph Embedding for Personalized Product Search.">94. Structural Relationship Representation Learning with Graph Embedding for Personalized Product Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411936">Paper Link</a>    Pages:915-924</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/91/3334.html">Shang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/196/5892.html">Wanli Gu</a> ; <a href="https://dblp.uni-trier.de/pid/33/3180.html">Gao Cong</a> ; <a href="https://dblp.uni-trier.de/pid/134/2883.html">Fuzheng Zhang</a></p>
<p>Abstract:
To provide more accurate personalized product search (PPS) results, it is compulsory to go beyond modeling user-query-item interaction. Graph embedding techniques open the potential to integrate node information and topological structure information. Existing graph embedding enhanced PPS methods are mostly based on entity-relation-entity graph learning. In this work, we propose to consider structural relationship in users' product search scenario with graph embedding by latent representation learning. We argue that explicitly modeling the structural relationship in graph embedding is essential for more accurate PPS results. We propose a novel method, Graph embedding based Structural Relationship Representation Learning (GraphSRRL), which explicitly models the structural relationship in users-queries-products interaction. It combines three key conjunctive graph patterns to learn graph embedding for better PPS. In addition, GraphSRRL facilitates the learning of affinities between users (resp. queries or products) in the designed geometric operation in low-dimensional latent space. We conduct extensive experiments on four datasets to evaluate GraphSRRL for PPS. Experimental results show that GraphSRRL outperforms the state-of-the-art algorithm on real-world search datasets by at least 50.7% in term of [email protected] and 48.7% in terms of [email protected]</p>
<p>Keywords:</p>
<h3 id="95. Personalized Re-ranking with Item Relationships for E-commerce.">95. Personalized Re-ranking with Item Relationships for E-commerce.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412332">Paper Link</a>    Pages:925-934</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/75/2746.html">Weiwen Liu</a> ; <a href="https://dblp.uni-trier.de/pid/53/4481.html">Qing Liu</a> ; <a href="https://dblp.uni-trier.de/pid/24/10003.html">Ruiming Tang</a> ; <a href="https://dblp.uni-trier.de/pid/196/7893.html">Junyang Chen</a> ; <a href="https://dblp.uni-trier.de/pid/11/5357.html">Xiuqiang He</a> ; <a href="https://dblp.uni-trier.de/pid/52/2889.html">Pheng-Ann Heng</a></p>
<p>Abstract:
Re-ranking is a critical task for large-scale commercial recommender systems. Given the initial ranked lists, top candidates are re-ranked to improve the accuracy of the ranking results. However, existing re-ranking strategies are sub-optimal due to (i) most prior works do not consider explicit item relationships, like being substitutable or complementary, which may mutually influence the user satisfaction on other items in the lists, and (ii) they usually apply an identical re-ranking strategy for all users, with personalized user preferences and intents ignored. To resolve the problem, we construct a heterogeneous graph to fuse the initial scoring information and item relationships information. We develop a graph neural network based framework, IRGPR, to explicitly model transitive item relationships by recursively aggregating relational information from multi-hop neighborhoods. We also incorporate a novel intent embedding network to embed personalized user intents into the propagation. We conduct extensive experiments on real-world datasets, demonstrating the effectiveness of IRGPR in re-ranking. Further analysis reveals that modeling the item relationships and personalized intents are particularly useful for improving the performance of re-ranking.</p>
<p>Keywords:</p>
<h3 id="96. An NVM SSD-Optimized Query Processing Framework.">96. An NVM SSD-Optimized Query Processing Framework.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412010">Paper Link</a>    Pages:935-944</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/98/738.html">Xinyu Liu</a> ; <a href="https://dblp.uni-trier.de/pid/76/1503.html">Yu Pan</a> ; <a href="https://dblp.uni-trier.de/pid/28/6239.html">Yusen Li</a> ; <a href="https://dblp.uni-trier.de/pid/71/4292-1.html">Gang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/25/1221.html">Xiaoguang Liu</a></p>
<p>Abstract:
Commercial search engines generally maintain hundreds of thousands of machines equipped with large sized DRAM in order to process huge volume of user queries with fast responsiveness, which incurs high hardware cost since DRAM is very expensive. Recently, NVM Optane SSD has been considered as a promising underlying storage device due to its price advantage over DRAM and speed advantage over traditional slow block devices. However, to achieve a comparable efficiency performance with in-memory index, applying NVM to both latency and I/O bandwidth critical applications such as search engine still faces non-trivial challenges, because NVM has much lower I/O speed and bandwidth compared to DRAM.</p>
<p>Keywords:</p>
<h3 id="97. Shapley Values and Meta-Explanations for Probabilistic Graphical Model Inference.">97. Shapley Values and Meta-Explanations for Probabilistic Graphical Model Inference.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411881">Paper Link</a>    Pages:945-954</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/24/3329.html">Yifei Liu</a> ; <a href="https://dblp.uni-trier.de/pid/66/3019.html">Chao Chen</a> ; <a href="https://dblp.uni-trier.de/pid/276/5107.html">Yazheng Liu</a> ; <a href="https://dblp.uni-trier.de/pid/87/1222.html">Xi Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/67/1229.html">Sihong Xie</a></p>
<p>Abstract:
Probabilistic graphical models, such as Markov random fields (MRF), exploit dependencies among random variables to model a rich family of joint probability distributions. Inference algorithms, such as belief propagation (BP), can effectively compute the marginal posteriors for decision making. Nonetheless, inferences involve sophisticated probability calculations and are difficult for humans to interpret. Among all existing explanation methods for MRFs, no method is designed for fair attributions of an inference outcome to elements on the MRF where the inference takes place. Shapley values provide rigorous attributions but so far have not been studied on MRFs. We thus define Shapley values for MRFs to capture both probabilistic and topological contributions of the variables on MRFs. We theoretically characterize the new definition regarding independence, equal contribution, additivity, and submodularity. As brute-force computation of the Shapley values is challenging, we propose GraphShapley, an approximation algorithm that exploits the decomposability of Shapley values, the structure of MRFs, and the iterative nature of BP inference to speed up the computation. In practice, we propose meta-explanations to explain the Shapley values and make them more accessible and trustworthy to human users. On four synthetic and nine real-world MRFs, we demonstrate that GraphShapley generates sensible and practical explanations.</p>
<p>Keywords:</p>
<h3 id="98. Recommending Inferior Results: A General and Feature-Free Model for Spam Detection.">98. Recommending Inferior Results: A General and Feature-Free Model for Spam Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411900">Paper Link</a>    Pages:955-974</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/183/0941.html">Yuli Liu</a></p>
<p>Abstract:
Spam activities on multifarious online platforms, such as the opinion spam and fake following relationships have been extensively studied for years. Existing works separately employ hand-crafted features --- mainly extracted from user behavior, text information, and relational network, to detect the specific spamming phenomenon on a certain kind of online platform. Although these attempts have made some headway, rapidly emerging spamming categories and frequently changing cheating strategies lead detection models to be subject to circumscribed usability and fragile effectiveness.</p>
<p>Keywords:</p>
<h3 id="99. Towards Locality-Aware Meta-Learning of Tail Node Embeddings on Networks.">99. Towards Locality-Aware Meta-Learning of Tail Node Embeddings on Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411910">Paper Link</a>    Pages:975-984</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/36/6192.html">Zemin Liu</a> ; <a href="https://dblp.uni-trier.de/pid/41/3249.html">Wentao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/22/981.html">Yuan Fang</a> ; <a href="https://dblp.uni-trier.de/pid/06/449.html">Xinming Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/h/StevenCHHoi.html">Steven C. H. Hoi</a></p>
<p>Abstract:
Network embedding is an active research area due to the prevalence of network-structured data. While the state of the art often learns high-quality embedding vectors for high-degree nodes with abundant structural connectivity, the quality of the embedding vectors for low-degree or tail nodes is often suboptimal due to their limited structural connectivity. While many real-world networks are long-tailed, to date little effort has been devoted to tail node embedding. In this paper, we formulate the goal of learning tail node embeddings as a few-shot regression problem, given the few links on each tail node. In particular, since each node resides in its own local context, we personalize the regression model for each tail node. To reduce overfitting in the personalization, we propose a locality-aware meta-learning framework, called meta-tail2vec, which learns to learn the regression model for the tail nodes at different localities. Finally, we conduct extensive experiments and demonstrate the promising results of meta-tail2vec. (Supplemental materials including code and data are available at <a href="https://github.com/smufang/meta-tail2vec">https://github.com/smufang/meta-tail2vec</a>.)</p>
<p>Keywords:</p>
<h3 id="100. Feature Fusion Based Subgraph Classification for Link Prediction.">100. Feature Fusion Based Subgraph Classification for Link Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411966">Paper Link</a>    Pages:985-994</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5103.html">Zheyi Liu</a> ; <a href="https://dblp.uni-trier.de/pid/64/7131.html">Darong Lai</a> ; <a href="https://dblp.uni-trier.de/pid/116/2991.html">Chuanyou Li</a> ; <a href="https://dblp.uni-trier.de/pid/93/6765.html">Meng Wang</a></p>
<p>Abstract:
Link prediction, which centers on whether or not a pair of nodes is likely to be connected, is a fundamental problem in complex network analysis. Network-embedding-based link prediction has shown strong performance and robustness in previous studies on complex networks, recommendation systems, and knowledge graphs. This approach has certain drawbacks, however; namely, the hierarchical structure of a subgraph is ignored and the importance of different nodes is not distinguished. In this study, we established the Subgraph Hierarchy Feature Fusion (SHFF) model for link prediction. To probe the existence of links between node pairs, the SHFF first extracts a subgraph around the two nodes and learns a function to map the subgraph to a vector for subsequent classification. This reveals any link between the two target nodes. The SHFF learns a function to obtain a representation of the extracted subgraph by hierarchically aggregating the features of nodes in that subgraph, which is accomplished by grouping nodes with similar structures and assigning different importance to the nodes during the feature fusion process. We compared the proposed model against other state-of-the-art link-prediction methods on a wide range of data sets to find that it consistently outperforms them.</p>
<p>Keywords:</p>
<h3 id="101. Fast Attributed Multiplex Heterogeneous Network Embedding.">101. Fast Attributed Multiplex Heterogeneous Network Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411944">Paper Link</a>    Pages:995-1004</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/11/3704.html">Zhijun Liu</a> ; <a href="https://dblp.uni-trier.de/pid/18/4087.html">Chao Huang</a> ; <a href="https://dblp.uni-trier.de/pid/63/5275.html">Yanwei Yu</a> ; <a href="https://dblp.uni-trier.de/pid/91/2474.html">Baode Fan</a> ; <a href="https://dblp.uni-trier.de/pid/40/6682.html">Junyu Dong</a></p>
<p>Abstract:
In recent years, heterogeneous network representation learning has attracted considerable attentions with the consideration of multiple node types. However, most of them ignore the rich set of network attributes (attributed network) and different types of relations (multiplex network), which can hardly recognize the multi-modal contextual signals across different interactions. While a handful of network embedding techniques are developed for attributed multiplex heterogeneous networks, they are significantly limited to the scalability issue on large-scale network data, due to their heavy cost both in computation and memory. In this work, we propose a Fast Attributed Multiplex heterogeneous network Embedding framework (FAME) for large-scale network data, by mapping the units from different modalities (i.e., network topological structures, various node features and relations) into the same latent space in a very efficient way. Our FAME is an integrative architecture with the scalable spectral transformation and sparse random projection, to automatically preserve both attribute semantics and multi-type interactions in the learned embeddings. Extensive experiments on four real-world datasets with various network analytical tasks, demonstrate that FAME achieves both effectiveness and significant efficiency over state-of-the-art baselines. The source code is available at: <a href="https://github.com/ZhijunLiu95/FAME">https://github.com/ZhijunLiu95/FAME</a>.</p>
<p>Keywords:</p>
<h3 id="102. Dynamic Representation Learning for Large-Scale Attributed Networks.">102. Dynamic Representation Learning for Large-Scale Attributed Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411945">Paper Link</a>    Pages:1005-1014</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/11/3704.html">Zhijun Liu</a> ; <a href="https://dblp.uni-trier.de/pid/18/4087.html">Chao Huang</a> ; <a href="https://dblp.uni-trier.de/pid/63/5275.html">Yanwei Yu</a> ; <a href="https://dblp.uni-trier.de/pid/58/3960-2.html">Peng Song</a> ; <a href="https://dblp.uni-trier.de/pid/91/2474.html">Baode Fan</a> ; <a href="https://dblp.uni-trier.de/pid/40/6682.html">Junyu Dong</a></p>
<p>Abstract:
Network embedding, which aims at learning low-dimensional representations of nodes in a network, has drawn much attention for various network mining tasks, ranging from link prediction to node classification. In addition to network topological information, there also exist rich attributes associated with network structure, which exerts large effects on the network formation. Hence, many efforts have been devoted to tackling attributed network embedding tasks. However, they are also limited in their assumption of static network data as they do not account for evolving network structure as well as changes in the associated attributes. Furthermore, scalability is a key factor when performing representation learning on large-scale networks with huge number of nodes and edges. In this work, we address these challenges by developing the DRLAN-Dynamic Representation Learning framework for large-scale Attributed Networks. The DRLAN model generalizes the dynamic attributed network embedding from two perspectives: First, we develop an integrative learning framework with an offline batch embedding module to preserve both the node and attribute proximities, and online network embedding model that recursively updates learned representation vectors. Second, we design a recursive pre-projection mechanism to efficiently model the attribute correlations based on the associative property of matrices. Finally, we perform extensive experiments on three real-world network datasets to show the superiority of DRLAN against state-of-the-art network embedding techniques in terms of both effectiveness and efficiency. The source code is available at: <a href="https://github.com/ZhijunLiu95/DRLAN">https://github.com/ZhijunLiu95/DRLAN</a>.</p>
<p>Keywords:</p>
<h3 id="103. Dual Head-wise Coattention Network for Machine Comprehension with Multiple-Choice Questions.">103. Dual Head-wise Coattention Network for Machine Comprehension with Multiple-Choice Questions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412013">Paper Link</a>    Pages:1015-1024</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/56/11346-1.html">Zhuang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/191/2871.html">Kaiyu Huang</a> ; <a href="https://dblp.uni-trier.de/pid/67/5547.html">Degen Huang</a> ; <a href="https://dblp.uni-trier.de/pid/56/11346-5.html">Zhuang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/47/2026.html">Jun Zhao</a></p>
<p>Abstract:
Multiple-choice Machine Comprehension (MC) is an important and challenging nature language processing (NLP) task where the machine is required to make the best answer from candidate answer set given particular passage and question. Existing approaches either only utilize the powerful pre-trained language models or only rely on an over complicated matching network that is design supposed to capture the relationship effectively among the triplet of passage, question and candidate answers. In this paper, we present a novel architecture, Dual Head-wise Coattention network (called DHC), which is a simple and efficient attention neural network designed to perform multiple-choice MC task. Our proposed DHC not only support a powerful pre-trained language model as encoder, but also models the MC relationship as attention mechanism straightforwardly, by head-wise matching and aggregating method on multiple layers, which better model relationships sufficiently between question and passage, and cooperate with large pre-trained language models more efficiently. To evaluate the performance, we test our proposed model on five challenging and well-known datasets for multiple-choice MC: RACE, DREAM, SemEval-2018 Task 11, OpenBookQA, and TOEFL. Extensive experimental results demonstrate that our proposal can achieve a significant increase in accuracy comparing existing models based on all five datasets, and it consistently outperforms all tested baselines including the state-of-the-arts techniques. More remarkably, our proposal is a pluggable and more flexible model, and it thus can be plugged into any pre-trained Language Models based on BERT. Ablation studies demonstrate its state-of-the-art performance and generalization.</p>
<p>Keywords:</p>
<h3 id="104. Spatiotemporal Adaptive Gated Graph Convolution Network for Urban Traffic Flow Forecasting.">104. Spatiotemporal Adaptive Gated Graph Convolution Network for Urban Traffic Flow Forecasting.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411894">Paper Link</a>    Pages:1025-1034</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/48/7036.html">Bin Lu</a> ; <a href="https://dblp.uni-trier.de/pid/13/29.html">Xiaoying Gan</a> ; <a href="https://dblp.uni-trier.de/pid/14/3177.html">Haiming Jin</a> ; <a href="https://dblp.uni-trier.de/pid/44/7207.html">Luoyi Fu</a> ; <a href="https://dblp.uni-trier.de/pid/220/2004.html">Haisong Zhang</a></p>
<p>Abstract:
Urban traffic flow forecasting is a critical issue in intelligent transportation systems. It is quite challenging due to the complicated spatiotemporal dependency and essential uncertainty brought about by the dynamic urban traffic conditions. In most of existing methods, the spatial correlation is captured by utilizing graph neural networks (GNNs) throughout a fixed graph based on local spatial proximity. However, urban road conditions are complex and changeable, which leads to the interactions between roads should also be dynamic over time. In addition, the global contextual information of roads are also crucial for accurate forecasting. In this paper, we exploit spatiotemporal correlation of urban traffic flow and construct a dynamic weighted graph by seeking both spatial neighbors and semantic neighbors of road nodes. Multi-head self-attention temporal convolution network is utilized to capture local and long-range temporal dependencies across historical observations. Besides, we propose an adaptive graph gating mechanism to extract selective spatial dependencies within multi-layer stacking and correct information deviations caused by artificially defined spatial correlation. Extensive experiments on real world urban traffic dataset from Didi Chuxing GAIA Initiative have verified the effectiveness, and the multi-step forecasting performance of our proposed models outperforms the state-of-the-art baselines. The source code of our model is publicly available at <a href="https://github.com/RobinLu1209/STAG-GCN">https://github.com/RobinLu1209/STAG-GCN</a>.</p>
<p>Keywords:</p>
<h3 id="105. Probabilistic Dynamic Non-negative Group Factor Model for Multi-source Text Mining.">105. Probabilistic Dynamic Non-negative Group Factor Model for Multi-source Text Mining.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411956">Paper Link</a>    Pages:1035-1043</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/241/3969.html">Chien Lu</a> ; <a href="https://dblp.uni-trier.de/pid/80/791.html">Jaakko Peltonen</a> ; <a href="https://dblp.uni-trier.de/pid/58/1177.html">Jyrki Nummenmaa</a> ; <a href="https://dblp.uni-trier.de/pid/j/KalervoJarvelin.html">Kalervo Jrvelin</a></p>
<p>Abstract:
Nonnegative matrix factorization (NMF) is a popular approach to model data, however, most models are unable to flexibly take into account multiple matrices across sources and time or apply only to integer-valued data. We introduce a probabilistic, Gaussian Process-based, more inclusive NMF-based model which jointly analyzes nonnegative data such as text data word content from multiple sources in a temporal dynamic manner. The model collectively models observed matrix data, source-wise latent variables, and their dependencies and temporal evolution with a full-fledged hierarchical approach including flexible nonparametric temporal dynamics. Experiments on simulated data and real data show the model out-performs, comparable models. A case study on social media and news demonstrates the model discovers semantically meaningful topical factors and their evolution</p>
<p>Keywords:</p>
<h3 id="106. Hierarchical Active Learning with Overlapping Regions.">106. Hierarchical Active Learning with Overlapping Regions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412022">Paper Link</a>    Pages:1045-1054</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/120/7554.html">Zhipeng Luo</a> ; <a href="https://dblp.uni-trier.de/pid/54/4898.html">Milos Hauskrecht</a></p>
<p>Abstract:
Learning of classification models from real-world data often requires substantial human effort devoted to instance annotation. As this process can be very time-consuming and costly, finding effective ways to reduce the annotation cost becomes critical for building such models. To address this problem we explore a new type of human feedback - region-based feedback. Briefly, a region is defined as a hypercubic subspace of the input data space and represents a subpopulation of data instances; the region's label is a human assessment of the class proportion of the data subpopulation. By using learning from label proportions algorithms one can learn instance-based classifiers from such labeled regions. In general, the key challenge is that there can be infinite many regions one can define and query in a given data space. To minimize the number and complexity of region-based queries, we propose and develop a hierarchical active learning solution that aims at incrementally building a concise hierarchy of regions. Furthermore, to avoid building a possibly class-irrelevant region hierarchy, we further propose to grow multiple different hierarchies in parallel and expand those more informative hierarchies. Through experiments on numerous data sets, we demonstrate that methods using region-based feedback can learn very good classifiers from very few and simple queries, and hence are highly effective in reducing human annotation effort needed for building classification models.</p>
<p>Keywords:</p>
<h3 id="107. Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification.">107. Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411951">Paper Link</a>    Pages:1055-1064</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/60/3634.html">Ning Ma</a> ; <a href="https://dblp.uni-trier.de/pid/50/3147.html">Jiajun Bu</a> ; <a href="https://dblp.uni-trier.de/pid/261/2773.html">Jieyu Yang</a> ; <a href="https://dblp.uni-trier.de/pid/19/5112.html">Zhen Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/90/10581.html">Chengwei Yao</a> ; <a href="https://dblp.uni-trier.de/pid/81/2909.html">Zhi Yu</a> ; <a href="https://dblp.uni-trier.de/pid/34/4858.html">Sheng Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/y/XifengYan.html">Xifeng Yan</a></p>
<p>Abstract:
Graph classification aims to extract accurate information from graph-structured data for classification and is becoming more and more important in the graph learning community. Although Graph Neural Networks (GNNs) have been successfully applied to graph classification tasks, most of them overlook the scarcity of labeled graph data in many applications. For example, in bioinformatics, obtaining protein graph labels usually needs laborious experiments. Recently, few-shot learning has been explored to alleviate this problem with only a few labeled graph samples of test classes. The shared sub-structures between training classes and test classes are essential in the few-shot graph classification. Existing methods assume that the test classes belong to the same set of super-classes clustered from training classes. However, according to our observations, the label spaces of training classes and test classes usually do not overlap in a real-world scenario. As a result, the existing methods don't well capture the local structures of unseen test classes. To overcome the limitation, in this paper, we propose a direct method to capture the sub-structures with a well initialized meta-learner within a few adaptation steps. More specifically, (1) we propose a novel framework consisting of a graph meta-learner, which uses GNNs based modules for fast adaptation on graph data, and a step controller for the robustness and generalization of meta-learner; (2) we provide quantitative analysis for the framework and give a graph-dependent upper bound of the generalization error based on our framework; (3) the extensive experiments on real-world datasets demonstrate that our framework gets state-of-the-art results on several few-shot graph classification tasks compared to baselines.</p>
<p>Keywords:</p>
<h3 id="108. Feature Selection on Data Stream via Multi-Cluster Structure Preservation.">108. Feature Selection on Data Stream via Multi-Cluster Structure Preservation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411928">Paper Link</a>    Pages:1065-1074</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/85/5058.html">Rui Ma</a> ; <a href="https://dblp.uni-trier.de/pid/91/1726.html">Yijie Wang</a> ; <a href="https://dblp.uni-trier.de/pid/13/4938.html">Li Cheng</a></p>
<p>Abstract:
The modern data arrive continuously in a rapid and time-varying stream, which appears to generate unstable associations on the data structure. However, most of the existing methods focus on dealing with the static data, and they cannot fully take them into the structure construction. To address this issue, we propose an online unsupervised Feature Selection method via Multi-Cluster structure Preservation (FSMCP for short). FSMCP weighs all features by minimizing the differences between the Multi-Cluster structures in the original and the selected feature space. The structure integrates the three-level associations, i.e., the individual-level associations, the aggregation-level associations, and the streaming-level associations. To provide informative features in time, FSMCP check and update the associations as soon as new instances arrive. In comparison with the baseline methods, FSMCP holds better efficiency than offline methods, while still providing almost similar or even better quantitative feature subsets. It outperforms the existing online methods with average NMI improvement of 10.33%.</p>
<p>Keywords:</p>
<h3 id="109. PSTIE: Time Information Enhanced Personalized Search.">109. PSTIE: Time Information Enhanced Personalized Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411877">Paper Link</a>    Pages:1075-1084</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/94/2633.html">Zhengyi Ma</a> ; <a href="https://dblp.uni-trier.de/pid/18/5740.html">Zhicheng Dou</a> ; <a href="https://dblp.uni-trier.de/pid/276/5086.html">Guanyue Bian</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
Personalized search aims to improve the search quality by re-ranking the candidate document list based on user's historical behavior. Existing approaches focus on modeling the order information of user's search history by sequential methods such as Recurrent Neural Network (RNN). However, these methods usually ignore the fine-grained time information associated with user actions. In fact, the time intervals between queries can help to capture the evolution of query intent and document interest of users. Besides, the time intervals between past actions and current query can reflect the re-finding tendency more accurately than discrete steps in RNN. In this paper, we propose PSTIE, a fine-grained Time Information Enhanced model to construct more accurate user interest representations for Personalized Search. To capture the short-term interest of users, we design time-aware LSTM architectures for modeling the subtle interest evolution of users in continuous time. We further leverage time in calculating the re-finding possibility of users to capture the long-term user interest. We propose two methods to utilize the time-enhanced user interest into personalized ranking. Experiments on two datasets show that PSTIE can effectively improve the ranking quality over state-of-the-art models.</p>
<p>Keywords:</p>
<h3 id="110. Examining the Additivity of Top-k Query Processing Innovations.">110. Examining the Additivity of Top-k Query Processing Innovations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412000">Paper Link</a>    Pages:1085-1094</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/174/0021.html">Joel Mackenzie</a> ; <a href="https://dblp.uni-trier.de/pid/m/AlistairMoffat.html">Alistair Moffat</a></p>
<p>Abstract:
Research activity spanning more than five decades has led to index organizations, compression schemes, and traversal algorithms that allow extremely rapid response to ranked queries against very large text collections. However, little attention has been paid to the interactions between these many components, and the additivity of algorithmic improvements has not been explored. Here we examine the extent to which efficiency improvements add up. We employ four query processing algorithms, four compression codecs, and all possible combinations of four distinct further optimizations, and compare the performance of the 256 resulting systems to determine when and how different optimizations interact. Our results over two test collections show that efficiency enhancements are, for the most part, additive, and that there is little risk of negative interactions. In addition, our detailed profiling across this large pool of systems leads to key insights as to why the various individual enhancements work well, and indicates that optimizing "simpler" implementations can result in higher query throughput than is available from non-optimized versions of the more "complex" techniques, with clear implications for the choices needing to be made by practitioners.</p>
<p>Keywords:</p>
<h3 id="111. Relational Reflection Entity Alignment.">111. Relational Reflection Entity Alignment.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412001">Paper Link</a>    Pages:1095-1104</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/72/4332.html">Xin Mao</a> ; <a href="https://dblp.uni-trier.de/pid/49/8549.html">Wenting Wang</a> ; <a href="https://dblp.uni-trier.de/pid/06/4963.html">Huimin Xu</a> ; <a href="https://dblp.uni-trier.de/pid/17/7186.html">Yuanbin Wu</a> ; <a href="https://dblp.uni-trier.de/pid/01/800.html">Man Lan</a></p>
<p>Abstract:
Entity alignment aims to identify equivalent entity pairs from different Knowledge Graphs (KGs), which is essential in integrating multi-source KGs. Recently, with the introduction of GNNs into entity alignment, the architectures of recent models have become more and more complicated. We even find two counter-intuitive phenomena within these methods: (1) The standard linear transformation in GNNs is not working well. (2) Many advanced KG embedding models designed for link prediction task perform poorly in entity alignment. In this paper, we abstract existing entity alignment methods into a unified framework, Shape-Builder &amp; Alignment, which not only successfully explains the above phenomena but also derives two key criteria for an ideal transformation operation. Furthermore, we propose a novel GNNs-based method, Relational Reflection Entity Alignment (RREA). RREA leverages Relational Reflection Transformation to obtain relation specific embeddings for each entity in a more efficient way. The experimental results on real-world datasets show that our model significantly outperforms the state-of-the-art methods, exceeding by 5.8%-10.9% on [email protected]</p>
<p>Keywords:</p>
<h3 id="112. CSNE: Conditional Signed Network Embedding.">112. CSNE: Conditional Signed Network Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411959">Paper Link</a>    Pages:1105-1114</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/168/2255.html">Alexandru Mara</a> ; <a href="https://dblp.uni-trier.de/pid/194/3547.html">Yoosof Mashayekhi</a> ; <a href="https://dblp.uni-trier.de/pid/62/8320.html">Jefrey Lijffijt</a> ; <a href="https://dblp.uni-trier.de/pid/49/2018.html">Tijl De Bie</a></p>
<p>Abstract:
Signed networks are mathematical structures that encode positive and negative relations between entities such as friend/foe or trust/distrust. Recently, several papers studied the construction of useful low-dimensional representations (embeddings) of these networks for the prediction of missing relations or signs. Existing network embedding methods for sign prediction, however, generally enforce different notions of status or balance theories in their optimization function. These theories, are often inaccurate or incomplete which negatively impacts method performance.</p>
<p>Keywords:</p>
<h3 id="113. Learning to Distract: A Hierarchical Multi-Decoder Network for Automated Generation of Long Distractors for Multiple-Choice Questions for Reading Comprehension.">113. Learning to Distract: A Hierarchical Multi-Decoder Network for Automated Generation of Long Distractors for Multiple-Choice Questions for Reading Comprehension.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411997">Paper Link</a>    Pages:1115-1124</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5025.html">Kaushal Kumar Maurya</a> ; <a href="https://dblp.uni-trier.de/pid/46/8779.html">Maunendra Sankar Desarkar</a></p>
<p>Abstract:
The task of generating incorrect options for multiple-choice questions is termed as distractor generation problem. The task requires high cognitive skills and is extremely challenging to automate. Existing neural approaches for the task leverage encoder-decoder architecture to generate long distractors. However, in this process two critical points are ignored - firstly, many methods use Jaccard similarity over a pool of candidate distractors to sample the distractors. This often makes the generated distractors too obvious or not relevant to the question context. Secondly, some approaches did not consider the answer in the model, which caused the generated distractors to be either answer-revealing or semantically equivalent to the answer.</p>
<p>Keywords:</p>
<h3 id="114. "Keep it Simple, Lazy" - MetaLazy: A New MetaStrategy for Lazy Text Classification.">114. "Keep it Simple, Lazy" - MetaLazy: A New MetaStrategy for Lazy Text Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412180">Paper Link</a>    Pages:1125-1134</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/83/7987.html">Luiz Felipe Mendes</a> ; <a href="https://dblp.uni-trier.de/pid/45/1395.html">Marcos Andr Gonalves</a> ; <a href="https://dblp.uni-trier.de/pid/268/1057.html">Washington Cunha</a> ; <a href="https://dblp.uni-trier.de/pid/89/1792.html">Leonardo C. da Rocha</a> ; <a href="https://dblp.uni-trier.de/pid/68/3720.html">Thierson Couto Rosa</a> ; <a href="https://dblp.uni-trier.de/pid/120/9618.html">Wellington Martins</a></p>
<p>Abstract:
Recent advances in text-related tasks on the Web, such as text (topic) classification and sentiment analysis, have been made possible by exploiting mostly the "rule of more": more data (massive amounts) more computing power, more complex solutions. We propose a shift in the paradigm to do "more with less" by focusing, at maximum extent, just on the task at hand (e.g., classify a single test instance). Accordingly, we propose MetaLazy, a new supervised lazy text classification meta-strategy that greatly extends the scope of lazy solutions. Lazy classifiers postpone the creation of a classification model until a given test instance for decision making is given. MetaLazy exploits new ideas and solutions, which have in common their lazy nature, producing altogether a solution for text classification, which is simpler, more efficient, and less data demanding than new alternatives. It extends and evolves the lazy creation of the model for the test instance by allowing: (i) to dynamically choose the best classifier for the task; (ii) the exploration of distances in the neighborhood of the test document when learning a classification model, thus diminishing the importance of irrelevant training instances; and (iii) a better representational space for training and test documents by augmenting them, in a lazy fashion, with new co-occurrence based features considering just those observed in the specific test instance. In a sizeable experimental evaluation, considering topics and sentiment analysis datasets and nine baselines, we show that our MetaLazy instantiations are among the top performers in most situations, even when compared to state-of-the-art deep learning classifiers such as Deep Network Transformer Architectures.</p>
<p>Keywords:</p>
<h3 id="115. A Methodology Based on Deep Q-Learning/Genetic Algorithms for Optimizing COVID-19 Pandemic Government Actions.">115. A Methodology Based on Deep Q-Learning/Genetic Algorithms for Optimizing COVID-19 Pandemic Government Actions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412179">Paper Link</a>    Pages:1135-1144</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/163/7107.html">Luis Miralles-Pechun</a> ; <a href="https://dblp.uni-trier.de/pid/08/6265.html">Fernando Jimnez</a> ; <a href="https://dblp.uni-trier.de/pid/92/9336.html">Hiram Ponce</a> ; <a href="https://dblp.uni-trier.de/pid/92/10327.html">Lourdes Martnez-Villaseor</a></p>
<p>Abstract:
Whenever countries are threatened by a pandemic, as is the case with the COVID-19 virus, governments need help to take the right actions to safeguard public health as well as to mitigate the negative effects on the economy. A restrictive approach can seriously damage the economy. Conversely, a relaxed one may put at risk a high percentage of the population. Other investigations in this area are focused on modelling the spread of the virus or estimating the impact of the different measures on its propagation. However, in this paper, we propose a new methodology for helping governments in planning the phases to combat the pandemic based on their priorities. To this end, we implement the SEIR epidemiological model to represent the evolution of the COVID-19 virus on the population.</p>
<p>Keywords:</p>
<h3 id="116. SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection.">116. SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411990">Paper Link</a>    Pages:1145-1154</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/259/7191.html">Guanyi Mou</a> ; <a href="https://dblp.uni-trier.de/pid/276/4998.html">Pengyi Ye</a> ; <a href="https://dblp.uni-trier.de/pid/22/8024.html">Kyumin Lee</a></p>
<p>Abstract:
Hate speech detection on online social networks has become one of the emerging hot topics in recent years. With the broad spread and fast propagation speed across online social networks, hate speech makes significant impacts on society by increasing prejudice and hurting people. Therefore, there are aroused attention and concern from both industry and academia. In this paper, we address the hate speech problem and propose a novel hate speech detection framework called SWE2, which only relies on the content of messages and automatically identifies hate speech. In particular, our framework exploits both word-level semantic information and sub-word knowledge. It is intuitively persuasive and also practically performs well under a situation with/without character-level adversarial attack. Experimental results show that our proposed model achieves 0.975 accuracy and 0.953 macro F1, outperforming 7 state-of-the-art baselines under no adversarial attack. Our model robustly and significantly performed well under extreme adversarial attack (manipulation of 50% messages), achieving 0.967 accuracy and 0.934 macro F1.</p>
<p>Keywords:</p>
<h3 id="117. Deep Generative Positive-Unlabeled Learning under Selection Bias.">117. Deep Generative Positive-Unlabeled Learning under Selection Bias.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411971">Paper Link</a>    Pages:1155-1164</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5100.html">Byeonghu Na</a> ; <a href="https://dblp.uni-trier.de/pid/215/6491.html">Hyemi Kim</a> ; <a href="https://dblp.uni-trier.de/pid/155/4867.html">Kyungwoo Song</a> ; <a href="https://dblp.uni-trier.de/pid/232/5614.html">Weonyoung Joo</a> ; <a href="https://dblp.uni-trier.de/pid/254/0952.html">Yoon-Yeong Kim</a> ; <a href="https://dblp.uni-trier.de/pid/97/4109.html">Il-Chul Moon</a></p>
<p>Abstract:
Learning in the positive-unlabeled (PU) setting is prevalent in real world applications. Many previous works depend upon theSelected Completely At Random (SCAR) assumption to utilize unlabeled data, but the SCAR assumption is not often applicable to the real world due to selection bias in label observations. This paper is the first generative PU learning model without the SCAR assumption. Specifically, we derive the PU risk function without the SCAR assumption, and we generate a set of virtual PU examples to train the classifier. Although our PU risk function is more generalizable, the function requires PU instances that do not exist in the observations. Therefore, we introduce the VAE-PU, which is a variant of variational autoencoders to separate two latent variables that generate either features or observation indicators. The separated latent information enables the model to generate virtual PU instances. We test the VAE-PU on benchmark datasets with and without the SCAR assumption. The results indicate that the VAE-PU is superior when selection bias exists, and the VAE-PU is also competent under the SCAR assumption. The results also emphasize that the VAE-PU is effective when there are few positive-labeled instances due to modeling on selection bias.</p>
<p>Keywords:</p>
<h3 id="118. FANG: Leveraging Social Context for Fake News Detection Using Graph Representation.">118. FANG: Leveraging Social Context for Fake News Detection Using Graph Representation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412046">Paper Link</a>    Pages:1165-1174</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/272/9171.html">Van-Hoang Nguyen</a> ; <a href="https://dblp.uni-trier.de/pid/50/7001.html">Kazunari Sugiyama</a> ; <a href="https://dblp.uni-trier.de/pid/19/1947.html">Preslav Nakov</a> ; <a href="https://dblp.uni-trier.de/pid/k/MinYenKan.html">Min-Yen Kan</a></p>
<p>Abstract:
We propose Factual News Graph (FANG), a novel graphical social context representation and learning framework for fake news detection. Unlike previous contextual models that have targeted performance, our focus is on representation learning. Compared to transductive models, FANG is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. Our experimental results show that FANG is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. In particular, FANG yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. We further demonstrate that the representations learned by FANG generalize to related tasks, such as predicting the factuality of reporting of a news medium.</p>
<p>Keywords:</p>
<h3 id="119. Uncovering Semantic Bias in Neural Network Models Using a Knowledge Graph.">119. Uncovering Semantic Bias in Neural Network Models Using a Knowledge Graph.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412009">Paper Link</a>    Pages:1175-1184</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/59/804.html">Andriy Nikolov</a> ; <a href="https://dblp.uni-trier.de/pid/55/4776.html">Mathieu d&apos;Aquin</a></p>
<p>Abstract:
While neural networks models have shown impressive performance in many NLP tasks, lack of interpretability is often seen as a disadvantage. Individual relevance scores assigned by post-hoc explanation methods are not sufficient to show deeper systematic preferences and potential biases of the model that apply consistently across examples. In this paper we apply rule mining using knowledge graphs in combination with neural network explanation methods to uncover such systematic preferences of trained neural models and capture them in the form of conjunctive rules. We test our approach in the context of text classification tasks and show that such rules are able to explain a substantial part of the model behaviour as well as indicate potential causes of misclassifications when the model is applied outside of the initial training context.</p>
<p>Keywords:</p>
<h3 id="120. STP-TrellisNets: Spatial-Temporal Parallel TrellisNets for Metro Station Passenger Flow Prediction.">120. STP-TrellisNets: Spatial-Temporal Parallel TrellisNets for Metro Station Passenger Flow Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411874">Paper Link</a>    Pages:1185-1194</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5118.html">Junjie Ou</a> ; <a href="https://dblp.uni-trier.de/pid/123/7092.html">Jiahui Sun</a> ; <a href="https://dblp.uni-trier.de/pid/215/4415.html">Yichen Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/14/3177.html">Haiming Jin</a> ; <a href="https://dblp.uni-trier.de/pid/276/5117.html">Yijuan Liu</a> ; <a href="https://dblp.uni-trier.de/pid/21/3626.html">Fan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/207/1901.html">Jianqiang Huang</a> ; <a href="https://dblp.uni-trier.de/pid/96/1149.html">Xinbing Wang</a></p>
<p>Abstract:
Recent years have witnessed a drastic increase in the number of urban metro passengers, which inevitably causes the overcrowdedness in the metro systems of many cities. Clearly, an accurate prediction of passenger flows at metro stations is critical for a variety of metro system management operations, such as line scheduling and staff preallocation, that help alleviate such overcrowdedness. Thus, in this paper, we aim to address the problem of accurately predicting metro station passenger (MSP) flows. Similar to other traffic data, such as road traffic volume and highway speed, MSP flows are also spatial-temporal in nature. However, existing methods for other traffic prediction tasks are usually suboptimal to predict MSP flows due to MSP flows' unique spatial-temporal characteristics. As a result, we propose a novel deep learning framework STP-TrellisNets, which for the first time augments the newly-emerged temporal convolutional framework TrellisNet for spatial-temporal prediction. The temporal module of STP-TrellisNets (named CP-TrellisNets) employs two TrellisNets in serial to jointly capture the short- and long-term temporal correlation of MSP flows. In parallel to CP-TrellisNets, its spatial module (named GC-TrellisNet) adopts a novel transfer flow-based metric to characterize the spatial correlation among MSP flows, and implements multiple diffusion graph convolutional networks (DGCNs) in time-series order with their outputs connected to a TrellisNet to capture the dynamics of such spatial correlation. Clearly, GC-TrellisNet essentially integrates TrellisNet with graph convolution, and empowers TrellisNet with the ability to capture dynamic graph-structured correlation. We conduct extensive experiments with two large-scale real-world automated fare collection datasets, which contain respectively about 1.5 billion records in Shenzhen, China and 70 million records in Hangzhou, China. The experimental results demonstrate that STP-TrellisNets outperforms the state-of-the-art baselines.</p>
<p>Keywords:</p>
<h3 id="121. Star Graph Neural Networks for Session-based Recommendation.">121. Star Graph Neural Networks for Session-based Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412014">Paper Link</a>    Pages:1195-1204</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/178/6933.html">Zhiqiang Pan</a> ; <a href="https://dblp.uni-trier.de/pid/71/2935.html">Fei Cai</a> ; <a href="https://dblp.uni-trier.de/pid/204/0075.html">Wanyu Chen</a> ; <a href="https://dblp.uni-trier.de/pid/15/4365.html">Honghui Chen</a> ; <a href="https://dblp.uni-trier.de/pid/r/MdRijke.html">Maarten de Rijke</a></p>
<p>Abstract:
Session-based recommendation is a challenging task. Without access to a user's historical user-item interactions, the information available in an ongoing session may be very limited. Previous work on session-based recommendation has considered sequences of items that users have interacted with sequentially. Such item sequences may not fully capture complex transition relationship between items that go beyond inspection order. Thus graph neural network (GNN) based models have been proposed to capture the transition relationship between items. However, GNNs typically propagate information from adjacent items only, thus neglecting information from items without direct connections. Importantly, GNN-based approaches often face serious overfitting problems. We propose Star Graph Neural Networks with Highway Networks (SGNN-HN) for session-based recommendation. The proposed SGNN-HN applies a star graph neural network (SGNN) to model the complex transition relationship between items in an ongoing session. To avoid overfitting, we employ highway networks (HN) to adaptively select embeddings from item representations. Finally, we aggregate the item embeddings generated by the SGNN in an ongoing session to represent a user's final preference for item prediction. Experiments on two public benchmark datasets show that SGNN-HN can outperform state-of-the-art models in terms of [email protected] and [email protected] for session-based recommendation.</p>
<p>Keywords:</p>
<h3 id="122. RKT: Relation-Aware Self-Attention for Knowledge Tracing.">122. RKT: Relation-Aware Self-Attention for Knowledge Tracing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411994">Paper Link</a>    Pages:1205-1214</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/206/8894.html">Shalini Pandey</a> ; <a href="https://dblp.uni-trier.de/pid/s/JaideepSrivastava.html">Jaideep Srivastava</a></p>
<p>Abstract:
The world has transitioned into a new phase of online learning in response to the recent Covid19 pandemic. Now more than ever, it has become paramount to push the limits of online learning in every manner to keep flourishing the education system. One crucial component of online learning is Knowledge Tracing (KT). The aim of KT is to model student's knowledge level based on their answers to a sequence of exercises referred as interactions. Students acquire their skills while solving exercises and each such interaction has a distinct impact on student ability to solve a future exercise. This impact is characterized by 1) the relation between exercises involved in the interactions and 2) student forget behavior. Traditional studies on knowledge tracing do not explicitly model both the components jointly to estimate the impact of these interactions. In this paper, we propose a novel Relation-aware self-attention model for Knowledge Tracing (RKT). We introduce a relation-aware self-attention layer that incorporates the contextual information. This contextual information integrates both the exercise relation information through their textual content as well as student performance data and the forget behavior information through modeling an exponentially decaying kernel function. Extensive experiments on three real-world datasets, among which two new collections are released to the public, show that our model outperforms state-of-the-art knowledge tracing methods. Furthermore, the interpretable attention weights help visualize the relation between interactions and temporal patterns in the human learning process.</p>
<p>Keywords:</p>
<h3 id="123. ST-GRAT: A Novel Spatio-temporal Graph Attention Networks for Accurately Forecasting Dynamically Changing Road Speed.">123. ST-GRAT: A Novel Spatio-temporal Graph Attention Networks for Accurately Forecasting Dynamically Changing Road Speed.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411940">Paper Link</a>    Pages:1215-1224</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/239/8130.html">Cheonbok Park</a> ; <a href="https://dblp.uni-trier.de/pid/243/0156.html">Chunggi Lee</a> ; <a href="https://dblp.uni-trier.de/pid/218/5470.html">Hyojin Bahng</a> ; <a href="https://dblp.uni-trier.de/pid/276/5054.html">Yunwon Tae</a> ; <a href="https://dblp.uni-trier.de/pid/255/9331.html">Seungmin Jin</a> ; <a href="https://dblp.uni-trier.de/pid/07/69.html">Kihwan Kim</a> ; <a href="https://dblp.uni-trier.de/pid/16/9189.html">Sungahn Ko</a> ; <a href="https://dblp.uni-trier.de/pid/07/2074.html">Jaegul Choo</a></p>
<p>Abstract:
Predicting road traffic speed is a challenging task due to different types of roads, abrupt speed change and spatial dependencies between roads; it requires the modeling of dynamically changing spatial dependencies among roads and temporal patterns over long input sequences. This paper proposes a novel spatio-temporal graph attention (ST-GRAT) that effectively captures the spatio-temporal dynamics in road networks. The novel aspects of our approach mainly include spatial attention, temporal attention, and spatial sentinel vectors. The spatial attention takes the graph structure information (e.g., distance between roads) and dynamically adjusts spatial correlation based on road states. The temporal attention is responsible for capturing traffic speed changes, and the sentinel vectors allow the model to retrieve new features from spatially correlated nodes or preserve existing features. The experimental results show that ST-GRAT outperforms existing models, especially in difficult conditions where traffic speeds rapidly change (e.g., rush hours). We additionally provide a qualitative study to analyze when and where ST-GRAT tended to make accurate predictions during rush-hour times.</p>
<p>Keywords:</p>
<h3 id="124. Minimal Edit-Based Diffs for Large Trees.">124. Minimal Edit-Based Diffs for Large Trees.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412026">Paper Link</a>    Pages:1225-1234</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/24/10719.html">Mateusz Pawlik</a> ; <a href="https://dblp.uni-trier.de/pid/76/3961.html">Nikolaus Augsten</a></p>
<p>Abstract:
Hierarchically structured data are commonly represented as trees and have given rise to popular data formats like XML or JSON. An interesting query computes the difference between two versions of a tree, expressed as the minimum set of node edits (deletion, insertion, label rename) that transform one tree into another, commonly known as the tree edit distance. Unfortunately, the fastest tree edit distance algorithms run in cubic time and quadratic space and are therefore not feasible for large inputs. In this paper, we leverage the fact that the difference between two versions of a tree is typically much smaller than the overall tree size. We propose a new tree edit distance algorithm that is linear in the tree size for similar trees. Our algorithm is based on the new concept of top node pairs and avoids redundant distance computations, the main issue with previous solutions for tree diffs. We empirically evaluate the runtime of our algorithm on large synthetic and real-world trees; our algorithm clearly outperforms the state of the art, often by orders of magnitude.</p>
<p>Keywords:</p>
<h3 id="125. Efficient Detection of Data Dependency Violations.">125. Efficient Detection of Data Dependency Violations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412062">Paper Link</a>    Pages:1235-1244</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/156/8798.html">Eduardo H. M. Pena</a> ; <a href="https://dblp.uni-trier.de/pid/149/9260.html">Edson Ramiro Lucas Filho</a> ; <a href="https://dblp.uni-trier.de/pid/53/2190.html">Eduardo Cunha de Almeida</a> ; <a href="https://dblp.uni-trier.de/pid/n/FelixNaumann.html">Felix Naumann</a></p>
<p>Abstract:
Research on data dependencies has experienced a revival as dependency violations can reveal errors in data. Several data cleaning systems use a DBMS to detect such violations. While DBMSs are efficient for some kinds of data dependencies (e.g., unique constraints), they are likely to fall short of satisfactory performance for more complex ones, such as order dependencies.</p>
<p>Keywords:</p>
<h3 id="126. EnDeA: Ensemble based Decoupled Adversarial Learning for Identifying Infrastructure Damage during Disasters.">126. EnDeA: Ensemble based Decoupled Adversarial Learning for Identifying Infrastructure Damage during Disasters.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412020">Paper Link</a>    Pages:1245-1254</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/228/7036.html">Shalini Priya</a> ; <a href="https://dblp.uni-trier.de/pid/276/5062.html">Apoorva Upadhyaya</a> ; <a href="https://dblp.uni-trier.de/pid/194/1712.html">Manish Bhanu</a> ; <a href="https://dblp.uni-trier.de/pid/97/8395.html">Sourav Kumar Dandapat</a> ; <a href="https://dblp.uni-trier.de/pid/59/4869.html">Joydeep Chandra</a></p>
<p>Abstract:
Identifying tweets related to infrastructure damage during a crisis event is an important problem. However, the unavailability of labeled data during the early stages of a crisis event poses major challenge in training suitable models. Several domain adaptation strategies have been proposed for text classification that can be used to train models using available source data of previous crisis events and apply on a target data related to a current event. However, these approaches are insufficient to handle the distribution drift in the source and target data along with the class imbalance in the target data. In this paper we introduce an Ensemble learning approach with a Decoupled Adversarial (EnDeA) model to classify infrastructure damage tweets in a target tweet dataset. EnDeA is an ensemble of three different models two of which separately learn the event invariant and specific features of a target data from a set of source and target data. The third model which is an adversarial model helps to improve the prediction accuracy of both models. Unlike the existing approaches that also identify the domain invariant and specific properties of target data for sentiment classification, our method works for short texts and can better handle the distribution drift and class imbalance problem. We rigorously investigate the performance of the proposed approach using multiple public datasets and compare it with several state-of-the-art baselines. We discover that EnDeA outperforms these baselines with around 20% improvement in the 1 scores.</p>
<p>Keywords:</p>
<h3 id="127. G-CREWE: Graph CompREssion With Embedding for Network Alignment.">127. G-CREWE: Graph CompREssion With Embedding for Network Alignment.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411924">Paper Link</a>    Pages:1255-1264</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/198/7079.html">Kyle Kai Qin</a> ; <a href="https://dblp.uni-trier.de/pid/08/1554.html">Flora D. Salim</a> ; <a href="https://dblp.uni-trier.de/pid/58/6608.html">Yongli Ren</a> ; <a href="https://dblp.uni-trier.de/pid/24/803-6.html">Wei Shao</a> ; <a href="https://dblp.uni-trier.de/pid/215/4357.html">Mark Heimann</a> ; <a href="https://dblp.uni-trier.de/pid/91/9987.html">Danai Koutra</a></p>
<p>Abstract:
Network alignment is useful for multiple applications that require increasingly large graphs to be processed. Existing research approaches this as an optimization problem or computes the similarity based on node representations. However, the process of aligning every pair of nodes between relatively large networks is time-consuming and resource-intensive. In this paper, we propose a framework, called G-CREWE (Graph CompREssion With Embedding) to solve the network alignment problem. G-CREWE uses node embeddings to align the networks on two levels of resolution, a fine resolution given by the original network and a coarse resolution given by a compressed version, to achieve an efficient and effective network alignment. The framework first extracts node features and learns the node embedding via a Graph Convolutional Network (GCN). Then, node embedding helps to guide the process of graph compression and finally improve the alignment performance. As part of G-CREWE, we also propose a new compression mechanism called MERGE (Minimum DEgRee NeiGhbors ComprEssion) to reduce the size of the input networks while preserving the consistency in their topological structure. Experiments on all real networks show that our method is more than twice as fast as the most competitive existing methods while maintaining high accuracy.</p>
<p>Keywords:</p>
<h3 id="128. Diversifying Search Results using Self-Attention Network.">128. Diversifying Search Results using Self-Attention Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411914">Paper Link</a>    Pages:1265-1274</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5009.html">Xubo Qin</a> ; <a href="https://dblp.uni-trier.de/pid/18/5740.html">Zhicheng Dou</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
Search results returned by search engines need to be diversified in order to satisfy different information needs of different users. Several supervised learning models have been proposed for diversifying search results in recent years. Most of the existing supervised methods greedily compare each candidate document with the selected document sequence and select the next local optimal document. However, the information utility of each candidate document is not independent with each other, and research has shown that the selection of a candidate document will affect the utilities of other candidate documents. As a result, the local optimal document rankings will not lead to the global optimal rankings. In this paper, we propose a new supervised diversification framework to address this issue. Based on a self-attention encoder-decoder structure, the model can take the whole candidate document sequence as input, and simultaneously leverage both the novelty and the subtopic coverage of the candidate documents. We call this framework Diversity Encoder with Self-Attention (DESA). Comparing with existing supervised methods, this framework can model the interactions between all candidate documents and return their diversification scores based on the whole candidate document sequence. Experimental results show that our proposed framework outperforms existing methods. These results confirm the effectiveness of modeling all the candidate documents for the overall novelty and subtopic coverage globally, instead of comparing every single candidate document with the selected sequence document selection.</p>
<p>Keywords:</p>
<h3 id="129. Time-Efficient Geo-Obfuscation to Protect Worker Location Privacy over Road Networks in Spatial Crowdsourcing.">129. Time-Efficient Geo-Obfuscation to Protect Worker Location Privacy over Road Networks in Spatial Crowdsourcing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411863">Paper Link</a>    Pages:1275-1284</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/121/1878.html">Chenxi Qiu</a> ; <a href="https://dblp.uni-trier.de/pid/s/AnnaCinziaSquicciarini.html">Anna Cinzia Squicciarini</a> ; <a href="https://dblp.uni-trier.de/pid/148/1926.html">Zhuozhao Li</a> ; <a href="https://dblp.uni-trier.de/pid/193/2452.html">Ce Pang</a> ; <a href="https://dblp.uni-trier.de/pid/71/7028-4.html">Li Yan</a></p>
<p>Abstract:
To promote cost-effective task assignment in Spatial Crowdsourcing (SC), workers are required to report their location to servers, which raises serious privacy concerns. As a solution, geo-obfuscation has been widely used to protect the location privacy of SC workers, where workers are allowed to report perturbed location instead of the true location. Yet, most existing geo-obfuscation methods consider workers? mobility on a 2 dimensional (2D) plane, wherein workers can move in arbitrary directions. Unfortunately, 2D-based geo-obfuscation is likely to generate high traveling cost for task assignment over roads, as it cannot accurately estimate the traveling costs distortion caused by location obfuscation. In this paper, we tackle the SC worker location privacy problem over road networks. Considering the network-constrained mobility features of workers, we describe workers? mobility by a weighted directed graph, which considers the dynamic traffic condition and road network topology. Based on the graph model, we design a geo-obfuscation (GO) function for workers to maximize the workers? overall location privacy without compromising the task assignment efficiency. We formulate the problem of deriving the optimal GO function as a linear programming (LP) problem. By using the angular block structure of the LP's constraint matrix, we apply Dantzig-Wolfe decomposition to improve the time-efficiency of the GO function generation. Our experimental results in the real-trace driven simulation and the real-world experiment demonstrate the effectiveness of our approach in terms of both privacy and task assignment efficiency.</p>
<p>Keywords:</p>
<h3 id="130. Hierarchical Query Graph Generation for Complex Question Answering over Knowledge Graph.">130. Hierarchical Query Graph Generation for Complex Question Answering over Knowledge Graph.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411888">Paper Link</a>    Pages:1285-1294</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/218/0101.html">Yunqi Qiu</a> ; <a href="https://dblp.uni-trier.de/pid/96/3115.html">Kun Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/65/5018.html">Yuanzhuo Wang</a> ; <a href="https://dblp.uni-trier.de/pid/00/1728.html">Xiaolong Jin</a> ; <a href="https://dblp.uni-trier.de/pid/65/7795.html">Long Bai</a> ; <a href="https://dblp.uni-trier.de/pid/205/7534.html">Saiping Guan</a> ; <a href="https://dblp.uni-trier.de/pid/44/912.html">Xueqi Cheng</a></p>
<p>Abstract:
Knowledge Graph Question Answering aims to automatically answer natural language questions via well-structured relation information between entities stored in knowledge graphs. When faced with a complex question with compositional semantics, query graph generation is a practical semantic parsing-based method. But existing works rely on heuristic rules with limited coverage, making them impractical on more complex questions. This paper proposes a Director-Actor-Critic framework to overcome these challenges. Through options over a Markov Decision Process, query graph generation is formulated as a hierarchical decision problem. The Director determines which types of triples the query graph needs, the Actor generates corresponding triples by choosing nodes and edges, and the Critic calculates the semantic similarity between the generated triples and the given questions. Moreover, to train from weak supervision, we base the framework on hierarchical Reinforcement Learning with intrinsic motivation. To accelerate the training process, we pre-train the Critic with high-reward trajectories generated by hand-crafted rules, and leverage curriculum learning to gradually increase the complexity of questions during query graph generation. Extensive experiments conducted over widely-used benchmark datasets demonstrate the effectiveness of the proposed framework.</p>
<p>Keywords:</p>
<h3 id="131. Robust Irregular Tensor Factorization and Completion for Temporal Health Data Analysis.">131. Robust Irregular Tensor Factorization and Completion for Temporal Health Data Analysis.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411982">Paper Link</a>    Pages:1295-1304</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/226/6676.html">Yifei Ren</a> ; <a href="https://dblp.uni-trier.de/pid/05/4625-1.html">Jian Lou</a> ; <a href="https://dblp.uni-trier.de/pid/39/3530-1.html">Li Xiong</a> ; <a href="https://dblp.uni-trier.de/pid/144/4961.html">Joyce C. Ho</a></p>
<p>Abstract:
Electronic health records (EHR) are often generated and collected across a large number of patients featuring distinctive medical conditions and clinical progress over a long period of time, which results in unaligned records along the time dimension. EHR is also prone to missing and erroneous data due to various practical reasons. Recently, PARAFAC2 has been re-popularized for successfully extracting meaningful medical concepts (phenotypes) from such temporal EHR by irregular tensor factorization. Despite recent advances, existing PARAFAC2 methods are unable to robustly handle erroneousness and missing data which are prevalent in clinical practice. We propose REPAIR, a Robust tEmporal PARAFAC2 method for IRregular tensor factorization and completion method, to complete an irregular tensor and extract phenotypes in the presence of missing and erroneous values. To achieve this, REPAIR designs a new effective low-rank regularization function for PARAFAC2 to handle missing and erroneous entries, which has not been explored for irregular tensors before. In addition, the optimization of REPAIR allows it to enjoy the same computational scalability and incorporate a variety of constraints as the state-of-the-art PARAFAC2 method for efficient and meaningful phenotype extraction. We evaluate REPAIR on two real temporal EHR datasets to verify its robustness in tensor factorization against various missing and outlier conditions. Furthermore, we conduct two case studies to demonstrate that REPAIR is able to extract meaningful and useful phenotypes from such corrupted temporal EHR. Our implementation is publicly available <a href="https://github.com/Emory-AIMS/Repair">https://github.com/Emory-AIMS/Repair</a>.</p>
<p>Keywords:</p>
<h3 id="132. The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation Objectively?">132. The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation Objectively?</h3>
<p><a href="https://doi.org/10.1145/3340531.3412048">Paper Link</a>    Pages:1305-1314</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/184/4597.html">Kevin Roitero</a> ; <a href="https://dblp.uni-trier.de/pid/222/1241.html">Michael Soprano</a> ; <a href="https://dblp.uni-trier.de/pid/272/5540.html">Beatrice Portelli</a> ; <a href="https://dblp.uni-trier.de/pid/74/2824.html">Damiano Spina</a> ; <a href="https://dblp.uni-trier.de/pid/m/VincenzoDellaMea.html">Vincenzo Della Mea</a> ; <a href="https://dblp.uni-trier.de/pid/12/1985-1.html">Giuseppe Serra</a> ; <a href="https://dblp.uni-trier.de/pid/74/4701.html">Stefano Mizzaro</a> ; <a href="https://dblp.uni-trier.de/pid/05/3422.html">Gianluca Demartini</a></p>
<p>Abstract:
Misinformation is an ever increasing problem that is difficult to solve for the research community and has a negative impact on the society at large. Very recently, the problem has been addressed with a crowdsourcing-based approach to scale up labeling efforts: to assess the truthfulness of a statement, instead of relying on a few experts, a crowd of (non-expert) judges is exploited. We follow the same approach to study whether crowdsourcing is an effective and reliable method to assess statements truthfulness during a pandemic. We specifically target statements related to the COVID-19 health emergency, that is still ongoing at the time of the study and has arguably caused an increase of the amount of misinformation that is spreading online (a phenomenon for which the term "infodemic" has been used). By doing so, we are able to address (mis)information that is both related to a sensitive and personal issue like health and very recent as compared to when the judgment is done: two issues that have not been analyzed in related work.</p>
<p>Keywords:</p>
<h3 id="133. ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot Retrieval of Images from Textual Descriptions.">133. ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot Retrieval of Images from Textual Descriptions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411995">Paper Link</a>    Pages:1315-1324</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/198/4191.html">Anurag Roy</a> ; <a href="https://dblp.uni-trier.de/pid/138/3106.html">Vinay Kumar Verma</a> ; <a href="https://dblp.uni-trier.de/pid/74/10289.html">Kripabandhu Ghosh</a> ; <a href="https://dblp.uni-trier.de/pid/06/900-1.html">Saptarshi Ghosh</a></p>
<p>Abstract:
Most existing algorithms for cross-modal Information Retrieval are based on a supervised train-test setup, where a model learns to align the mode of the query (e.g., text) to the mode of the documents (e.g., images) from a given training set. Such a setup assumes that the training set contains an exhaustive representation of all possible classes of queries. In reality, a retrieval model may need to be deployed on previously unseen classes, which implies a zero-shot IR setup. In this paper, we propose a novel GAN-based model for zero-shot text to image retrieval. When given a textual description as the query, our model can retrieve relevant images in a zero-shot setup. The proposed model is trained using an Expectation-Maximization framework. Experiments on multiple benchmark datasets show that our proposed model comfortably outperforms several state-of-the-art zero-shot text to image retrieval models, as well as zero-shot classification and hashing models suitably used for retrieval.</p>
<p>Keywords:</p>
<h3 id="134. Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models.">134. Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411866">Paper Link</a>    Pages:1325-1334</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/215/3742.html">Benedek Rozemberczki</a> ; <a href="https://dblp.uni-trier.de/pid/82/4961.html">Rik Sarkar</a></p>
<p>Abstract:
In this paper, we propose a flexible notion of characteristic functions defined on graph vertices to describe the distribution of vertex features at multiple scales. We introduce FEATHER, a computationally efficient algorithm to calculate a specific variant of these characteristic functions where the probability weights of the characteristic function are defined as the transition probabilities of random walks. We argue that features extracted by this procedure are useful for node level machine learning tasks. We discuss the pooling of these node representations, resulting in compact descriptors of graphs that can serve as features for graph classification algorithms. We analytically prove that FEATHER describes isomorphic graphs with the same representation and exhibits robustness to data corruption. Using the node feature characteristic functions we define parametric models where evaluation points of the functions are learned parameters of supervised classifiers. Experiments on real world large datasets show that our proposed algorithm creates high quality representations, performs transfer learning efficiently, exhibits robustness to hyperparameter changes and scales linearly with the input size.</p>
<p>Keywords:</p>
<h3 id="135. A GAN-based Framework for Modeling Hashtag Popularity Dynamics Using Assistive Information.">135. A GAN-based Framework for Modeling Hashtag Popularity Dynamics Using Assistive Information.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412025">Paper Link</a>    Pages:1335-1344</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/228/2505.html">Avirup Saha</a> ; <a href="https://dblp.uni-trier.de/pid/52/6987.html">Niloy Ganguly</a></p>
<p>Abstract:
Temporal point process (TPP) models have hitherto been moderately good at nowcasting hashtag popularity, but have been very poor at forecasting due to insufficient modeling of Twitter microdynamics. Recent studies have shown that the highly fluctuating nature of hashtag popularity dynamics is due to the influence of two external factors: (i) hashtag-tweet reinforcement and (ii) inter-hashtag competition. In this paper, we propose a marked TPP based on Generative Adversarial Networks (GANs) which can seamlessly incorporate the assistive information necessary to capture the above effects and successfully forecast distant popularity trends. To achieve this, we employ a unique linear semi-autoregressive model for mark generation and couple the time and mark generative aspects. On seven diverse datasets crawled from Twitter covering several real-world events, our model yields remarkably stable performance in predicting hashtag popularity in diverse situations and offers a substantial improvement over the existing state of the art generative models.</p>
<p>Keywords:</p>
<h3 id="136. Index Obfuscation for Oblivious Document Retrieval in a Trusted Execution Environment.">136. Index Obfuscation for Oblivious Document Retrieval in a Trusted Execution Environment.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412035">Paper Link</a>    Pages:1345-1354</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/135/7121.html">Jinjin Shao</a> ; <a href="https://dblp.uni-trier.de/pid/117/9197.html">Shiyu Ji</a> ; <a href="https://dblp.uni-trier.de/pid/211/0057.html">Alvin Oliver Glova</a> ; <a href="https://dblp.uni-trier.de/pid/200/8215.html">Yifan Qiao</a> ; <a href="https://dblp.uni-trier.de/pid/67/1120-9.html">Tao Yang</a> ; <a href="https://dblp.uni-trier.de/pid/23/3778.html">Tim Sherwood</a></p>
<p>Abstract:
This paper studies privacy-aware inverted index design and document retrieval for multi-keyword document search in a trusted hardware execution environment such as Intel SGX. The previous work uses time-consuming oblivious computing techniques to avoid the leakage of memory access patterns for privacy preservations in such an environment. This paper proposes an efficiency-enhanced design that obfuscates the inverted index structure with posting bucketing and document ID masking, which aims to hide document-term association and avoid the access pattern leakage. This paper describes privacy-aware oblivious document retrieval during online query processing based on such an index. Both privacy and efficiency analyses are provided, followed by evaluation results comparing proposed designs with multiple baselines.</p>
<p>Keywords:</p>
<h3 id="137. Auxiliary-task Based Deep Reinforcement Learning for Participant Selection Problem in Mobile Crowdsourcing.">137. Auxiliary-task Based Deep Reinforcement Learning for Participant Selection Problem in Mobile Crowdsourcing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411913">Paper Link</a>    Pages:1355-1364</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/71/3692.html">Wei Shen</a> ; <a href="https://dblp.uni-trier.de/pid/273/4311.html">Xiaonan He</a> ; <a href="https://dblp.uni-trier.de/pid/241/9716.html">Chuheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/87/3074.html">Qiang Ni</a> ; <a href="https://dblp.uni-trier.de/pid/57/5595.html">Wanchun Dou</a> ; <a href="https://dblp.uni-trier.de/pid/59/2227.html">Yan Wang</a></p>
<p>Abstract:
In mobile crowdsourcing (MCS), the platform selects participants to complete location-aware tasks from the recruiters aiming to achieve multiple goals (e.g., profit maximization, energy efficiency, and fairness). However, different MCS systems have different goals and there are possibly conflicting goals even in one MCS system. Therefore, it is crucial to design a participant selection algorithm that applies to different MCS systems to achieve multiple goals. To deal with this issue, we formulate the participant selection problem as a reinforcement learning problem and propose to solve it with a novel method, which we call auxiliary-task based deep reinforcement learning (ADRL). We use transformers to extract representations from the context of the MCS system and a pointer network to deal with the combinatorial optimization problem. To improve the sample efficiency, we adopt an auxiliary-task training process that trains the network to predict the imminent tasks from the recruiters, which facilitates the embedding learning of the deep learning model. Additionally, we release a simulated environment on a specific MCS task, the ride-sharing task, and conduct extensive performance evaluations in this environment. The experimental results demonstrate that ADRL outperforms and improves sample efficiency over other well-recognized baselines in various settings.</p>
<p>Keywords:</p>
<h3 id="138. Neural Logic Reasoning.">138. Neural Logic Reasoning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411949">Paper Link</a>    Pages:1365-1374</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/59/3732.html">Shaoyun Shi</a> ; <a href="https://dblp.uni-trier.de/pid/32/6638.html">Hanxiong Chen</a> ; <a href="https://dblp.uni-trier.de/pid/169/1390.html">Weizhi Ma</a> ; <a href="https://dblp.uni-trier.de/pid/174/8367.html">Jiaxin Mao</a> ; <a href="https://dblp.uni-trier.de/pid/83/5342.html">Min Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/82/7829.html">Yongfeng Zhang</a></p>
<p>Abstract:
Recent years have witnessed the success of deep neural networks in many research areas. The fundamental idea behind the design of most neural networks is to learn similarity patterns from data for prediction and inference, which lacks the ability of cognitive reasoning. However, the concrete ability of reasoning is critical to many theoretical and practical problems. On the other hand, traditional symbolic reasoning methods do well in making logical inference, but they are mostly hard rule-based reasoning, which limits their generalization ability to different tasks since difference tasks may require different rules. Both reasoning and generalization ability are important for prediction tasks such as recommender systems, where reasoning provides strong connection between user history and target items for accurate prediction, and generalization helps the model to draw a robust user portrait over noisy inputs.</p>
<p>Keywords:</p>
<h3 id="139. METEOR: Learning Memory and Time Efficient Representations from Multi-modal Data Streams.">139. METEOR: Learning Memory and Time Efficient Representations from Multi-modal Data Streams.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411991">Paper Link</a>    Pages:1375-1384</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/220/0876.html">Amila Silva</a> ; <a href="https://dblp.uni-trier.de/pid/47/5584.html">Shanika Karunasekera</a> ; <a href="https://dblp.uni-trier.de/pid/73/1139.html">Christopher Leckie</a> ; <a href="https://dblp.uni-trier.de/pid/00/1811.html">Ling Luo</a></p>
<p>Abstract:
Many learning tasks involve multi-modal data streams, where continuous data from different modes convey a comprehensive description about objects. A major challenge in this context is how to efficiently interpret multi-modal information in complex environments. This has motivated numerous studies on learning unsupervised representations from multi-modal data streams. These studies aim to understand higher-level contextual information (e.g., a Twitter message) by jointly learning embeddings for the lower-level semantic units in different modalities (e.g., text, user, and location of a Twitter message). However, these methods directly associate each low-level semantic unit with a continuous embedding vector, which results in high memory requirements. Hence, deploying and continuously learning such models in low-memory devices (e.g., mobile devices) becomes a problem. To address this problem, we present METEOR, a novel MEmory and Time Efficient Online Representation learning technique, which: (1) learns compact representations for multi-modal data by sharing parameters within semantically meaningful groups and preserves the domain-agnostic semantics; (2) can be accelerated using parallel processes to accommodate different stream rates while capturing the temporal changes of the units; and (3) can be easily extended to capture implicit/explicit external knowledge related to multi-modal data streams. We evaluate METEOR using two types of multi-modal data streams (i.e., social media streams and shopping transaction streams) to demonstrate its ability to adapt to different domains. Our results show that METEOR preserves the quality of the representations while reducing memory usage by around 80% compared to the conventional memory-intensive embeddings.</p>
<p>Keywords:</p>
<h3 id="140. Carpe Diem, Seize the Samples Uncertain "at the Moment" for Adaptive Batch Selection.">140. Carpe Diem, Seize the Samples Uncertain "at the Moment" for Adaptive Batch Selection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411898">Paper Link</a>    Pages:1385-1394</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/204/3381.html">Hwanjun Song</a> ; <a href="https://dblp.uni-trier.de/pid/65/2574.html">Minseok Kim</a> ; <a href="https://dblp.uni-trier.de/pid/164/1411.html">Sundong Kim</a> ; <a href="https://dblp.uni-trier.de/pid/28/3904.html">Jae-Gil Lee</a></p>
<p>Abstract:
The accuracy of deep neural networks is significantly affected by how well mini-batches are constructed during the training step. In this paper, we propose a novel adaptive batch selection algorithm called Recency Bias that exploits the uncertain samples predicted inconsistently in recent iterations. The historical label predictions of each training sample are used to evaluate its predictive uncertainty within a sliding window. Then, the sampling probability for the next mini-batch is assigned to each training sample in proportion to its predictive uncertainty. By taking advantage of this design, Recency Bias not only accelerates the training step but also achieves a more accurate network. We demonstrate the superiority of Recency Bias by extensive evaluation on two independent tasks. Compared with existing batch selection methods, the results showed that Recency Bias reduced the test error by up to 20.97% in a fixed wall-clock training time. At the same time, it improved the training time by up to 59.32% to reach the same test error.</p>
<p>Keywords:</p>
<h3 id="141. Continual Domain Adaptation for Machine Reading Comprehension.">141. Continual Domain Adaptation for Machine Reading Comprehension.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412047">Paper Link</a>    Pages:1395-1404</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/39/2380.html">Lixin Su</a> ; <a href="https://dblp.uni-trier.de/pid/02/146.html">Jiafeng Guo</a> ; <a href="https://dblp.uni-trier.de/pid/203/8270.html">Ruqing Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/188/2160.html">Yixing Fan</a> ; <a href="https://dblp.uni-trier.de/pid/00/6040.html">Yanyan Lan</a> ; <a href="https://dblp.uni-trier.de/pid/44/912.html">Xueqi Cheng</a></p>
<p>Abstract:
Machine reading comprehension (MRC) has become a core component in a variety of natural language processing (NLP) applications such as question answering and dialogue systems. It becomes a practical challenge that an MRC model needs to learn in non-stationary environments, in which the underlying data distribution changes over time. A typical scenario is the domain drift, i.e. different domains of data come one after another, where the MRC model is required to adapt to the new domain while maintaining previously learned ability. To tackle such a challenge, in this work, we introduce the Continual Domain Adaptation (CDA) task for MRC. So far as we know, this is the first study on the continual learning perspective of MRC. We build two benchmark datasets for the CDA task, by re-organizing existing MRC collections into different domains with respect to context type and question type, respectively. We then analyze and observe the catastrophic forgetting (CF) phenomenon of MRC under the CDA setting. To tackle the CDA task, we propose several BERT-based continual learning MRC models using either regularization-based methodology or dynamic-architecture paradigm. We analyze the performance of different continual learning MRC models under the CDA task and show that the proposed dynamic-architecture based model achieves the best performance.</p>
<p>Keywords:</p>
<h3 id="142. Multi-modal Knowledge Graphs for Recommender Systems.">142. Multi-modal Knowledge Graphs for Recommender Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411947">Paper Link</a>    Pages:1405-1414</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/01/3595.html">Rui Sun</a> ; <a href="https://dblp.uni-trier.de/pid/49/11206.html">Xuezhi Cao</a> ; <a href="https://dblp.uni-trier.de/pid/88/5320.html">Yan Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/276/5081.html">Junchen Wan</a> ; <a href="https://dblp.uni-trier.de/pid/48/3927.html">Kun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/134/2883.html">Fuzheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/84/6394.html">Zhongyuan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/209/6316.html">Kai Zheng</a></p>
<p>Abstract:
Recommender systems have shown great potential to solve the information explosion problem and enhance user experience in various online applications. To tackle data sparsity and cold start problems in recommender systems, researchers propose knowledge graphs (KGs) based recommendations by leveraging valuable external knowledge as auxiliary information. However, most of these works ignore the variety of data types (e.g., texts and images) in multi-modal knowledge graphs (MMKGs). In this paper, we propose Multi-modal Knowledge Graph Attention Network (MKGAT) to better enhance recommender systems by leveraging multi-modal knowledge. Specifically, we propose a multi-modal graph attention technique to conduct information propagation over MMKGs, and then use the resulting aggregated embedding representation for recommendation. To the best of our knowledge, this is the first work that incorporates multi-modal knowledge graph into recommender systems. We conduct extensive experiments on two real datasets from different domains, results of which demonstrate that our model MKGAT can successfully employ MMKGs to improve the quality of recommendation system.</p>
<p>Keywords:</p>
<h3 id="143. Anomaly Subgraph Detection with Feature Transfer.">143. Anomaly Subgraph Detection with Feature Transfer.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411968">Paper Link</a>    Pages:1415-1424</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/10/5415-5.html">Ying Sun</a> ; <a href="https://dblp.uni-trier.de/pid/21/5941-2.html">Wenjun Wang</a> ; <a href="https://dblp.uni-trier.de/pid/66/6346.html">Nannan Wu</a> ; <a href="https://dblp.uni-trier.de/pid/82/2790-16.html">Wei Yu</a> ; <a href="https://dblp.uni-trier.de/pid/48/761-5.html">Xue Chen</a></p>
<p>Abstract:
Anomaly detection in multilayer graphs becomes more critical in many application scenarios, i.e., identifying crime hotspots in urban areas by discovering suspicious and illicit behaviors in social networks. However, it is a big challenge to identify anomalies in a layer graph due to the insufficient anomaly features. Most existing methods of anomaly detection determine whether a node is abnormal by looking at the observable anomalous feature values. However, these methods are not suitable for scenarios in which the abnormal features are scarce, e.g., geometric graphs or non-public data in social network services. In this paper, to detect anomaly in a graph with insufficient anomalous features, we propose a pioneering approach ASD-FT (Anomaly Subgraph Detection with Feature Transfer) based on a strategy of anomalous feature transfers between different layers of a multilayer graph. The proposed ASD-FT detects anomaly subgraphs from the graph of the target layer by analyzing the anomalous features in the graph of another layer. We demonstrate the effectiveness and robustness of our approach ASD-FT with extensive experiments on five real-world datasets.</p>
<p>Keywords:</p>
<h3 id="144. OHEA: Secure Data Aggregation in Wireless Sensor Networks against Untrusted Sensors.">144. OHEA: Secure Data Aggregation in Wireless Sensor Networks against Untrusted Sensors.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412045">Paper Link</a>    Pages:1425-1434</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/91/4820.html">Li Tang</a> ; <a href="https://dblp.uni-trier.de/pid/90/5236.html">Haibo Hu</a></p>
<p>Abstract:
Data aggregation is a key problem in wireless sensor networks (WSNs). To secure the aggregation results, researchers have proposed to adopt homomorphic encryptions. Since aggregation is conducted in the ciphertext space without decryption, both the confidentiality and integrity can be protected against untrusted or compromised aggregators. However, such techniques cannot protect against untrusted or compromised sources, i.e., wireless sensors, as homomorphic encryptions require all sources to share a common encryption key. Since wireless sensor networks are often vulnerable to physical or network attacks, new secure aggregation schemes that can protect against compromised sources are needed. This paper proposes Onion Homomorphic Encryption-based Aggregation (OHEA), where sources form groups with their dedicated encryption keys, a.k.a., the group keys. OHEA has a nice property that group keys themselves can be aggregated, so it can work recursively with any level of aggregation hierarchy. By security analysis, we show that even if multiple aggregators or sources are compromised, an adversary is still unable to compromise the data of other nodes in the same or upper levels of the hierarchy. Furthermore, the experimental results show that OHEA incurs low computation and communication cost, and is thus scalable to large WSNs.</p>
<p>Keywords:</p>
<h3 id="145. Investigating and Mitigating Degree-Related Biases in Graph Convoltuional Networks.">145. Investigating and Mitigating Degree-Related Biases in Graph Convoltuional Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411872">Paper Link</a>    Pages:1435-1444</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/33/7694.html">Xianfeng Tang</a> ; <a href="https://dblp.uni-trier.de/pid/197/1635.html">Huaxiu Yao</a> ; <a href="https://dblp.uni-trier.de/pid/20/8149.html">Yiwei Sun</a> ; <a href="https://dblp.uni-trier.de/pid/178/8638.html">Yiqi Wang</a> ; <a href="https://dblp.uni-trier.de/pid/64/10812.html">Jiliang Tang</a> ; <a href="https://dblp.uni-trier.de/pid/a/CharuCAggarwal.html">Charu C. Aggarwal</a> ; <a href="https://dblp.uni-trier.de/pid/19/3308.html">Prasenjit Mitra</a> ; <a href="https://dblp.uni-trier.de/pid/136/9440.html">Suhang Wang</a></p>
<p>Abstract:
Graph Convolutional Networks (GCNs) show promising results for semi-supervised learning tasks on graphs, thus become favorable comparing with other approaches. Despite the remarkable success of GCNs, it is difficult to train GCNs with insufficient supervision. When labeled data are limited, the performance of GCNs becomes unsatisfying for low-degree nodes. While some prior work analyze successes and failures of GCNs on the entire model level, profiling GCNs on individual node level is still underexplored.</p>
<p>Keywords:</p>
<h3 id="146. QSAN: A Quantum-probability based Signed Attention Network for Explainable False Information Detection.">146. QSAN: A Quantum-probability based Signed Attention Network for Explainable False Information Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411890">Paper Link</a>    Pages:1445-1454</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/62/5501.html">Tian Tian</a> ; <a href="https://dblp.uni-trier.de/pid/04/2118.html">Yudong Liu</a> ; <a href="https://dblp.uni-trier.de/pid/71/1692.html">Xiaoyu Yang</a> ; <a href="https://dblp.uni-trier.de/pid/269/4531.html">Yuefei Lyu</a> ; <a href="https://dblp.uni-trier.de/pid/87/1222.html">Xi Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/87/254.html">Binxing Fang</a></p>
<p>Abstract:
False information detection on social media is challenging as it commonly requires tedious evidence-collecting but lacks available comparative information. Clues mined from user comments, as the wisdom of crowds, could be of considerable benefit to this task. However, it is non-trivial to capture the complex semantics from the contents and comments in consideration of their implicit correlations. Although deep neural networks have good expressive power, one major drawback is the lack of explainability. In this paper, we focus on how to learn from the post contents and related comments in social media to understand and detect the false information more effectively, with explainability. We thus propose a Quantum-probability based Signed Attention Network (QSAN) that integrates the quantum-driven text encoding and a novel signed attention mechanism in a unified framework. QSAN is not only able to distinguish important comments from the others, but also can exploit the conflicting social viewpoints in the comments to facilitate the detection. Moreover, QSAN is advantageous with its explainability in terms of transparency due to quantum physics meanings and the attention weights. Extensive experiments on real-world datasets show that our approach outperforms state-of-the-art baselines and can provide different kinds of user comments to explain why a piece of information is detected as false.</p>
<p>Keywords:</p>
<h3 id="147. Quaternion-Based Self-Attentive Long Short-term User Preference Encoding for Recommendation.">147. Quaternion-Based Self-Attentive Long Short-term User Preference Encoding for Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411926">Paper Link</a>    Pages:1455-1464</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/181/2525.html">Thanh Tran</a> ; <a href="https://dblp.uni-trier.de/pid/83/8652.html">Di You</a> ; <a href="https://dblp.uni-trier.de/pid/22/8024.html">Kyumin Lee</a></p>
<p>Abstract:
Quaternion space has brought several benefits over the traditional Euclidean space: Quaternions (i) consist of a real and three imaginary components, encouraging richer representations; (ii) utilize Hamilton product which better encodes the inter-latent interactions across multiple Quaternion components; and (iii) result in a model with smaller degrees of freedom and less prone to overfitting. Unfortunately, most of the current recommender systems rely on real-valued representations in Euclidean space to model either user's long-term or short-term interests. In this paper, we fully utilize Quaternion space to model both user's long-term and short-term preferences. We first propose a QUaternion-based self-Attentive Long term user Encoding (QUALE) to study the user's long-term intents. Then, we propose a QUaternion-based self-Attentive Short term user Encoding (QUASE) to learn the user's short-term interests. To enhance our models' capability, we propose to fuse QUALE and QUASE into one model, namely QUALSE, by using a Quaternion-based gating mechanism. We further develop Quaternion-based Adversarial learning along with the Bayesian Personalized Ranking (QABPR) to improve our model's robustness. Extensive experiments on six real-world datasets show that our fused QUALSE model outperformed 11 state-of-the-art baselines, improving 8.43% at [email protected] and 10.27% at [email protected] on average compared with the best baseline.</p>
<p>Keywords:</p>
<h3 id="148. E-Commerce Dispute Resolution Prediction.">148. E-Commerce Dispute Resolution Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411906">Paper Link</a>    Pages:1465-1474</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/192/1691.html">David Tsurel</a> ; <a href="https://dblp.uni-trier.de/pid/245/5957.html">Michael Doron</a> ; <a href="https://dblp.uni-trier.de/pid/115/6272.html">Alexander Nus</a> ; <a href="https://dblp.uni-trier.de/pid/01/5865.html">Arnon Dagan</a> ; <a href="https://dblp.uni-trier.de/pid/46/650.html">Ido Guy</a> ; <a href="https://dblp.uni-trier.de/pid/02/2672.html">Dafna Shahaf</a></p>
<p>Abstract:
E-Commerce marketplaces support millions of daily transactions, and some disagreements between buyers and sellers are unavoidable. Resolving disputes in an accurate, fast, and fair manner is of great importance for maintaining a trustworthy platform. Simple cases can be automated, but intricate cases are not sufficiently addressed by hard-coded rules, and therefore most disputes are currently resolved by people. In this work we take a first step towards automatically assisting human agents in dispute resolution at scale. We construct a large dataset of disputes from the eBay online marketplace, and identify several interesting behavioral and linguistic patterns. We then train classifiers to predict dispute outcomes with high accuracy. We explore the model and the dataset, reporting interesting correlations, important features, and insights.</p>
<p>Keywords:</p>
<h3 id="149. When Inverse Propensity Scoring does not Work: Affine Corrections for Unbiased Learning to Rank.">149. When Inverse Propensity Scoring does not Work: Affine Corrections for Unbiased Learning to Rank.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412031">Paper Link</a>    Pages:1475-1484</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/145/5406.html">Ali Vardasbi</a> ; <a href="https://dblp.uni-trier.de/pid/166/3041.html">Harrie Oosterhuis</a> ; <a href="https://dblp.uni-trier.de/pid/r/MdRijke.html">Maarten de Rijke</a></p>
<p>Abstract:
Besides position bias, which has been well-studied, trust bias is another type of bias prevalent in user interactions with rankings: users are more likely to click incorrectly w.r.t. their preferences on highly ranked items because they trust the ranking system. While previous work has observed this behavior in users, we prove that existing Counterfactual Learning to Rank (CLTR) methods do not remove this bias, including methods specifically designed to mitigate this type of bias. Moreover, we prove that Inverse Propensity Scoring (IPS) is principally unable to correct for trust bias under non-trivial circumstances. Our main contribution is a new estimator based on affine corrections: it both reweights clicks and penalizes items displayed on ranks with high trust bias. Our estimator is the first estimator that is proven to remove the effect of both trust bias and position bias. Furthermore, we show that our estimator is a generalization of the existing (CLTR) framework: if no trust bias is present, it reduces to the original (IPS) estimator. Our semi-synthetic experiments indicate that by removing the effect of trust bias in addition to position bias, (CLTR) can approximate the optimal ranking system even closer than previously possible.</p>
<p>Keywords:</p>
<h3 id="150. A Graph Matching Attack on Privacy-Preserving Record Linkage.">150. A Graph Matching Attack on Privacy-Preserving Record Linkage.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411931">Paper Link</a>    Pages:1485-1494</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/221/2923.html">Anushka Vidanage</a> ; <a href="https://dblp.uni-trier.de/pid/c/PeterChristen.html">Peter Christen</a> ; <a href="https://dblp.uni-trier.de/pid/162/3257.html">Thilina Ranbaduge</a> ; <a href="https://dblp.uni-trier.de/pid/127/7152.html">Rainer Schnell</a></p>
<p>Abstract:
To facilitate advanced analytics, data science projects increasingly require records about individuals to be linked across databases. Generally no unique entity identifiers are available in the databases to be linked, and therefore quasi-identifiers such as names, addresses, and dates of birth are used to link records. The process of linking records without revealing any sensitive or confidential information about the entities represented by these records is known as privacy-preserving record linkage (PPRL). Various encoding and encryption based PPRL methods have been developed in the past two decades. Most existing PPRL methods calculate approximate similarities between records because errors and variations can occur in quasi-identifying attribute values. Even though being used in real-world linkage applications, certain PPRL methods, such as popular Bloom filter encoding, have shown to be vulnerable to cryptanalysis attacks. In this paper we present a novel attack on PPRL methods that exploits the approximate similarities calculated between encoded records. Our attack matches nodes in a similarity graph generated from an encoded database with a corresponding similarity graph generated from a plain-text database to re-identify sensitive values. Our attack is not limited to any specific PPRL method, and in an experimental evaluation we apply it on three PPRL encoding methods using three different databases. This evaluation shows that our attack can successfully re-identify sensitive values from these encodings with high accuracy where no previous attack on PPRL would have been successful.</p>
<p>Keywords:</p>
<h3 id="151. Semi-Supervised Max-Sum Clustering.">151. Semi-Supervised Max-Sum Clustering.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411896">Paper Link</a>    Pages:1495-1504</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/63/8246.html">Konstantin Voevodski</a></p>
<p>Abstract:
We study max-sum clustering in a semi-supervised setting. Our objective function maximizes the pairwise within-cluster similarity with respect to some null hypothesis regarding the similarity. This is a natural objective that does not require any additional parameters, and is a generalization of the well-known modularity objective function. We show that for such an objective function in a semi-supervised setting we can compute an additive approximation of the optimal solution in the general case, and a constant-factor approximation when the optimal objective value is large. The supervision that we consider is in the form of cluster assignment queries and same-cluster queries; we also study the setting where the query responses are noisy. Our algorithm also generalizes to the min-sum objective function, for which we can achieve similar performance guarantees. We present computational experiments to show that our framework is effective for clustering text data - we are able to find clusterings that are close to the queried clustering and have a good objective value.</p>
<p>Keywords:</p>
<h3 id="152. Efficient Sampling Algorithms for Approximate Temporal Motif Counting.">152. Efficient Sampling Algorithms for Approximate Temporal Motif Counting.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411862">Paper Link</a>    Pages:1505-1514</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/62/2631-4.html">Jingjing Wang</a> ; <a href="https://dblp.uni-trier.de/pid/123/2365-1.html">Yanhao Wang</a> ; <a href="https://dblp.uni-trier.de/pid/55/7770.html">Wenjun Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/143/0258.html">Yuchen Li</a> ; <a href="https://dblp.uni-trier.de/pid/t/KianLeeTan.html">Kian-Lee Tan</a></p>
<p>Abstract:
A great variety of complex systems ranging from user interactions in communication networks to transactions in financial markets can be modeled as temporal graphs, which consist of a set of vertices and a series of timestamped and directed edges. Temporal motifs in temporal graphs are generalized from subgraph patterns in static graphs which take into account edge orderings and durations in addition to structures. Counting the number of occurrences of temporal motifs is a fundamental problem for temporal network analysis. However, existing methods either cannot support temporal motifs or suffer from performance issues. In this paper, we focus on approximate temporal motif counting via random sampling. We first propose a generic edge sampling (ES) algorithm for estimating the number of instances of any temporal motif. Furthermore, we devise an improved EWS algorithm that hybridizes edge sampling with wedge sampling for counting temporal motifs with 3 vertices and 3 edges. We provide comprehensive analyses of the theoretical bounds and complexities of our proposed algorithms. Finally, we conduct extensive experiments on several real-world datasets, and the results show that our ES and EWS algorithms have higher efficiency, better accuracy, and greater scalability than the state-of-the-art sampling method for temporal motif counting.</p>
<p>Keywords:</p>
<h3 id="153. Streaming Graph Neural Networks via Continual Learning.">153. Streaming Graph Neural Networks via Continual Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411963">Paper Link</a>    Pages:1515-1524</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/142/9564.html">Junshan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/37/2900.html">Guojie Song</a> ; <a href="https://dblp.uni-trier.de/pid/44/3684.html">Yi Wu</a> ; <a href="https://dblp.uni-trier.de/pid/56/4499.html">Liang Wang</a></p>
<p>Abstract:
Graph neural networks (GNNs) have achieved strong performance in various applications. In the real world, network data is usually formed in a streaming fashion. The distributions of patterns that refer to neighborhood information of nodes may shift over time. The GNN model needs to learn the new patterns that cannot yet be captured. But learning incrementally leads to the catastrophic forgetting problem that historical knowledge is overwritten by newly learned knowledge. Therefore, it is important to train GNN model to learn new patterns and maintain existing patterns simultaneously, which few works focus on. In this paper, we propose a streaming GNN model based on continual learning so that the model is trained incrementally and up-to-date node representations can be obtained at each time step. Firstly, we design an approximation algorithm to detect new coming patterns efficiently based on information propagation. Secondly, we combine two perspectives of data replaying and model regularization for existing pattern consolidation. Specially, a hierarchy-importance sampling strategy for nodes is designed and a weighted regularization term for GNN parameters is derived, achieving greater stability and generalization of knowledge consolidation. Our model is evaluated on real and synthetic data sets and compared with multiple baselines. The results of node classification prove that our model can efficiently update model parameters and achieve comparable performance to model retraining. In addition, we also conduct a case study on the synthetic data, and carry out some specific analysis for each part of our model, illustrating its ability to learn new knowledge and maintain existing knowledge from different perspectives.</p>
<p>Keywords:</p>
<h3 id="154. Soap: Soaking Capacity Optimization for Multi-Document Summarization.">154. Soap: Soaking Capacity Optimization for Multi-Document Summarization.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411909">Paper Link</a>    Pages:1525-1534</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/53/5161.html">Kexiang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/91/6051.html">Baobao Chang</a> ; <a href="https://dblp.uni-trier.de/pid/22/5834.html">Zhifang Sui</a></p>
<p>Abstract:
Multi-document summarization (MDS) aims at giving a brief summary for a cluster of related documents. In this paper, we consider the MDS task as an optimization problem with a novel measure named soaking capacity being the objective function. The origin of our method is the classic hypothesis: the summary components are the sinks of information diffusion. We point out that the hypothesis only gives the role of summary but does not cover how well a summary acts as this role. To fill in the gap, soaking capacity is formally defined to quantify the ability of summary to soak up information. We explicitly demonstrate its fitness as an indicator for both the saliency and the diversity goal of MDS. For solving the optimization problem, we propose a greedy algorithm named Soap by adopting a surrogate of soaking capacity to accelerate the computation. Experiments on MDS datasets across various domains show the great potential of Soap as compared with the state-of-the-art MDS systems.</p>
<p>Keywords:</p>
<h3 id="155. Mining Infrequent High-Quality Phrases from Domain-Specific Corpora.">155. Mining Infrequent High-Quality Phrases from Domain-Specific Corpora.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412029">Paper Link</a>    Pages:1535-1544</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/58/6810.html">Li Wang</a> ; <a href="https://dblp.uni-trier.de/pid/83/4805.html">Wei Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/236/6174.html">Sihang Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/69/6137.html">Sheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/01/10613.html">Keqiang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/70/2170.html">Yuan Ni</a> ; <a href="https://dblp.uni-trier.de/pid/73/5346.html">Guotong Xie</a> ; <a href="https://dblp.uni-trier.de/pid/96/999.html">Yanghua Xiao</a></p>
<p>Abstract:
Phrase mining is a fundamental task for text analysis and has various downstream applications such as named entity recognition, topic modeling, and relation extraction. In this paper, we focus on mining high-quality phrases from domain-specific corpora with special consideration of infrequent ones. Previous methods might miss infrequent high-quality phrases in the candidate selection stage. And these methods rely on explicit features to mine phrases while rarely considering the implicit features. In addition, completeness is rarely explicitly considered in the evaluation of a high-quality phrase. In this paper, we propose a novel approach that exploits a sequence labeling model to capture infrequent phrases. And we employ implicit semantic features and contextual POS tag statistics to measure meaningfulness and completeness, respectively. Experiments over four real-world corpora demonstrate that our method achieves significant improvements over previous state-of-the-art methods across different domains and languages.</p>
<p>Keywords:</p>
<h3 id="156. Graph Few-shot Learning with Attribute Matching.">156. Graph Few-shot Learning with Attribute Matching.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411923">Paper Link</a>    Pages:1545-1554</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/46/2005.html">Ning Wang</a> ; <a href="https://dblp.uni-trier.de/pid/99/10051.html">Minnan Luo</a> ; <a href="https://dblp.uni-trier.de/pid/234/6878.html">Kaize Ding</a> ; <a href="https://dblp.uni-trier.de/pid/181/2714.html">Lingling Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/144/7997.html">Jundong Li</a> ; <a href="https://dblp.uni-trier.de/pid/32/1858.html">Qinghua Zheng</a></p>
<p>Abstract:
Due to the expensive cost of data annotation, few-shot learning has attracted increasing research interests in recent years. Various meta-learning approaches have been proposed to tackle this problem and have become the de facto practice. However, most of the existing approaches along this line mainly focus on image and text data in the Euclidean domain. However, in many real-world scenarios, a vast amount of data can be represented as attributed networks defined in the non-Euclidean domain, and the few-shot learning studies in such structured data have largely remained nascent. Although some recent studies have tried to combine meta-learning with graph neural networks to enable few-shot learning on attributed networks, they fail to account for the unique properties of attributed networks when creating diverse tasks in the meta-training phase---the feature distributions of different tasks could be quite different as instances (i.e., nodes) do not follow the data i.i.d. assumption on attributed networks. Hence, it may inevitably result in suboptimal performance in the meta-testing phase. To tackle the aforementioned problem, we propose a novel graph meta-learning framework--Attribute Matching Meta-learning Graph Neural Networks (AMM-GNN). Specifically, the proposed AMM-GNN leverages an attribute-level attention mechanism to capture the distinct information of each task and thus learns more effective transferable knowledge for meta-learning. We conduct extensive experiments on real-world datasets under a wide range of settings and the experimental results demonstrate the effectiveness of the proposed AMM-GNN framework.</p>
<p>Keywords:</p>
<h3 id="157. Multi-task Adversarial Spatial-Temporal Networks for Crowd Flow Prediction.">157. Multi-task Adversarial Spatial-Temporal Networks for Crowd Flow Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412054">Paper Link</a>    Pages:1555-1564</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/118/5055.html">Senzhang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5069.html">Hao Miao</a> ; <a href="https://dblp.uni-trier.de/pid/175/3324.html">Hao Chen</a> ; <a href="https://dblp.uni-trier.de/pid/70/2080.html">Zhiqiu Huang</a></p>
<p>Abstract:
Crowd flow prediction, which aims to predict the in-out flows (e.g. the traffic of crowds, taxis and bikes ) of different areas of a city, is critically important to many real applications including public safety and intelligent transportation systems. The challenges of this problem lie in both the dynamic mobility patterns of crowds and the complex spatial-temporal correlations. Meanwhile, crowd flow is highly correlated to and affected by the Origin-Destination (OD) locations of the flow trajectories, which is largely ignored by existing works. In this paper, we study the novel problem of predicting the crowd flow and flow OD simultaneously, and propose a multi-task adversarial spatial-temporal network model entitled MT-ASTN to effectively address it. As a multi-task learning model, MT-ASTN adopts a shared-private framework which contains private spatial-temporal encoders, a shared spatial-temporal encoder, and decoders to learn the task-specific features and shared features. To effectively extract high quality shared features, a discriminative loss on task classification and an adversarial loss on shared feature extraction are incorporated to reduce information redundancy. We also design an attentive temporal queue to automatically capture the complex temporal dependency without the help of domain knowledge. Extensive evaluations are conducted over the bike and taxicab trip datasets in New York. The results demonstrate that our approach significantly outperforms state-of-the-art methods by a large margin on both tasks.</p>
<p>Keywords:</p>
<h3 id="158. Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification.">158. Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411978">Paper Link</a>    Pages:1565-1574</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/08/5760.html">Xi Wang</a> ; <a href="https://dblp.uni-trier.de/pid/21/141.html">Iadh Ounis</a> ; <a href="https://dblp.uni-trier.de/pid/02/2224.html">Craig MacDonald</a></p>
<p>Abstract:
The incompleteness of positive labels and the presence of many unlabelled instances are common problems in binary classification applications such as in review helpfulness classification. Various studies from the classification literature consider all unlabelled instances as negative examples. However, a classification model that learns to classify binary instances with incomplete positive labels while assuming all unlabelled data to be negative examples will often generate a biased classifier. In this work, we propose a novel Negative Confidence-aware Weakly Supervised approach (NCWS), which customises a binary classification loss function by discriminating the unlabelled examples with different negative confidences during the classifier's training. NCWS allows to effectively, unbiasedly identify and separate positive and negative instances after its integration into various binary classifiers from the literature, including SVM, CNN and BERT-based classifiers. We use the review helpfulness classification as a test case for examining the effectiveness of our NCWS approach. We thoroughly evaluate NCWS by using three different datasets, namely one from Yelp (venue reviews), and two from Amazon (Kindle and Electronics reviews). Our results show that NCWS outperforms strong baselines from the literature including an existing SVM-based approach (i.e. SVM-P), the positive and unlabelled learning-based approach (i.e. C-PU) and the positive confidence-based approach (i.e. P-conf) in addressing the classifier's bias problem. Moreover, we further examine the effectiveness of NCWS by using its classified helpful reviews in a state-of-the-art review-based venue recommendation model (i.e. DeepCoNN) and demonstrate the benefits of using NCWS in enhancing venue recommendation effectiveness in comparison to the baselines.</p>
<p>Keywords:</p>
<h3 id="159. Fast Graph Convolution Network Based Multi-label Image Recognition via Cross-modal Fusion.">159. Fast Graph Convolution Network Based Multi-label Image Recognition via Cross-modal Fusion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411880">Paper Link</a>    Pages:1575-1584</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/150/8599.html">Yangtao Wang</a> ; <a href="https://dblp.uni-trier.de/pid/261/6589.html">Yanzhao Xie</a> ; <a href="https://dblp.uni-trier.de/pid/97/2274.html">Yu Liu</a> ; <a href="https://dblp.uni-trier.de/pid/78/2949-1.html">Ke Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/185/9845.html">Xiaocui Li</a></p>
<p>Abstract:
In multi-label image recognition, it has become a popular method to predict those labels that co-occur in an image via modeling the label dependencies. Previous works focus on capturing the correlation between labels, but neglect to effectively fuse the image features and label embeddings, which severely affects the convergence efficiency of the model and inhibits the further precision improvement of multi-label image recognition. To overcome this shortcoming, in this paper, we introduce Multi-modal Factorized Bilinear pooling (MFB) which works as an efficient component to fuse cross-modal embeddings and propose F-GCN, a fast graph convolution network (GCN) based multi-label image recognition model. F-GCN consists of three key modules: (1) an image representation learning module which adopts a convolution neural network (CNN) to learn and generate image representations, (2) a label co-occurrence embedding module which first obtains the label vectors via the word embeddings technique and then adopts GCN to capture label co-occurrence embeddings and (3) an MFB fusion module which efficiently fuses these cross-modal vectors to enable an end-to-end model with a multi-label loss function. We conduct extensive experiments on two multi-label datasets including MS-COCO and VOC2007. Experimental results demonstrate the MFB component efficiently fuses image representations and label co-occurrence embeddings and thus greatly improves the convergence efficiency of the model. In addition, the performance of image recognition has also been promoted compared with the state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="160. Bringing Order to Network Embedding: A Relative Ranking based Approach.">160. Bringing Order to Network Embedding: A Relative Ranking based Approach.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412041">Paper Link</a>    Pages:1585-1594</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/192/7228.html">Yaojing Wang</a> ; <a href="https://dblp.uni-trier.de/pid/252/1280.html">Guosheng Pan</a> ; <a href="https://dblp.uni-trier.de/pid/25/4120-1.html">Yuan Yao</a> ; <a href="https://dblp.uni-trier.de/pid/58/1757.html">Hanghang Tong</a> ; <a href="https://dblp.uni-trier.de/pid/69/3036.html">Hongxia Yang</a> ; <a href="https://dblp.uni-trier.de/pid/03/2611.html">Feng Xu</a> ; <a href="https://dblp.uni-trier.de/pid/225/6330.html">Jian Lu</a></p>
<p>Abstract:
Network embedding aims to automatically learn the node representations in networks. The basic idea of network embedding is to first construct a network to describe the neighborhood context for each node, and then learn the node representations by designing an objective function to preserve certain properties of the constructed context network. The vast majority of the existing methods, explicitly or implicitly, follow a pointwise design principle. That is, the objective can be decomposed into the summation of the certain goodness function over each individual edge of the context network. In this paper, we propose to go beyond such pointwise approaches, and introduce the ranking-oriented design principle for network embedding. The key idea is to decompose the overall objective function into the summation of a goodness function over a set of edges to collectively preserve their relative rankings on the context network. We instantiate the ranking-oriented design principle by two new network embedding algorithms, including a pairwise network embedding method PaWine which optimizes the relative weights of edge pairs, and a listwise method LiWine which optimizes the relative weights of edge lists. Both proposed algorithms bear a linear time complexity, making themselves scalable to large networks. We conduct extensive experimental evaluations on five real datasets with a variety of downstream learning tasks, which demonstrate that the proposed approaches consistently outperform the existing methods.</p>
<p>Keywords:</p>
<h3 id="161. Efficient Knowledge Graph Validation via Cross-Graph Representation Learning.">161. Efficient Knowledge Graph Validation via Cross-Graph Representation Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411902">Paper Link</a>    Pages:1595-1604</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/147/1393.html">Yaqing Wang</a> ; <a href="https://dblp.uni-trier.de/pid/85/10856.html">Fenglong Ma</a> ; <a href="https://dblp.uni-trier.de/pid/67/4834.html">Jing Gao</a></p>
<p>Abstract:
Recent advances in information extraction have motivated the automatic construction of huge Knowledge Graphs (KGs) by mining from large-scale text corpus. However, noisy facts are unavoidably introduced into KGs that could be caused by automatic extraction.</p>
<p>Keywords:</p>
<h3 id="162. DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation.">162. DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411996">Paper Link</a>    Pages:1605-1614</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/47/6959.html">Yifan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5040.html">Suyao Tang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5004.html">Yuntong Lei</a> ; <a href="https://dblp.uni-trier.de/pid/02/9110.html">Weiping Song</a> ; <a href="https://dblp.uni-trier.de/pid/85/1868.html">Sheng Wang</a> ; <a href="https://dblp.uni-trier.de/pid/73/1844.html">Ming Zhang</a></p>
<p>Abstract:
Heterogeneous information network has been widely used to alleviate sparsity and cold start problems in recommender systems since it can model rich context information in user-item interactions. Graph neural network is able to encode this rich context information through propagation on the graph. However, existing heterogeneous graph neural networks neglect entanglement of the latent factors stemming from different aspects. Moreover, meta paths in existing approaches are simplified as connecting paths or side information between node pairs, overlooking the rich semantic information in the paths. In this paper, we propose a novel disentangled heterogeneous graph attention network DisenHAN for top-N recommendation, which learns disentangled user/item representations from different aspects in a heterogeneous information network. In particular, we use meta relations to decompose high-order connectivity between node pairs and propose a disentangled embedding propagation layer which can iteratively identify the major aspect of meta relations. Our model aggregates corresponding aspect features from each meta relation for the target user/item. With different layers of embedding propagation, DisenHAN is able to explicitly capture the collaborative filtering effect semantically. Extensive experiments on three real-world datasets show that DisenHAN consistently outperforms state-of-the-art approaches. We further demonstrate the effectiveness and interpretability of the learned disentangled representations via insightful case studies and visualization.</p>
<p>Keywords:</p>
<h3 id="163. Succinct Adaptive Manifold Transfer.">163. Succinct Adaptive Manifold Transfer.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411921">Paper Link</a>    Pages:1615-1624</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/29/11273.html">Pengfei Wei</a> ; <a href="https://dblp.uni-trier.de/pid/07/3111.html">Yiping Ke</a> ; <a href="https://dblp.uni-trier.de/pid/72/51.html">Zhiqiang Xu</a> ; <a href="https://dblp.uni-trier.de/pid/16/3956.html">Tze-Yun Leong</a></p>
<p>Abstract:
Capturing the relatedness of different domains is a key challenge in transferring knowledge across domains. In this paper, we propose an effective and efficient Gaussian process (GP) modelling framework, mTGPmk, that can explicitly model domain relatedness and adaptively control the space as well as the strength of knowledge transfer. mTGPmk takes both the discrepancy of input feature space and the discrepancy of predictive function into account in the transfer procedure. Specifically, mTGPmk adaptively selects a good latent manifold shared by different domains, and utilizes a parametric similarity coefficient to measure the predictive function covariance of different domains in this manifold. The latent shared manifold and the similarity coefficient are jointly learned in a coupled manner. By doing so, mTGPmk maximizes the strength of the shared knowledge transfer by choosing the transfer space with the best transfer capacity. More importantly, mTGPmk exploits a succinct and computationally efficient manifold learning approach so that it can be well trained with scarce target training data. Extensive experimental studies using 36 synthetic transfer tasks and 10 real-world transfer tasks show the effectiveness of mTGPmk on capturing the relatedness and the transfer adaptiveness.</p>
<p>Keywords:</p>
<h3 id="164. Personalized Imputation on Wearable-Sensory Time Series via Knowledge Transfer.">164. Personalized Imputation on Wearable-Sensory Time Series via Knowledge Transfer.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411879">Paper Link</a>    Pages:1625-1634</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/03/5595.html">Xian Wu</a> ; <a href="https://dblp.uni-trier.de/pid/239/8981.html">Stephen M. Mattingly</a> ; <a href="https://dblp.uni-trier.de/pid/228/5384.html">Shayan Mirjafari</a> ; <a href="https://dblp.uni-trier.de/pid/18/4087-1.html">Chao Huang</a> ; <a href="https://dblp.uni-trier.de/pid/c/NiteshVChawla.html">Nitesh V. Chawla</a></p>
<p>Abstract:
The analysis of wearable-sensory time series data (e.g., heart rate records) benefits many applications (e.g., activity recognition, disease diagnosis). However, sensor measurements usually contain missing values due to various factors (e.g., user behavior, lack of charging), which may degrade the performance of downstream analytical tasks (e.g., regression, prediction). Thus, time series imputation is desired, which is capable of making sensory time series complete. Existing time series imputation methods generally employ various deep neural network models (e.g., GRU and GAN) to fill missing values by leveraging temporal patterns extracted from the contextual observations. Despite their effectiveness, we argue that most existing models can only achieve sub-optimal imputation performance due to the fact that they are inherently limited in sharing only one single set of model parameters to perform imputation on all individuals. Relying on one set of parameters limits the expressiveness of the imputation model as such models are bound to fail in capturing various complex personal characteristics. Therefore, most existing models tend to achieve inferior imputation performance, especially when a long duration of missing values, i.e., a large gap, is observed in the time series data. To address the limitation, this work develops a new imputation framework--Personalized Wearable-Sensory Time Series Imputation framework (PTSI) to provide a fully personalized treatment for time series imputation via effective knowledge transfer. In particular, PTSI first leverages a meta-learning paradigm to learn a well-generalized initialization to facilitate the adaption process for each user. To make the time series imputation be reflective of an individual's unique characteristics, we further endow PTSI with the capability of learning personalized model parameters, which is achieved by designing a parameter initialization modulating component. Extensive experiments on real-world human heart rate datasets demonstrate that our PTSI framework outperforms various state-of-the-art methods by a large margin consistently.</p>
<p>Keywords:</p>
<h3 id="165. Providing Direct Answers in Search Results: A Study of User Behavior.">165. Providing Direct Answers in Search Results: A Study of User Behavior.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412017">Paper Link</a>    Pages:1635-1644</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/204/0172-2.html">Zhijing Wu</a> ; <a href="https://dblp.uni-trier.de/pid/s/MarkSanderson.html">Mark Sanderson</a> ; <a href="https://dblp.uni-trier.de/pid/276/5088.html">B. Barla Cambazoglu</a> ; <a href="https://dblp.uni-trier.de/pid/c/WBruceCroft.html">W. Bruce Croft</a> ; <a href="https://dblp.uni-trier.de/pid/98/1631.html">Falk Scholer</a></p>
<p>Abstract:
To study the impact of providing direct answers in search results on user behavior, we conducted a controlled user study to analyze factors including reading time, eye-tracked attention, and the influence of the quality of answer module content. We also studied a more advanced answer interface, where multiple answers are shown on the search engine results page (SERP). Our results show that users focus more extensively than normal on the top items in the result list when answers are provided. The existence of the answer module helps to improve user engagement on SERPs, reduces user effort, and promotes user satisfaction during the search process. Furthermore, we investigate how the question type -- factoid or non-factoid -- affects user interaction patterns. This work provides insight into the design of SERPs that includes direct answers to queries, including when answers should be shown.</p>
<p>Keywords:</p>
<h3 id="166. CAFE: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation.">166. CAFE: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412038">Paper Link</a>    Pages:1645-1654</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/151/4542.html">Yikun Xian</a> ; <a href="https://dblp.uni-trier.de/pid/146/6971.html">Zuohui Fu</a> ; <a href="https://dblp.uni-trier.de/pid/79/8522.html">Handong Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/240/9457.html">Yingqiang Ge</a> ; <a href="https://dblp.uni-trier.de/pid/83/6331.html">Xu Chen</a> ; <a href="https://dblp.uni-trier.de/pid/175/5362.html">Qiaoying Huang</a> ; <a href="https://dblp.uni-trier.de/pid/171/3642.html">Shijie Geng</a> ; <a href="https://dblp.uni-trier.de/pid/122/2668-1.html">Zhou Qin</a> ; <a href="https://dblp.uni-trier.de/pid/86/1747.html">Gerard de Melo</a> ; <a href="https://dblp.uni-trier.de/pid/m/SMuthukrishnan.html">S. Muthukrishnan</a> ; <a href="https://dblp.uni-trier.de/pid/82/7829.html">Yongfeng Zhang</a></p>
<p>Abstract:
Recent research explores incorporating knowledge graphs (KG) into e-commerce recommender systems, not only to achieve better recommendation performance, but more importantly to generate explanations of why particular decisions are made. This can be achieved by explicit KG reasoning, where a model starts from a user node, sequentially determines the next step, and walks towards an item node of potential interest to the user. However, this is challenging due to the huge search space, unknown destination, and sparse signals over the KG, so informative and effective guidance is needed to achieve a satisfactory recommendation quality. To this end, we propose a CoArse-to-FinE neural symbolic reasoning approach (CAFE). It first generates user profiles as coarse sketches of user behaviors, which subsequently guide a path-finding process to derive reasoning paths for recommendations as fine-grained predictions. User profiles can capture prominent user behaviors from the history, and provide valuable signals about which kinds of path patterns are more likely to lead to potential items of interest for the user. To better exploit the user profiles, an improved path-finding algorithm called Profile-guided Path Reasoning (PPR) is also developed, which leverages an inventory of neural symbolic reasoning modules to effectively and efficiently find a batch of paths over a large-scale KG. We extensively experiment on four real-world benchmarks and observe substantial gains in the recommendation performance compared with state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="167. OPHiForest: Order Preserving Hashing Based Isolation Forest for Robust and Scalable Anomaly Detection.">167. OPHiForest: Order Preserving Hashing Based Isolation Forest for Robust and Scalable Anomaly Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411988">Paper Link</a>    Pages:1655-1664</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/194/6883.html">Haolong Xiang</a> ; <a href="https://dblp.uni-trier.de/pid/99/3221.html">Zoran Salcic</a> ; <a href="https://dblp.uni-trier.de/pid/57/5595.html">Wanchun Dou</a> ; <a href="https://dblp.uni-trier.de/pid/10/137.html">Xiaolong Xu</a> ; <a href="https://dblp.uni-trier.de/pid/01/8326.html">Lianyong Qi</a> ; <a href="https://dblp.uni-trier.de/pid/54/8558.html">Xuyun Zhang</a></p>
<p>Abstract:
Anomaly detection is one of the most important data mining tasks in many real-life applications such as network intrusion detection for cybersecurity and medical diagnosis for healthcare. In the big data era, these applications demand fast and versatile anomaly detection capability to handle various types of increasingly huge-volume data. However, existing detection methods are either slow due to high computational complexity, or unable to deal with complicated anomalies like local anomalies. In this paper, we propose a novel anomaly detection method named OPHiForest with the use of the order preserving hashing based isolation forest. The core idea is to learn the information from data to construct better isolation forest structure than the state-of-the-art methods like iForest and LSHiForest, which can achieve robust detection of various anomaly types. We design a fast two-step learning process for the order preserving hashing scheme. This leads to stronger order preservation for better hashing, and therefore enhances anomaly detection robustness and accuracy. Extensive experiments on both synthetic and real-world data sets demonstrate that our method is highly robust and scalable.</p>
<p>Keywords:</p>
<h3 id="168. Deep Graph Convolutional Networks for Incident-Driven Traffic Speed Prediction.">168. Deep Graph Convolutional Networks for Incident-Driven Traffic Speed Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411873">Paper Link</a>    Pages:1665-1674</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/205/5853.html">Qinge Xie</a> ; <a href="https://dblp.uni-trier.de/pid/226/2490.html">Tiancheng Guo</a> ; <a href="https://dblp.uni-trier.de/pid/48/4792-1.html">Yang Chen</a> ; <a href="https://dblp.uni-trier.de/pid/54/5385.html">Yu Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/10/5630-3.html">Xin Wang</a> ; <a href="https://dblp.uni-trier.de/pid/z/BenYZhao.html">Ben Y. Zhao</a></p>
<p>Abstract:
Accurate traffic speed prediction is an important and challenging topic for transportation planning. Previous studies on traffic speed prediction predominately used spatio-temporal and context features for prediction. However, they have not made good use of the impact of traffic incidents. In this work, we aim to make use of the information of incidents to achieve a better prediction of traffic speed. Our incident-driven prediction framework consists of three processes. First, we propose a critical incident discovery method to discover traffic incidents with high impact on traffic speed. Second, we design a binary classifier, which uses deep learning methods to extract the latent incident impact features. Combining above methods, we propose a Deep Incident-Aware Graph Convolutional Network (DIGC-Net) to effectively incorporate traffic incident, spatio-temporal, periodic and context features for traffic speed prediction. We conduct experiments using two real-world traffic datasets of San Francisco and New York City. The results demonstrate the superior performance of our model compared with the competing benchmarks.</p>
<p>Keywords:</p>
<h3 id="169. Controllable Multi-Character Psychology-Oriented Story Generation.">169. Controllable Multi-Character Psychology-Oriented Story Generation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411937">Paper Link</a>    Pages:1675-1684</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/49/1462.html">Feifei Xu</a> ; <a href="https://dblp.uni-trier.de/pid/156/1668.html">Xinpeng Wang</a> ; <a href="https://dblp.uni-trier.de/pid/199/8143.html">Yunpu Ma</a> ; <a href="https://dblp.uni-trier.de/pid/t/VolkerTresp.html">Volker Tresp</a> ; <a href="https://dblp.uni-trier.de/pid/118/4761-1.html">Yuyi Wang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5016.html">Shanlin Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/48/10264.html">Haizhou Du</a></p>
<p>Abstract:
Story generation, which aims to generate a long and coherent story automatically based on the title or an input sentence, is an important research area in the field of natural language generation. There is relatively little work on story generation with appointed emotions. Most existing works focus on using only one specific emotion to control the generation of a whole story and ignore the emotional changes in the characters in the course of the story. In our work, we aim to design an emotional line for each character that considers multiple emotions common in psychological theories, with the goal of generating stories with richer emotional changes in the characters. To the best of our knowledge, this work is first to focuses on characters' emotional lines in story generation. We present a novel model-based attention mechanism that we call SoCP (Storytelling of multi-Character Psychology). We show that the proposed model can generate stories considering the changes in the psychological state of different characters. To take into account the particularity of the model, in addition to commonly used evaluation indicators(BLEU, ROUGE, etc.), we introduce the accuracy rate of psychological state control as a novel evaluation metric. The new indicator reflects the effect of the model on the psychological state control of story characters. Experiments show that with SoCP, the generated stories follow the psychological state for each character according to both automatic and human evaluations.</p>
<p>Keywords:</p>
<h3 id="170. Schema2QA: High-Quality and Low-Cost Q&A Agents for the Structured Web.">170. Schema2QA: High-Quality and Low-Cost Q&amp;A Agents for the Structured Web.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411974">Paper Link</a>    Pages:1685-1694</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/143/9693.html">Silei Xu</a> ; <a href="https://dblp.uni-trier.de/pid/167/5968.html">Giovanni Campagna</a> ; <a href="https://dblp.uni-trier.de/pid/33/5448.html">Jian Li</a> ; <a href="https://dblp.uni-trier.de/pid/l/MonicaSLam.html">Monica S. Lam</a></p>
<p>Abstract:
Building a question-answering agent currently requires large annotated datasets, which are prohibitively expensive. This paper proposes Schema2QA, an open-source toolkit that can generate a Q&amp;A system from a database schema augmented with a few annotations for each field. The key concept is to cover the space of possible compound queries on the database with a large number of in-domain questions synthesized with the help of a corpus of generic query templates. The synthesized data and a small paraphrase set are used to train a novel neural network based on the BERT pretrained model. We use Schema2QA to generate Q&amp;A systems for five Schema.org domains, restaurants, people, movies, books and music, and obtain an overall accuracy between 64% and 75% on crowdsourced questions for these domains. Once annotations and paraphrases are obtained for a Schema.org schema, no additional manual effort is needed to create a Q&amp;A agent for any website that uses the same schema. Furthermore, we demonstrate that learning can be transferred from the restaurant to the hotel domain, obtaining a 64% accuracy on crowdsourced questions with no manual effort. Schema2QA achieves an accuracy of 60% on popular restaurant questions that can be answered using Schema.org. Its performance is comparable to Google Assistant, 7% lower than Siri, and 15% higher than Alexa. It outperforms all these assistants by at least 18% on more complex, long-tail questions.</p>
<p>Keywords:</p>
<h3 id="171. E-commerce Recommendation with Weighted Expected Utility.">171. E-commerce Recommendation with Weighted Expected Utility.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411993">Paper Link</a>    Pages:1695-1704</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/146/0697.html">Zhichao Xu</a> ; <a href="https://dblp.uni-trier.de/pid/27/4390.html">Yi Han</a> ; <a href="https://dblp.uni-trier.de/pid/82/7829.html">Yongfeng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/169/1808.html">Qingyao Ai</a></p>
<p>Abstract:
Different from shopping at retail stores, consumers on e-commerce platforms usually cannot touch or try products before purchasing, which means that they have to make decisions when they are uncertain about the outcome (e.g., satisfaction level) of purchasing a product. To study people's preferences with regard to choices that have uncertain outcomes, economics researchers have proposed the hypothesis of Expected Utility (EU) that models the subject value associated with an individual's choice as the statistical expectations of that individual's valuations of the outcomes of this choice. Despite its success in studies of game theory and decision theory, the effectiveness of EU, however, is mostly unknown in e-commerce recommendation systems. Previous research on e-commerce recommendation interprets the utility of purchase decisions either as a function of the consumed quantity of the product or as the gain of sellers/buyers in the monetary sense. As most consumers just purchase one unit of a product at a time and most alternatives have similar prices, such modeling of purchase utility is likely to be inaccurate in practice. In this paper, we interpret purchase utility as the satisfaction level a consumer gets from a product and propose a recommendation framework using EU to model consumers' behavioral patterns. We assume that consumer estimates the expected utilities of all the alternatives and choose products with maximum expected utility for each purchase. To deal with the potential psychological biases of each consumer, we introduce the usage of Probability Weight Function (PWF) and design our algorithm based on Weighted Expected Utility (WEU). Empirical study on real-world e-commerce datasets shows that our proposed ranking-based recommendation framework achieves statistically significant improvement against both classical Collaborative Filtering/Latent Factor Models and state-of-the-art deep models in top-K recommendation.</p>
<p>Keywords:</p>
<h3 id="172. NHP: Neural Hypergraph Link Prediction.">172. NHP: Neural Hypergraph Link Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411870">Paper Link</a>    Pages:1705-1714</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/220/5382.html">Naganand Yadati</a> ; <a href="https://dblp.uni-trier.de/pid/252/5277.html">Vikram Nitin</a> ; <a href="https://dblp.uni-trier.de/pid/180/5919.html">Madhav Nimishakavi</a> ; <a href="https://dblp.uni-trier.de/pid/220/5741.html">Prateek Yadav</a> ; <a href="https://dblp.uni-trier.de/pid/72/7588.html">Anand Louis</a> ; <a href="https://dblp.uni-trier.de/pid/86/687.html">Partha P. Talukdar</a></p>
<p>Abstract:
Link prediction insimple graphs is a fundamental problem in which new links between vertices are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among vertices that go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is a need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Graph Convolutional Network (GCN) has recently emerged as a powerful deep learning-based approach for link prediction over simple graphs. However, their suitability for link prediction in hypergraphs is underexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP -- NHP-U and NHP-D -- for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first-ever method for link prediction over directed hypergraphs. An important feature of NHP is that it can also be used for hyperlinks in which dissimilar vertices interact (e.g. acids reacting with bases). Another attractive feature of NHP is that it can be used to predict unseen hyperlinks at test time (inductive hyperlink prediction). Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness.</p>
<p>Keywords:</p>
<h3 id="173. Fair Class Balancing: Enhancing Model Fairness without Observing Sensitive Attributes.">173. Fair Class Balancing: Enhancing Model Fairness without Observing Sensitive Attributes.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411980">Paper Link</a>    Pages:1715-1724</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/51/8939.html">Shen Yan</a> ; <a href="https://dblp.uni-trier.de/pid/239/7453.html">Hsien-Te Kao</a> ; <a href="https://dblp.uni-trier.de/pid/38/8773.html">Emilio Ferrara</a></p>
<p>Abstract:
Machine learning models are at the foundation of modern society. Accounts of unfair models penalizing subgroups of a population have been reported in domains including law enforcement, job screening, etc. Unfairness can spur from biases in the training data, as well as from class imbalance, i.e., when a sensitive group's data is not sufficiently represented. Under such settings, balancing techniques are commonly used to achieve better prediction performance, but their effects on model fairness are largely unknown. In this paper, we first illustrate the extent to which common balancing techniques exacerbate unfairness in real-world data. Then, we propose a new method, called fair class balancing, that allows to enhance model fairness without using any information about sensitive attributes. We show that our method can achieve accurate prediction performance while concurrently improving fairness.</p>
<p>Keywords:</p>
<h3 id="174. Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching.">174. Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411908">Paper Link</a>    Pages:1725-1734</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/27/3367.html">Liu Yang</a> ; <a href="https://dblp.uni-trier.de/pid/76/4874-1.html">Mingyang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/16/6465-12.html">Cheng Li</a> ; <a href="https://dblp.uni-trier.de/pid/80/4305.html">Michael Bendersky</a> ; <a href="https://dblp.uni-trier.de/pid/n/MarcNajork.html">Marc Najork</a></p>
<p>Abstract:
Many natural language processing and information retrieval problems can be formalized as the task of semantic matching. Existing work in this area has been largely focused on matching between short texts (e.g., question answering), or between a short and a long text (e.g., ad-hoc retrieval). Semantic matching between long-form documents, which has many important applications like news recommendation, related article recommendation and document clustering, is relatively less explored and needs more research effort. In recent years, self-attention based models like Transformers and BERT have achieved state-of-the-art performance in the task of text matching. These models, however, are still limited to short text like a few sentences or one paragraph due to the quadratic computational complexity of self-attention with respect to input text length. In this paper, we address the issue by proposing the Siamese Multi-depth Transformer-based Hierarchical (SMITH) Encoder for long-form document matching. Our model contains several innovations to adapt self-attention models for longer text input. We propose a transformer based hierarchical encoder to capture the document structure information. In order to better capture sentence level semantic relations within a document, we pre-train the model with a novel masked sentence block language modeling task in addition to the masked word language modeling task used by BERT. Our experimental results on several benchmark data sets for long-form document matching show that our proposed SMITH model outperforms the previous state-of-the-art models including hierarchical attention, multi-depth attention-based hierarchical recurrent neural network, and BERT. Comparing to BERT based baselines, our model is able to increase maximum input text length from 512 to 2048. We will open source a Wikipedia based benchmark data set, code and a pre-trained model to accelerate future research on long-form document matching.</p>
<p>Keywords:</p>
<h3 id="175. NagE: Non-Abelian Group Embedding for Knowledge Graphs.">175. NagE: Non-Abelian Group Embedding for Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411875">Paper Link</a>    Pages:1735-1742</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/44/7710.html">Tong Yang</a> ; <a href="https://dblp.uni-trier.de/pid/139/3857.html">Long Sha</a> ; <a href="https://dblp.uni-trier.de/pid/89/4734.html">Pengyu Hong</a></p>
<p>Abstract:
We demonstrated the existence of a group algebraic structure hidden in relational knowledge embedding problems, which suggests that a group-based embedding framework is essential for designing embedding models. Our theoretical analysis explores merely the intrinsic property of the embedding problem itself hence is model independent. Motivated by the theoretical analysis, we have proposed a group theory-based knowledge graph embedding framework, in which relations are embedded as group elements, and entities are represented by vectors in group action spaces. We provide a generic recipe to construct embedding models associated with two instantiating examples: SO3E and SU2E, both of which apply a continuous non-Abelian group as the relation embedding. Empirical experiments using these two exampling models have shown state-of-the-art results on benchmark datasets.</p>
<p>Keywords:</p>
<h3 id="176. LB-CGM: Latent Based Conditional Generative Model with Reliable Distribution Prediction.">176. LB-CGM: Latent Based Conditional Generative Model with Reliable Distribution Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412002">Paper Link</a>    Pages:1743-1751</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/178/7287.html">Yichen Yao</a> ; <a href="https://dblp.uni-trier.de/pid/130/0123.html">Guozheng Li</a> ; <a href="https://dblp.uni-trier.de/pid/74/3270.html">Yujie Chen</a> ; <a href="https://dblp.uni-trier.de/pid/171/2216.html">Rongqi Li</a> ; <a href="https://dblp.uni-trier.de/pid/119/6410.html">Yinzhi Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/37/4356.html">Xiaodong Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/205/3156.html">Haoyuan Hu</a> ; <a href="https://dblp.uni-trier.de/pid/15/2775.html">Yinghui Xu</a></p>
<p>Abstract:
Randomness exists either due to the inherent noise of the problem or lack of important input features, which could lead to multimodality of the data distribution. Therefore, in more and more scenarios, it is required not only to predict a single point-value, but also the distribution of the prediction. However, well-studied prediction models usually focus on point prediction that minimizes the mean squared error or the mean absolute error. These approaches could miss important knowledge when their outputs are applied to the downstream decision process. In this paper, we combine the advantages of both GANs (Generative Adversarial Nets) and VAEs (Variational Auto-Encoders), and introduce a latent-based conditional generative model (LB-CGM) to handle the distribution regression problems. The VAE framework is adopted, and the adversarial network is applied to estimate the validity of the generated sample. Besides, the latent-based reconstruction loss is introduced to mitigate mode collapse, in which the direct pairwise comparison between the original and generated samples ensures the correctness and completeness of the generated mode pattern. In this work, we explore a path for the generative model to be used in probabilistic prediction problems. This method can produce conditional prediction distribution close to the actual distribution and is verified on both the synthetic dataset and benchmark dataset.</p>
<p>Keywords:</p>
<h3 id="177. LSAN: Modeling Long-term Dependencies and Short-term Correlations with Hierarchical Attention for Risk Prediction.">177. LSAN: Modeling Long-term Dependencies and Short-term Correlations with Hierarchical Attention for Risk Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411864">Paper Link</a>    Pages:1753-1762</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/251/3433.html">Muchao Ye</a> ; <a href="https://dblp.uni-trier.de/pid/198/0850.html">Junyu Luo</a> ; <a href="https://dblp.uni-trier.de/pid/170/1833.html">Cao Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/85/10856.html">Fenglong Ma</a></p>
<p>Abstract:
Risk prediction using electronic health records (EHR) is a challenging data mining task due to the two-level hierarchical structure of EHR data. EHR data consist of a set of time-ordered visits, and within each visit, there is a set of unordered diagnosis codes. Existing approaches focus on modeling temporal visits with deep neural network (DNN) techniques. However, they ignore the importance of modeling diagnosis codes within visits, and a lot of task-unrelated information within visits usually leads to unsatisfactory performance of existing approaches. To minimize the effect caused by noise information of EHR data, in this paper, we propose a novel DNN for risk prediction termed as LSAN, which consists of a Hierarchical Attention Module (HAM) and a Temporal Aggregation Module (TAM). Particularly, LSAN applies HAM to model the hierarchical structure of EHR data. Using the attention mechanism in the hierarchy of diagnosis code, HAM is able to retain diagnosis details and assign flexible attention weights to different diagnosis codes by their relevance to corresponding diseases. Moreover, the attention mechanism in the hierarchy of visit learns a comprehensive feature throughout the visit history by paying greater attention to visits with higher relevance. Based on the foundation laying by HAM, TAM uses a two-pathway structure to learn a robust temporal aggregation mechanism among all visits for LSAN. It extracts long-term dependencies by a Transformer encoder and short-term correlations by a parallel convolutional layer among different visits. With the construction of HAM and TAM, LSAN achieves the state-of-the-art performance on three real-world datasets with larger AUCs, recalls and F1 scores. Furthermore, the model analysis results demonstrate the effectiveness of the network construction with good interpretability and robustness of decision making by LSAN.</p>
<p>Keywords:</p>
<h3 id="178. Logic Enhanced Commonsense Inference with Chain Transformer.">178. Logic Enhanced Commonsense Inference with Chain Transformer.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411895">Paper Link</a>    Pages:1763-1772</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/194/1605.html">Chenxi Yuan</a> ; <a href="https://dblp.uni-trier.de/pid/00/4572.html">Chun Yuan</a> ; <a href="https://dblp.uni-trier.de/pid/39/6825.html">Yang Bai</a> ; <a href="https://dblp.uni-trier.de/pid/187/3454.html">Ziran Li</a></p>
<p>Abstract:
We study the commonsense inference task that aims to reason and generate the causes and effects of a given event. Existing neural methods focus more on understanding and representing the event itself, but pay little attention to the relations between different commonsense dimensions (e.g. causes or effects) of the event, making the generated results logically inconsistent and unreasonable. To alleviate this issue, we propose Chain Transformer, a logic enhanced commonsense inference model that combines both direct and indirect inferences to construct a logical chain so as to reason in a more logically consistent way. First, we apply a self-attention based encoder to represent and encode the given event. Then a chain of decoders is implemented to reason and generate for different dimensions following the logical chain, where an attention module is designed to link different decoders and to make each decoder attend to the previous reasoned inferences. Experiments on two real-world datasets show that Chain Transformer outperforms previous methods on both automatic and human evaluation, and demonstrate that Chain Transformer can generate more reasonable and logically consistent inference results.</p>
<p>Keywords:</p>
<h3 id="179. Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering.">179. Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411917">Paper Link</a>    Pages:1773-1782</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/19/772.html">Feng Yuan</a> ; <a href="https://dblp.uni-trier.de/pid/56/6651.html">Lina Yao</a> ; <a href="https://dblp.uni-trier.de/pid/b/BoualemBenatallah.html">Boualem Benatallah</a></p>
<p>Abstract:
Adversarial examples can be detrimental to a recommender,leading to a surging enthusiasm for applying adversarial learning to improve recommendation performance, e.g. raising model robustness, alleviating data sparsity, generating initial profiles for cold-start users or items, etc. Most existing adversarial example generation methods fall within three categories: attacking the user-item interactions or auxiliary contents, adding perturbations in latent space, sampling the latent space according to certain distribution. In this work, we focus on the semantic-rich user-item interactions in a recommender system and propose a novel generative adversarial network (GAN) named Convolutional Generative Collaborative Filtering (Conv-GCF). We develop an effective perturbation mechanism (adversarial noise layer) for convolutional neural networks (CNN), based on which we design a generator with residual blocks to synthesize user-item interactions. We empirically demonstrate that on Conv-GCF, the adversarial noise layer is superior to the conventional noise-adding approach. Moreover, we propose two types of discriminators: one using Bayes Personalized Ranking (BPR) and the other with binary classification. On four public datasets, we show that our approach achieves the state-of-the-art top-n recommendation performance among competitive baselines.</p>
<p>Keywords:</p>
<h3 id="180. GeneraLight: Improving Environment Generalization of Traffic Signal Control via Meta Reinforcement Learning.">180. GeneraLight: Improving Environment Generalization of Traffic Signal Control via Meta Reinforcement Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411859">Paper Link</a>    Pages:1783-1792</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/176/1415.html">Huichu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/52/5716-21.html">Chang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/28/10261-1.html">Weinan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/204/3356.html">Guanjie Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/43/5685-1.html">Yong Yu</a></p>
<p>Abstract:
The heavy traffic congestion problem has always been a concern for modern cities. To alleviate traffic congestion, researchers use reinforcement learning (RL) to develop better traffic signal control (TSC) algorithms in recent years. However, most RL models are trained and tested in the same traffic flow environment, which results in a serious overfitting problem. Since the traffic flow environment in the real world keeps varying, these models can hardly be applied due to the lack of generalization ability. Besides, the limited number of accessible traffic flow data brings extra difficulty in testing the generalization ability of the models. In this paper, we design a novel traffic flow generator based on Wasserstein generative adversarial network to generate sufficient diverse and quality traffic flows and use them to build proper training and testing environments. Then we propose a meta-RL TSC framework GeneraLight to improve the generalization ability of TSC models. GeneraLight boosts the generalization performance by combining the idea of flow clustering and model-agnostic meta-learning. We conduct extensive experiments on multiple real-world datasets to show the superior performance of GeneraLight on generalizing to different traffic flows.</p>
<p>Keywords:</p>
<h3 id="181. TOMATO: A Topic-Wise Multi-Task Sparsity Model.">181. TOMATO: A Topic-Wise Multi-Task Sparsity Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411972">Paper Link</a>    Pages:1793-1802</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/188/3925.html">Jason (Jiasheng) Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/l/DongwonLee.html">Dongwon Lee</a></p>
<p>Abstract:
The Multi-Task Learning (MTL) leverages the inter-relationship across tasks and is useful for applications with limited data. Existing works articulate different task relationship assumptions, whose validity is vital to successful multi-task training. We observe that, in many scenarios, the inter-relationship across tasks varies across different groups of data (i.e., topic), which we call within-topic task relationship hypothesis. In this case, current MTL models with homogeneous task relationship assumption cannot fully exploit different task relationships among different groups of data. Based on this observation, in this paper, we propose a generalized topic-wise multi-task architecture, to capture the within-topic task relationship, which can be combined with any existing MTL designs. Further, we propose a new specialized MTL design, topic-task-sparsity, along with two different types of sparsity constraints. The architecture, combined with the topic-task-sparsity design, constructs our proposed TOMATO model. The experiments on both synthetic and 4 real-world datasets show that our proposed models consistently outperform 6 state-of-the-art models and 2 baselines with improvement from $5%$ to $46%$ in terms of task-wise comparison, demonstrating the validity of the proposed within-topic task relationship hypothesis. We release the source codes and datasets of TOMATO at: <a href="https://github.com/JasonLC506/MTSEM">https://github.com/JasonLC506/MTSEM</a>.</p>
<p>Keywords:</p>
<h3 id="182. More Than One: A Cluster-Prototype Matching Framework for Zero-Shot Learning.">182. More Than One: A Cluster-Prototype Matching Framework for Zero-Shot Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411883">Paper Link</a>    Pages:1803-1812</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/05/3499.html">Jing Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/190/7083.html">Yangli-ao Geng</a> ; <a href="https://dblp.uni-trier.de/pid/29/4219.html">Qingyong Li</a> ; <a href="https://dblp.uni-trier.de/pid/64/3041.html">Chuan Shi</a></p>
<p>Abstract:
Zero-shot learning (ZSL) aims to recognize unseen categories whose data is unavailable during the training stage. Most existing ZSL algorithms focus on learning an embedding space and determine the classes of test samples according to sample-prototype similarities in this space. However, we observe that, in contrast to the single sample-prototype relationship, an ensemble criterion usually benefits the final classification, just as the saying "more than one". Inspired by this, we introduce a novel cluster-prototype matching (CPM) strategy and propose a ZSL framework based on CPM. Firstly, we learn a mapping between the visual space and the semantic space utilizing a well-established ZSL algorithm. Via the learned mapping, all test samples are projected into the embedding space and clustered in this space. Secondly, two CPM methods, soft-CPM and hard-CPM, are proposed to match clusters and class prototypes, along with cluster-prototype similarities calculated. Finally, the label of each sample is determined by the combination of the sample-prototype similarity and the cluster-prototype similarity. We apply our framework to five basic ZSL methods and compare them with several advanced baselines of ZSL. The experimental results demonstrate that the proposed framework can significantly improve the performance of the basic ZSL models and help them achieve or beyond the state-of-the-art.</p>
<p>Keywords:</p>
<h3 id="183. A Feature-Importance-Aware and Robust Aggregator for GCN.">183. A Feature-Importance-Aware and Robust Aggregator for GCN.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411983">Paper Link</a>    Pages:1813-1822</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/89/5992.html">Li Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/96/142.html">Haiping Lu</a></p>
<p>Abstract:
Neighborhood aggregation is a key step in Graph Convolutional Networks (GCNs) for graph representation learning. Two commonly used aggregators, sum and mean, are designed with the homophily assumption that connected nodes are likely to share the same label. However, real-world graphs are noisy and adjacent nodes do not necessarily imply similarity.Learnable aggregators are proposed in Graph Attention Network (GAT) and Learnable Graph Convolutional Layer (LGCL). However, GAT considers node importance but not the importance of different features. The convolution aggregator in LGCL considers feature importance but it can not directly operate on graphs due to the irregular connectivity and lack of orderliness. In this paper, we firstly unify the current learnable aggregators in a framework: Learnable Aggregator for GCN (LA-GCN) by introducing a shared auxiliary model that provides a customized schema in neighborhood aggregation. Under this framework, we propose a new model called LA-GCNMask consisting of a new aggregator function,mask aggregator. The auxiliary model learns a specific mask for each neighbor of a given node, allowing both node-level and feature-level attention. This mechanism learns to assign different importance to both nodes and features for prediction, which provides interpretable explanations for prediction and increases the model robustness. Experiments on seven graphs for node classification and graph classification tasks show that LA-GCNMask outperforms the state-of-the-art methods. Moreover, our aggregator can identify both the important nodes and node features simultaneously, which provides a quantified understanding of the relationship between input nodes and the prediction. We further conduct experiments on noisy graphs to evaluate the robustness of our model. Experiments show that LA-GCNMask consistently outperforms the state-of-the-art methods, with up to 15% improvements in terms of accuracy compared to the second best.</p>
<p>Keywords:</p>
<h3 id="184. Query Understanding via Intent Description Generation.">184. Query Understanding via Intent Description Generation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411999">Paper Link</a>    Pages:1823-1832</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/203/8270.html">Ruqing Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/02/146.html">Jiafeng Guo</a> ; <a href="https://dblp.uni-trier.de/pid/188/2160.html">Yixing Fan</a> ; <a href="https://dblp.uni-trier.de/pid/00/6040.html">Yanyan Lan</a> ; <a href="https://dblp.uni-trier.de/pid/44/912.html">Xueqi Cheng</a></p>
<p>Abstract:
Query understanding is a fundamental problem in information retrieval (IR), which has attracted continuous attention through the past decades. Many different tasks have been proposed for understanding users' search queries, e.g., query classification or query clustering. However, it is not that precise to understand a search query at the intent class/cluster level due to the loss of many detailed information. As we may find in many benchmark datasets, e.g., TREC and SemEval, queries are often associated with a detailed description provided by human annotators which clearly describes its intent to help evaluate the relevance of the documents. If a system could automatically generate a detailed and precise intent description for a search query, like human annotators, that would indicate much better query understanding has been achieved. In this paper, therefore, we propose a novel Query-to-Intent-Description (Q2ID) task for query understanding. Unlike those existing ranking tasks which leverage the query and its description to compute the relevance of documents, Q2ID is a reverse task which aims to generate a natural language intent description based on both relevant and irrelevant documents of a given query. To address this new task, we propose a novel Contrastive Generation model, namely CtrsGen for short, to generate the intent description by contrasting the relevant documents with the irrelevant documents given a query. We demonstrate the effectiveness of our model by comparing with several state-of-the-art generation models on the Q2ID task. We discuss the potential usage of such Q2ID technique through an example application.</p>
<p>Keywords:</p>
<h3 id="185. Generating Categories for Sets of Entities.">185. Generating Categories for Sets of Entities.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412019">Paper Link</a>    Pages:1833-1842</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/83/3714-6.html">Shuo Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/85/4125.html">Krisztian Balog</a> ; <a href="https://dblp.uni-trier.de/pid/c/JamesPCallan.html">Jamie Callan</a></p>
<p>Abstract:
Category systems are central components of knowledge bases, as they provide a hierarchical grouping of semantically related concepts and entities. They are a unique and valuable resource that is utilized in a broad range of information access tasks. To aid knowledge editors in the manual process of expanding a category system, this paper presents a method of generating categories for sets of entities. First, we employ neural abstractive summarization models to generate candidate categories. Next, the location within the hierarchy is identified for each candidate. Finally, structure-, content-, and hierarchy-based features are used to rank candidates to identify by the most promising ones (measured in terms of specificity, hierarchy, and importance). We develop a test collection based on Wikipedia categories and demonstrate the effectiveness of the proposed approach.</p>
<p>Keywords:</p>
<h3 id="186. CommDGI: Community Detection Oriented Deep Graph Infomax.">186. CommDGI: Community Detection Oriented Deep Graph Infomax.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412042">Paper Link</a>    Pages:1843-1852</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/76/4971.html">Tianqi Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/67/4330.html">Yun Xiong</a> ; <a href="https://dblp.uni-trier.de/pid/10/239.html">Jiawei Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/57/3892-9.html">Yao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/250/9757.html">Yizhu Jiao</a> ; <a href="https://dblp.uni-trier.de/pid/43/3858.html">Yangyong Zhu</a></p>
<p>Abstract:
Graph Neural Networks(GNNs), like GCN and GAT, have achieved great success in a number of supervised or semi-supervised tasks including node classification and link prediction. These existing graph neural networks can effectively encode neighborhood information of graph nodes through their message aggregating mechanisms. However, there are some unsupervised and structure-related tasks like community detection, which is a fundamental problem in network analysis that finds densely-connected groups of nodes and separates them from others in graphs. It is still difficult for these general-purposed GNNs to learn the needed structural information in these particular problems. To overcome the shortcomings of general-purposed graph representation learning methods, we propose the Community Deep Graph Infomax (CommDGI), a graph neural network designed to handle community detection problems. Inspired by the success of deep graph infomax in self-supervised graph learning, we design a novel mutual information mechanism to capture neighborhood as well as community information in graphs. A trainable clustering layer is employed to learn the community partition in an end-to-end manner. Disentangled representation learning is applied in our graph neural network so that the model can improve interpretability and generalization. Throughout the whole learning process, joint optimization is applied to learn the community-related node representations. The experimental results show that our algorithm outperforms state-of-the-art community detection methods.</p>
<p>Keywords:</p>
<h3 id="187. Spatial-Temporal Convolutional Graph Attention Networks for Citywide Traffic Flow Forecasting.">187. Spatial-Temporal Convolutional Graph Attention Networks for Citywide Traffic Flow Forecasting.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411941">Paper Link</a>    Pages:1853-1862</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/35/9455.html">Xiyue Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/18/4087.html">Chao Huang</a> ; <a href="https://dblp.uni-trier.de/pid/07/4630.html">Yong Xu</a> ; <a href="https://dblp.uni-trier.de/pid/270/6586.html">Lianghao Xia</a></p>
<p>Abstract:
Traffic flow prediction plays an important role in many spatial-temporal data applications, e.g., traffic management and urban planning. Various deep learning techniques are developed to model the traffic dynamic patterns with different neural network architectures, such as attention mechanism, recurrent neural network. However, two important challenges have yet to be well addressed: (i) Most of these methods solely focus on local spatial dependencies and ignore the global inter-region dependencies in terms of traffic distributions; (ii) It is important to capture channel-aware semantics when performing spatial-temporal information aggregation. To address these challenges, we propose a new traffic prediction framework--Spatial-Temporal Convolutional Graph Attention Network (ST-CGA), to enable the traffic prediction with the modeling of region dependencies, from locally to globally in a comprehensive manner. In our ST-CGA framework, we first develop a hierarchical attention networks with a graph-based neural architecture, to capture both the multi-level temporal relations and cross-region traffic dependencies. Furthermore, a region-wise spatial relation encoder is proposed to supercharge ST-CGA mapping spatial and temporal signals into different representation subspaces, with channel-aware recalibration residual network. Extensive experiments on four real-world datasets demonstrate that ST-CGA achieve substantial gains over many state-of-the-art baselines. Source codes are available at: <a href="https://github.com/shurexiyue/ST-CGA">https://github.com/shurexiyue/ST-CGA</a>.</p>
<p>Keywords:</p>
<h3 id="188. Semi-Supervised Graph-to-Graph Translation.">188. Semi-Supervised Graph-to-Graph Translation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411977">Paper Link</a>    Pages:1863-1872</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/232/5561.html">Tianxiang Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/33/7694.html">Xianfeng Tang</a> ; <a href="https://dblp.uni-trier.de/pid/91/4353.html">Xiang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/136/9440.html">Suhang Wang</a></p>
<p>Abstract:
Graph translation is very promising research direction and has awide range of potential real-world applications. Graph is a natural structure for representing relationship and interactions, and its translation can encode the intrinsic semantic changes of relation-ships in different scenarios. However, despite its seemingly wide possibilities, usage of graph translation so far is still quite limited.One important reason is the lack of high-quality paired dataset. For example, we can easily build graphs representing peoples? shared music tastes and those representing co-purchase behavior, but a well paired dataset is much more expensive to obtain. Therefore,in this work, we seek to provide a graph translation model in the semi-supervised scenario. This task is non-trivial, because graph translation involves changing the semantics in the form of link topology and node attributes, which is difficult to capture due to the combinatory nature and inter-dependencies. Furthermore, due to the high order of freedom in graph's composition, it is difficult to assure the generalization ability of trained models. These difficulties impose a tighter requirement for the exploitation of unpaired samples. Addressing them, we propose to construct a dual representation space, where transformation is performed explicitly to model the semantic transitions. Special encoder/decoder structures are designed, and auxiliary mutual information loss is also adopted to enforce the alignment of unpaired/paired examples. We evaluate the proposed method in three different datasets.</p>
<p>Keywords:</p>
<h3 id="189. Error-Bounded Graph Anomaly Loss for GNNs.">189. Error-Bounded Graph Anomaly Loss for GNNs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411979">Paper Link</a>    Pages:1873-1882</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/94/6503-3.html">Tong Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/276/5044.html">Chuchen Deng</a> ; <a href="https://dblp.uni-trier.de/pid/276/5059.html">Kaifeng Yu</a> ; <a href="https://dblp.uni-trier.de/pid/207/5395.html">Tianwen Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/223/3148.html">Daheng Wang</a> ; <a href="https://dblp.uni-trier.de/pid/69/339-1.html">Meng Jiang</a></p>
<p>Abstract:
Graph neural networks (GNNs) have been widely used to learn node representations from graph data in an unsupervised way for downstream tasks. However, when applied to detect anomalies (e.g., outliers, unexpected density), they deliver unsatisfactory performance as existing loss functions fail. For example, any loss based on random walk (RW) algorithms would no longer work because the assumption that anomalous nodes were close with each other could not hold. Moreover, the nature of class imbalance in anomaly detection tasks brings great challenges to reduce the prediction error. In this work, we propose a novel loss function to train GNNs for anomaly-detectable node representations. It evaluates node similarity using global grouping patterns discovered from graph mining algorithms. It can automatically adjust margins for minority classes based on data distribution. Theoretically, we prove that the prediction error is bounded given the proposed loss function. We empirically investigate the GNN effectiveness of different loss variants based on different algorithms. Experiments on two real-world datasets show that they perform significantly better than RW-based loss for graph anomaly detection.</p>
<p>Keywords:</p>
<h3 id="190. Whole-Chain Recommendations.">190. Whole-Chain Recommendations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412044">Paper Link</a>    Pages:1883-1891</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/08/890.html">Xiangyu Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/160/7582.html">Long Xia</a> ; <a href="https://dblp.uni-trier.de/pid/193/4216.html">Lixin Zou</a> ; <a href="https://dblp.uni-trier.de/pid/93/4010.html">Hui Liu</a> ; <a href="https://dblp.uni-trier.de/pid/91/4572.html">Dawei Yin</a> ; <a href="https://dblp.uni-trier.de/pid/64/10812.html">Jiliang Tang</a></p>
<p>Abstract:
With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in developing RL-based recommender systems. In practical recommendation sessions, users will sequentially access multiple scenarios, such as the entrance pages and the item detail pages, and each scenario has its specific characteristics. However, the majority of existing RL-based recommender systems focus on optimizing one strategy for all scenarios or separately optimizing each strategy, which could lead to sub-optimal overall performance. In this paper, we study the recommendation problem with multiple (consecutive) scenarios, i.e., whole-chain recommendations. We propose a multi-agent RL-based approach (DeepChain), which can capture the sequential correlation among different scenarios and jointly optimize multiple recommendation strategies. To be specific, all recommender agents (RAs) share the same memory of users' historical behaviors, and they work collaboratively to maximize the overall reward of a session. Note that optimizing multiple recommendation strategies jointly faces two challenges in the existing model-free RL model - (i) it requires huge amounts of user behavior data, and (ii) the distribution of reward (users' feedback) are extremely unbalanced. In this paper, we introduce model-based RL techniques to reduce the training data requirement and execute more accurate strategy updates. The experimental results based on a real e-commerce platform demonstrate the effectiveness of the proposed framework.</p>
<p>Keywords:</p>
<h3 id="191. S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization.">191. S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411954">Paper Link</a>    Pages:1893-1902</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/48/3927.html">Kun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/39/721.html">Hui Wang</a> ; <a href="https://dblp.uni-trier.de/pid/52/8700.html">Wayne Xin Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/71/9704.html">Yutao Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/93/10146.html">Sirui Wang</a> ; <a href="https://dblp.uni-trier.de/pid/134/2883.html">Fuzheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/84/6394.html">Zhongyuan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
Recently, significant progress has been made in sequential recommendation with deep learning. Existing neural sequential recommendation models usually rely on the item prediction loss to learn model parameters or data representations. However, the model trained with this loss is prone to suffer from data sparsity problem. Since it overemphasizes the final performance, the association or fusion between context data and sequence data has not been well captured and utilized for sequential recommendation.</p>
<p>Keywords:</p>
<h3 id="192. Top-k Graph Summarization on Hierarchical DAGs.">192. Top-k Graph Summarization on Hierarchical DAGs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411899">Paper Link</a>    Pages:1903-1912</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/272/4234.html">Xuliang Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/98/5766.html">Xin Huang</a> ; <a href="https://dblp.uni-trier.de/pid/07/1560.html">Byron Choi</a> ; <a href="https://dblp.uni-trier.de/pid/x/JianliangXu.html">Jianliang Xu</a></p>
<p>Abstract:
Directed acyclic graph (DAG) is an essentially important model to represent terminologies and their hierarchical relationships, such as Disease Ontology. Due to massive terminologies and complex structures in a large DAG, it is challenging to summarize the whole hierarchical DAG.</p>
<p>Keywords:</p>
<h3 id="193. When Structure Meets Keywords: Cohesive Attributed Community Search.">193. When Structure Meets Keywords: Cohesive Attributed Community Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412006">Paper Link</a>    Pages:1913-1922</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/14/10147.html">Yuanyuan Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/24/6837.html">Jian He</a> ; <a href="https://dblp.uni-trier.de/pid/276/5058.html">Junhao Ye</a> ; <a href="https://dblp.uni-trier.de/pid/51/5585.html">Lu Qin</a> ; <a href="https://dblp.uni-trier.de/pid/98/5766.html">Xin Huang</a> ; <a href="https://dblp.uni-trier.de/pid/y/JXuYu.html">Jeffrey Xu Yu</a></p>
<p>Abstract:
As an online, query-dependent variant of the well-known community detection problem, community search has been studied for years to find communities containing the query vertices. Along with the generation of graphs with rich attribute information, attributed community search has attracted increasing interest recently, aiming to select communities where vertices are cohesively connected and share homogeneous attributes. However, existing community models may include cut-edges/vertices and thus cannot well guarantee the strong connectivity required by a cohesive community. In this paper, we propose a new cohesive attributed community (CAC) model that can ensure both structure cohesiveness and attribute cohesiveness of communities. Specifically, for a query with vertex vq and keyword set S, we aim to find the cohesively connected communities containing vq with the most shared keywords in S. It is nontrivial as we need to explore all possible subsets of S to verify the existence of structure cohesive communities until we find the communities with the most common keywords. To tackle this problem, we make efforts in two aspects. The first is to reduce the candidate keyword subsets. We achieve this by exploring the anti-monotonicity and neighborhood-constraint properties of our CAC model so that we can filter out the unpromising keyword subsets. The second is to speed up the verification process for each candidate keyword subset. We propose two indexes TIndex and MTIndex to reduce the size of the candidate subgraph before the verification. Moreover, we derive two new properties based on these indexes to reduce the candidate keyword subsets further. We conducted extensive experimental studies on four real-world graphs and validated the effectiveness and efficiency of our approaches.</p>
<p>Keywords:</p>
<h3 id="194. LRHNE: A Latent-Relation Enhanced Embedding Method for Heterogeneous Information Networks.">194. LRHNE: A Latent-Relation Enhanced Embedding Method for Heterogeneous Information Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411891">Paper Link</a>    Pages:1923-1932</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/138/5936.html">Zhihua Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/06/2888.html">Xinxin Fan</a> ; <a href="https://dblp.uni-trier.de/pid/240/9271.html">Xiaokai Chu</a> ; <a href="https://dblp.uni-trier.de/pid/29/592.html">Jianhui Huang</a> ; <a href="https://dblp.uni-trier.de/pid/46/4889.html">Jingping Bi</a></p>
<p>Abstract:
Heterogeneous information networks (HINs) have been successfully applied into several fields to accomplish complex data analytics, such as bibliography, bioinformatics, NLP, etc. In the meantime, network embedding at present has emerged as a convenient tool to mine and learn from networked data. As a result, it is of interest to develop HIN embedding methods. Despite recent breakthroughs in HIN embedding methods, little research attention has been paid to exploit the relation semantics in HINs and further integrate it to improve the embedding quality. Considering the sophisticated correlations in HINs, we in this paper propose a novel HIN embedding method LRHNE to yield latent-relation enhanced embeddings for nodes. Our work mainly involves three contributions: i) we verify that the latent relation can promote the embedding quality indeed through a real-world dataset, then a novel graph inception network is proposed to extract the latent relational features under the guidance of partial prior knowledge; ii) taking into account the existing structure information and inferred latent relation knowledge, we propose a cross-aligned variational graph autoencoder to extract and further fuse both the structure and latent relational features into the embeddings; and iii) we perform extensive experiments to validate our proposed LRHNE, and experimental results show that our LRHNE can significantly outperform state-of-the-art methods. The multi-facet inspections also exhibit our method is robust and hyper-parameter insensitive, therefore, our method can serve as a radical tool to tackle the relation-sophisticated HINs.</p>
<p>Keywords:</p>
<h3 id="195. Corpus Bootstrapping for Assessment of the Properties of Effectiveness Measures.">195. Corpus Bootstrapping for Assessment of the Properties of Effectiveness Measures.</h3>
<p><a href="https://doi.org/10.1145/3340531.3411998">Paper Link</a>    Pages:1933-1952</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/z/JZobel.html">Justin Zobel</a> ; <a href="https://dblp.uni-trier.de/pid/08/10247.html">Lida Rashidi</a></p>
<p>Abstract:
Bootstrapping is an established tool for examining the behaviour of offline information retrieval (IR) experiments, where it has primarily been used to assess statistical significance and the robustness of significance tests. In this work we consider how bootstrapping can be used to assess the reliability of effectiveness measures for experimental IR. We use bootstrapping of the corpus of documents rather than, as in most prior work, the set of queries. We demonstrate that bootstrapping can provide new insights into the behaviour of effectiveness measures: the precision of the measurement of a system for a query can be quantified; some measures are more consistent than others; rankings of systems on a test corpus likewise have a precision (or uncertainty) that can be quantified; and, in experiments with limited volumes of relevance judgements, measures can be wildly different in terms of reliability and precision. Our results show that the uncertainty in measurement and ranking of system performance can be substantial and thus our approach to corpus bootstrapping provides a key tool for helping experimenters to choose measures and understand reported outcomes.</p>
<p>Keywords:</p>
<h2 id="Short Paper Track    102">Short Paper Track    102</h2>
<h3 id="196. Building Test Collections using Bandit Techniques: A Reproducibility Study.">196. Building Test Collections using Bandit Techniques: A Reproducibility Study.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412121">Paper Link</a>    Pages:1953-1956</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/245/4221.html">Bahadir Altun</a> ; <a href="https://dblp.uni-trier.de/pid/115/5953.html">Mucahid Kutlu</a></p>
<p>Abstract:
The high cost of constructing test collections led many researchers to develop intelligent document selection methods to find relevant documents with fewer judgments than the standard pooling method requires. In this paper, we conduct a comprehensive set of experiments to evaluate six bandit-based document selection methods, in terms of evaluation reliability, fairness, and reusability of the resultant test collections. In our experiments, the best performing method varies across test collections, showing the importance of using diverse test collections for an accurate performance analysis. Our experiments with six test collections also show that Move-To-Front is the most robust method among the ones we investigate.</p>
<p>Keywords:</p>
<h3 id="197. FDCM: Towards Balanced and Generalizable Concept-based Models for Effective Medical Ranking.">197. FDCM: Towards Balanced and Generalizable Concept-based Models for Effective Medical Ranking.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412151">Paper Link</a>    Pages:1957-1960</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/75/4002.html">Mohammad Bahrani</a> ; <a href="https://dblp.uni-trier.de/pid/r/TRolleke.html">Thomas Roelleke</a></p>
<p>Abstract:
Concept-based IR is expected to improve the quality of medical ranking since it captures more semantics than BOW representations. However, bringing concepts and BOW together into a transparent IR framework is challenging. We propose a new aggregation parameter to combine conceptual and term-based Dirichlet Compound Model scores effectively. The determination of this linear parameter is the result of exploring to what degree the difference of the conceptual and term-based sum of IDFs is influential to the integration. Instead of employing heuristics to find combined models, this paper aims to build the grounds for establishing reasonable aggregation standards based on semantic query performance predictors.</p>
<p>Keywords:</p>
<h3 id="198. Application Performance Anomaly Detection with LSTM on Temporal Irregularities in Logs.">198. Application Performance Anomaly Detection with LSTM on Temporal Irregularities in Logs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412157">Paper Link</a>    Pages:1961-1964</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/27/6813.html">Xavier Baril</a> ; <a href="https://dblp.uni-trier.de/pid/250/0699.html">Oihana Cousti</a> ; <a href="https://dblp.uni-trier.de/pid/m/JosianeMothe.html">Josiane Mothe</a> ; <a href="https://dblp.uni-trier.de/pid/t/OlivierTeste.html">Olivier Teste</a></p>
<p>Abstract:
Performance anomalies are a core problem in modern information systems, that affects the execution of the hosted applications. The detection of these anomalies often relies on the analysis of the application execution logs. The current most effective approach is to detect samples that differ from a learnt nominal model. However, current methods often focus on detecting sequential anomalies in logs, neglecting the time elapsed between logs, which is a core component of the performance anomaly detection. In this paper, we develop a new model for performance anomaly detection that captures temporal deviations from the nominal model, by means of a sliding window data representation. This nominal model is trained by a Long Short-Term Memory neural network, which is appropriate to represent complex sequential dependencies. We assess the effectiveness of our model on both simulated and real datasets. We show that it is more robust to temporal variations than current state-of-the-art approaches, while remaining as effective.</p>
<p>Keywords:</p>
<h3 id="199. Automatic Gaussian Process Model Retrieval for Big Data.">199. Automatic Gaussian Process Model Retrieval for Big Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412182">Paper Link</a>    Pages:1965-1968</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/236/7409.html">Fabian Berns</a> ; <a href="https://dblp.uni-trier.de/pid/40/998.html">Christian Beecks</a></p>
<p>Abstract:
Gaussian Process Models (GPMs) are widely regarded as a prominent tool for capturing the inherent characteristics of data. These bayesian machine learning models allow for data analysis tasks such as regression and classification. Usually a process of automatic GPM retrieval is needed to find an optimal model for a given dataset, despite prevailing default instantiations and existing prior knowledge in some scenarios, which both shortcut the way to an optimal GPM. Since non-approximative Gaussian Processes only allow for processing small datasets with low statistical versatility, we propose a new approach that allows to efficiently and automatically retrieve GPMs for large-scale data. The resulting model is composed of independent statistical representations for non-overlapping segments of the given data. Our performance evaluation of the new approach demonstrates the quality of resulting models, which clearly outperform default GPM instantiations, while maintaining reasonable model training time.</p>
<p>Keywords:</p>
<h3 id="200. Query Abandonment Prediction with Recurrent Neural Models of Mouse Cursor Movements.">200. Query Abandonment Prediction with Recurrent Neural Models of Mouse Cursor Movements.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412126">Paper Link</a>    Pages:1969-1972</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5097.html">Lukas Brckner</a> ; <a href="https://dblp.uni-trier.de/pid/07/6290.html">Ioannis Arapakis</a> ; <a href="https://dblp.uni-trier.de/pid/61/4278.html">Luis A. Leiva</a></p>
<p>Abstract:
Most successful search queries do not result in a click if the user can satisfy their information needs directly on the SERP. Modeling query abandonment in the absence of click-through data is challenging because search engines must rely on other behavioral signals to understand the underlying search intent. We show that mouse cursor movements make a valuable, low-cost behavioral signal that can discriminate good and bad abandonment. We model mouse movements on SERPs using recurrent neural nets and explore several data representations that do not rely on expensive hand-crafted features and do not depend on a particular SERP structure. We also experiment with data resampling and augmentation techniques that we adopt for sequential data. Our results can help search providers to gauge user satisfaction for queries without clicks and ultimately contribute to a better understanding of search engine performance.</p>
<p>Keywords:</p>
<h3 id="201. NumClaim: Investor's Fine-grained Claim Detection.">201. NumClaim: Investor's Fine-grained Claim Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412100">Paper Link</a>    Pages:1973-1976</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/177/6602.html">Chung-Chi Chen</a> ; <a href="https://dblp.uni-trier.de/pid/23/10489.html">Hen-Hsen Huang</a> ; <a href="https://dblp.uni-trier.de/pid/84/3130.html">Hsin-Hsi Chen</a></p>
<p>Abstract:
The goal of claim detection in argument mining is to sort out the key points from a long narrative. In this paper, we design a novel task for argument mining in the financial domain, and provide an expert-annotated dataset, NumClaim, for the proposed task. Based on the statistics, we discuss the differences between the claims in other datasets and the claims of the investors in NumClaim. With the ablation analysis, we show that encoding numeral and co-training with the auxiliary task of the numeral understanding, i.e., the category classification task, can improve the performance of the proposed task under different neural network architectures. The annotations in the NumClaim is published for academic usage under the CC BY-NC-SA 4.0 license.</p>
<p>Keywords:</p>
<h3 id="202. Label-Aware Graph Convolutional Networks.">202. Label-Aware Graph Convolutional Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412139">Paper Link</a>    Pages:1977-1980</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/175/3324.html">Hao Chen</a> ; <a href="https://dblp.uni-trier.de/pid/29/3925.html">Yue Xu</a> ; <a href="https://dblp.uni-trier.de/pid/163/3996.html">Feiran Huang</a> ; <a href="https://dblp.uni-trier.de/pid/238/1004.html">Zengde Deng</a> ; <a href="https://dblp.uni-trier.de/pid/155/3181.html">Wenbing Huang</a> ; <a href="https://dblp.uni-trier.de/pid/118/5055.html">Senzhang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/84/6016.html">Peng He</a> ; <a href="https://dblp.uni-trier.de/pid/76/2866.html">Zhoujun Li</a></p>
<p>Abstract:
Recent advances in Graph Convolutional Networks (GCNs) have led to state-of-the-art performance on various graph-related tasks. However, most existing GCN models do not explicitly identify whether all the aggregated neighbors are valuable to the learning tasks, which may harm the learning performance. In this paper, we consider the problem of node classification and propose the Label-Aware Graph Convolutional Network (LAGCN) framework which can directly identify valuable neighbors to enhance the performance of existing GCN models. Our contribution is three-fold. First, we propose a label-aware edge classifier that can filter distracting neighbors and add valuable neighbors for each node to refine the original graph into a label-aware (LA) graph. Existing GCN models can directly learn from the LA graph to improve the performance without changing their model architectures. Second, we introduce the concept of positive ratio to evaluate the density of valuable neighbors in the LA graph. Theoretical analysis reveals that using the edge classifier to increase the positive ratio can improve the learning performance of existing GCN models. Third, we conduct extensive node classification experiments on benchmark datasets. The results verify that LAGCN can improve the performance of existing GCN models considerably, in terms of node classification.</p>
<p>Keywords:</p>
<h3 id="203. Graph Unfolding Networks.">203. Graph Unfolding Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412141">Paper Link</a>    Pages:1981-1984</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/175/3324.html">Hao Chen</a> ; <a href="https://dblp.uni-trier.de/pid/155/3181.html">Wenbing Huang</a> ; <a href="https://dblp.uni-trier.de/pid/29/3925.html">Yue Xu</a> ; <a href="https://dblp.uni-trier.de/pid/02/2737.html">Fuchun Sun</a> ; <a href="https://dblp.uni-trier.de/pid/76/2866.html">Zhoujun Li</a></p>
<p>Abstract:
The technique of recursive neighborhood aggregation has dominated the implementation of existing successful Graph Neural Networks (GNNs). However, the recursive information propagation across layers inevitably brings in extra calculations, potentially large variance, and difficulty of parallel computation. In this paper, we propose Graph Unfolding Networks (GUNets) as an alternative mechanism of recursive neighborhood aggregation for graph representation learning. Comparing to generic GNNs, our proposed GUNets are efficient, robust and practically effective. At their core, GUNets unfold the local structure of every node, i.e. the rooted tree, to a set of trajectories, and then adopt set function to capture the topology of the rooted subtree, which is more convenient for parallel computation than the recursive neighborhood aggregation process. More importantly, through a specific design of the set function, our architecture enables efficient and robust learning on large-scale graphs without resorting to any pruning of the rooted subtree that is usually necessary in generic GNNs. Extensive experiments on five large datasets (the number of nodes ranges from 104 to 106) show that our GUNets achieve comparable or even better results than current successful GNNs while gaining significantly more efficiency and lower accuracy variance. Codes can be found at github.com/GUNets/GUNets.</p>
<p>Keywords:</p>
<h3 id="204. CONE-Align: Consistent Network Alignment with Proximity-Preserving Node Embedding.">204. CONE-Align: Consistent Network Alignment with Proximity-Preserving Node Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412136">Paper Link</a>    Pages:1985-1988</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/15/2639.html">Xiyuan Chen</a> ; <a href="https://dblp.uni-trier.de/pid/215/4357.html">Mark Heimann</a> ; <a href="https://dblp.uni-trier.de/pid/136/3815.html">Fatemeh Vahedian</a> ; <a href="https://dblp.uni-trier.de/pid/91/9987.html">Danai Koutra</a></p>
<p>Abstract:
Network alignment, the process of finding correspondences between nodes in different graphs, has many scientific and industrial applications. Existing unsupervised network alignment methods find suboptimal alignments that break up node neighborhoods, i.e. do not preserve matched neighborhood consistency. To improve this, we propose CONE-Align, which models intra-network proximity with node embeddings and uses them to match nodes across networks after aligning the embedding subspaces. Experiments on diverse, challenging datasets show that CONE-Align is robust and obtains 19.25% greater accuracy on average than the best-performing state-of-the-art graph alignment algorithm in highly noisy settings.</p>
<p>Keywords:</p>
<h3 id="205. Generative Adversarial Attributed Network Anomaly Detection.">205. Generative Adversarial Attributed Network Anomaly Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412070">Paper Link</a>    Pages:1989-1992</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/71/2937.html">Zhenxing Chen</a> ; <a href="https://dblp.uni-trier.de/pid/58/2670.html">Bo Liu</a> ; <a href="https://dblp.uni-trier.de/pid/45/1777.html">Meiqing Wang</a> ; <a href="https://dblp.uni-trier.de/pid/08/3547.html">Peng Dai</a> ; <a href="https://dblp.uni-trier.de/pid/30/731.html">Jun Lv</a> ; <a href="https://dblp.uni-trier.de/pid/17/6808.html">Liefeng Bo</a></p>
<p>Abstract:
Anomaly detection is a useful technique in many applications such as network security and fraud detection. Due to the insufficiency of anomaly samples as training data, it is usually formulated as an unsupervised model learning problem. In recent years there is a surge of adopting graph data structure in numerous applications. Detecting anomaly in an attributed network is more challenging than the sample based task because of the sample information representations in the form of graph nodes and edges. In this paper, we propose a generative adversarial attributed network (GAAN) anomaly detection framework. The fake graph nodes are generated by a generator module with Gaussian noise as input. An encoder module is employed to map both real and fake graph nodes into a latent space. To encode the graph structure information into the node latent representation, we compute the sample covariance matrix for real nodes and fake nodes respectively. A discriminator is trained to recognize whether two connected nodes are from the real or fake graph. With the learned encoder module output, an anomaly evaluation measurement considering the sample reconstruction error and real-sample identification confidence is employed to make prediction. We conduct extensive experiments on benchmark datasets and compare with state-of-the-art attributed graph anomaly detection methods. The superior AUC score demonstrates the effectiveness of the proposed method.</p>
<p>Keywords:</p>
<h3 id="206. Joint Estimation of User And Publisher Credibility for Fake News Detection.">206. Joint Estimation of User And Publisher Credibility for Fake News Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412066">Paper Link</a>    Pages:1993-1996</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5102.html">Rajdipa Chowdhury</a> ; <a href="https://dblp.uni-trier.de/pid/74/3399-4.html">Sriram Srinivasan</a> ; <a href="https://dblp.uni-trier.de/pid/g/LiseGetoor.html">Lise Getoor</a></p>
<p>Abstract:
Fast propagation, ease-of-access, and low cost have made social media an increasingly popular means for news consumption. However, this has also led to an increase in the preponderance of fake news. Widespread propagation of fake news can be detrimental to society, and this has created enormous interest in fake news detection on social media. Many approaches to fake news detection use the news content, social context, or both. In this work, we look at fake news detection as a problem of estimating the credibility of both the news publishers and users that propagate news articles. We introduce a new approach called the credibility score-based model that can jointly infer fake news and credibility scores for publishers and users. We use a state-of-the-art statistical relational learning framework called probabilistic soft logic to perform this joint inference effectively. We show that our approach is accurate at both fake news detection and inferring credibility scores. Further, our model can easily integrate any auxiliary information that can aid in fake news detection. Using the FakeNewsNet dataset, we show that our approach significantly outperforms previous approaches at fake news detection by up to 10% in recall and 4% in accuracy. Furthermore, the credibility scores learned for both publishers and users are representative of their true behavior.</p>
<p>Keywords:</p>
<h3 id="207. Learning Discriminative Virtual Sequences for Time Series Classification.">207. Learning Discriminative Virtual Sequences for Time Series Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412099">Paper Link</a>    Pages:2001-2004</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5045.html">Abhilash Dorle</a> ; <a href="https://dblp.uni-trier.de/pid/52/1767.html">Fangyu Li</a> ; <a href="https://dblp.uni-trier.de/pid/63/4299.html">Wenzhan Song</a> ; <a href="https://dblp.uni-trier.de/pid/23/3439.html">Sheng Li</a></p>
<p>Abstract:
Temporal data are continuously collected in a wide range of domains. The increasing availability of such data has led to significant developments of time series analysis. Time series classification, as an essential task in time series analysis, aims to assign a set of temporal sequences to different categories. Among various approaches for time series classification, the distance metric learning based ones, such as the virtual sequence metric learning (VSML), have attracted increased attention due to their remarkable performance. In VSML, virtual sequences attract samples from different classes to facilitate time series classification. However, the existing VSML methods simply employ fixed virtual sequences, which might not be optimal for the subsequent classification tasks. To address this issue, in this paper, we propose a novel time series classification method named Discriminative Virtual Sequence Learning (DVSL). Following the unified framework of sequence metric learning, our DVSL method jointly learns a set of discriminative virtual sequences that help separate time series samples in a feature space, and optimizes the temporal alignment by dynamic time warping. Extensive experiments on 15 UCR time series datasets demonstrate the efficiency of DVSL, compared with several representative baselines.</p>
<p>Keywords:</p>
<h3 id="208. DECWA: Density-Based Clustering using Wasserstein Distance.">208. DECWA: Density-Based Clustering using Wasserstein Distance.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412125">Paper Link</a>    Pages:2005-2008</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/218/4766.html">Nabil El Malki</a> ; <a href="https://dblp.uni-trier.de/pid/276/5043.html">Robin Cugny</a> ; <a href="https://dblp.uni-trier.de/pid/t/OlivierTeste.html">Olivier Teste</a> ; <a href="https://dblp.uni-trier.de/pid/23/1370.html">Franck Ravat</a></p>
<p>Abstract:
Clustering is a data analysis method for extracting knowledge by discovering groups of data called clusters. Among these methods, state-of-the-art density-based clustering methods have proven to be effective for arbitrary-shaped clusters. Despite their encouraging results, they suffer to find low-density clusters, near clusters with similar densities, and high-dimensional data. Our proposals are a new characterization of clusters and a new clustering algorithm based on spatial density and probabilistic approach. First of all, sub-clusters are built using spatial density represented as probability density function (p.d.f) of pairwise distances between points. A method is then proposed to agglomerate similar sub-clusters by using both their density (p.d.f) and their spatial distance. The key idea we propose is to use the Wasserstein metric, a powerful tool to measure the distance between p.d.f of sub-clusters. We show that our approach outperforms other state-of-the-art density-based clustering methods on a wide variety of datasets.</p>
<p>Keywords:</p>
<h3 id="209. Why is That a Background Article: A Qualitative Analysis of Relevance for News Background Linking.">209. Why is That a Background Article: A Qualitative Analysis of Relevance for News Background Linking.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412120">Paper Link</a>    Pages:2009-2012</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/260/2094.html">Marwa Essam</a> ; <a href="https://dblp.uni-trier.de/pid/99/5856.html">Tamer Elsayed</a></p>
<p>Abstract:
News background linking is the problem of finding online resources that can provide valuable context and background information to help the reader comprehend a given news article. While the problem has recently attracted several researchers, however, the notion of background relevance is not well-studied and it requires better understanding to ensure effective system performance. In this paper, we conduct a qualitative analysis on a sample of 25 query news articles and 152 of their corresponding background articles, in addition to 50 of non-background ones. The goal of the study is to shed some light on the relationship between the query articles and the background articles, and provide informative insights for developing more effective background retrieval models. For instance, our analysis shows that event-driven query articles are, on average, harder to process than others, hence they should be handled differently. It also shows that discussing subtopics in detail and adding new informative topics are both essential factors for highly-relevant background articles. Moreover, it shows that a high lexical similarity between a query article and a background one is neither sufficient nor necessary.</p>
<p>Keywords:</p>
<h3 id="210. Hybrid Dynamic Pruning for Efficient and Effective Query Processing.">210. Hybrid Dynamic Pruning for Efficient and Effective Query Processing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412113">Paper Link</a>    Pages:2013-2016</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/262/1282.html">Wenxiu Fang</a> ; <a href="https://dblp.uni-trier.de/pid/169/9502.html">Trent G. Marbach</a> ; <a href="https://dblp.uni-trier.de/pid/71/4292.html">Gang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/25/1221.html">Xiaoguang Liu</a></p>
<p>Abstract:
The performance of query processing has always been a concern in the field of information retrieval. Dynamic pruning algorithms have been proposed to improve query processing performance in terms of efficiency and effectiveness. However, a single pruning algorithm generally does not have both advantages. In this work, we investigate the performance of the main dynamic pruning algorithms in terms of average and tail latency as well as the accuracy of query results, and find that they are complementary. Inspired by these findings, we propose two types of hybrid dynamic pruning algorithms that choose different combinations of strategies according to the characteristics of each query. Experimental results demonstrate that our proposed methods yield a good balance between both efficiency and effectiveness.</p>
<p>Keywords:</p>
<h3 id="211. Sample Optimization For Display Advertising.">211. Sample Optimization For Display Advertising.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412162">Paper Link</a>    Pages:2017-2020</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/58/6731.html">Hongliang Fei</a> ; <a href="https://dblp.uni-trier.de/pid/97/8692.html">Shulong Tan</a> ; <a href="https://dblp.uni-trier.de/pid/276/5123.html">Pengju Guo</a> ; <a href="https://dblp.uni-trier.de/pid/31/966.html">Wenbo Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/267/0061.html">Hongfang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/62/5860-1.html">Ping Li</a></p>
<p>Abstract:
Sample optimization, which involves sample augmentation and sample refinement, is an essential but often neglected component in modern display advertising platforms. Due to the massive number of ad candidates, industrial ad service usually leverages a multi-layer funnel-shaped structure involving at least two stages: candidate generation and re-ranking. In the candidate generation step, an offline neural network matching model is often trained based on past click/conversion data to obtain the user feature vector and ad feature vector. However, there is a covariate shift problem between the user observed ads and all possible ones. As a result, the candidate generation model trained from the click/conversion history cannot fully capture users' potential intentions or generalize well to unseen ads. In this paper, we utilize several sample optimization strategies to alleviate the covariate shift problem for training candidate generation models. We have launched these strategies in Baidu display ad platform and achieved considerable improvements in offline metrics, including both offline click-recall, cost-recall, as well as online metric cost per mille (CPM).</p>
<p>Keywords:</p>
<h3 id="212. A Reinforced Semi-supervised Neural Network for Helpful Review Identification.">212. A Reinforced Semi-supervised Neural Network for Helpful Review Identification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412101">Paper Link</a>    Pages:2021-2024</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/13/6965.html">Yue Feng</a> ; <a href="https://dblp.uni-trier.de/pid/130/8157.html">Miao Fan</a> ; <a href="https://dblp.uni-trier.de/pid/87/8665.html">Mingming Sun</a> ; <a href="https://dblp.uni-trier.de/pid/62/5860.html">Ping Li</a></p>
<p>Abstract:
It is crucial to recommend helpful product reviews to consumers in e-commercial service, as the helpful ones can promote consumption. Existing methods for identifying helpful reviews are based on the supervised learning paradigm. The capacity of supervised methods, however, is limited by the lack of annotated reviews. In addition, there is a serious distributional bias between the labeled and unlabeled reviews. Therefore, this paper proposes a reinforced semi-supervised neural learning method (abbreviated as RSSNL) for helpful review identification, which can automatically select high-related unlabeled reviews to help training. Concretely, RSSNL composes with a reinforced unlabeled review selection policy and a semi-supervised pseudo-labeling review classifier. These two parts train jointly and integrate together based on the policy gradient framework. Extensive experiments on Amazon product reviews verify the effectiveness of RSSNL for using unlabeled reviews.</p>
<p>Keywords:</p>
<h3 id="213. A View-Adversarial Framework for Multi-View Network Embedding.">213. A View-Adversarial Framework for Multi-View Network Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412127">Paper Link</a>    Pages:2025-2028</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/273/0228.html">Dongqi Fu</a> ; <a href="https://dblp.uni-trier.de/pid/97/3701.html">Zhe Xu</a> ; <a href="https://dblp.uni-trier.de/pid/50/3402.html">Bo Li</a> ; <a href="https://dblp.uni-trier.de/pid/58/1757.html">Hanghang Tong</a> ; <a href="https://dblp.uni-trier.de/pid/34/2685.html">Jingrui He</a></p>
<p>Abstract:
Network embedding has demonstrated effective empirical performance for various network mining tasks such as node classification, link prediction, clustering, and anomaly detection. However, most of these algorithms focus on the single-view network scenario. From a real-world perspective, one individual node can have different connectivity patterns in different networks. For example, one user can have different relationships on Twitter, Facebook, and LinkedIn due to varying user behaviors on different platforms. In this case, jointly considering the structural information from multiple platforms (i.e., multiple views) can potentially lead to more comprehensive node representations, and eliminate noises and bias from a single view. In this paper, we propose a view-adversarial framework to generate comprehensive and robust multi-view network representations named VANE, which is based on two adversarial games. The first adversarial game enhances the comprehensiveness of the node representation by discriminating the view information which is obtained from the subgraph induced by neighbors of that node. The second adversarial game improves the robustness of the node representation with the challenging of fake node representations from the generative adversarial net. We conduct extensive experiments on downstream tasks with real-world multi-view networks, which shows that our proposed VANE framework significantly outperforms other baseline methods.</p>
<p>Keywords:</p>
<h3 id="214. Can Adversarial Weight Perturbations Inject Neural Backdoors.">214. Can Adversarial Weight Perturbations Inject Neural Backdoors.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412130">Paper Link</a>    Pages:2029-2032</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/82/8467.html">Siddhant Garg</a> ; <a href="https://dblp.uni-trier.de/pid/117/9889-1.html">Adarsh Kumar</a> ; <a href="https://dblp.uni-trier.de/pid/136/3911.html">Vibhor Goel</a> ; <a href="https://dblp.uni-trier.de/pid/88/7458.html">Yingyu Liang</a></p>
<p>Abstract:
Adversarial machine learning has exposed several security hazards of neural models. Thus far, the concept of an "adversarial perturbation" has exclusively been used with reference to the input space referring to a small, imperceptible change which can cause a ML model to err. In this work we extend the idea of "adversarial perturbations" to the space of model weights, specifically to inject backdoors in trained DNNs, which exposes a security risk of publicly available trained models. Here, injecting a backdoor refers to obtaining a desired outcome from the model when a trigger pattern is added to the input, while retaining the original predictions on a non-triggered input. From the perspective of an adversary, we characterize these adversarial perturbations to be constrained within an  norm around the original model weights. We introduce adversarial perturbations in model weights using a composite loss on the predictions of the original model and the desired trigger through projected gradient descent. Our results show that backdoors can be successfully injected with a very small average relative change in model weight values for several CV and NLP applications.</p>
<p>Keywords:</p>
<h3 id="215. Estimating Topic Difficulty Using Normalized Discounted Cumulated Gain.">215. Estimating Topic Difficulty Using Normalized Discounted Cumulated Gain.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412109">Paper Link</a>    Pages:2033-2036</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/245/1834.html">Lukas Gienapp</a> ; <a href="https://dblp.uni-trier.de/pid/69/4806-1.html">Benno Stein</a> ; <a href="https://dblp.uni-trier.de/pid/95/1130.html">Matthias Hagen</a> ; <a href="https://dblp.uni-trier.de/pid/87/6573.html">Martin Potthast</a></p>
<p>Abstract:
Information retrieval evaluation has to consider the varying "difficulty" between topics. Topic difficulty is often defined in terms of the aggregated effectiveness of a set of retrieval systems to satisfy a respective information need. Current approaches to estimate topic difficulty come with drawbacks such as being incomparable across different experimental settings. We introduce a new approach to estimate topic difficulty, which is based on the ratio of systems that achieve an NDCG score that is better than a baseline formed as random ranking of the pool of judged documents. We modify the NDCG measure to explicitly reflect a system's divergence from this hypothetical random ranker. In this way we achieve relative comparability of topic difficulty scores across experimental settings as well as stability to outlier systems?features lacking in previous difficulty estimations. We reevaluate the TREC 2012 Web Track's ad hoc task to demonstrate the feasibility of our approach in practice.</p>
<p>Keywords:</p>
<h3 id="216. The Impact of Negative Relevance Judgments on NDCG.">216. The Impact of Negative Relevance Judgments on NDCG.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412123">Paper Link</a>    Pages:2037-2040</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/245/1834.html">Lukas Gienapp</a> ; <a href="https://dblp.uni-trier.de/pid/256/9118.html">Maik Frbe</a> ; <a href="https://dblp.uni-trier.de/pid/95/1130.html">Matthias Hagen</a> ; <a href="https://dblp.uni-trier.de/pid/87/6573.html">Martin Potthast</a></p>
<p>Abstract:
NDCG is one of the most commonly used measures to quantify system performance in retrieval experiments. Though originally not considered, graded relevance judgments nowadays frequently include negative labels. Negative relevance labels cause NDCG to be unbounded. This is probably why widely used implementations of NDCG map negative relevance labels to zero, thus ensuring the resulting scores to originate from the [0,1] range. But zeroing negative labels discards valuable relevance information, e.g., by treating spam documents the same as unjudged ones, which are assigned the relevance label of zero by default. We show that, instead of zeroing negative labels, a min-max-normalization of NDCG retains its statistical power while improving its reliability and stability.</p>
<p>Keywords:</p>
<h3 id="217. Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots.">217. Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412330">Paper Link</a>    Pages:2041-2044</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/93/3604.html">Jia-Chen Gu</a> ; <a href="https://dblp.uni-trier.de/pid/239/8678.html">Tianda Li</a> ; <a href="https://dblp.uni-trier.de/pid/67/6917.html">Quan Liu</a> ; <a href="https://dblp.uni-trier.de/pid/70/5210.html">Zhen-Hua Ling</a> ; <a href="https://dblp.uni-trier.de/pid/173/0908.html">Zhiming Su</a> ; <a href="https://dblp.uni-trier.de/pid/06/7720.html">Si Wei</a> ; <a href="https://dblp.uni-trier.de/pid/93/310.html">Xiaodan Zhu</a></p>
<p>Abstract:
In this paper, we study the problem of employing pre-trained language models for multi-turn response selection in retrieval-based chatbots. A new model, named Speaker-Aware BERT (SA-BERT), is proposed in order to make the model aware of the speaker change information, which is an important and intrinsic property of multi-turn dialogues. Furthermore, a speaker-aware disentanglement strategy is proposed to tackle the entangled dialogues. This strategy selects a small number of most important utterances as the filtered context according to the speakers' information in them. Finally, domain adaptation is performed to incorporate the in-domain knowledge into pre-trained language models. Experiments on five public datasets show that our proposed model outperforms the present models on all metrics by large margins and achieves new state-of-the-art performances for multi-turn response selection.</p>
<p>Keywords:</p>
<h3 id="218. Subsampled Randomized Hadamard Transform for Regression of Dynamic Graphs.">218. Subsampled Randomized Hadamard Transform for Regression of Dynamic Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412158">Paper Link</a>    Pages:2045-2048</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/98/6406.html">Mostafa Haghir Chehreghani</a></p>
<p>Abstract:
A well-known problem in data science and machine learning is linear regression, which is recently extended to dynamic graphs. Existing exact algorithms for updating solutions of dynamic graph regression require at least a linear time (in terms of n: the number of nodes of the graph). However, this time complexity might be intractable in practice. In this paper, we utilize subsampled randomized Hadamard transform to propose a randomized algorithm for dynamic graphs. Suppose that we are given an nxm matrix embedding M of the graph, where m  n. Let r be the number of samples required for a guaranteed approximation error, which is a sublinear function of n. After an edge insertion or an edge deletion in the graph, our algorithm updates the approximate solution in O(rm) time.</p>
<p>Keywords:</p>
<h3 id="219. Learning to Form Skill-based Teams of Experts.">219. Learning to Form Skill-based Teams of Experts.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412140">Paper Link</a>    Pages:2049-2052</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/232/3038.html">Radin Hamidi Rad</a> ; <a href="https://dblp.uni-trier.de/pid/166/4506.html">Hossein Fani</a> ; <a href="https://dblp.uni-trier.de/pid/27/3128.html">Mehdi Kargar</a> ; <a href="https://dblp.uni-trier.de/pid/06/9379.html">Jaroslaw Szlichta</a> ; <a href="https://dblp.uni-trier.de/pid/25/806.html">Ebrahim Bagheri</a></p>
<p>Abstract:
We focus on the composition of teams of experts that collectively cover a set of required skills based on their historical collaboration network and expertise. Prior works are primarily based on the shortest path between experts on the expert collaboration network, and suffer from three major shortcomings: (1) they are computationally expensive due to the complexity of finding paths on large network structures; (2) they use a small portion of the entire historical collaboration network to reduce the search space; hence, may form sub-optimal teams; and, (3) they fall short in sparse networks where the majority of the experts have only participated in a few teams in the past. Instead of forming a large network of experts, we propose to learn relationships among experts and skills through a variational Bayes neural architecture wherein: i) we consider all past team compositions as training instances to predict future teams; ii) we bring scalability for large networks of experts due to the neural architecture; and, iii) we address sparsity by incorporating uncertainty on the neural network's parameters which yields a richer representation and more accurate team composition. We empirically demonstrate how our proposed model outperforms the state-of-the-art approaches in terms of effectiveness and efficiency based on a large DBLP dataset.</p>
<p>Keywords:</p>
<h3 id="220. GAEAT: Graph Auto-Encoder Attention Networks for Knowledge Graph Completion.">220. GAEAT: Graph Auto-Encoder Attention Networks for Knowledge Graph Completion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412148">Paper Link</a>    Pages:2053-2056</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/180/2780.html">Yanfei Han</a> ; <a href="https://dblp.uni-trier.de/pid/119/0328.html">Quan Fang</a> ; <a href="https://dblp.uni-trier.de/pid/28/441.html">Jun Hu</a> ; <a href="https://dblp.uni-trier.de/pid/138/4249.html">Shengsheng Qian</a> ; <a href="https://dblp.uni-trier.de/pid/85/1301.html">Changsheng Xu</a></p>
<p>Abstract:
Knowledge graph embedding (KGE) encodes components of a KG including entities and relations into continuous low vector space. Most existing methods focus on treating entities and relations in triples independently and thus failing to capture the complex and hidden information that is inherently implicit inside the local neighborhood surrounding a triple. In this paper, we present a new approach for knowledge graph completion called GAEAT (Graph Auto-encoder Attention Network Embedding), which can encapsulate both entity and relation features. Specifically, we construct a triple-level auto-encoder by extending graph attention mechanisms to obtain latent representations of entities and relations simultaneously. To justify our proposed model, we evaluate GAEAT on two real-world datasets. The experimental results demonstrate that GAEAT can outperform state-of-the-art KGE models in knowledge graph completion task, which validates the effectiveness of GAEAT. The source code of this paper can be obtained from <a href="https://github.com/TomersHan/GAEAT">https://github.com/TomersHan/GAEAT</a>.</p>
<p>Keywords:</p>
<h3 id="221. Learning to Re-Rank with Contextualized Stopwords.">221. Learning to Re-Rank with Contextualized Stopwords.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412079">Paper Link</a>    Pages:2057-2060</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/238/6322.html">Sebastian Hofsttter</a> ; <a href="https://dblp.uni-trier.de/pid/150/5264.html">Aldo Lipani</a> ; <a href="https://dblp.uni-trier.de/pid/200/5842.html">Markus Zlabinger</a> ; <a href="https://dblp.uni-trier.de/pid/55/6683.html">Allan Hanbury</a></p>
<p>Abstract:
The use of stopwords has been thoroughly studied in traditional Information Retrieval systems, but remains unexplored in the context of neural models. Neural re-ranking models take the full text of both the query and document into account. Naturally, removing tokens that do not carry relevance information provides us with an opportunity to improve the effectiveness by reducing noise and lower document representation caching-storage requirements. In this work we propose a novel contextualized stopword detection mechanism for neural re-ranking models. This mechanism consists of training a sparse vector in order to filter out document tokens from the ranking decision. This vector is learned end-to-end based on the contextualized document representations, allowing the model to filter terms on a per occurrence basis. This leads to a more explainable model, as it reduces noise. We integrate our component into the state-of-the-art interaction-based TK neural re-ranking model. Our experiments on the MS MARCO passage collection and queries from the TREC 2019 Deep Learning Track show that filtering out traditional stopwords prior to the neural model reduces its effectiveness, while learning to filter out contextualized representations improves it.</p>
<p>Keywords:</p>
<h3 id="222. DATSING: Data Augmented Time Series Forecasting with Adversarial Domain Adaptation.">222. DATSING: Data Augmented Time Series Forecasting with Adversarial Domain Adaptation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412155">Paper Link</a>    Pages:2061-2064</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/209/7188.html">Hailin Hu</a> ; <a href="https://dblp.uni-trier.de/pid/77/4752.html">MingJian Tang</a> ; <a href="https://dblp.uni-trier.de/pid/226/9453.html">Chengcheng Bai</a></p>
<p>Abstract:
Due to the high temporal uncertainty and low signal-to-noise ratio, transfer learning for univariate time series forecasting remains a challenging task. In addition, data scarcity, which is commonly encountered in business forecasting, further limits the application of conventional transfer learning protocols. In this work, we have developed, DATSING, a transfer learning-based framework that effectively leverages cross-domain time series latent representations to augment target domain forecasting. In particular, we aim to transfer domain-invariant feature representations from a pre-trained stacked deep residual network to the target domains, so as to assist the prediction of each target time series. To effectively avoid noisy feature representations, we propose a two-phased framework which first clusters similar mixed domains time series data and then performs a fine-tuning procedure with domain adversarial regularization to achieve better out-of-sample generalization. Extensive experiments with real-world datasets have demonstrated that our method significantly improves the forecasting performance of the pre-trained model. DATSING has the unique potential to empower forecasting practitioners to unleash the power of cross-domain time series data.</p>
<p>Keywords:</p>
<h3 id="223. Homogenization with Explicit Semantics Preservation for Heterogeneous Information Network.">223. Homogenization with Explicit Semantics Preservation for Heterogeneous Information Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412135">Paper Link</a>    Pages:2065-2068</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/180/7292.html">Tiancheng Huang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5034.html">Zifeng Zhuang</a> ; <a href="https://dblp.uni-trier.de/pid/34/3535.html">Shanshan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/80/7163.html">Donglin Wang</a></p>
<p>Abstract:
Heterogeneous information network (HIN), especially its embedding task, has drawn much attention recently as its rich latent information brings great benefits to complex classification and clustering. Many prior embedding works focus on designing a specific approach for the HIN while others implicitly homogenize the HIN with losing some semantic information. In this paper, a novel explicit homogenization method is proposed to preserve more semantic information, where the latent information of intermediate nodes among each meta-path instance and that among multiple meta-path instances are incorporated into the conventional adjacent matrix (or weight matrix). Then, the transfer of weight matrix and the fusion of node-level embeddings are considered to obtain graph-level embedding to solve the HIN problem. In such way, much more latent information of meta-path is preserved so that the proposed method exhibits its superiority in comparison to state-of-the-art works in classification and clustering tasks.</p>
<p>Keywords:</p>
<h3 id="224. DistilSum: : Distilling the Knowledge for Extractive Summarization.">224. DistilSum: : Distilling the Knowledge for Extractive Summarization.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412078">Paper Link</a>    Pages:2069-2072</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/231/9095.html">Ruipeng Jia</a> ; <a href="https://dblp.uni-trier.de/pid/97/5152.html">Yanan Cao</a> ; <a href="https://dblp.uni-trier.de/pid/180/1745.html">Haichao Shi</a> ; <a href="https://dblp.uni-trier.de/pid/74/3719.html">Fang Fang</a> ; <a href="https://dblp.uni-trier.de/pid/84/4048.html">Yanbing Liu</a> ; <a href="https://dblp.uni-trier.de/pid/19/336.html">Jianlong Tan</a></p>
<p>Abstract:
A popular choice for extractive summarization is to conceptualize it as sentence-level classification, supervised by binary labels. While the common metric ROUGE prefers to measure the text similarity, instead of the performance of classifier. For example, BERTSUMEXT, the best extractive classifier so far, only achieves a precision of 32.9% at the top 3 extracted sentences ([email protected]) on CNN/DM dataset. It is obvious that current approaches cannot model the complex relationship of sentences exactly with 0/1 targets. In this paper, we introduce DistilSum, which contains teacher mechanism and student model. Teacher mechanism produces high entropy soft targets at a high temperature. Our student model is trained with the same temperature to match these informative soft targets and tested with temperature of 1 to distill for ground-truth labels. Compared with large version of BERTSUMEXT, our experimental result on CNN/DM achieves a substantial improvement of 0.99 ROUGE-L score (text similarity) and 3.95 [email protected] score (performance of classifier). Our source code will be available on Github.</p>
<p>Keywords:</p>
<h3 id="225. T-REX: A Topic-Aware Relation Extraction Model.">225. T-REX: A Topic-Aware Relation Extraction Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412133">Paper Link</a>    Pages:2073-2076</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/193/7295.html">Woohwan Jung</a> ; <a href="https://dblp.uni-trier.de/pid/s/KyuseokShim.html">Kyuseok Shim</a></p>
<p>Abstract:
Document-level relation extraction (RE) has recently received a lot of attention. However, existing models for document-level RE have similar structures to the models for sentence-level RE. Thus, they still do not consider some unique characteristics of the new problem setting. For example, in Wikipedia, there is a title for each page and it usually represents the topic entity that is mainly described on the page. In many cases, the topic entity is omitted in the text. Thus, existing RE models often fail to find the relations with the omitted topic entity. To tackle the problem, we propose a Topic-aware Relation EXtraction (T-REX) model. To extract the relations with the (possibly omitted) topic entity, the proposed model first encodes the topic entity by aggregating the information of all its mentions in the document. Then it finds the relations between the topic entity and each mention of other entities. Finally, the output layer combines the mention-wise results and outputs all relations expressed in the document. Our performance study with a large-scale dataset confirms the effectiveness of the T-REX model.</p>
<p>Keywords:</p>
<h3 id="226. CR-Graph: Community Reinforcement for Accurate Community Detection.">226. CR-Graph: Community Reinforcement for Accurate Community Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412145">Paper Link</a>    Pages:2077-2080</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/180/8258.html">Yoonsuk Kang</a> ; <a href="https://dblp.uni-trier.de/pid/49/2274.html">Jun Seok Lee</a> ; <a href="https://dblp.uni-trier.de/pid/05/2819.html">Won-Yong Shin</a> ; <a href="https://dblp.uni-trier.de/pid/64/5810.html">Sang-Wook Kim</a></p>
<p>Abstract:
In this paper, we present CR-Graph (community reinforcement on graphs), a novel method that helps existing algorithms to perform more-accurate community detection (CD). Toward this end, CR-Graph strengthens the community structure of a given original graph by adding non-existent predicted intra-community edges and deleting existing predicted inter-community edges. To design CR-Graph, we propose the following two strategies: (1) predicting intra-community and inter-community edges (i.e., the type of edges) and (2) determining the amount of edges to be added/deleted. To show the effectiveness of CR-Graph, we conduct extensive experiments with various CD algorithms on 7 synthetic and 4 real-world graphs. The results demonstrate that CR-Graph improves the accuracy of all underlying CD algorithms universally and consistently.</p>
<p>Keywords:</p>
<h3 id="227. What Rankers Can be Statistically Distinguished in Multileaved Comparisons?">227. What Rankers Can be Statistically Distinguished in Multileaved Comparisons?</h3>
<p><a href="https://doi.org/10.1145/3340531.3412143">Paper Link</a>    Pages:2081-2084</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/14/7537.html">Makoto P. Kato</a> ; <a href="https://dblp.uni-trier.de/pid/204/0154.html">Akiomi Nishida</a> ; <a href="https://dblp.uni-trier.de/pid/162/7956.html">Tomohiro Manabe</a> ; <a href="https://dblp.uni-trier.de/pid/46/1330.html">Sumio Fujita</a> ; <a href="https://dblp.uni-trier.de/pid/38/4395.html">Takehiro Yamamoto</a></p>
<p>Abstract:
This paper presents findings from an empirical study of multileaved comparisons, an efficient online evaluation methodology, in a commercial Web service. The most important difference from the previous studies is the number of rankers involved in the online evaluation: we compared 30 rankers for around 90 days by multileaved comparisons. A relatively large number of rankers answered several questions that could not be addressed in the previous work due to a small number of rankers: How much ranking difference is required for rankers to be statistically distinguished? How many impressions are necessary for finding statistically significant differences for correlated rankers? How large difference in offline evaluation can predict significant differences in a multileaved comparison? We answer these questions with the results of the multileaved comparisons, and generalized some of the findings by simulation-based experiments.</p>
<p>Keywords:</p>
<h3 id="228. A Synopses Data Engine for Interactive Extreme-Scale Analytics.">228. A Synopses Data Engine for Interactive Extreme-Scale Analytics.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412154">Paper Link</a>    Pages:2085-2088</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/261/2671.html">Antonis Kontaxakis</a> ; <a href="https://dblp.uni-trier.de/pid/17/1242.html">Nikos Giatrakos</a> ; <a href="https://dblp.uni-trier.de/pid/d/ADeligiannakis.html">Antonios Deligiannakis</a></p>
<p>Abstract:
We detail the novel architecture of a Synopses Data Engine (SDE) which combines the virtues of parallel processing and stream summarization towards interactive analytics at scale. Our SDE, built on top of Apache Flink, has a unique design that supports a very wide variety of synopses, allows for dynamically adding new functionality to it at runtime, and introduces a synopsis-as-a-service paradigm to enable various types of scalability.</p>
<p>Keywords:</p>
<h3 id="229. NASE: : Learning Knowledge Graph Embedding for Link Prediction via Neural Architecture Search.">229. NASE: : Learning Knowledge Graph Embedding for Link Prediction via Neural Architecture Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412104">Paper Link</a>    Pages:2089-2092</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/242/9273.html">Xiaoyu Kou</a> ; <a href="https://dblp.uni-trier.de/pid/174/8458.html">Bingfeng Luo</a> ; <a href="https://dblp.uni-trier.de/pid/225/5365.html">Huang Hu</a> ; <a href="https://dblp.uni-trier.de/pid/04/3348.html">Yan Zhang</a></p>
<p>Abstract:
Link prediction is the task of predicting missing connections between entities in the knowledge graph (KG). While various forms of models are proposed for the link prediction task, most of them are designed based on a few known relation patterns in several well-known datasets. Due to the diversity and complexity nature of the real-world KGs, it is inherently difficult to design a model that fits all datasets well. To address this issue, previous work has tried to use Automated Machine Learning (AutoML) to search for the best model for a given dataset. However, their search space is limited only to bilinear model families. In this paper, we propose a novel Neural Architecture Search (NAS) framework for the link prediction task. First, the embeddings of the input triplet are refined by the Representation Search Module. Then, the prediction score is searched within the Score Function Search Module. This framework entails a more general search space, which enables us to take advantage of several mainstream model families, and thus it can potentially achieve better performance. We relax the search space to be continuous so that the architecture can be optimized efficiently using gradient-based search strategies. Experimental results on several benchmark datasets demonstrate the effectiveness of our method compared with several state-of-the-art approaches.</p>
<p>Keywords:</p>
<h3 id="230. Ranking Clarification Questions via Natural Language Inference.">230. Ranking Clarification Questions via Natural Language Inference.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412137">Paper Link</a>    Pages:2093-2096</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/64/7535.html">Vaibhav Kumar</a> ; <a href="https://dblp.uni-trier.de/pid/205/2388.html">Vikas Raunak</a> ; <a href="https://dblp.uni-trier.de/pid/c/JamesPCallan.html">Jamie Callan</a></p>
<p>Abstract:
Given a natural language query, teaching machines to ask clarifying questions is of immense utility in practical natural language processing systems. Such interactions could help in filling information gaps for better machine comprehension of the query. For the task of ranking clarification questions, we hypothesize that determining whether a clarification question pertains to a missing entry in a given post (on QA forums such as StackExchange) could be considered as a special case of Natural Language Inference (NLI), where both the post and the most relevant clarification question point to a shared latent piece of information or context. We validate this hypothesis by incorporating representations from a Siamese BERT model fine-tuned on NLI and Multi-NLI datasets into our models and demonstrate that our best performing model obtains a relative performance improvement of 40 percent and 60 percent respectively (on the key metric of [email protected]), over the state-of-the-art baseline(s) on the two evaluation sets of the StackExchange dataset, thereby, significantly surpassing the state-of-the-art.</p>
<p>Keywords:</p>
<h3 id="231. MetaTPOT: Enhancing A Tree-based Pipeline Optimization Tool Using Meta-Learning.">231. MetaTPOT: Enhancing A Tree-based Pipeline Optimization Tool Using Meta-Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412147">Paper Link</a>    Pages:2097-2100</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/252/5753.html">Doron Laadan</a> ; <a href="https://dblp.uni-trier.de/pid/228/2573.html">Roman Vainshtein</a> ; <a href="https://dblp.uni-trier.de/pid/252/5534.html">Yarden Curiel</a> ; <a href="https://dblp.uni-trier.de/pid/54/10321.html">Gilad Katz</a> ; <a href="https://dblp.uni-trier.de/pid/r/LiorRokach.html">Lior Rokach</a></p>
<p>Abstract:
Automatic machine learning (AutoML) aims to automate the different aspects of the data science process and, by extension, allow non-experts to utilize "off the shelf" machine learning solution. One of the more popular AutoML methods is the Tree-based Pipeline Optimization Tool (TPOT), which uses genetic programming (GP) to efficiently explore the vast space of ML pipelines and produce a working ML solution. However, TPOT's GP process comes with substantial time and computational costs. In this study, we explore TPOT's GP process and propose MetaTPOT, an enhanced variant that uses a meta learning-based approach to predict the performance of TPOT's pipeline candidates. MetaTPOT leverages domain knowledge in the form of pipelines pre-ranking to improve TPOT's speed and performance. Evaluation on 65 classification datasets shows that our approach often improves the outcome of the genetic process while simultaneously substantially reduce its running time and computational cost.</p>
<p>Keywords:</p>
<h3 id="232. Rethinking Operators Placement of Stream Data Application in the Edge.">232. Rethinking Operators Placement of Stream Data Application in the Edge.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412116">Paper Link</a>    Pages:2101-2104</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/19/11139.html">Thomas Lambert</a> ; <a href="https://dblp.uni-trier.de/pid/164/9876.html">David Guyon</a> ; <a href="https://dblp.uni-trier.de/pid/00/981.html">Shadi Ibrahim</a></p>
<p>Abstract:
Maximum Sustainable Throughput (MST) refers to the amount of data that a Data Stream Processing (DSP) system can ingest while keeping stable performance. It has been acknowledged as an accurate metric to evaluate the performance of stream data processing. Yet, existing operators placements continue to focus on latency and throughput, not MST, as main performance objective when deploying stream data applications in the Edge. In this paper, we argue that MST should be used as an optimization objective when placing operators. This is specially important in the Edge, where network bandwidth and data streams are highly dynamic. We demonstrate that through the design and evaluation of a MST-driven operators placement (based on constraint programming) for stream data applications. Through simulations, we show how existing placement strategies that target overall communications reduction often fail to keep up with the rate of data streams. Importantly, the constraint programming-based operators placement is able to sustain up to 5x increased data ingestion compared to baseline strategies.</p>
<p>Keywords:</p>
<h3 id="233. An Index Advisor Using Deep Reinforcement Learning.">233. An Index Advisor Using Deep Reinforcement Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412106">Paper Link</a>    Pages:2105-2108</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/66/3149.html">Hai Lan</a> ; <a href="https://dblp.uni-trier.de/pid/20/3716.html">Zhifeng Bao</a> ; <a href="https://dblp.uni-trier.de/pid/88/3891.html">Yuwei Peng</a></p>
<p>Abstract:
We study the problem of index selection to maximize the workload performance, which is critical to database systems. In contrast to existing methods, we seamlessly integrate index recommendation rules and deep reinforcement learning, such that we can recommend single-attribute and multi-attribute indexes together for complex queries and meanwhile support multiple-index access to a table. Specifically, we first propose five heuristic rules to generate the index candidates. Then, we formulate the index selection problem as a reinforcement learning task and employ Deep Q Network (DQN) on it. Using the heuristic rules can significantly reduce the dimensions of the action space and state space in reinforcement learning. With the neural network used in DQN, we can model the interactions between indexes better than previous methods. We conduct experiments on various workloads to show its superiority.</p>
<p>Keywords:</p>
<h3 id="234. Bridging the Gap between Click and Relevance for Learning-to-Rank with Minimal Supervision.">234. Bridging the Gap between Click and Relevance for Learning-to-Rank with Minimal Supervision.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412144">Paper Link</a>    Pages:2109-2112</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/207/9942.html">Jae-woong Lee</a> ; <a href="https://dblp.uni-trier.de/pid/56/3235.html">Young-In Song</a> ; <a href="https://dblp.uni-trier.de/pid/50/8097.html">Deokmin Haam</a> ; <a href="https://dblp.uni-trier.de/pid/58/6214.html">Sanghoon Lee</a> ; <a href="https://dblp.uni-trier.de/pid/184/5433.html">Woo-Sik Choi</a> ; <a href="https://dblp.uni-trier.de/pid/04/3445.html">Jongwuk Lee</a></p>
<p>Abstract:
Recently, unbiased learning-to-rank models have been widely studied to learn a better ranker by eliminating the biases from click data. Toward this goal, existing work mainly focused on estimating the propensity weight to design a specific bias type from click data. From a different perspective, we propose a simple-yet-effective ranking model, namely wLambdaMART, which estimates the confidence of click data with a few labeled data, instead of learning the propensity weight to reduce the bias from click data. We first train a confidence estimator to bridge the gap between biased click data and unbiased relevance. Then, we infer confidence weights for all click data and apply them to LambdaMART to learn a debiased ranker. Practically, since it is found that learning the confidence estimator only requires a few labeled data, it does not incur high labeling costs. Our experimental results show that wLambdaMART outperforms state-of-the-art click models and unbiased learning-to-rank models on the real-world click datasets collected from a commercial search engine.</p>
<p>Keywords:</p>
<h3 id="235. Are Negative Links Really Beneficial to Network Embedding?: In-Depth Analysis and Interesting Results.">235. Are Negative Links Really Beneficial to Network Embedding?: In-Depth Analysis and Interesting Results.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412107">Paper Link</a>    Pages:2113-2116</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/167/5996.html">Yeon-Chang Lee</a> ; <a href="https://dblp.uni-trier.de/pid/270/6547.html">Nayoun Seo</a> ; <a href="https://dblp.uni-trier.de/pid/64/5810.html">Sang-Wook Kim</a></p>
<p>Abstract:
In this paper, we start by pointing out the limitations on the validation of existing signed network embedding (NE) methods. To address the limitations, we design the two research questions: (1) are signed NE methods consistently more effective in various types of tasks than unsigned NE methods? (2) in signed NE methods, does the utilization of negative links help provide higher accuracy in various tasks? To answer the questions, we present our evaluation framework consisting of three components: (1) five signed network datasets; (2) six signed and two unsigned NE methods; (3) five types of tasks. Through extensive experiments on our evaluation framework, we demonstrate that additional utilization of negative links really helps only in some tasks related to negative links but not in tasks related to positive links.</p>
<p>Keywords:</p>
<h3 id="236. Non-local Self-attentive Autoencoder for Genetic Functionality Prediction.">236. Non-local Self-attentive Autoencoder for Genetic Functionality Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412084">Paper Link</a>    Pages:2117-2120</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/87/6284.html">Yun Li</a> ; <a href="https://dblp.uni-trier.de/pid/70/1220.html">Zhe Liu</a> ; <a href="https://dblp.uni-trier.de/pid/56/6651.html">Lina Yao</a> ; <a href="https://dblp.uni-trier.de/pid/276/5061.html">Zihuai He</a></p>
<p>Abstract:
A big challenge existing in genetic functionality prediction is that genetic datasets comprise few samples but massive unclear structured features, i.e., 'large p, small N' problem. To tackle this problem, we propose Non-local Self-attentive Autoencoder (NSAE) which applies attention-driven genetic variant modelling. The backbone attention layer captures long-range dependency relationship among cells (i.e., features) and thus allocates weights to construct attention maps based on cell significance. Utilizing attention maps, NSAE can effectively seize and leverage significant features in a non-local way from numerous cells. Our proposed NSAE outperforms the state-of-the-art algorithms on two genomics datasets from Roadmap projects. The visualization of the attention layer also validates NSAE's ability to highlight important features.</p>
<p>Keywords:</p>
<h3 id="237. Recursive Balanced k-Subset Sum Partition for Rule-constrained Resource Allocation.">237. Recursive Balanced k-Subset Sum Partition for Rule-constrained Resource Allocation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412076">Paper Link</a>    Pages:2121-2124</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/51/4015-10.html">Zhuo Li</a> ; <a href="https://dblp.uni-trier.de/pid/c/JiannongCao.html">Jiannong Cao</a> ; <a href="https://dblp.uni-trier.de/pid/274/6349.html">Zhongyu Yao</a> ; <a href="https://dblp.uni-trier.de/pid/09/11146.html">Wengen Li</a> ; <a href="https://dblp.uni-trier.de/pid/16/4505.html">Yu Yang</a> ; <a href="https://dblp.uni-trier.de/pid/58/6299.html">Jia Wang</a></p>
<p>Abstract:
Balanced rule-constrained resource allocation aims to evenly distribute tasks to different processors under allocation rule constraints. Conventional heuristic approach fails to achieve optimal solution while simple brute force method has the defect of high computational complexity. To address these limitations, we propose recursive balanced k-subset sum partition (RBkSP), in which iterative 'cut-one-out' policy is employed that in each round, only one subset whose weight of tasks sums up to 1/k of the total weight of all tasks is taken out from the set. In a single partition, we first create a dynamic programming table with its elements recursively computed, then use 'zig-zag search' method to explore the table, find out elements with optimal subset partition and assign different partitions to proper places. Next, to resolve conflicts during allocation, we use simple but effective heuristic method to adjust the allocation of tasks that is contradicted to allocation rules. Testing results show RBkSP can achieve more balanced results with lower computational complexity over classical benchmarks.</p>
<p>Keywords:</p>
<h3 id="238. Alike and Unlike: Resolving Class Imbalance Problem in Financial Credit Risk Assessment.">238. Alike and Unlike: Resolving Class Imbalance Problem in Financial Credit Risk Assessment.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412111">Paper Link</a>    Pages:2125-2128</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/51/3710.html">Yang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/71/1982.html">Xiang Ao</a> ; <a href="https://dblp.uni-trier.de/pid/257/5630.html">Qiwei Zhong</a> ; <a href="https://dblp.uni-trier.de/pid/22/4976.html">Jinghua Feng</a> ; <a href="https://dblp.uni-trier.de/pid/14/533.html">Jiayu Tang</a> ; <a href="https://dblp.uni-trier.de/pid/14/3700-3.html">Qing He</a></p>
<p>Abstract:
Financial credit risk assessment serves as the impetus to evaluate the credit admission or potential business failure of customers in order to make early actions prior to the actual financial crisis. It aims to predict the probability that a customer may belong to a high-risk group, which is usually formulated as a binary classification problem. However, due to the lack of high-risk samples, the prevailing models suffer from the severe class-imbalance problem. Oversampling those high-risk users could alleviate this problem but the effect of noise examples is also amplified. In this paper, we propose a novel adversarial data augmentation method to solve the class imbalance problem in financial credit risk assessment. We train a generator for synthetic sample generation with a discriminator to identify real or fake instances. Besides, an auxiliary risk discriminator is trained cooperatively with the generator to assess the credit risk. Experimental results on three real-world datasets demonstrate the effectiveness of the proposed</p>
<p>Keywords:</p>
<h3 id="239. Active Query of Private Demographic Data for Learning Fair Models.">239. Active Query of Private Demographic Data for Learning Fair Models.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412074">Paper Link</a>    Pages:2129-2132</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/41/3457.html">Yijun Liu</a> ; <a href="https://dblp.uni-trier.de/pid/91/8842.html">Chao Lan</a></p>
<p>Abstract:
Learning a fair prediction model is an important research problem with profound societal impacts. Most approaches assume free access to the sensitive demographic data, whereas these data are becoming restricted to use by privacy regulations. Existing solutions are broadly based on multi-party computation or demographic proxy, but each direction has its own limits in certain scenarios.</p>
<p>Keywords:</p>
<h3 id="240. Neural Relation Extraction on Wikipedia Tables for Augmenting Knowledge Graphs.">240. Neural Relation Extraction on Wikipedia Tables for Augmenting Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412164">Paper Link</a>    Pages:2133-2136</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/149/8481.html">Erin MacDonald</a> ; <a href="https://dblp.uni-trier.de/pid/b/DBarbosa.html">Denilson Barbosa</a></p>
<p>Abstract:
Knowledge Graph Augmentation is the task of adding missing facts to an incomplete knowledge graph to improve its effectiveness in applications such as web search and question answering. State-of-the-art methods rely on information extraction from running text, leaving rich sources of facts such as tables behind. We help close this gap with a neural method that uses contextual information surrounding a table in a Wikipedia article to extract relations between entities appearing in the same row of a table or between the entity of said article and entities appearing in the table. We trained and tested our method on a much larger dataset compared to previous work which we have made public and observed experimentally that our method is very promising for the task.</p>
<p>Keywords:</p>
<h3 id="241. Fairness-Aware Learning with Prejudice Free Representations.">241. Fairness-Aware Learning with Prejudice Free Representations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412150">Paper Link</a>    Pages:2137-2140</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/259/2265.html">Ramanujam Madhavan</a> ; <a href="https://dblp.uni-trier.de/pid/169/9751.html">Mohit Wadhwa</a></p>
<p>Abstract:
Machine learning models are extensively being used to make decisions that have a significant impact on human life. These models are trained over historical data that may contain information about sensitive attributes such as race, sex, religion, etc. The presence of such sensitive attributes can impact certain population subgroups unfairly. It is straightforward to remove sensitive features from the data; however, a model could pick up prejudice from latent sensitive attributes that may exist in the training data. This has led to the growing apprehension about the fairness of the employed models. In this paper, we propose a novel algorithm that can effectively identify and treat latent discriminating features. The approach is agnostic of the learning algorithm and generalizes well for classification as well as regression tasks. It can also be used as a key aid in proving that the model is free of discrimination towards regulatory compliance if the need arises. The approach helps to collect discrimination-free features that would improve the model performance while ensuring the fairness of the model. The experimental results from our evaluations on publicly available real-world datasets show a near-ideal fairness measurement in comparison to other methods.</p>
<p>Keywords:</p>
<h3 id="242. A Comparison of Top-k Threshold Estimation Techniques for Disjunctive Query Processing.">242. A Comparison of Top-k Threshold Estimation Techniques for Disjunctive Query Processing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412080">Paper Link</a>    Pages:2141-2144</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/204/0179.html">Antonio Mallia</a> ; <a href="https://dblp.uni-trier.de/pid/234/2710.html">Michal Siedlaczek</a> ; <a href="https://dblp.uni-trier.de/pid/251/2720.html">Mengyang Sun</a> ; <a href="https://dblp.uni-trier.de/pid/s/TorstenSuel.html">Torsten Suel</a></p>
<p>Abstract:
In the top-k threshold estimation problem, given a query q, the goal is to estimate the score of the result at rank k. A good estimate of this score can result in significant performance improvements for several query processing scenarios, including selective search, index tiering, and widely used disjunctive query processing algorithms such as MaxScore, WAND, and BMW. Several approaches have been proposed, including parametric approaches, methods using random sampling, and a recent approach based on machine learning. However, previous work fails to perform any experimental comparison between these approaches. In this paper, we address this issue by reimplementing four major approaches and comparing them in terms of estimation error, running time, likelihood of an overestimate, and end-to-end performance when applied to common classes of disjunctive top-k query processing algorithms.</p>
<p>Keywords:</p>
<h3 id="243. Feedback Loop and Bias Amplification in Recommender Systems.">243. Feedback Loop and Bias Amplification in Recommender Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412152">Paper Link</a>    Pages:2145-2148</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/183/7693.html">Masoud Mansoury</a> ; <a href="https://dblp.uni-trier.de/pid/184/2105.html">Himan Abdollahpouri</a> ; <a href="https://dblp.uni-trier.de/pid/37/4649.html">Mykola Pechenizkiy</a> ; <a href="https://dblp.uni-trier.de/pid/01/4475.html">Bamshad Mobasher</a> ; <a href="https://dblp.uni-trier.de/pid/58/2337.html">Robin Burke</a></p>
<p>Abstract:
Recommendation algorithms are known to suffer from popularity bias; a few popular items are recommended frequently while the majority of other items are ignored. These recommendations are then consumed by the users, their reaction will be logged and added to the system: what is generally known as a feedback loop. In this paper, we propose a method for simulating the users interaction with the recommenders in an offline setting and study the impact of feedback loop on the popularity bias amplification of several recommendation algorithms. We then show how this bias amplification leads to several other problems such as declining the aggregate diversity, shifting the representation of users' taste over time and also homogenization of the users. In particular, we show that the impact of feedback loop is generally stronger for the users who belong to the minority group.</p>
<p>Keywords:</p>
<h3 id="244. Diversifying Top-k Point-of-Interest Queries via Collective Social Reach.">244. Diversifying Top-k Point-of-Interest Queries via Collective Social Reach.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412097">Paper Link</a>    Pages:2149-2152</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5116.html">Stella Maropaki</a> ; <a href="https://dblp.uni-trier.de/pid/25/7564.html">Sean Chester</a> ; <a href="https://dblp.uni-trier.de/pid/14/3086.html">Christos Doulkeridis</a> ; <a href="https://dblp.uni-trier.de/pid/n/KjetilNorvag.html">Kjetil Nrvg</a></p>
<p>Abstract:
By "checking into'' various points-of-interest (POIs), users create a rich source of location-based social network data that can be used in expressive spatio-social queries. This paper studies the use of popularity as a means to diversify results of top-k nearby POI queries. In contrast to previous work, we evaluate social diversity as a group-based, rather than individual POI, metric. Algorithmically, evaluating this set-based notion of diversity is challenging, yet we present several effective algorithms based on (integer) linear programming, a greedy framework, and r-tree distance browsing. Experiments show scalability and interactive response times for up to 100 million unique check-ins across 25000 POIs.</p>
<p>Keywords:</p>
<h3 id="245. Transformer Models for Recommending Related Questions in Web Search.">245. Transformer Models for Recommending Related Questions in Web Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412067">Paper Link</a>    Pages:2153-2156</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/210/1074.html">Rajarshee Mitra</a> ; <a href="https://dblp.uni-trier.de/pid/181/2823.html">Manish Gupta</a> ; <a href="https://dblp.uni-trier.de/pid/71/4474.html">Sandipan Dandapat</a></p>
<p>Abstract:
People Also Ask (PAA) is an exciting feature in most of the leading search engines which recommends related questions for a given user query, thereby attempting to reduce the gap between user's information need. This helps users in diving deep into the topic of interest, and reduces task completion time. However, showing unrelated or irrelevant questions is highly detrimental to the user experience. While there has been significant work on query reformulation and related searches, there is hardly any published work on recommending related questions for a query. Question suggestion is challenging because the question needs to be interesting, structurally correct, not be a duplicate of other visible information, and must be reasonably related to the original query. In this paper, we present our system which is based on a Transformer-based neural representation, BERT (Bidirectional Encoder Representations from Transformers), for query, question and corresponding search result snippets. Our best model provides an accuracy of ~81%.</p>
<p>Keywords:</p>
<h3 id="246. Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models.">246. Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412159">Paper Link</a>    Pages:2157-2160</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/210/4225.html">Isaiah Onando Mulang</a> ; <a href="https://dblp.uni-trier.de/pid/81/4530-1.html">Kuldeep Singh</a> ; <a href="https://dblp.uni-trier.de/pid/272/5269.html">Chaitali Prabhu</a> ; <a href="https://dblp.uni-trier.de/pid/249/6479.html">Abhishek Nadgeri</a> ; <a href="https://dblp.uni-trier.de/pid/99/7948.html">Johannes Hoffart</a> ; <a href="https://dblp.uni-trier.de/pid/71/4882.html">Jens Lehmann</a></p>
<p>Abstract:
Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual information from the text to improve the performance of several NLP tasks. These models, albeit powerful, still require specialized knowledge in specific scenarios. In this paper, we argue that context derived from a knowledge graph (in our case: Wikidata) provides enough signals to inform pretrained transformer models and improve their performance for named entity disambiguation (NED) on Wikidata KG. We further hypothesize that our proposed KG context can be standardized for Wikipedia, and we evaluate the impact of KG context on the state of the art NED model for the Wikipedia knowledge base. Our empirical results validate that the proposed KG context can be generalized (for Wikipedia), and providing KG context in transformer architectures considerably outperforms the existing baselines, including the vanilla transformer models.</p>
<p>Keywords:</p>
<h3 id="247. Deep Metric Learning Based on Rank-sensitive Optimization of Top-k Precision.">247. Deep Metric Learning Based on Rank-sensitive Optimization of Top-k Precision.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412142">Paper Link</a>    Pages:2161-2164</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/259/0485.html">Naoki Muramoto</a> ; <a href="https://dblp.uni-trier.de/pid/274/0908.html">Hai-Tao Yu</a></p>
<p>Abstract:
Deep metric learning has shown significantly increasing values in a wide range of domains, such as image retrieval, face recognition, zero-shot learning, to name a few. When evaluating the methods for deep metric learning, top-k precision is commonly used as a key metric, since few users bother to scroll down to lower-ranked items. Despite being widely studied, how to directly optimize top-k precision is still an open problem. In this paper, we propose a new method on how to optimize top-k precision in a rank-sensitive manner. Given the cutoff value k, our key idea is to impose different weights to further differentiate misplaced images sampled according to the top-k precision. To validate the effectiveness of the proposed method, we conduct a series of experiments on three widely used benchmark datasets. The experimental results demonstrate that: (1) Our proposed method outperforms the baseline methods on two datasets, which shows the potential value of rank-sensitive optimization of top-k precision for deep metric learning. (2) The factors, such as batch size and cutoff value k, significantly affect the performance of approaches that rely on optimising top-k precision for deep metric learning. Careful examinations of these factors are highly recommended.</p>
<p>Keywords:</p>
<h3 id="248. Gated Heterogeneous Graph Representation Learning for Shop Search in E-commerce.">248. Gated Heterogeneous Graph Representation Learning for Shop Search in E-commerce.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412087">Paper Link</a>    Pages:2165-2168</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/244/2046.html">Xichuan Niu</a> ; <a href="https://dblp.uni-trier.de/pid/173/4985.html">Bofang Li</a> ; <a href="https://dblp.uni-trier.de/pid/52/9457.html">Chenliang Li</a> ; <a href="https://dblp.uni-trier.de/pid/75/5560-5.html">Rong Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/265/5559.html">Haochuan Sun</a> ; <a href="https://dblp.uni-trier.de/pid/70/5417.html">Honggang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/09/43.html">Hongbo Deng</a> ; <a href="https://dblp.uni-trier.de/pid/07/954.html">Zhenzhong Chen</a></p>
<p>Abstract:
In e-commerce search, vectorized matching is the most important approach besides lexical matching, where learning vector representations for entities (e.g., query, item, shop) plays a crucial role. In this work, we focus on vectorized search matching model for shop search in Taobao. Unlike item search, shop search is faced with serious behavior sparsity and long-tail problem. To tackle this, we take the first step to transfer knowledge from item search, i.e., leveraging items purchased under a query and the shops they belong to. Moreover, we propose a novel gated heterogeneous graph learning model (named GHL) to derive vector representations for entities. Both first-order and second-order proximity of queries and shops are exploited to fully mine the heterogeneous relationships. And to relieve long-tail phenomenon, we devise an innovative gated neighbor aggregation scheme where each type of entities (i.e., hot ones and long-tail ones) can benefit from the heterogeneous graph in an automatic way. Finally, the whole framework is jointly trained in an end-to-end fashion. Offline evaluation results on real-world data of Taobao shop search platform demonstrate that the proposed model outperforms existing graph based methods, and online A/B tests show that it is highly effective and achieves significant CTR improvements.</p>
<p>Keywords:</p>
<h3 id="249. A Reproducibility Study of Deep and Surface Machine Learning Methods for Human-related Trajectory Prediction.">249. A Reproducibility Study of Deep and Surface Machine Learning Methods for Human-related Trajectory Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412088">Paper Link</a>    Pages:2169-2172</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/211/9434.html">Bardh Prenkaj</a> ; <a href="https://dblp.uni-trier.de/pid/12/2807.html">Paola Velardi</a> ; <a href="https://dblp.uni-trier.de/pid/94/2975.html">Damiano Distante</a> ; <a href="https://dblp.uni-trier.de/pid/06/5387.html">Stefano Faralli</a></p>
<p>Abstract:
In this paper, we compare several deep and surface state-of-the-art machine learning methods for risk prediction in problems that can be modelled as a trajectory of events separated by irregular time intervals. Trajectories are the abstract representation of many real-life data, such as patient records, student e-tivities, online financial transactions, and many others. Given the continuously increasing number of machine learning methods to predict future high-risk events in these contexts, we aim to provide more insight into reproducibility and applicability of these methods when changing datasets, parameters, and evaluation measures. As an additional contribution, we release to the community the implementations of all compared methods.</p>
<p>Keywords:</p>
<h3 id="250. CGTR: Convolution Graph Topology Representation for Document Ranking.">250. CGTR: Convolution Graph Topology Representation for Document Ranking.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412073">Paper Link</a>    Pages:2173-2176</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/28/8596.html">Yuanyuan Qi</a> ; <a href="https://dblp.uni-trier.de/pid/55/10289.html">Jiayue Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/98/818.html">Yansong Liu</a> ; <a href="https://dblp.uni-trier.de/pid/41/5448.html">Weiran Xu</a> ; <a href="https://dblp.uni-trier.de/pid/204/6231.html">Jun Guo</a></p>
<p>Abstract:
Contextualized neural language models have gained much attention in Information Retrieval (IR) with its ability to achieve better text understanding by capturing contextual structure. However, to achieve better document understanding, it is necessary to involve global structure of a document. In this paper, we take the advantage of Graph Convolutional Networks (GCN) to model global word-relation structure of a document to improve context-aware document ranking. We propose to build a graph for a document to model the global structure. The nodes and edges of the graph are constructed from contextual embeddings. Then we apply graph convolution on the graph to learning a new representation, and this representation covers both contextual and global structure information. The experimental results show that our method outperforms the state-of-the-art contextual language models, which demonstrate that incorporating global structure is useful for improving document ranking and GCN is an effective way to achieve it.</p>
<p>Keywords:</p>
<h3 id="251. Representative Negative Instance Generation for Online Ad Targeting.">251. Representative Negative Instance Generation for Online Ad Targeting.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412114">Paper Link</a>    Pages:2177-2180</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/222/7913.html">Yuhan Quan</a> ; <a href="https://dblp.uni-trier.de/pid/166/5946.html">Jingtao Ding</a> ; <a href="https://dblp.uni-trier.de/pid/46/5770.html">Depeng Jin</a> ; <a href="https://dblp.uni-trier.de/pid/20/2427.html">Jianbo Yang</a> ; <a href="https://dblp.uni-trier.de/pid/23/6266.html">Xing Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/93/2334.html">Yong Li</a></p>
<p>Abstract:
Online ad targeting can be formulated as a problem of learning the relevance ranking among possible audiences for a given ad. It has to deal with the massive number of negative,i.e., non-interacted, instances in impression data due to the nature of this service, and thus suffers from data imbalance problem. In this work, we tackle this problem by improving the quality of negative instances used in training the targeting model. We propose to enhance the generalization capability by introducing unobserved data as possible negative instances, and extract more reliable negative instances from the observed negatives in impression data. However, this idea is non-trivial to implement because of the limited learning signal and existing noise signal. To this end, we design a novel RNIG method (short for Representative Negative Instance Generator) to leverage feature matching technique. It aims to generate reliable negative instances that are similar to the observed negatives and further improves the representativeness of generated negatives by matching the most important feature. Extensive experiments on the real-world ad targeting dataset show that our RNIG model has achieved a relative improvement of more than 5%.</p>
<p>Keywords:</p>
<h3 id="252. Training Sensitivity in Graph Isomorphism Network.">252. Training Sensitivity in Graph Isomorphism Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412089">Paper Link</a>    Pages:2181-2184</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/164/0562.html">Md. Khaledur Rahman</a></p>
<p>Abstract:
Graph neural network (GNN) is a popular tool to learn the lower-dimensional representation of a graph. It facilitates the applicability of machine learning tasks on graphs by incorporating domain-specific features. There are various options for underlying procedures (such as optimization functions, activation functions, etc.) that can be considered in the implementation of GNN. However, most of the existing tools are confined to one approach without any analysis. Thus, this emerging field lacks a robust implementation ignoring the highly irregular structure of the real-world graphs. In this paper, we attempt to fill this gap by studying various alternative functions for a respective module using a diverse set of benchmark datasets. Our empirical results suggest that the generally used underlying techniques do not always perform well to capture the overall structure from a set of graphs.</p>
<p>Keywords:</p>
<h3 id="253. Securing Bloom Filters for Privacy-preserving Record Linkage.">253. Securing Bloom Filters for Privacy-preserving Record Linkage.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412105">Paper Link</a>    Pages:2185-2188</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/162/3257.html">Thilina Ranbaduge</a> ; <a href="https://dblp.uni-trier.de/pid/127/7152.html">Rainer Schnell</a></p>
<p>Abstract:
Privacy-preserving record linkage (PPRL) facilitates the matching of records that correspond to the same real-world entities across different databases while preserving the privacy of the individuals in these databases. A Bloom filter (BF) is a space efficient probabilistic data structure that is becoming popular in PPRL as an efficient privacy technique to encode sensitive information in records while still enabling approximate similarity computations between attribute values. However, BF encoding is susceptible to privacy attacks which can re-identify the values that are being encoded. In this paper we propose two novel techniques that can be applied on BF encoding to improve privacy against attacks. Our techniques use neighbouring bits in a BF to generate new bit values. An empirical study on large real databases shows that our techniques provide high security against privacy attacks, and achieve better similarity computation accuracy and linkage quality compared to other privacy improvements that can be applied on BF encoding.</p>
<p>Keywords:</p>
<h3 id="254. Product Insights: Analyzing Product Intents in Web Search.">254. Product Insights: Analyzing Product Intents in Web Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412090">Paper Link</a>    Pages:2189-2192</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/264/5210.html">Nikitha Rao</a> ; <a href="https://dblp.uni-trier.de/pid/47/9801.html">Chetan Bansal</a> ; <a href="https://dblp.uni-trier.de/pid/37/11030.html">Subhabrata Mukherjee</a> ; <a href="https://dblp.uni-trier.de/pid/203/9619.html">Chandra Shekhar Maddila</a></p>
<p>Abstract:
Web search engines are frequently used to access information about products. This has increased in recent times with the rising popularity of e-commerce. However, there is limited understanding of what users search for and their intents when it comes to product search on the web. In this work, we study search logs from Bing web search engine to characterize user intents and study user behavior for product search. We propose a taxonomy of product intents by analyzing product search queries. This itself is a challenging task given that only 15%-17% of queries in the web refer to products. We train machine learning classifiers with query log features to classify queries based on intent with an overall F1-score of 78%. We further analyze various characteristics of product search queries in terms of search metrics like dwell time, success, popularity and session-specific information.</p>
<p>Keywords:</p>
<h3 id="255. Muse: Multi-query Event Trend Aggregation.">255. Muse: Multi-query Event Trend Aggregation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412138">Paper Link</a>    Pages:2193-2196</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/228/6081.html">Allison Rozet</a> ; <a href="https://dblp.uni-trier.de/pid/71/7422.html">Olga Poppe</a> ; <a href="https://dblp.uni-trier.de/pid/87/10957.html">Chuan Lei</a> ; <a href="https://dblp.uni-trier.de/pid/r/EARundensteiner.html">Elke A. Rundensteiner</a></p>
<p>Abstract:
Streaming analytics deploy Kleene pattern queries to detect and aggregate event trends on high-rate data streams. Despite increasing workloads, most state-of-the-art systems process each query independently, thus missing cost-saving sharing opportunities. Sharing event trend aggregation poses several technical challenges. First, Kleene patterns are in general difficult to share due to complex nesting and arbitrarily long matches. Second, not all sharing opportunities are beneficial because sharing Kleene patterns incurs non-trivial overhead to ensure the correctness of final aggregation results. We propose MUSE (Multi-query Shared Event trend aggregation), the first framework that shares aggregation queries with Kleene patterns while avoiding expensive trend construction. To find the beneficial sharing plan, the MUSE optimizer effectively selects robust sharing candidates from the exponentially large search space. Our experiments demonstrate that MUSE increases throughput by 4 orders of magnitude compared to state-of-the-art approaches.</p>
<p>Keywords:</p>
<h3 id="256. Distant Supervision in BERT-based Adhoc Document Retrieval.">256. Distant Supervision in BERT-based Adhoc Document Retrieval.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412124">Paper Link</a>    Pages:2197-2200</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/139/5123.html">Koustav Rudra</a> ; <a href="https://dblp.uni-trier.de/pid/02/7062.html">Avishek Anand</a></p>
<p>Abstract:
Recently introduced pre-trained contextualized autoregressive models like BERT have shown improvements in document retrieval tasks. One of the major limitations of the current approaches can be attributed to the manner they deal with variable-size document lengths using a fixed input BERT model. Common approaches either truncate or split longer documents into small sentences/passages and subsequently label them - using the original document label or from another externally trained model. The other problem is the scarcity of labelled query-document pairs that directly hampers the performance of modern data hungry neural models. This process gets even more complicated with the partially labelled large dataset of queries derived from query logs (TREC-DL). In this paper, we handle both the issues simultaneously and introduce passage level weak supervision in contrast to standard document level supervision. We conduct a preliminary study on the document to passage label transfer and influence of unlabelled documents on the performance of adhoc document retrieval. We observe that direct transfer of relevance labels from documents to passages introduces label noise that strongly affects retrieval effectiveness. We propose a weak-supervision based transfer passage labelling scheme that helps in performance improvement and gathering relevant passages from unlabelled documents.</p>
<p>Keywords:</p>
<h3 id="257. Modelling Regional Crime Risk using Directed Graph of Check-ins.">257. Modelling Regional Crime Risk using Directed Graph of Check-ins.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412065">Paper Link</a>    Pages:2201-2204</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/228/4141.html">Shakila Khan Rumi</a> ; <a href="https://dblp.uni-trier.de/pid/08/1554.html">Flora D. Salim</a></p>
<p>Abstract:
The location-based social network, Foursquare, reflects the human activities of a city. The mobility dynamics inferred from Foursquare helps us understanding urban social events like crime In this paper, we propose a directed graph from the aggregated movement between regions using Foursquare data. We derive region risk factor from the movement direction, quantity and crime history in different periods of the day. Later, we propose a new set of features, DIrected graph Flow FEatuRes (DIFFER) which are associated with region risk factor. The reliable correlations between DIFFER and crime count are observed. We verify the effectiveness of the DIFFER in monthly crime count using Linear, XGBoost, and Random Forest regression in two cities, Chicago and New York City.</p>
<p>Keywords:</p>
<h3 id="258. Relation Extraction with Self-determined Graph Convolutional Network.">258. Relation Extraction with Self-determined Graph Convolutional Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412072">Paper Link</a>    Pages:2205-2208</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/182/2588.html">Sunil Kumar Sahu</a> ; <a href="https://dblp.uni-trier.de/pid/268/0906.html">Derek Thomas</a> ; <a href="https://dblp.uni-trier.de/pid/144/1140.html">Billy Chiu</a> ; <a href="https://dblp.uni-trier.de/pid/24/10955.html">Neha Sengupta</a> ; <a href="https://dblp.uni-trier.de/pid/268/1051.html">Mohammady Mahdy</a></p>
<p>Abstract:
Relation Extraction is a way of obtaining the semantic relationship between entities in text. The state-of-the-art methods use linguistic tools to build a graph for the text in which the entities appear and then a Graph Convolutional Network (GCN) is employed to encode the pre-built graphs. Although their performance is promising, the reliance on linguistic tools results in a non end-to-end process. In this work, we propose a novel model, the Self-determined Graph Convolutional Network (SGCN), which determines a weighted graph using a self-attention mechanism, rather using any linguistic tool. Then, the self-determined graph is encoded using a GCN. We test our model on the TACRED dataset and achieve the state-of-the-art result. Our experiments show that SGCN outperforms the traditional GCN, which uses dependency parsing tools to build the graph.</p>
<p>Keywords:</p>
<h3 id="259. A Framework for Analyzing the Impact of Missing Data in Predictive Models.">259. A Framework for Analyzing the Impact of Missing Data in Predictive Models.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412129">Paper Link</a>    Pages:2209-2212</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/248/7918.html">Fabiola Santore</a> ; <a href="https://dblp.uni-trier.de/pid/53/2190.html">Eduardo Cunha de Almeida</a> ; <a href="https://dblp.uni-trier.de/pid/276/5010.html">Wagner H. Bonat</a> ; <a href="https://dblp.uni-trier.de/pid/156/8798.html">Eduardo H. M. Pena</a> ; <a href="https://dblp.uni-trier.de/pid/276/5110.html">Luiz Eduardo S. de Oliveira</a></p>
<p>Abstract:
We propose a stochastic framework to evaluate the impact of missing data on the performance of predictive models. The framework allows full control of important aspects of the data set structure. These include the number and type of the input variables, the correlation between the input variables and their general predictive power, and sample size. The missing process is generated from a multivariate Bernoulli distribution, which allows us to simulate missing patterns corresponding to the MCAR, MAR and MNAR mechanisms. Although the framework may be applied to virtually all types of predictive models, in this article, we focus on the logistic regression model and choose the accuracy as the predictive measure. The simulation results show that the effects of missing data disappear for large sample sizes, as expected. On the other hand, as the number of input variables increases, the accuracy decreases mainly for binary inputs.</p>
<p>Keywords:</p>
<h3 id="260. Deep Adaptive Feature Aggregation in Multi-task Convolutional Neural Networks.">260. Deep Adaptive Feature Aggregation in Multi-task Convolutional Neural Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412132">Paper Link</a>    Pages:2213-2216</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/86/7619.html">Zhen Shen</a> ; <a href="https://dblp.uni-trier.de/pid/23/8313.html">Chaoran Cui</a> ; <a href="https://dblp.uni-trier.de/pid/49/2488.html">Jin Huang</a> ; <a href="https://dblp.uni-trier.de/pid/224/1726.html">Jian Zong</a> ; <a href="https://dblp.uni-trier.de/pid/25/687.html">Meng Chen</a> ; <a href="https://dblp.uni-trier.de/pid/94/458.html">Yilong Yin</a></p>
<p>Abstract:
Convolutional Neural Network (CNN) based multi-task learning methods have been widely used in a variety of applications of computer vision. Towards effective multi-task CNN architectures, recent studies automatically learn the optimal combinations of task-specific features at single network layers. However, they generally construct an unchanged operation of feature aggregation after training, regardless of the characteristics of input features. In this paper, we propose a novel Adaptive Feature Aggregation (AFA) layer for multi-task CNNs, in which a dynamic aggregation mechanism is designed to allow each task to adaptively determine the degree to which the feature aggregation of different tasks is needed according to the feature dependencies. On both pixel-level and image-level tasks, we demonstrate that our approach significantly outperforms the previous state-of-the-art methods of multi-task CNNs.</p>
<p>Keywords:</p>
<h3 id="261. GGDs: Graph Generating Dependencies.">261. GGDs: Graph Generating Dependencies.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412149">Paper Link</a>    Pages:2217-2220</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/227/4708.html">Larissa Capobianco Shimomura</a> ; <a href="https://dblp.uni-trier.de/pid/f/GeorgeHLFletcher.html">George Fletcher</a> ; <a href="https://dblp.uni-trier.de/pid/92/9686.html">Nikolay Yakovets</a></p>
<p>Abstract:
We propose Graph Generating Dependencies (GGDs), a new class of dependencies for property graphs. Extending the expressivity of state of the art constraint languages, GGDs can express both tuple- and equality-generating dependencies on property graphs, both of which find broad application in graph data management. We provide the formal definition of GGDs, analyze the validation problem for GGDs, and demonstrate the practical utility of GGDs.</p>
<p>Keywords:</p>
<h3 id="262. Do You Really Like Her Post?: Network-Based Analysis for Understanding Like Activities in SNS.">262. Do You Really Like Her Post?: Network-Based Analysis for Understanding Like Activities in SNS.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412166">Paper Link</a>    Pages:2221-2224</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/04/10798.html">Junho Song</a> ; <a href="https://dblp.uni-trier.de/pid/226/0774.html">Hyekyoung Park</a> ; <a href="https://dblp.uni-trier.de/pid/18/9204.html">Kyungsik Han</a> ; <a href="https://dblp.uni-trier.de/pid/64/5810.html">Sang-Wook Kim</a></p>
<p>Abstract:
As social network services (SNS) are expanding from friend-based to interest-based, users form a new type of relationships, namely interest-based relationships, with friends and others through social activities (e.g., likes, comments). Although such relationships are highlighted in the common-identity theory and have important values in theoretical and practical aspects, little evidence exists in the literature pertaining to the explanation of social activities as a central component for social network analysis and an association with friendship. In this paper, we build like networks in Instagram and analyze them through the lens of two salient aspects - friendship and interest - that constitute social networks. Our study results (1) show ambiguous interpretations of the like activities between users who are friends, based on the comparative analysis between friend- and non-friend-based like networks, and (2) demonstrate strong signals of the hashtag characterizing the interest-based relationships in users and content. Our research substantiates and gives insights on the common-identity theory applied in online social networks through data-driven, empirical analysis.</p>
<p>Keywords:</p>
<h3 id="263. DREAM: A Dynamic Relation-Aware Model for Social Recommendation.">263. DREAM: A Dynamic Relation-Aware Model for Social Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412115">Paper Link</a>    Pages:2225-2228</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/239/1436.html">Liqiang Song</a> ; <a href="https://dblp.uni-trier.de/pid/148/8280.html">Ye Bi</a> ; <a href="https://dblp.uni-trier.de/pid/270/6523.html">Mengqiu Yao</a> ; <a href="https://dblp.uni-trier.de/pid/87/6581.html">Zhenyu Wu</a> ; <a href="https://dblp.uni-trier.de/pid/01/1176.html">Jianming Wang</a> ; <a href="https://dblp.uni-trier.de/pid/67/4008.html">Jing Xiao</a></p>
<p>Abstract:
Social connections play a vital role in improving the performance of recommendation systems (RS). However, incorporating social information into RS is challenging. Most existing models usually consider social influences in a given session, ignoring that both users? preferences and their friends? influences are evolving. Moreover, in real world, social relations are sparse. Modeling dynamic influences and alleviating data sparsity is of great importance.</p>
<p>Keywords:</p>
<h3 id="264. LogBug: Generating Adversarial System Logs in Real Time.">264. LogBug: Generating Adversarial System Logs in Real Time.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412165">Paper Link</a>    Pages:2229-2232</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/75/809.html">Jingyu Sun</a> ; <a href="https://dblp.uni-trier.de/pid/150/2645.html">Bingyu Liu</a> ; <a href="https://dblp.uni-trier.de/pid/79/5433.html">Yuan Hong</a></p>
<p>Abstract:
Log parsers first convert large-scale and unstructured system logs into structured data, and then cluster them into groups for anomaly detection and monitoring. However, the security vulnerabilities of the log parsers have not been unveiled yet. In this paper, to our best knowledge, we take the first step to propose a novel real-time black-box attack framework LogBug in which attackers slightly modify the logs to deviate the analysis result (i.e., evading the anomaly detection) without knowing the learning model and parameters of the log parser. We have empirically evaluated LogBug on five emerging log parsers using system logs collected from five different systems. The results demonstrate that LogBug can greatly reduce the accuracy of log parsers with minor perturbations in real time.</p>
<p>Keywords:</p>
<h3 id="265. TABLE: A Task-Adaptive BERT-based ListwisE Ranking Model for Document Retrieval.">265. TABLE: A Task-Adaptive BERT-based ListwisE Ranking Model for Document Retrieval.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412071">Paper Link</a>    Pages:2233-2236</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/228/5449.html">Xingwu Sun</a> ; <a href="https://dblp.uni-trier.de/pid/184/8085.html">Hongyin Tang</a> ; <a href="https://dblp.uni-trier.de/pid/134/2883.html">Fuzheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/152/1728.html">Yanling Cui</a> ; <a href="https://dblp.uni-trier.de/pid/75/1099.html">Beihong Jin</a> ; <a href="https://dblp.uni-trier.de/pid/84/6394.html">Zhongyuan Wang</a></p>
<p>Abstract:
Document retrieval (DR) is a crucial task in NLP. Recently, the pre-trained BERT-like language models have achieved remarkable success, obtaining a state-of-the-art result in DR. In this paper, we come up with a new BERT-based ranking model for DR task, named TABLE. In the pre-training stage of TABLE, we present a domain-adaptive strategy. More essentially, in the fine-tuning stage, we develop a two-phase task-adaptive process, i.e., type-adaptive pointwise fine-tuning and listwise fine-tuning. In the type-adaptive pointwise fine-tuning phase, the model can learn different matching patterns regarding different query types. In the listwise fine-tuning phase, the model matches documents with regard to a given query in a listwise fashion. This task-adaptive process makes the model more robust. In addition, a simple but effective exact matching feature is introduced in fine-tuning, which can effectively compute matching of out-of-vocabulary (OOV) words between a query and a document. As far as we know, we are the first who propose a listwise ranking model with BERT. This work can explore rich matching features between queries and documents. Therefore it substantially improves model performance in DR. Notably, our TABLE model shows excellent performance on the MS MARCO leaderboard.</p>
<p>Keywords:</p>
<h3 id="266. DynamicRec: A Dynamic Convolutional Network for Next Item Recommendation.">266. DynamicRec: A Dynamic Convolutional Network for Next Item Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412118">Paper Link</a>    Pages:2237-2240</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/213/9139.html">Md. Mehrab Tanjim</a> ; <a href="https://dblp.uni-trier.de/pid/251/5554.html">Hammad A. Ayyubi</a> ; <a href="https://dblp.uni-trier.de/pid/c/GWCottrell.html">Garrison W. Cottrell</a></p>
<p>Abstract:
Recently convolutional networks have shown significant promise for modeling sequential user interactions for recommendations. Critically, such networks rely on fixed convolutional kernels to capture sequential behavior. In this paper, we argue that all the dynamics of the item-to-item transition in session-based settings may not be observable at training time. Hence we propose DynamicRec, which uses dynamic convolutions to compute the convolutional kernels on the fly based on the current input. We show through experiments that this approach significantly outperforms existing convolutional models on real datasets in session-based settings.</p>
<p>Keywords:</p>
<h3 id="267. Schema-Agnostic Entity Matching using Pre-trained Language Models.">267. Schema-Agnostic Entity Matching using Pre-trained Language Models.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412131">Paper Link</a>    Pages:2241-2244</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/238/1900.html">Kai Sheng Teong</a> ; <a href="https://dblp.uni-trier.de/pid/47/4141.html">Lay-Ki Soon</a> ; <a href="https://dblp.uni-trier.de/pid/276/5001.html">Tin Tin Su</a></p>
<p>Abstract:
Entity matching (EM) is the process of linking records from different data sources. While extensive research has been done in various aspects of EM, many of these studies generally assume EM tasks as schema-specific, which attempt to match record pairs at attributes level. Unfortunately, in the real-world, tables that undergo EM may not have an aligned schema, and often, the schema or metadata of the table and attributes are not known beforehand.In view of this challenge, this paper presents an effective approach for schema-agnostic EM, where having schema-aligned tables is not compulsory. The proposed method stemmed from the idea of treating tuples in tables for EM similar to sentence pair classification problem in natural language processing (NLP). A pre-trained language model, BERT is adopted by fine-tuning it using labeled dataset. The proposed method was experimented using benchmark datasets and compared against two state-of-the-art approaches,namely DeepMatcher and Magellan. The experimental results show that our proposed solution outperforms by an average of 9% in F1 score. The performance is in fact consistent across different types of datasets, showing significant improvement of 29.6% for one of dirty datasets. These prove that our proposed solution is versatile for EM.</p>
<p>Keywords:</p>
<h3 id="268. Denoising Individual Bias for Fairer Binary Submatrix Detection.">268. Denoising Individual Bias for Fairer Binary Submatrix Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412156">Paper Link</a>    Pages:2245-2248</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/15/158.html">Changlin Wan</a> ; <a href="https://dblp.uni-trier.de/pid/176/1429.html">Wennan Chang</a> ; <a href="https://dblp.uni-trier.de/pid/94/6503.html">Tong Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/161/1874.html">Sha Cao</a> ; <a href="https://dblp.uni-trier.de/pid/91/195.html">Chi Zhang</a></p>
<p>Abstract:
Low rank representation of binary matrix is powerful in disentangling sparse individual-attribute associations, and has received wide applications. Existing binary matrix factorization (BMF) or co-clustering (CC) methods often assume i.i.d background noise. However, this assumption could be easily violated in real data, where heterogeneous row- or column-wise probability of binary entries results in disparate element-wise background distribution, and paralyzes the rationality of existing methods. We propose a binary data denoising framework, namely BIND, which optimizes the detection of true patterns by estimating the row- or column-wise mixture distribution of patterns and disparate background, and eliminating the binary attributes that are more likely from the background. BIND is supported by thoroughly derived mathematical property of the row- and column-wise mixture distributions. Our experiment on synthetic and real-world data demonstrated BIND effectively removes background noise and drastically increases the fairness and accuracy of state-of-the arts BMF and CC methods.</p>
<p>Keywords:</p>
<h3 id="269. Dual Autoencoder Network with Swap Reconstruction for Cold-Start Recommendation.">269. Dual Autoencoder Network with Swap Reconstruction for Cold-Start Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412069">Paper Link</a>    Pages:2249-2252</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/08/6391.html">Bei Wang</a> ; <a href="https://dblp.uni-trier.de/pid/123/8149.html">Chenrui Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/55/2270.html">Hao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/221/8947.html">Xiaoqing Lyu</a> ; <a href="https://dblp.uni-trier.de/pid/16/4222.html">Zhi Tang</a></p>
<p>Abstract:
Cold-start is a long-standing and challenging problem in recommendation systems. To tackle this issue, many cross-domain recommendation approaches are proposed. However, most of them follow a two-stage embedding-and-mapping paradigm, which is hard to be optimized. Besides, they ignore the structure information of the user-item interaction graph, resulting in that the embedding is insufficient to capture the latent collaborative filtering effect. In this paper, we propose a Dual Autoencoder Network (DAN), which implements cross-domain recommendations to cold-start users in an end-to-end manner. The graph convolutional network (GCN) based encoder in DAN explicitly captures high-order collaborative information in user-item interaction graphs. The two-branched decoder is proposed for fully exploiting the data across domains, and therefore the elaborate reconstruction constraints are obtained under a domain swapping strategy. Experiments on two pairs of real-world cross-domain datasets demonstrate that DAN outperforms existing state-of-the-art methods.</p>
<p>Keywords:</p>
<h3 id="270. Embedding Node Structural Role Identity into Hyperbolic Space.">270. Embedding Node Structural Role Identity into Hyperbolic Space.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412102">Paper Link</a>    Pages:2253-2256</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/23/5672.html">Lili Wang</a> ; <a href="https://dblp.uni-trier.de/pid/20/6679.html">Ying Lu</a> ; <a href="https://dblp.uni-trier.de/pid/276/4995.html">Chenghan Huang</a> ; <a href="https://dblp.uni-trier.de/pid/01/1709.html">Soroush Vosoughi</a></p>
<p>Abstract:
Recently, there has been an interest in embedding networks in hyperbolic space, since hyperbolic space has been shown to work well in capturing graph/network structure as it can naturally reflect some properties of complex networks. However, the work on network embedding in hyperbolic space has been focused on microscopic node embedding. In this work, we are the first to present a framework to embed the structural roles of nodes into hyperbolic space. Our framework extends struct2vec, a well-known structural role preserving embedding method, by moving it to a hyperboloid model. We evaluated our method on four real-world and one synthetic network. Our results show that hyperbolic space is more effective than euclidean space in learning latent representations for the structural role of nodes.</p>
<p>Keywords:</p>
<h3 id="271. Calibration of Google Trends Time Series.">271. Calibration of Google Trends Time Series.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412075">Paper Link</a>    Pages:2257-2260</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/142/8100.html">Robert West</a></p>
<p>Abstract:
Google Trends is a tool that allows researchers to analyze the popularity of Google search queries across time and space. In a single request, users can obtain time series for up to 5 queries on a common scale, normalized to the range from 0 to 100 and rounded to integer precision. Despite the overall value of Google Trends, rounding causes major problems, to the extent that entirely uninformative, all-zero time series may be returned for unpopular queries when requested together with more popular queries. We address this issue by proposing Google Trends Anchor Bank (G-TAB), an efficient solution for the calibration of Google Trends data. Our method expresses the popularity of an arbitrary number of queries on a common scale without being compromised by rounding errors. The method proceeds in two phases. In the offline preprocessing phase, an "anchor bank" is constructed, a set of queries spanning the full spectrum of popularity, all calibrated against a common reference query by carefully chaining together multiple Google Trends requests. In the online deployment phase, any given search query is calibrated by performing an efficient binary search in the anchor bank. Each search step requires one Google Trends request, but few steps suffice, as we demonstrate in an empirical evaluation. We make our code publicly available as an easy-to-use library at <a href="https://github.com/epfl-dlab/GoogleTrendsAnchorBank">https://github.com/epfl-dlab/GoogleTrendsAnchorBank</a>.</p>
<p>Keywords:</p>
<h3 id="272. Tolerant Markov Boundary Discovery for Feature Selection.">272. Tolerant Markov Boundary Discovery for Feature Selection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3415927">Paper Link</a>    Pages:2261-2264</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/143/0523.html">Xingyu Wu</a> ; <a href="https://dblp.uni-trier.de/pid/172/2593.html">Bingbing Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/81/5094.html">Yan Zhong</a> ; <a href="https://dblp.uni-trier.de/pid/72/5816.html">Huanhuan Chen</a></p>
<p>Abstract:
Due to the interpretability and robustness, Markov boundary (MB) has received much attention and been widely applied to causal feature selection. However, enormous empirical studies show that, existing algorithms achieve outstanding performance only on the standard Bayesian network data. While on the real-world data, they could not identify some of the relevant features since the large conditioning set and the ignored multivariate dependence lead to performance degradation. In this paper, we propose a tolerant MB discovery algorithm (TLMB), which maps the feature space and target space to a reproducing kernel Hilbert space through the conditional covariance operator, to measure the causal information carried by a feature. Specifically, TLMB uses a score function to filter the redundant features first and then minimize the trace of the conditional covariance operator, where both of the score function and the optimization problem work in the reproducing kernel Hilbert space so that TLMB can select features with not only pairwise dependence but also multivariate dependence. Moreover, as a MB-based method, TLMB can automatically determine the number of selected features due to the property of MB.</p>
<p>Keywords:</p>
<h3 id="273. Deep Multi-Interest Network for Click-through Rate Prediction.">273. Deep Multi-Interest Network for Click-through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412092">Paper Link</a>    Pages:2265-2268</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/184/0716.html">Zhibo Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/156/1159.html">Luwei Yang</a> ; <a href="https://dblp.uni-trier.de/pid/37/6235.html">Wen Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/04/470.html">Yi Wei</a> ; <a href="https://dblp.uni-trier.de/pid/77/1274.html">Yi Hu</a> ; <a href="https://dblp.uni-trier.de/pid/181/2812.html">Hao Wang</a></p>
<p>Abstract:
Click-through rate prediction plays an important role in many fields, such as recommender and advertising systems. It is one of the crucial parts to improve user experience and increase industry revenue. Recently, several deep learning-based models are successfully applied to this area. Some existing studies further model user representation based on user historical behavior sequence, in order to capture dynamic and evolving interests. We observe that users usually have multiple interests at a time and the latent dominant interest is expressed by the behavior. The switch of latent dominant interest results in the behavior changes. Thus, modeling and tracking latent multiple interests would be beneficial. In this paper, we propose a novel method named as Deep Multi-Interest Network (DMIN) which models user's latent multiple interests for click-through rate prediction task. Specifically, we design a Behavior Refiner Layer using multi-head self-attention to capture better user historical item representations. Then the Multi-Interest Extractor Layer is applied to extract multiple user interests. We evaluate our method on three real-world datasets. Experimental results show that the proposed DMIN outperforms various state-of-the-art baselines in terms of click-through rate prediction task.</p>
<p>Keywords:</p>
<h3 id="274. Learning to Generate Reformulation Actions for Scalable Conversational Query Understanding.">274. Learning to Generate Reformulation Actions for Scalable Conversational Query Understanding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412112">Paper Link</a>    Pages:2269-2272</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/123/2241.html">Zihan Xu</a> ; <a href="https://dblp.uni-trier.de/pid/35/5763.html">Jiangang Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/215/7554.html">Ling Geng</a> ; <a href="https://dblp.uni-trier.de/pid/48/450.html">Yang Yang</a> ; <a href="https://dblp.uni-trier.de/pid/25/10089.html">Bojia Lin</a> ; <a href="https://dblp.uni-trier.de/pid/77/5094.html">Daxin Jiang</a></p>
<p>Abstract:
The ability of conversational query understanding (CQU) is indispensable to multi-turn QA. However, existing methods are data-driven and expensive to extend to new conversation domains, or under specific frameworks and hard to apply to other underlying QA technologies. We propose a novel contextual query reformulation (CQR) module based on reformulation actions for general CQU. The actions are domain-independent and scalable, since they capture syntactic regularities of conversations. For action generation, we propose a multi-task learning framework enhanced by coreference resolution, and introduce grammar constraints into the decoding process. Then CQR synthesizes standalone queries based on the actions, which naturally adapts to original downstream technologies. Experiments on different CQU datasets suggest that action-based methods substantially outperform direct reformulation, and the proposed model performs the best among the methods.</p>
<p>Keywords:</p>
<h3 id="275. Enhance Prototypical Network with Text Descriptions for Few-shot Relation Classification.">275. Enhance Prototypical Network with Text Descriptions for Few-shot Relation Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412153">Paper Link</a>    Pages:2273-2276</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/238/4159.html">Kaijia Yang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5130.html">Nantao Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/39/5815.html">Xinyu Dai</a> ; <a href="https://dblp.uni-trier.de/pid/42/963.html">Liang He</a> ; <a href="https://dblp.uni-trier.de/pid/57/8451.html">Shujian Huang</a> ; <a href="https://dblp.uni-trier.de/pid/42/4315.html">Jiajun Chen</a></p>
<p>Abstract:
Recently few-shot relation classification has drawn much attention. It devotes to addressing the long-tail relation problem by recognizing the relations from few instances. The existing metric learning methods aim to learn the prototype of classes and make prediction according to distances between query and prototypes. However, it is likely to make unreliable predictions due to the text diversity. It is intuitive that the text descriptions of relation and entity can provide auxiliary support evidence for relation classification. In this paper, we propose TD-Proto, which enhances prototypical network with relation and entity descriptions. We design a collaborative attention module to extract beneficial and instructional information of sentence and entity respectively. A gate mechanism is proposed to fuse both information dynamically so as to obtain a knowledge-aware instance. Experimental results demonstrate that our method achieves excellent performance.</p>
<p>Keywords:</p>
<h3 id="276. Analysis of Multivariate Scoring Functions for Automatic Unbiased Learning to Rank.">276. Analysis of Multivariate Scoring Functions for Automatic Unbiased Learning to Rank.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412128">Paper Link</a>    Pages:2277-2280</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/67/1120.html">Tao Yang</a> ; <a href="https://dblp.uni-trier.de/pid/270/2142.html">Shikai Fang</a> ; <a href="https://dblp.uni-trier.de/pid/12/6956.html">Shibo Li</a> ; <a href="https://dblp.uni-trier.de/pid/88/3960.html">Yulan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/169/1808.html">Qingyao Ai</a></p>
<p>Abstract:
Leveraging biased click data for optimizing learning to rank systems has been a popular approach in information retrieval. Because click data is often noisy and biased, a variety of methods have been proposed to construct unbiased learning to rank (ULTR) algorithms for the learning of unbiased ranking models. Among them, automatic unbiased learning to rank (AutoULTR) algorithms that jointly learn user bias models (i.e., propensity models) with unbiased rankers have received a lot of attention due to their superior performance and low deployment cost in practice. Despite their differences in theories and algorithm design, existing studies on ULTR usually use uni-variate ranking functions to score each document or result independently. On the other hand, recent advances in context-aware learning-to-rank models have shown that multivariate scoring functions, which read multiple documents together and predict their ranking scores jointly, are more powerful than uni-variate ranking functions in ranking tasks with human-annotated relevance labels. Whether such superior performance would hold in ULTR with noisy data, however, is mostly unknown. In this paper, we investigate existing multivariate scoring functions and AutoULTR algorithms in theory and prove that permutation invariance is a crucial factor that determines whether a context-aware learning-to-rank model could be applied to existing AutoULTR framework. Our experiments with synthetic clicks on two large-scale benchmark datasets show that AutoULTR models with permutation-invariant multivariate scoring functions significantly outperform those with uni-variate scoring functions and permutation-variant multivariate scoring functions.</p>
<p>Keywords:</p>
<h3 id="277. Time-aware Graph Relational Attention Network for Stock Recommendation.">277. Time-aware Graph Relational Attention Network for Stock Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412160">Paper Link</a>    Pages:2281-2284</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5070.html">Xiaoting Ying</a> ; <a href="https://dblp.uni-trier.de/pid/47/4804.html">Cong Xu</a> ; <a href="https://dblp.uni-trier.de/pid/91/296.html">Jianliang Gao</a> ; <a href="https://dblp.uni-trier.de/pid/75/2669.html">Jianxin Wang</a> ; <a href="https://dblp.uni-trier.de/pid/l/ZhaoLi.html">Zhao Li</a></p>
<p>Abstract:
Recommending stock with the highest return ratio is always a challenging problem in the field of financial technology. In this paper, we propose a time-aware graph relational attention network (TRAN) for stock recommendation based on return ratio ranking. In TRAN, time-aware relational attention mechanism is the key unit to capture time-varying correlation strength between stocks by the interaction of historical sequences and stock description documents. With the dynamic strength, the nodes of the stock relation graph aggregate the features of neighbor stock nodes by graph convolution operation. For a given group of stocks, our model can output the ranking results of stocks according to their return ratios. The experimental results on several real-world datasets demonstrate the effectiveness of our TRAN for stock recommendation.</p>
<p>Keywords:</p>
<h3 id="278. Deep Interaction Machine: A Simple but Effective Model for High-order Feature Interactions.">278. Deep Interaction Machine: A Simple but Effective Model for High-order Feature Interactions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412077">Paper Link</a>    Pages:2285-2288</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/28/1708.html">Feng Yu</a> ; <a href="https://dblp.uni-trier.de/pid/50/7648.html">Zhaocheng Liu</a> ; <a href="https://dblp.uni-trier.de/pid/61/3234.html">Qiang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/263/7892.html">Haoli Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/06/3577.html">Shu Wu</a> ; <a href="https://dblp.uni-trier.de/pid/56/4499.html">Liang Wang</a></p>
<p>Abstract:
Click-Through Rate (CTR) prediction is a crucial task for various online applications, such as recommendation and online advertising. The task of CTR prediction is to predict the probability of users' clicking behaviors, with high-dimensional input features. To avoid heavy handcrafted feature engineering, the core topic of CTR prediction is the automatic interactions of the input features. Factorization Machine (FM) is an effective approach for modeling second-order feature interactions. Recently, FM has been extended for modeling higher-order feature interactions, such as xDeepFM and Higher-Order Factorization Machine (HOFM). However, these approaches are with either high complexity or iterative computation consuming much time and space. To overcome above problems, we express arbitrary-order FM in the form of power sums according to Newton's identities. Accordingly, we propose a novel Interaction Machine (IM) model. IM is an efficient and exact implementation of high-order FM, whose time complexity linearly grows with the order of interactions and the number of feature fields. Via IM, we can conduct arbitrary-order feature interactions in a very simple way. Moreover, we perform IM together with deep neural networks, and the resulted DeepIM model is more efficient than xDeepFM with comparable or even better performance. We conduct experiments on two real-world datasets, in which effectiveness and efficiency of both IM and DeepIM are strongly verified.</p>
<p>Keywords:</p>
<h3 id="279. Few-shot Insider Threat Detection.">279. Few-shot Insider Threat Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412161">Paper Link</a>    Pages:2289-2292</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/172/2711.html">Shuhan Yuan</a> ; <a href="https://dblp.uni-trier.de/pid/202/2302.html">Panpan Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/w/XintaoWu.html">Xintao Wu</a> ; <a href="https://dblp.uni-trier.de/pid/58/1757.html">Hanghang Tong</a></p>
<p>Abstract:
Insiders cause significant cyber-security threats to organizations. Due to a very limited number of insiders, most of the current studies adopt unsupervised learning approaches to detect insiders by analyzing the audit data that record information about employees' activities. However, in practice, we do observe a small number of insiders. How to make full use of these few observed insiders to improve a classifier for insider threat detection is a key challenge. In this work, we propose a novel framework combining the idea of self-supervised pre-training and metric-based few-shot learning to detect insiders. Experimental results on insider threat datasets demonstrate that our model outperforms the existing anomaly detection approaches by only using a few insiders.</p>
<p>Keywords:</p>
<h3 id="280. Leveraging User Email Actions to Improve Ad-Close Prediction.">280. Leveraging User Email Actions to Improve Ad-Close Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412093">Paper Link</a>    Pages:2293-2296</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/245/1783.html">Oleg Zendel</a> ; <a href="https://dblp.uni-trier.de/pid/57/4898.html">Yaroslav Fyodorov</a> ; <a href="https://dblp.uni-trier.de/pid/62/8700.html">Fiana Raiber</a> ; <a href="https://dblp.uni-trier.de/pid/05/2017.html">Natalia Silberstein</a> ; <a href="https://dblp.uni-trier.de/pid/18/4818.html">Oren Somekh</a> ; <a href="https://dblp.uni-trier.de/pid/272/2875.html">Ali Tabaja</a></p>
<p>Abstract:
Online advertising systems often provide means for users to close ads and also leave feedback. Although closing ads requires additional user engagement and usually indicates a poor user experience, ad closes are not as scarce as one might expect. Recently it was shown that penalizing ads with high closing likelihood during auctions may substantially reduce the number of ad closes while maintaining a small predefined revenue loss. In this work, we focus on email since this is the property in which most ad closes occur. Using data collected from a major email provider, we present interesting insights about the interplay between ad closes in email and email-related user actions. In particular, we explore the merits of integrating information derived from user actions in email for ad-close prediction. Thorough performance evaluation reveals that incorporating such signals significantly improves ad-close prediction quality over previously reported results.</p>
<p>Keywords:</p>
<h3 id="281. Event-Driven Network for Cross-Modal Retrieval.">281. Event-Driven Network for Cross-Modal Retrieval.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412081">Paper Link</a>    Pages:2297-2300</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/23/10840.html">Zhixiong Zeng</a> ; <a href="https://dblp.uni-trier.de/pid/26/4304.html">Nan Xu</a> ; <a href="https://dblp.uni-trier.de/pid/16/2159.html">Wenji Mao</a></p>
<p>Abstract:
Despite extensive research on cross-modal retrieval, existing methods focus on the matching between image objects and text words. However, for the large amount of social media, such as news reports and online posts with images, previous methods are insufficient to model the associations between long text and image. As long text contains multiple entities and relationships between them, as well as complex events sharing a common scenario of the text, it poses unique research challenge to cross-modal retrieval. To tackle the challenge, in this paper, we focus on the retrieval task on long text and image, and propose an event-driven network for cross-modal retrieval. Our approach consists of two modules, namely the contextual neural tensor network (CNTN) and cross-modal matching network (CMMN). The CNTN module captures both event-level and text-level semantics of the sequential events extracted from a long text. The CMMN module learns a common representation space to compute the similarity of image and text modalities. We construct a multimodal dataset based on the news reports in People's Daily. The experimental results demonstrate that our model outperforms the existing state-of-the-art methods and can provide semantic richer text representations to enhance the effectiveness in cross-modal retrieval.</p>
<p>Keywords:</p>
<h3 id="282. Integrating Diagnosis Rules into Deep Neural Networks for Bladder Cancer Staging.">282. Integrating Diagnosis Rules into Deep Neural Networks for Bladder Cancer Staging.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412122">Paper Link</a>    Pages:2301-2304</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/82/6384.html">Cheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/36/4716.html">Xiaodong Yue</a> ; <a href="https://dblp.uni-trier.de/pid/79/4489.html">Yufei Chen</a> ; <a href="https://dblp.uni-trier.de/pid/127/8758.html">Ying Lv</a></p>
<p>Abstract:
Bladder cancer is a malignant disease with substantial morbidity and mortality. Bladder cancer staging is crucial to determine the effective treatments of bladder tumors in clinic. As to the superiority of feature learning, Deep Convolutional Neural Networks (DCNN) are widely used to predict the cancer stage based on medical images. However, most existing DCNN-based cancer staging methods are data-driven and neglect the domain knowledge and experiences of clinicians. Besides, the deep neural networks are short of model interpretability and may lead to risky diagnosis. To tackle the problems, we construct the diagnosis rules of bladder cancer staging based on the clinical experiences of tumor penetration into bladder wall. The diagnosis rules are extracted from Magnetic Resonance (MR) images and further integrated into DCNN for joint identification of tumor stage. The experiments validate that the integrated rules improve the model interpretability and guide DCNN to focus on the regions of tumor penetration and thereby produce precise prediction of cancer staging.</p>
<p>Keywords:</p>
<h3 id="283. Hyper-Substructure Enhanced Link Predictor.">283. Hyper-Substructure Enhanced Link Predictor.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412096">Paper Link</a>    Pages:2305-2308</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/07/314-23.html">Jian Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/93/3489.html">Jun Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/50/415.html">Jinyin Chen</a> ; <a href="https://dblp.uni-trier.de/pid/37/8888.html">Qi Xuan</a></p>
<p>Abstract:
Link prediction has long been the focus in the analysis of network-structured data. Though straightforward and efficient, heuristic approaches like Common Neighbors perform link prediction with pre-defined assumptions and only use superficial structural features. While it is widely acknowledged that a vertex could be characterized by a bunch of neighbor vertices, network embedding algorithms and newly emerged graph neural networks still exploit structural features on the whole network, which may inevitably bring in noises and limits the scalability of those methods. In this paper, we propose an end-to-end deep learning framework, namely hyper-substructure enhanced link predictor (HELP), for link prediction. HELP utilizes local topological structures from the neighborhood of the given vertex pairs, avoiding useless features. For further exploiting higher-order structural information, HELP also learns features from hyper-substructure network (HSN).Extensive experiments on six benchmark datasets have shown the state-of-the-art performance of HELP on link prediction.</p>
<p>Keywords:</p>
<h3 id="284. Seasonal-Periodic Subgraph Mining in Temporal Networks.">284. Seasonal-Periodic Subgraph Mining in Temporal Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412091">Paper Link</a>    Pages:2309-2312</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/186/8495.html">Qianzhen Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/74/6501.html">Deke Guo</a> ; <a href="https://dblp.uni-trier.de/pid/07/668-2.html">Xiang Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/139/4257.html">Xinyi Li</a> ; <a href="https://dblp.uni-trier.de/pid/08/5760.html">Xi Wang</a></p>
<p>Abstract:
\emphSeasonal periodicity is a frequent phenomenon for social interactions in temporal networks. A key property of this behavior is that it exhibits periodicity for multiple particular periods in temporal networks. Mining such seasonal-periodic patterns is significant since it can indicate interesting relationships between the individuals involved in the interactions. Unfortunately, most previous studies for periodic pattern mining ignore the seasonal feature. This motivates us to explore mining seasonal-periodic subgraphs, and the investigation presents a novel model, called maximal -periodic $mega$-seasonal k-subgraph. It represents a subgraph with size larger than k and that appears at least  times periodically in at least $mega$ particular periods on the temporal graph. Since seasonal-periodic patterns do not satisfy the anti-monotonic property, we propose a weak version of support measure with an anti-monotonic property to reduce the search space efficiently. Then, we present an effective mining algorithm to seek all maximal -periodic $mega$-seasonal k-subgraphs. Experimental results on real-life datasets show the effectiveness and efficiency of our approach.</p>
<p>Keywords:</p>
<h3 id="285. Multiplex Graph Neural Networks for Multi-behavior Recommendation.">285. Multiplex Graph Neural Networks for Multi-behavior Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412119">Paper Link</a>    Pages:2313-2316</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/19/949.html">Weifeng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/121/3615.html">Jingwen Mao</a> ; <a href="https://dblp.uni-trier.de/pid/00/3090.html">Yi Cao</a> ; <a href="https://dblp.uni-trier.de/pid/44/2633.html">Congfu Xu</a></p>
<p>Abstract:
This paper focuses on the multi-behavior recommendation problem, i.e., generating personalized recommendation based on multiple types of user behaviors. Methods proposed recently usually leverage the ordinal assumption, which means that users? different types of behaviors should take place in a fixed order. However, this assumption may be too strong in some scenarios. In this paper, a more general model named Multiplex Graph Neural Network (MGNN) is proposed as a remedy. MGNN tackles the multi-behavior recommendation problem from a novel perspective, i.e., the perspective of link prediction in multiplex networks. By taking advantage of both the multiplex network structure and graph representation learning techniques, MGNN learns shared embeddings and behavior-specific embeddings for users and items to model the collective effect of multiple types of behaviors. Experiments conducted on both ordinal-behavior datasets and generic-behavior datasets demonstrate the effectiveness of the proposed MGNN model.</p>
<p>Keywords:</p>
<h3 id="286. Robust Normalized Squares Maximization for Unsupervised Domain Adaptation.">286. Robust Normalized Squares Maximization for Unsupervised Domain Adaptation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412083">Paper Link</a>    Pages:2317-2320</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/21/4273.html">Wenju Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/91/4353.html">Xiang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/09/8600-1.html">Qing Liao</a> ; <a href="https://dblp.uni-trier.de/pid/48/3396.html">Wenjing Yang</a> ; <a href="https://dblp.uni-trier.de/pid/124/2136.html">Long Lan</a> ; <a href="https://dblp.uni-trier.de/pid/02/2039.html">Zhigang Luo</a></p>
<p>Abstract:
Unsupervised domain adaptation (UDA) attempts to transfer specific knowledge from one domain with labeled data to another domain without labels. Recently, maximum squares loss has been proposed to tackle UDA problem but it does not consider the prediction diversity which has proven beneficial to UDA. In this paper, we propose a novel normalized squares maximization (NSM) loss in which the maximum squares is normalized by the sum of squares of class sizes. The normalization term enforces the class sizes of predictions to be balanced to explicitly increase the diversity. Theoretical analysis shows that the optimal solution to NSM is one-hot vectors with balanced class sizes, i.e., NSM encourages both discriminate and diverse predictions. We further propose a robust variant of NSM, RNSM, by replacing the square loss with L2,1-norm to reduce the influence of outliers and noises. Experiments of cross-domain image classification on two benchmark datasets illustrate the effectiveness of both NSM and RNSM. RNSM achieves promising performance compared to state-of-the-art methods. The code is available at <a href="https://github.com/wj-zhang/NSM">https://github.com/wj-zhang/NSM</a>.</p>
<p>Keywords:</p>
<h3 id="287. Community Identification in Signed Networks: A K-Truss Based Model.">287. Community Identification in Signed Networks: A K-Truss Based Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412117">Paper Link</a>    Pages:2321-2324</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/47/2026.html">Jun Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/274/6445.html">Renjie Sun</a> ; <a href="https://dblp.uni-trier.de/pid/05/6340.html">Qiuyu Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/81/1832.html">Xiaoyang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/65/4423-17.html">Chen Chen</a></p>
<p>Abstract:
Community detection is a fundamental problem in social network analysis, and most existing studies focus on unsigned graphs, i.e., treating all relationships as positive. However, friend and foe relationships naturally exist in many real-world applications. Ignoring the signed information may lead to unstable communities. To better describe the communities, we propose a novel model, named signed k-truss, which leverages the properties of k-truss and balanced triangle. We prove that the problem of identifying the maximum signed k-truss is NP-hard. To deal with large graphs, novel pruning strategies and algorithms are developed. Finally, we conduct comprehensive experiments on real-world signed networks to evaluate the performance of proposed techniques.</p>
<p>Keywords:</p>
<h3 id="288. An Event-Oriented Neural Ranking Model for News Retrieval.">288. An Event-Oriented Neural Ranking Model for News Retrieval.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412082">Paper Link</a>    Pages:2325-2328</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/72/2195.html">Lin Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/245/3679.html">Wanhui Qian</a> ; <a href="https://dblp.uni-trier.de/pid/65/1380.html">Liangjun Zang</a> ; <a href="https://dblp.uni-trier.de/pid/200/8105.html">Fuqing Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/43/5240.html">Yijun Lu</a> ; <a href="https://dblp.uni-trier.de/pid/60/4429.html">Ruixuan Li</a> ; <a href="https://dblp.uni-trier.de/pid/72/6837.html">Jizhong Han</a> ; <a href="https://dblp.uni-trier.de/pid/67/4108.html">Songlin Hu</a></p>
<p>Abstract:
Event-oriented news retrieval (ENR) is the task of retrieving news articles related to the specific event in response to the event-oriented query. Previous approaches usually focus on optimizing traditional retrieval models through hand-crafted features from the perspective of new articles. However, these approaches often fail to work well in reality, as they do not consider the essential natures of the event, i.e., dynamics, coupling. In this paper, we propose a novel and effective event-oriented neural ranking model for news retrieval (ENRMNR). Our model exploits a deep attention mechanism to tackle the dynamics and coupling derived from event evolution. Specifically, the word-level bidirectional attention allows the model to identify which query words about the subevent are related to the news article words, and vice-versa, in order to tackle the dynamics. Moreover, the hierarchical attention at passage-level and document-level allows it to capture fine-grained event representations for the coupling between different events within a news article. Experimental results on real-world datasets demonstrate that ENRMNR model significantly outperforms competitive models.</p>
<p>Keywords:</p>
<h3 id="289. Revisiting Alternative Experimental Settings for Evaluating Top-N Item Recommendation Algorithms.">289. Revisiting Alternative Experimental Settings for Evaluating Top-N Item Recommendation Algorithms.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412095">Paper Link</a>    Pages:2329-2332</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/52/8700.html">Wayne Xin Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/31/7484.html">Junhua Chen</a> ; <a href="https://dblp.uni-trier.de/pid/90/4693.html">Pengfei Wang</a> ; <a href="https://dblp.uni-trier.de/pid/18/4144.html">Qi Gu</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
Top-N item recommendation has been a widely studied task from implicit feedback. Although much progress has been made with neural methods, there is increasing concern on appropriate evaluation of recommendation algorithms. In this paper, we revisit alternative experimental settings for evaluating top-N recommendation algorithms, considering three important factors, namely dataset splitting, sampled metrics and domain selection. We select eight representative recommendation algorithms (covering both traditional and neural methods) and construct extensive experiments on a very large dataset. By carefully revisiting different options, we make several important findings on the three factors, which directly provide useful suggestions on how to appropriately set up the experiments for top-N item recommendation.</p>
<p>Keywords:</p>
<h3 id="290. Dimension Relation Modeling for Click-Through Rate Prediction.">290. Dimension Relation Modeling for Click-Through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412108">Paper Link</a>    Pages:2333-2336</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/63/9613.html">Zihao Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/54/1588.html">Zhiwei Fang</a> ; <a href="https://dblp.uni-trier.de/pid/93/2334.html">Yong Li</a> ; <a href="https://dblp.uni-trier.de/pid/274/7573.html">Changping Peng</a> ; <a href="https://dblp.uni-trier.de/pid/52/5055.html">Yongjun Bao</a> ; <a href="https://dblp.uni-trier.de/pid/216/8297.html">Weipeng Yan</a></p>
<p>Abstract:
Embedding mechanism plays an important role in Click-Through-Rate (CTR) prediction. Essentially, it tries to learn a new feature space with some learned latent properties as the basis, and maps the high dimensional and categorical raw data to dense, rich and expressive representations, i.e., the embedding features. Current researches usually focus on learning the interactions through operations on the whole embedding features without considering the relations among the learned latent properties. In this paper, we find it has clear positive effects on CTR prediction to model such relations and propose a novel Dimension Relation Module (DRM) to capture them through dimension recalibration. We show that DRM can improve the performance of existing models consistently and the improvements are more obvious when the embedding dimension is higher. We further boost Field-wise and Element-wise embedding methods with our DRM and name this new model FED network. Extensive experiments demonstrate that FED is very powerful in CTR prediction task and achieves new state-of-the-art results on Criteo, Avazu and JD.com datasets.</p>
<p>Keywords:</p>
<h3 id="291. On-demand Influencer Discovery on Social Media.">291. On-demand Influencer Discovery on Social Media.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412134">Paper Link</a>    Pages:2337-2340</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/37/170.html">Cheng Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/45/47.html">Qin Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/22/6900.html">Sean D. Young</a> ; <a href="https://dblp.uni-trier.de/pid/35/7092.html">Wei Wang</a></p>
<p>Abstract:
Identifying influencers on social media, such as Twitter, has played a central role in many applications, including online marketing and political campaigns. Compared with social media celebrities, domain-specific influencers are less expensive to hire and more engaged in spreading messages such as new treatment or timely prevention for HIV. However, most of the existing topic modeling based approaches fail to identify influencers who are dedicated to the rare yet important topics such as HIV and suicide. To alleviate this limitation, we investigate an on-Demand Influencer Discovery (DID) framework that is able to identify influencers on any subject depicted by a few user-specified keywords, regardless of its popularity on social media. The DID model employs an iterative learning process that integrates the language attention network as a subject filter and the influence convolution network built on user interactions. Comprehensive evaluations on Twitter datasets show that the DID model can reliably identify influencers even on rare subjects such as HIV and suicide, outperforming existing topic-specific influencer detection models.</p>
<p>Keywords:</p>
<h3 id="292. Data Augmentation for Graph Classification.">292. Data Augmentation for Graph Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412086">Paper Link</a>    Pages:2341-2344</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/201/0596.html">Jiajun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/32/1203.html">Jie Shen</a> ; <a href="https://dblp.uni-trier.de/pid/37/8888.html">Qi Xuan</a></p>
<p>Abstract:
Graph classification, which aims to identify the category labels of graphs, plays a significant role in drug classification, toxicity detection, protein analysis etc. However, the limitation of scale of benchmark datasets makes it easy for graph classification models to fall into over-fitting and undergeneralization. Towards this, we introduce data augmentation on graphs and present two heuristic algorithms: \emrandom mapping and \emmotif-similarity mapping, to generate more weakly labeled data for small-scale benchmark datasets via heuristic modification of graph structures. Furthermore, we propose a generic model evolution framework, named \emM-Evolve, which combines graph augmentation, data filtration and model retraining to optimize pre-trained graph classifiers. Experiments conducted on six benchmark datasets demonstrate that \emM-Evolve helps existing graph classification models alleviate over-fitting when training on small-scale benchmark datasets and %achieve significant improvement of classification performance. yields an average improvement of 3-12% accuracy on graph classification tasks.</p>
<p>Keywords:</p>
<h3 id="293. Diversifying Multi-aspect Search Results Using Simpson's Diversity Index.">293. Diversifying Multi-aspect Search Results Using Simpson's Diversity Index.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412163">Paper Link</a>    Pages:2345-2348</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/204/2523.html">Jianghong Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/26/1185.html">Eugene Agichtein</a> ; <a href="https://dblp.uni-trier.de/pid/09/9727.html">Surya Kallumadi</a></p>
<p>Abstract:
In search and recommendation, diversifying the multi-aspect search results could help with reducing redundancy, and promoting results that might not be shown otherwise. Many previous methods have been proposed for this task. However, previous methods do not explicitly consider the uniformity of the number of the items' classes, or evenness, which could degrade the search and recommendation quality. To address this problem, we introduce a novel method by adapting the Simpson's Diversity Index from biology, which enables a more effective and efficient quadratic search result diversification algorithm. We also extend the method to balance the diversity between multiple aspects through weighted factors and further improve computational complexity by developing a fast approximation algorithm. We demonstrate the feasibility of the proposed method using the openly available Kaggle shoes competition dataset. Our experimental results show that our approach outperforms previous state of the art diversification methods, while reducing computational complexity.</p>
<p>Keywords:</p>
<h3 id="294. Leveraging Historical Interaction Data for Improving Conversational Recommender System.">294. Leveraging Historical Interaction Data for Improving Conversational Recommender System.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412098">Paper Link</a>    Pages:2349-2352</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/48/3927.html">Kun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/52/8700.html">Wayne Xin Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/39/721.html">Hui Wang</a> ; <a href="https://dblp.uni-trier.de/pid/93/10146.html">Sirui Wang</a> ; <a href="https://dblp.uni-trier.de/pid/134/2883.html">Fuzheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/84/6394.html">Zhongyuan Wang</a> ; <a href="https://dblp.uni-trier.de/pid/w/JRWen.html">Ji-Rong Wen</a></p>
<p>Abstract:
Recently, conversational recommender system (CRS) has become an emerging and practical research topic. Most of the existing CRS methods focus on learning effective preference representations for users from conversation data alone. While, we take a new perspective to leverage historical interaction data for improving CRS. For this purpose, we propose a novel pre-training approach to integrating both item-based preference sequence (from historical interaction data) and attribute-based preference sequence (from conversation data) via pre-training methods. We carefully design two pre-training tasks to enhance information fusion between item- and attribute-based preference. To improve the learning performance, we further develop an effective negative sample generator which can produce high-quality negative samples. Experiment results on two real-world datasets have demonstrated the effectiveness of our approach for improving CRS.</p>
<p>Keywords:</p>
<h3 id="295. Behavior-driven Student Performance Prediction with Tri-branch Convolutional Neural Network.">295. Behavior-driven Student Performance Prediction with Tri-branch Convolutional Neural Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412110">Paper Link</a>    Pages:2353-2356</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/224/1726.html">Jian Zong</a> ; <a href="https://dblp.uni-trier.de/pid/23/8313.html">Chaoran Cui</a> ; <a href="https://dblp.uni-trier.de/pid/225/0189.html">Yuling Ma</a> ; <a href="https://dblp.uni-trier.de/pid/83/6976.html">Li Yao</a> ; <a href="https://dblp.uni-trier.de/pid/25/687.html">Meng Chen</a> ; <a href="https://dblp.uni-trier.de/pid/94/458.html">Yilong Yin</a></p>
<p>Abstract:
Student performance prediction aims to leverage student-related information to predict their future academic outcomes, which may be beneficial to numerous educational applications, such as personalized teaching and academic early warning. In this paper, we seek to address the problem by analyzing students' daily studying and living behavior, which is comprehensively recorded via campus smart cards. Different from previous studies, we propose an end-to-end student performance prediction model, namely Tri-branch CNN, which is equipped with three types of convolutional filters, i.e., the row-wise convolution, column-wise convolution, and group-wise convolution, to effectively capture the duration, periodicity, and location-aware characteristic of student behavior, respectively. We also introduce the attention mechanism and cost-sensitive learning strategy to further improve the accuracy of our approach. Extensive experiments on a large-scale real-world dataset demonstrate the potential of our approach for student performance prediction.</p>
<p>Keywords:</p>
<h3 id="296. Multimodal Clustering via Deep Commonness and Uniqueness Mining.">296. Multimodal Clustering via Deep Commonness and Uniqueness Mining.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412103">Paper Link</a>    Pages:2357-2360</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/160/3158.html">Linlin Zong</a> ; <a href="https://dblp.uni-trier.de/pid/276/5064.html">Faqiang Miao</a> ; <a href="https://dblp.uni-trier.de/pid/40/4372.html">Xianchao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/26/1194-8.html">Bo Xu</a></p>
<p>Abstract:
Deep multimodal clustering have shown their competitiveness among different multimodal clustering algorithms. Existing algorithms usually boost the multimodal clustering by exploring the common knowledge among multiple modalities, which underutilizes the uniqueness of multiple modalities. In this paper, we enhance the mining of modality-common knowledge by extracting the modality-unique knowledge of each modality simultaneously. Specifically, we first utilize autoencoders to extract the modality-common and modality-unique features of each modality respectively. Meanwhile, the cross reconstruction is used to build latent connections among different modalities, i.e., maintain the consistency of modality-common features of each modality as well as heightening the diversity of modality-unique features of each modality. After that, modality-common features are fused to cluster the multimodal data. Experimental results on several benchmark datasets demonstrate that the proposed method outperforms state-of-art works obviously.</p>
<p>Keywords:</p>
<h3 id="297. An Empirical Study on Clarifying Question-Based Systems.">297. An Empirical Study on Clarifying Question-Based Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412094">Paper Link</a>    Pages:2361-2364</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/49/6450.html">Jie Zou</a> ; <a href="https://dblp.uni-trier.de/pid/22/3088.html">Evangelos Kanoulas</a> ; <a href="https://dblp.uni-trier.de/pid/49/1579-1.html">Yiqun Liu</a></p>
<p>Abstract:
Search and recommender systems that take the initiative to ask clarifying questions to better understand users' information needs are receiving increasing attention from the research community. However, to the best of our knowledge, there is no empirical study to quantify whether and to what extent users are willing or able to answer these questions. In this work, we conduct an online experiment by deploying an experimental system, which interacts with users by asking clarifying questions against a product repository. We collect both implicit interaction behavior data and explicit feedback from users showing that: (a) users are willing to answer a good number of clarifying questions (11 on average), but not many more than that; (b) most users answer questions until they reach the target product, but also a fraction of them stops due to fatigue or due to receiving irrelevant questions; (c) part of the users' answers (17%) are actually opposite to the description of the target product; while (d) most of the users (84%) find the question-based system helpful towards completing their tasks. Some of the findings of the study contradict current assumptions on simulated evaluations in the field, while they point towards improvements in the evaluation framework and can inspire future interactive search/recommender system designs.</p>
<p>Keywords:</p>
<h2 id="Applied Research Track    73">Applied Research Track    73</h2>
<h3 id="298. AutoADR: Automatic Model Design for Ad Relevance.">298. AutoADR: Automatic Model Design for Ad Relevance.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412688">Paper Link</a>    Pages:2365-2372</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/157/1780.html">Yiren Chen</a> ; <a href="https://dblp.uni-trier.de/pid/204/3789.html">Yaming Yang</a> ; <a href="https://dblp.uni-trier.de/pid/37/5447.html">Hong Sun</a> ; <a href="https://dblp.uni-trier.de/pid/16/4075.html">Yujing Wang</a> ; <a href="https://dblp.uni-trier.de/pid/27/0.html">Yu Xu</a> ; <a href="https://dblp.uni-trier.de/pid/71/3692.html">Wei Shen</a> ; <a href="https://dblp.uni-trier.de/pid/z/RongZhou.html">Rong Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/14/1705.html">Yunhai Tong</a> ; <a href="https://dblp.uni-trier.de/pid/35/328.html">Jing Bai</a> ; <a href="https://dblp.uni-trier.de/pid/36/2351.html">Ruofei Zhang</a></p>
<p>Abstract:
Large-scale pre-trained models have attracted extensive attention in the research community and shown promising results on various tasks of natural language processing. However, these pre-trained models are memory and computation intensive, hindering their deployment into industrial online systems like Ad Relevance. Meanwhile, how to design an effective yet efficient model architecture is another challenging problem in online Ad Relevance. Recently, AutoML shed new lights on architecture design, but how to integrate it with pre-trained language models remains unsettled. In this paper, we propose AutoADR (Automatic model design for AD Relevance) --- a novel end-to-end framework to address this challenge, and share our experience to ship these cutting-edge techniques into online Ad Relevance system at Microsoft Bing. Specifically, AutoADR leverages a one-shot neural architecture search algorithm to find a tailored network architecture for Ad Relevance. The search process is simultaneously guided by knowledge distillation from a large pre-trained teacher model (e.g. BERT), while taking the online serving constraints (e.g. memory and latency) into consideration. We add the model designed by AutoADR as a sub-model into the production Ad Relevance model. This additional sub-model improves the Precision-Recall AUC (PR AUC) on top of the original Ad Relevance model by 2.65X of the normalized shipping bar. More importantly, adding this automatically designed sub-model leads to a statistically significant 4.6% Bad-Ad ratio reduction in online A/B testing. This model has been shipped into Microsoft Bing Ad Relevance Production model.</p>
<p>Keywords:</p>
<h3 id="299. U-rank: Utility-oriented Learning to Rank with Implicit Feedback.">299. U-rank: Utility-oriented Learning to Rank with Implicit Feedback.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412756">Paper Link</a>    Pages:2373-2380</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/230/0439.html">Xinyi Dai</a> ; <a href="https://dblp.uni-trier.de/pid/230/4045.html">Jiawei Hou</a> ; <a href="https://dblp.uni-trier.de/pid/53/4481.html">Qing Liu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5122.html">Yunjia Xi</a> ; <a href="https://dblp.uni-trier.de/pid/24/10003.html">Ruiming Tang</a> ; <a href="https://dblp.uni-trier.de/pid/28/10261-1.html">Weinan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/11/5357.html">Xiuqiang He</a> ; <a href="https://dblp.uni-trier.de/pid/w/JunWang12.html">Jun Wang</a> ; <a href="https://dblp.uni-trier.de/pid/43/5685-1.html">Yong Yu</a></p>
<p>Abstract:
Learning to rank with implicit feedback is one of the most important tasks in many real-world information systems where the objective is some specific utility, e.g., clicks and revenue. However, we point out that existing methods based on probabilistic ranking principle do not necessarily achieve the highest utility. To this end, we propose a novel ranking framework called U-rank that directly optimizes the expected utility of the ranking list. With a position-aware deep click-through rate prediction model, we address the attention bias considering both query-level and item-level features. Due to the item-specific attention bias modeling, the optimization for expected utility corresponds to a maximum weight matching on the item-position bipartite graph. We base the optimization of this objective in an efficient Lambdaloss framework, which is supported by both theoretical and empirical analysis. We conduct extensive experiments for both web search and recommender systems over three benchmark datasets and two proprietary datasets, where the performance gain of U-rank over state-of-the-arts is demonstrated. Moreover, our proposed U-rank has been deployed on a large-scale commercial recommender and a large improvement over the production baseline has been observed in an online A/B testing.</p>
<p>Keywords:</p>
<h3 id="300. Personalized Bundle Recommendation in Online Games.">300. Personalized Bundle Recommendation in Online Games.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412734">Paper Link</a>    Pages:2381-2388</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/74/6524.html">Qilin Deng</a> ; <a href="https://dblp.uni-trier.de/pid/78/2022.html">Kai Wang</a> ; <a href="https://dblp.uni-trier.de/pid/44/9546.html">Minghao Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/276/5108.html">Zhene Zou</a> ; <a href="https://dblp.uni-trier.de/pid/180/4550.html">Runze Wu</a> ; <a href="https://dblp.uni-trier.de/pid/185/4005.html">Jianrong Tao</a> ; <a href="https://dblp.uni-trier.de/pid/71/882.html">Changjie Fan</a> ; <a href="https://dblp.uni-trier.de/pid/01/5394.html">Liang Chen</a></p>
<p>Abstract:
In business domains, bundling is one of the most important marketing strategies to conduct product promotions, which is commonly used in online e-commerce and offline retailers. Existing recommender systems mostly focus on recommending individual items that users may be interested in. In this paper, we target at a practical but less explored recommendation problem named bundle recommendation, which aims to offer a combination of items to users. To tackle this specific recommendation problem in the context of the virtual mall in online games, we formalize it as a link prediction problem on a user-item-bundle tripartite graph constructed from the historical interactions, and solve it with a neural network model that can learn directly on the graph-structure data. Extensive experiments on three public datasets and one industrial game dataset demonstrate the effectiveness of the proposed method. Further, the bundle recommendation model has been deployed in production for more than one year in a popular online game developed by Netease Games, and the launch of the model yields more than 60% improvement on conversion rate of bundles, and a relative improvement of more than 15% on gross merchandise volume (GMV).</p>
<p>Keywords:</p>
<h3 id="301. Learning Formatting Style Transfer and Structure Extraction for Spreadsheet Tables with a Hybrid Neural Network Architecture.">301. Learning Formatting Style Transfer and Structure Extraction for Spreadsheet Tables with a Hybrid Neural Network Architecture.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412718">Paper Link</a>    Pages:2389-2396</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/180/5089.html">Haoyu Dong</a> ; <a href="https://dblp.uni-trier.de/pid/64/5141.html">Jiong Yang</a> ; <a href="https://dblp.uni-trier.de/pid/23/3395.html">Shi Han</a> ; <a href="https://dblp.uni-trier.de/pid/87/461.html">Dongmei Zhang</a></p>
<p>Abstract:
Table formatting is a typical task for spreadsheet users to better exhibit table structures and data relationships. But quickly and effectively formatting tables is a challenge for users. Lots of manual operations are needed, especially for complex tables. In this paper, we propose techniques for table formatting style transfer, i.e., to automatically format a target table according to the style of a reference table. Considering the latent many-to-many mappings between table structures and formats, we propose CellNet, which is a novel end-to-end, multi-task model leveraging conditional Generative Adversarial Networks (cGANs) with three key components to (1) model and recognize table structures; (2) encode formatting styles; (3) learn and apply the latent mapping based on recognized table structure and encoded style, respectively. Moreover, we build up a spreadsheet table corpus containing 5,226 tables with high-quality formats and 784 tables with human-labeled structures. Our evaluation shows that CellNet is highly effective according to both quantitative metrics and human perception studies by comparing with heuristic-based and other learning-based methods.</p>
<p>Keywords:</p>
<h3 id="302. The Utility of Context When Extracting Entities From Legal Documents.">302. The Utility of Context When Extracting Entities From Legal Documents.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412746">Paper Link</a>    Pages:2397-2404</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/238/6320.html">Jonathan Donnelly</a> ; <a href="https://dblp.uni-trier.de/pid/122/5812.html">Adam Roegiest</a></p>
<p>Abstract:
When reviewing documents for legal tasks such as Mergers and Acquisitions, granular information (such as start dates and exit clauses) need to be identified and extracted. Inspired by previous work in Named Entity Recognition (NER), we investigate how NER techniques can be leveraged to aid lawyers in this review process. Due to the extremely low prevalence of target information in legal documents, we find that the traditional approach of tagging all sentences in a document is inferior, in both effectiveness and data required to train and predict, to using a first-pass layer to identify sentences that are likely to contain the relevant information and then running the more traditional sentence-level sequence tagging. Moreover, we find that such entity-level models can be improved by training on a balanced sample of relevant and non-relevant sentences. We additionally describe the use of our system in production and how its usage by clients means that deep learning architectures tend to be cost inefficient, especially with respect to the necessary time to train models.</p>
<p>Keywords:</p>
<h3 id="303. Learning to Rank in the Position Based Model with Bandit Feedback.">303. Learning to Rank in the Position Based Model with Bandit Feedback.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412723">Paper Link</a>    Pages:2405-2412</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/117/9290.html">Beyza Ermis</a> ; <a href="https://dblp.uni-trier.de/pid/81/8780.html">Patrick Ernst</a> ; <a href="https://dblp.uni-trier.de/pid/131/6605.html">Yannik Stein</a> ; <a href="https://dblp.uni-trier.de/pid/82/8411.html">Giovanni Zappella</a></p>
<p>Abstract:
Personalization is a crucial aspect of many online experiences. In particular, content ranking is often a key component in delivering sophisticated personalization results. Commonly, supervised learning-to-rank methods are applied, which suffer from bias introduced during data collection by production systems in charge of producing the ranking. To compensate for this problem, we leverage contextual multi-armed bandits. We propose novel extensions of two well-known algorithms viz. LinUCB and Linear Thompson Sampling to the ranking use-case. To account for the biases in a production environment, we employ the position-based click model. Finally, we show the validity of the proposed algorithms by conducting extensive offline experiments on synthetic datasets as well as customer facing online A/B experiments.</p>
<p>Keywords:</p>
<h3 id="304. Fusing Global Domain Information and Local Semantic Information to Classify Financial Documents.">304. Fusing Global Domain Information and Local Semantic Information to Classify Financial Documents.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412707">Paper Link</a>    Pages:2413-2420</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5026.html">Mengzhen Fan</a> ; <a href="https://dblp.uni-trier.de/pid/135/6864.html">Dawei Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/166/9351.html">Fangzhou Yang</a> ; <a href="https://dblp.uni-trier.de/pid/117/5965.html">Siqiang Luo</a> ; <a href="https://dblp.uni-trier.de/pid/01/5820.html">Yifeng Luo</a> ; <a href="https://dblp.uni-trier.de/pid/55/3364.html">Weining Qian</a> ; <a href="https://dblp.uni-trier.de/pid/z/AoyingZhou.html">Aoying Zhou</a></p>
<p>Abstract:
Many institutions are devoted to providing investment advising services to stock investors to help them make sound investment decisions. Industry analysts at these institutions need to analyze huge amounts of financial news documents, and yield investment advising reports to the service subscribers. Automatic document classification is required to organize collected financial news documents into pre-defined fine-grained categories, before the document analysis tasks. It is challenging to implement accurate fine-grained classification over massive financial documents, because documents from close fine-grained categories are highly semantically similar, while existing classification methods may fail to differentiate the subtle differences for documents from close fine-grained categories. In this paper, we implement a document classification framework, named GraphSEAT, to classify financial documents for a leading financial information service provider in China. Specifically, we build a heterogeneous graph to model the global structure of our targeting financial documents, where documents and financial named entities are deemed as nodes, and a document is connected to a contained named entity with an edge, and we then train a graph convolutional network (GCN) with attention mechanisms, to learn an embedding representation containing domain information for a document. We also extract semantic information from a document's word sequence with a neural sequence encoder, and finally form an overall embedding representation for a document and make the prediction, via fusing the two learned representations of the document with attention mechanisms. We perform extensive experiments on our real-world financial news dataset and three public datasets, to evaluate the performance of the document classification framework, and the experimental results demonstrate that GraphSEAT outperforms all compared eight baseline models, especially on our dataset.</p>
<p>Keywords:</p>
<h3 id="305. MTBRN: Multiplex Target-Behavior Relation Enhanced Network for Click-Through Rate Prediction.">305. MTBRN: Multiplex Target-Behavior Relation Enhanced Network for Click-Through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412729">Paper Link</a>    Pages:2421-2428</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/227/9107.html">Yufei Feng</a> ; <a href="https://dblp.uni-trier.de/pid/220/4314.html">Fuyu Lv</a> ; <a href="https://dblp.uni-trier.de/pid/150/1977.html">Binbin Hu</a> ; <a href="https://dblp.uni-trier.de/pid/51/394.html">Fei Sun</a> ; <a href="https://dblp.uni-trier.de/pid/194/4245.html">Kun Kuang</a> ; <a href="https://dblp.uni-trier.de/pid/51/3710.html">Yang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/67/4161.html">Qingwen Liu</a> ; <a href="https://dblp.uni-trier.de/pid/198/5430.html">Wenwu Ou</a></p>
<p>Abstract:
Click-through rate (CTR) prediction is a critical task for many industrial systems, such as display advertising and recommender systems. Recently, modeling user behavior sequences attracts much attention and shows great improvements in the CTR field. Existing works mainly exploit attention mechanism based on embedding product when considering relations between user behaviors and target item. However, this methodology lacks of concrete semantics and overlooks the underlying reasons driving a user to click on a target item. In this paper, we propose a new framework named Multiplex Target-Behavior Relation enhanced Network (MTBRN) to leverage multiplex relations between user behaviors and target item to enhance CTR prediction. Multiplex relations consist of meaningful semantics, which can bring a better understanding on users' interests from different perspectives. To explore and model multiplex relations, we propose to incorporate various graphs (e.g., knowledge graph and item-item similarity graph) to construct multiple relational paths between user behaviors and target item. Then Bi-LSTM is applied to encode each path in the path extractor layer. A path fusion network and a path activation network are devised to adaptively aggregate and finally learn the representation of all paths for CTR prediction. Extensive offline and online experiments clearly verify the effectiveness of our framework.</p>
<p>Keywords:</p>
<h3 id="306. Fine-Tuned Compressed Representations of Vessel Trajectories.">306. Fine-Tuned Compressed Representations of Vessel Trajectories.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412706">Paper Link</a>    Pages:2429-2436</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/264/9493.html">Giannis Fikioris</a> ; <a href="https://dblp.uni-trier.de/pid/90/3526.html">Kostas Patroumpas</a> ; <a href="https://dblp.uni-trier.de/pid/a/AArtikis.html">Alexander Artikis</a> ; <a href="https://dblp.uni-trier.de/pid/55/2039.html">Georgios Paliouras</a> ; <a href="https://dblp.uni-trier.de/pid/222/6346.html">Manolis Pitsikalis</a></p>
<p>Abstract:
In the maritime domain, vessels typically maintain straight, predictable routes at open sea, except in the rare cases of adverse weather conditions, accidents and traffic restrictions. Consequently, large amounts of streaming positional updates from vessels can hardly contribute additional knowledge about their actual motion patterns. We have been developing a system for vessel trajectory compression discarding a significant part of the original positional updates, with minimal trajectory reconstruction error. In this work, we present an extension of this system, that allows the user to fine-tune trajectory compression according to the requirements of a given application. The extended system avoids the issues of hyper-parameter tuning, supports incremental optimization and facilitates composite maritime event recognition. Finally, we report empirical results from a comprehensive empirical evaluation against two real-world datasets of vessel positions.</p>
<p>Keywords:</p>
<h3 id="307. Intent-Driven Similarity in E-Commerce Listings.">307. Intent-Driven Similarity in E-Commerce Listings.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412715">Paper Link</a>    Pages:2437-2444</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5050.html">Gilad Fuchs</a> ; <a href="https://dblp.uni-trier.de/pid/276/5021.html">Yoni Acriche</a> ; <a href="https://dblp.uni-trier.de/pid/276/5006.html">Idan Hasson</a> ; <a href="https://dblp.uni-trier.de/pid/224/0361.html">Pavel Petrov</a></p>
<p>Abstract:
Discovering similarities between online listings is a common backend task being used across different downstream experiences in eBay. Our baseline unstructured listing similarity method relies on measuring the semantic textual similarity between the embedding vectors of listing titles. However, we discovered that even with the latest contextualized embedding methods, our similarity fails to give the proper weight to the key tokens in the title that matter. This often results in identifying listing similarities that are not sufficient, which later hurts the downstream experiences. In this paper we present a method we call "Listing2Query", or "L2Q", which uses a Sequence Labeling approach to learn token importance from our users? search queries and on-site behaviour. We used pairs of listing titles and their matching search queries, and leveraged a contextualized character language model, to train L2Q as a bidirectional recurrent neural network to produce token importance weights. We demonstrate that plugging these weights into relatively straightforward listing similarity methods is a simple way to significantly improve the similarity results, even to the extent that it consistently outperforms those created by popular representations such as BERT. Notably, this approach is not reserved to only large online marketplaces but can be generalized to other cases that include a search-driven experience and a recall set of short documents.</p>
<p>Keywords:</p>
<h3 id="308. Impression Pacing for Jobs Marketplace at LinkedIn.">308. Impression Pacing for Jobs Marketplace at LinkedIn.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412711">Paper Link</a>    Pages:2445-2452</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/24/2673.html">Sahin Cem Geyik</a> ; <a href="https://dblp.uni-trier.de/pid/276/4997.html">Luthfur Chowdhury</a> ; <a href="https://dblp.uni-trier.de/pid/78/1725.html">Florian Raudies</a> ; <a href="https://dblp.uni-trier.de/pid/76/6838.html">Wen Pu</a> ; <a href="https://dblp.uni-trier.de/pid/90/6386.html">Jianqiang Shen</a></p>
<p>Abstract:
The goal of Jobs Marketplace at LinkedIn is to match members to promoted job postings such that both job posters' ROI is optimized (amount of money spent per job clicks and applications) and the members are presented with relevant jobs that they are interested in and qualified for. This is achieved via a first-price auction mechanism where each job provides a bid for the member that comes to the job recommendations page. This bid depends on the match of the member to the job, as well as the daily budget that remains for the job, and its capability to spend it via clicks (e.g. some jobs might have more demand and have it easier to spend their budgets via clicks than others). In such a scheme, budget pacing, i.e. the capability of a job to spend its daily budget evenly, or according to a preset plan, is extremely important towards efficient utilization of its budget via reaching a higher number of candidates, and obey a variety of spending plans optimizing for different events such as clicks and applications.</p>
<p>Keywords:</p>
<h3 id="309. Bid Shading in The Brave New World of First-Price Auctions.">309. Bid Shading in The Brave New World of First-Price Auctions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412689">Paper Link</a>    Pages:2453-2460</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/173/4600.html">Djordje Gligorijevic</a> ; <a href="https://dblp.uni-trier.de/pid/31/4578.html">Tian Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/274/1542.html">Bharatbhushan Shetty</a> ; <a href="https://dblp.uni-trier.de/pid/96/2817.html">Brendan Kitts</a> ; <a href="https://dblp.uni-trier.de/pid/60/2507.html">Shengjun Pan</a> ; <a href="https://dblp.uni-trier.de/pid/210/6440.html">Junwei Pan</a> ; <a href="https://dblp.uni-trier.de/pid/46/11207.html">Aaron Flores</a></p>
<p>Abstract:
Online auctions play a central role in online advertising, and are one of the main reasons for the industry's scalability and growth. With great changes in how auctions are being organized, such as changing the second- to first-price auction type, advertisers and demand platforms are compelled to adapt to a new volatile environment. Bid shading is a known technique for preventing overpaying in auction systems that can help maintain the strategy equilibrium in first-price auctions, tackling one of its greatest drawbacks. In this study, we propose a machine learning approach of modeling optimal bid shading for non-censored online first-price ad auctions. We clearly motivate the approach and extensively evaluate it in both offline and online settings on a major demand side platform. The results demonstrate the superiority and robustness of the new approach as compared to the existing approaches across a range of performance metrics.</p>
<p>Keywords:</p>
<h3 id="310. Prospective Modeling of Users for Online Display Advertising via Deep Time-Aware Model.">310. Prospective Modeling of Users for Online Display Advertising via Deep Time-Aware Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412739">Paper Link</a>    Pages:2461-2468</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/173/4600.html">Djordje Gligorijevic</a> ; <a href="https://dblp.uni-trier.de/pid/217/3050.html">Jelena Gligorijevic</a> ; <a href="https://dblp.uni-trier.de/pid/46/11207.html">Aaron Flores</a></p>
<p>Abstract:
Prospective display advertising poses a particular challenge for large advertising platforms. The existing machine learning algorithms are easily biased towards the highly predictable retargeting events that are often non-eligible for the prospective campaigns, thus exhibiting a decline in advertising performance. To that end, efforts are made to design powerful models that can learn from signals of various strength and temporal impact collected about each user from different data sources and provide a good quality and early estimation of users' conversion rates. In this study, we propose a novel deep time-aware approach designed to model sequences of users' activities and capture implicit temporal signals of users' conversion intents. On several real-world datasets, we show that the proposed approach consistently outperforms other, previously proposed approaches by a significant margin while providing interpretability of signal impact to conversion probability.</p>
<p>Keywords:</p>
<h3 id="311. Learning to Profile: User Meta-Profile Network for Few-Shot Learning.">311. Learning to Profile: User Meta-Profile Network for Few-Shot Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412722">Paper Link</a>    Pages:2469-2476</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/99/4318.html">Hao Gong</a> ; <a href="https://dblp.uni-trier.de/pid/250/9600.html">Qifang Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/92/9835.html">Tianyu Li</a> ; <a href="https://dblp.uni-trier.de/pid/274/0675.html">Derek Cho</a> ; <a href="https://dblp.uni-trier.de/pid/274/0649.html">DuyKhuong Nguyen</a></p>
<p>Abstract:
Meta-learning approaches have shown great success in solving challenging knowledge transfer and fast adaptation problems with few samples in vision and language domains. However, few studies discuss the practice of meta-learning for large-scale industrial applications, e.g., representation learning for e-commerce platform users. Although e-commerce companies have spent many efforts on learning accurate and expressive representations to provide a better user experience, we argue that such efforts cannot be stopped at this step. In addition to learning a strong profile of user behaviors, the challenging question about how to effectively transfer the learned representation and quickly adapt the learning process to the subsequent learning tasks or applications is raised simultaneously.</p>
<p>Keywords:</p>
<h3 id="312. EdgeRec: Recommender System on Edge in Mobile Taobao.">312. EdgeRec: Recommender System on Edge in Mobile Taobao.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412700">Paper Link</a>    Pages:2477-2484</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/76/3005.html">Yu Gong</a> ; <a href="https://dblp.uni-trier.de/pid/50/7345.html">Ziwen Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/227/9107.html">Yufei Feng</a> ; <a href="https://dblp.uni-trier.de/pid/150/1977.html">Binbin Hu</a> ; <a href="https://dblp.uni-trier.de/pid/127/6172-1.html">Kaiqi Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/67/4161.html">Qingwen Liu</a> ; <a href="https://dblp.uni-trier.de/pid/198/5430.html">Wenwu Ou</a></p>
<p>Abstract:
Recommender system (RS) has become a crucial module in most web-scale applications. Recently, most RSs are in the waterfall form based on the cloud-to-edge framework, where recommended results are transmitted to edge (e.g., user mobile) by computing in advance in the cloud server. Despite effectiveness, network bandwidth and latency between cloud server and edge may cause the delay for system feedback and user perception. Hence, real-time computing on edge could help capture user preferences more preciously and thus make more satisfactory recommendations. Our work, to our best knowledge, is the first attempt to design and implement the novel Recommender System on Edge (EdgeRec), which achieves Real-time User Perception and Real-time System Feedback. Moreover, we propose Heterogeneous User Behavior Sequence Modeling and Context-aware Reranking with Behavior Attention Networks to capture user's diverse interests and adjust recommendation results accordingly. Experimental results on both the offline evaluation and online performance in Taobao home-page feeds demonstrate the effectiveness of EdgeRec.</p>
<p>Keywords:</p>
<h3 id="313. Price Forecast with High-Frequency Finance Data: An Autoregressive Recurrent Neural Network Model with Technical Indicators.">313. Price Forecast with High-Frequency Finance Data: An Autoregressive Recurrent Neural Network Model with Technical Indicators.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412738">Paper Link</a>    Pages:2485-2492</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5011.html">Yuechun Gu</a> ; <a href="https://dblp.uni-trier.de/pid/81/9436-1.html">Da Yan</a> ; <a href="https://dblp.uni-trier.de/pid/274/4114.html">Sibo Yan</a> ; <a href="https://dblp.uni-trier.de/pid/50/4629-1.html">Zhe Jiang</a></p>
<p>Abstract:
The availability of high-frequency trade data has made it possible for the intraday forecast of price patterns. With the help of technical indicators, recent studies have shown that LSTM based deep learning models are able to predict price directions (a binary classification problem) with performance better than a random guess. However, only naive recurrent networks were adopted, and these works did not compare with the tools used by finance practitioners. Our experiments show that GARCH beats their LSTM models by a large margin.</p>
<p>Keywords:</p>
<h3 id="314. Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems.">314. Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412697">Paper Link</a>    Pages:2493-2500</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/98/2750.html">Yulong Gu</a> ; <a href="https://dblp.uni-trier.de/pid/14/7676.html">Zhuoye Ding</a> ; <a href="https://dblp.uni-trier.de/pid/16/1524.html">Shuaiqiang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/193/4216.html">Lixin Zou</a> ; <a href="https://dblp.uni-trier.de/pid/155/1107.html">Yiding Liu</a> ; <a href="https://dblp.uni-trier.de/pid/91/4572.html">Dawei Yin</a></p>
<p>Abstract:
Recommender Systems have been playing essential roles in e-commerce portals. Existing recommendation algorithms usually learn the ranking scores of items by optimizing a single task (e.g. Click-through rate prediction) based on users' historical click sequences, but they generally pay few attention to simultaneously modeling users' multiple types of behaviors or jointly optimize multiple objectives (e.g. both Click-through rate and Conversion rate), which are both vital for e-commerce sites. In this paper, we argue that it is crucial to formulate users' different interests based on multiple types of behaviors and perform multi-task learning for significant improvement in multiple objectives simultaneously. We propose Deep Multifaceted Transformers (DMT), a novel framework that can model users' multiple types of behavior sequences simultaneously with multiple Transformers. It utilizes Multi-gate Mixture-of-Experts to optimize multiple objectives. Besides, it exploits unbiased learning to reduce the selection bias in the training data. Experiments on JD real production dataset demonstrate the effectiveness of DMT, which significantly outperforms state-of-art methods. DMT has been successfully deployed to serve the main traffic in the commercial Recommender System in JD.com. To facilitate future research, we release the codes and datasets at <a href="https://github.com/guyulongcs/CIKM2020_DMT">https://github.com/guyulongcs/CIKM2020_DMT</a>.</p>
<p>Keywords:</p>
<h3 id="315. A Deep Prediction Network for Understanding Advertiser Intent and Satisfaction.">315. A Deep Prediction Network for Understanding Advertiser Intent and Satisfaction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412681">Paper Link</a>    Pages:2501-2508</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/272/8939.html">Liyi Guo</a> ; <a href="https://dblp.uni-trier.de/pid/33/2451.html">Rui Lu</a> ; <a href="https://dblp.uni-trier.de/pid/65/7161.html">Haoqi Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/151/6168.html">Junqi Jin</a> ; <a href="https://dblp.uni-trier.de/pid/132/8083.html">Zhenzhe Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/07/6378.html">Fan Wu</a> ; <a href="https://dblp.uni-trier.de/pid/48/1097.html">Jin Li</a> ; <a href="https://dblp.uni-trier.de/pid/80/1339.html">Haiyang Xu</a> ; <a href="https://dblp.uni-trier.de/pid/07/1429.html">Han Li</a> ; <a href="https://dblp.uni-trier.de/pid/62/4827.html">Wenkai Lu</a> ; <a href="https://dblp.uni-trier.de/pid/73/1149.html">Jian Xu</a> ; <a href="https://dblp.uni-trier.de/pid/59/2902.html">Kun Gai</a></p>
<p>Abstract:
For e-commerce platforms such as Taobao and Amazon, advertisers play an important role in the entire digital ecosystem: their behaviors explicitly influence users' browsing and shopping experience; more importantly, advertiser's expenditure on advertising constitutes a primary source of platform revenue. Therefore, providing better services for advertisers is essential for the long-term prosperity for e-commerce platforms. To achieve this goal, the ad platform needs to have an in-depth understanding of advertisers in terms of both their marketing intents and satisfaction over the advertising performance, based on which further optimization could be carried out to service the advertisers in the correct direction. In this paper, we propose a novel Deep Satisfaction Prediction Network (DSPN), which models advertiser intent and satisfaction simultaneously. It employs a two-stage network structure where advertiser intent vector and satisfaction are jointly learned by considering the features of advertiser's action information and advertising performance indicators. Experiments on an Alibaba advertisement dataset and online evaluations show that our proposed DSPN outperforms state-of-the-art baselines and has stable performance in terms of AUC in the online environment. Further analyses show that DSPN not only predicts advertisers' satisfaction accurately but also learns an explainable advertiser intent, revealing the opportunities to optimize the advertising performance further.</p>
<p>Keywords:</p>
<h3 id="316. DeText: A Deep Text Ranking Framework with BERT.">316. DeText: A Deep Text Ranking Framework with BERT.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412699">Paper Link</a>    Pages:2509-2516</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/02/7667.html">Weiwei Guo</a> ; <a href="https://dblp.uni-trier.de/pid/04/2106.html">Xiaowei Liu</a> ; <a href="https://dblp.uni-trier.de/pid/34/10207.html">Sida Wang</a> ; <a href="https://dblp.uni-trier.de/pid/77/9023.html">Huiji Gao</a> ; <a href="https://dblp.uni-trier.de/pid/04/2298.html">Ananth Sankar</a> ; <a href="https://dblp.uni-trier.de/pid/271/8099.html">Zimeng Yang</a> ; <a href="https://dblp.uni-trier.de/pid/67/398.html">Qi Guo</a> ; <a href="https://dblp.uni-trier.de/pid/50/6759.html">Liang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/96/6993.html">Bo Long</a> ; <a href="https://dblp.uni-trier.de/pid/57/2178.html">Bee-Chung Chen</a> ; <a href="https://dblp.uni-trier.de/pid/11/5430.html">Deepak Agarwal</a></p>
<p>Abstract:
Ranking is the most important component in a search system. Most search systems deal with large amounts of natural language data, hence an effective ranking system requires a deep understanding of text semantics. Recently, deep learning based natural language processing (deep NLP) models have generated promising results on ranking systems. BERT is one of the most successful models that learn contextual embedding, which has been applied to capture complex query-document relations for search ranking. However, this is generally done by exhaustively interacting each query word with each document word, which is inefficient for online serving in search product systems. In this paper, we investigate how to build an efficient BERT-based ranking model for industry use cases. The solution is further extended to a general ranking framework, DeText, that is open sourced and can be applied to various ranking productions. Offline and online experiments of DeText on three real-world search systems present significant improvement over state-of-the-art approaches.</p>
<p>Keywords:</p>
<h3 id="317. P-Companion: A Principled Framework for Diversified Complementary Product Recommendation.">317. P-Companion: A Principled Framework for Diversified Complementary Product Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412732">Paper Link</a>    Pages:2517-2524</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/192/4730.html">Junheng Hao</a> ; <a href="https://dblp.uni-trier.de/pid/94/6503.html">Tong Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/48/1097.html">Jin Li</a> ; <a href="https://dblp.uni-trier.de/pid/d/XinLunaDong.html">Xin Luna Dong</a> ; <a href="https://dblp.uni-trier.de/pid/f/CFaloutsos.html">Christos Faloutsos</a> ; <a href="https://dblp.uni-trier.de/pid/37/3868.html">Yizhou Sun</a> ; <a href="https://dblp.uni-trier.de/pid/35/7092.html">Wei Wang</a></p>
<p>Abstract:
If one customer buys a tennis racket, what are the best 3 complementary products to purchase together? 3 tennis ball packs, 3 headbands, 3 overgrips, or 1 of each respectively? Complementary product recommendation (CPR), aiming at providing product suggestions that are often bought together to serve a joint demand, forms a pivotal component of e-commerce service, however, existing methods are far from optimal. Given one product, how to recommend its complementary products of different types is the key problem we tackle in this work. We first conduct an extensive analysis to correct the inaccurate assumptions adopted by existing work to show that co-purchased products are not always complementary and further propose a new strategy to generate clean distant supervision labels for CPR modeling. Moreover, to bridge in the gap from existing work that CPR does not only need relevance modeling but also requires diversity to fulfill the whole purchase demand, we develop a deep learning framework, P-Companion to explicitly model both relevance and diversity. More specifically, given one product with its product type, P-Companion first uses an encoder-decoder network to predict multiple complementary product types, then a transfer metric learning network is developed to project the embedding of query product to each predicted complementary product type subspace and further learn the complementary relationship based on the distant supervision labels within each subspace. The whole framework can be trained from end-to-end and robust to cold-start products attributed to a novel pretrained product embedding module named Product2Vec, based on graph attention networks. Extensive offline experiments show that P-Companion outperforms state-of-the-art baselines by 7.1% increase on the [email protected] score with well-controlled diversity. Production-wise, we deploy P-Companion to provide online recommendations for over 200M products at Amazon and observe significant gains on product sales and profit.</p>
<p>Keywords:</p>
<h3 id="318. Loan Default Analysis with Multiplex Graph Learning.">318. Loan Default Analysis with Multiplex Graph Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412724">Paper Link</a>    Pages:2525-2532</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/150/1977.html">Binbin Hu</a> ; <a href="https://dblp.uni-trier.de/pid/67/2010.html">Zhiqiang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/99/3847-11.html">Jun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/234/2977.html">Jingli Fang</a> ; <a href="https://dblp.uni-trier.de/pid/257/5636.html">Quanhui Jia</a> ; <a href="https://dblp.uni-trier.de/pid/234/2760.html">Yanming Fang</a> ; <a href="https://dblp.uni-trier.de/pid/47/2918.html">Quan Yu</a> ; <a href="https://dblp.uni-trier.de/pid/57/2210.html">Yuan Qi</a></p>
<p>Abstract:
Aiming to effectively distinguish loan default in the Mobile Credit Payment Service, industrial efforts mainly attempt to employ conventional classifier with complicated feature engineer for prediction. However, these solutions fail to exploit multiplex relations existed in the financial scenarios and ignore the key intrinsic properties of the loan default detection, i.e., communicability, complementation and induction. To address these issues, we develop a novel attributed multiplex graph based loan default detection approach for effectively integrating multiplex relations in financial scenarios. Considering the complexity of financial scenario, an Attributed Multiplex Graph (AMG) is proposed to jointly model various relations and objects as well as the rich attributes on nodes and edges. We elaborately design relation-specific receptive layers equipped with adaptive breadth function to incorporate important information derived from local structure in each aspect of AMG and stack multiple propagation layer to explore the high-order connectivity information. Furthermore, a relation-specific attention mechanism is adopted to emphasize relevant information during end-to-end training. Extensive experiments conducted on the large-scale real- world dataset verify the effectiveness of the proposed model com- pared with state of arts. Moreover, AMG-DP has also achieved a performance improvement of 9.37% on KS metric in recent months after successful deployment in the Alipay APP.</p>
<p>Keywords:</p>
<h3 id="319. Imbalanced Time Series Classification for Flight Data Analyzing with Nonlinear Granger Causality Learning.">319. Imbalanced Time Series Classification for Flight Data Analyzing with Nonlinear Granger Causality Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412710">Paper Link</a>    Pages:2533-2540</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/04/5616.html">Hao Huang</a> ; <a href="https://dblp.uni-trier.de/pid/188/4029.html">Chenxiao Xu</a> ; <a href="https://dblp.uni-trier.de/pid/69/1062.html">Shinjae Yoo</a> ; <a href="https://dblp.uni-trier.de/pid/87/4073.html">Weizhong Yan</a> ; <a href="https://dblp.uni-trier.de/pid/88/8398.html">Tianyi Wang</a> ; <a href="https://dblp.uni-trier.de/pid/03/517.html">Feng Xue</a></p>
<p>Abstract:
Identifying the faulty class of multivariate time series is crucial for today's flight data analysis. However, most of the existing time series classification methods suffer from imbalanced data and lack of model interpretability, especially on flight data of which faulty events are usually uncommon with a limited amount of data. Here, we present a neural network classification model for imbalanced multivariate time series by leveraging the information learned from normal class, which can also learn the nonlinear Granger causality for each class, so that we can pinpoint how time series classes differ from each other. Experiments on simulated data and real flight data shows that this model can achieve high accuracy of identifying anomalous flights.</p>
<p>Keywords:</p>
<h3 id="320. Personalized Flight Itinerary Ranking at Fliggy.">320. Personalized Flight Itinerary Ranking at Fliggy.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412735">Paper Link</a>    Pages:2541-2548</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/32/8084.html">Jinhong Huang</a> ; <a href="https://dblp.uni-trier.de/pid/37/4190.html">Yang Li</a> ; <a href="https://dblp.uni-trier.de/pid/83/8595.html">Shan Sun</a> ; <a href="https://dblp.uni-trier.de/pid/79/2113.html">Bufeng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/49/2488-9.html">Jin Huang</a></p>
<p>Abstract:
Flight itinerary ranking is critical for Online Travel Agencies (OTAs) since more and more customers book flights online. Currently, most OTAs still adopt rule-based strategies. However, rule-based methods are not able to model context-aware information and user preferences. To this end, a novel Personalized Flight itinerary Ranking Network (PFRN) is proposed in this paper. In PFRN, a Listwise Feature Encoding (LFE) structure is proposed to capture global context-aware information and mutual influences among inputs. Besides, we utilize behaviors of both individual user and group users sharing the same intention to express user preferences. Then a User Attention Mechanism is proposed to rank flight itineraries based on the user preferences effectively and efficiently. Offline experiments on real-world datasets from Amadeus and Fliggy show the superior performance of the proposed PFRN. Moreover, PFRN has been successfully deployed on online system for searching itineraries at Fliggy and achieved significant improvements.</p>
<p>Keywords:</p>
<h3 id="321. Learning Effective Representations for Person-Job Fit by Feature Fusion.">321. Learning Effective Representations for Person-Job Fit by Feature Fusion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412717">Paper Link</a>    Pages:2549-2556</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/267/5709.html">Junshu Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/267/5700.html">Songyun Ye</a> ; <a href="https://dblp.uni-trier.de/pid/35/7092.html">Wei Wang</a> ; <a href="https://dblp.uni-trier.de/pid/267/5274.html">Jingran Xu</a> ; <a href="https://dblp.uni-trier.de/pid/215/9338.html">Xiaosheng Luo</a></p>
<p>Abstract:
Person-job fit is to match candidates and job posts on online recruitment platforms using machine learning algorithms. The effectiveness of matching algorithms heavily depends on the learned representations for the candidates and job posts. In this paper, we propose to learn comprehensive and effective representations of the candidates and job posts via feature fusion. First, in addition to applying deep learning models for processing the free text in resumes and job posts, which is adopted by existing methods, we extract semantic entities from the whole resume (and job post) and then learn features for them. By fusing the features from the free text and the entities, we get a comprehensive representation for the information explicitly stated in the resume and job post. Second, however, some information of a candidate or a job may not be explicitly captured in the resume or job post. Nonetheless, the historical applications including accepted and rejected cases can reveal some implicit intentions of the candidates or recruiters. Therefore, we propose to learn the representations of implicit intentions by processing the historical applications using LSTM. Last, by fusing the representations for the explicit and implicit intentions, we get a more comprehensive and effective representation for person-job fit. Experiments over 10 months real data show that our solution outperforms existing methods with a large margin. Ablation studies confirm the contribution of each component of the fused representation. The extracted semantic entities help interpret the matching results in the case study.</p>
<p>Keywords:</p>
<h3 id="322. Incorporating User Feedback into Sequence to Sequence Model Training.">322. Incorporating User Feedback into Sequence to Sequence Model Training.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412714">Paper Link</a>    Pages:2557-2564</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/185/5538.html">Michaeel Kazi</a> ; <a href="https://dblp.uni-trier.de/pid/02/7667.html">Weiwei Guo</a> ; <a href="https://dblp.uni-trier.de/pid/77/9023.html">Huiji Gao</a> ; <a href="https://dblp.uni-trier.de/pid/96/6993.html">Bo Long</a></p>
<p>Abstract:
As the largest professional network, LinkedIn hosts millions of user profiles and job postings. Users effectively find what they need by entering search queries. However, finding what they are looking for can be a challenge, especially if they are unfamiliar with specific keywords from their industry. Query Suggestion is a popular feature where a search engine can suggest alternate, related queries. At LinkedIn, we have productionized a deep learning Seq2Seq model to transform an input query into several alternatives. This model is trained by examining search history directly typed by users. Once online, we can determine whether or not users clicked on suggested queries. This new feedback data indicates which suggestions caught the user's attention. In this work, we propose training a model with both the search history and user feedback datasets. We examine several ways to incorporate feedback without any architectural change, including adding a novel pairwise ranking loss term during training. The proposed new training technique produces the best combined score out of several alternatives in offline metrics. Deployed in the LinkedIn search engine, it significantly outperforms the control model with respect to key business metrics.</p>
<p>Keywords:</p>
<h3 id="323. Magellan: A Personalized Travel Recommendation System Using Transaction Data.">323. Magellan: A Personalized Travel Recommendation System Using Transaction Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412725">Paper Link</a>    Pages:2565-2572</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/220/5760.html">Konik Kothari</a> ; <a href="https://dblp.uni-trier.de/pid/275/3049.html">Dhruv Gelda</a> ; <a href="https://dblp.uni-trier.de/pid/10/4661.html">Wei Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/54/4089.html">Hao Yang</a></p>
<p>Abstract:
We present Magellan - a personalized travel recommendation system that is built entirely from card transaction data. The data logs contain extensive metadata for each transaction between a user and a merchant. We describe the procedure employed to extract travel itineraries from such transaction data. Unlike traditional approaches, we formulate the recommendation problem into two steps: (1) predict coarse granularity information such as location and category of the next merchant; and (2) provide fine granularity individual merchant recommendations based on the predicted location and category. The breakdown helps us build a scalable recommendation system. We propose a quadtree-based algorithm that provides an adaptive spatial resolution for the location classes in our first step while also reducing the class-imbalance across various location labels. Finally, we propose a novel neural architecture, SoLEmNet, that implicitly learns the inherent class label hierarchy and achieves a higher performance on our dataset compared to previous baselines.</p>
<p>Keywords:</p>
<h3 id="324. ART (Attractive Recommendation Tailor): How the Diversity of Product Recommendations Affects Customer Purchase Preference in Fashion Industry?">324. ART (Attractive Recommendation Tailor): How the Diversity of Product Recommendations Affects Customer Purchase Preference in Fashion Industry?</h3>
<p><a href="https://doi.org/10.1145/3340531.3412687">Paper Link</a>    Pages:2573-2580</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5096.html">Hyokmin Kwon</a> ; <a href="https://dblp.uni-trier.de/pid/252/8205.html">Jaeho Han</a> ; <a href="https://dblp.uni-trier.de/pid/18/9204.html">Kyungsik Han</a></p>
<p>Abstract:
This study examines the impact of the 'diversity' of product recommendations on the 'preference' of a customer, using online/offline data from a leading fashion company. First, through interviews with fashion professionals, we categorized the characteristics of customers into four types - gift, coordinator, carry-over, and trendsetter. Then, using a hybrid filtering method, we increased the accuracy and diversity of recommended products. We derived 13 salient features that reflect customer behavior based on the Purchase Funnel model and built a classification model that predicts a customer's preference rates. Second, we conducted two large-scale user tests with 20,000 real customers to verify the effectiveness of our recommendation system. Study results empirically demonstrated the importance of diversity of recommended products. The more diverse the product recommendations were, the higher the purchase rate, the average purchase amount, and the cross purchase rate were observed. In addition, we tracked the customers? purchase for two months after the user tests and found that diverse product exposure positively influenced customer retention (e.g., repurchase rate, amount).</p>
<p>Keywords:</p>
<h3 id="325. AliMeKG: Domain Knowledge Graph Construction and Application in E-commerce.">325. AliMeKG: Domain Knowledge Graph Construction and Application in E-commerce.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412685">Paper Link</a>    Pages:2581-2588</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/31/7637.html">Feng-Lin Li</a> ; <a href="https://dblp.uni-trier.de/pid/275/3148.html">Hehong Chen</a> ; <a href="https://dblp.uni-trier.de/pid/205/7621.html">Guohai Xu</a> ; <a href="https://dblp.uni-trier.de/pid/32/222.html">Tian Qiu</a> ; <a href="https://dblp.uni-trier.de/pid/50/6349.html">Feng Ji</a> ; <a href="https://dblp.uni-trier.de/pid/86/1953.html">Ji Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/34/6243.html">Haiqing Chen</a></p>
<p>Abstract:
Pre-sales customer service is of importance to E-commerce platforms as it contributes to optimizing customers? buying process. To better serve users, we propose AliMe KG, a domain knowledge graph in E-commerce that captures user problems, points of interest (POI), item information and relations thereof. It helps to under stand user needs, answer pre-sales questions and generate explanation texts. We applied AliMe KG to several online business scenarios such as shopping guide, question answering over properties and selling point generation, and gained positive and beneficial business results. In the paper, we systematically introduce how we construct domain knowledge graph from free text, and demonstrate its business value with several applications. Our experience shows that min ing structured knowledge from free text in vertical domain is practicable, and can be of substantial value in industrial settings.</p>
<p>Keywords:</p>
<h3 id="326. Peer-inspired Student Performance Prediction in Interactive Online Question Pools with Graph Neural Network.">326. Peer-inspired Student Performance Prediction in Interactive Online Question Pools with Graph Neural Network.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412733">Paper Link</a>    Pages:2589-2596</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/135/9708-1.html">Haotian Li</a> ; <a href="https://dblp.uni-trier.de/pid/127/2894.html">Huan Wei</a> ; <a href="https://dblp.uni-trier.de/pid/84/2694.html">Yong Wang</a> ; <a href="https://dblp.uni-trier.de/pid/86/2159.html">Yangqiu Song</a> ; <a href="https://dblp.uni-trier.de/pid/65/1792.html">Huamin Qu</a></p>
<p>Abstract:
Student performance prediction is critical to online education. It can benefit many downstream tasks on online learning platforms, such as estimating dropout rates, facilitating strategic intervention, and enabling adaptive online learning. Interactive online question pools provide students with interesting interactive questions to practice their knowledge in online education. However, little research has been done on student performance prediction in interactive online question pools. Existing work on student performance prediction targets at online learning platforms with predefined course curriculum and accurate knowledge labels like MOOC platforms, but they are not able to fully model knowledge evolution of students in interactive online question pools. In this paper, we propose a novel approach using Graph Neural Networks (GNNs) to achieve better student performance prediction in interactive online question pools. Specifically, we model the relationship between students and questions using student interactions to construct the student-interaction-question network and further present a new GNN model, called R2GCN, which intrinsically works for the heterogeneous networks, to achieve generalizable student performance prediction in interactive online question pools. We evaluate the effectiveness of our approach on a real-world dataset consisting of 104,113 mouse trajectories generated in the problem-solving process of over 4,000 students on 1,631 questions. The experiment results show that our approach can achieve a much higher accuracy of student performance prediction than both traditional machine learning approaches and GNN models.</p>
<p>Keywords:</p>
<h3 id="327. Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection.">327. Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412745">Paper Link</a>    Pages:2597-2604</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/234/8650.html">Liangwei Li</a> ; <a href="https://dblp.uni-trier.de/pid/273/3781.html">Liucheng Sun</a> ; <a href="https://dblp.uni-trier.de/pid/273/3956.html">Chenwei Weng</a> ; <a href="https://dblp.uni-trier.de/pid/81/8757.html">Chengfu Huo</a> ; <a href="https://dblp.uni-trier.de/pid/214/8201.html">Weijun Ren</a></p>
<p>Abstract:
Online electronic coupon (e-coupon) is becoming a primary tool for e-commerce platforms to attract users to place orders. E-coupons are the digital equivalent of traditional paper coupons which provide customers with discounts or gifts. One of the fundamental problems related is how to deliver e-coupons with minimal cost while users' willingness to place an order is maximized. We call this problem the coupon allocation problem. This is a non-trivial problem since the number of regular users on a mature e-platform often reaches hundreds of millions and the types of e-coupons to be allocated are often multiple. The policy space is extremely large and the online allocation has to satisfy a budget constraint. Besides, one can never observe the responses of one user under different policies which increases the uncertainty of the policy making process. Previous work fails to deal with these challenges. In this paper, we decompose the coupon allocation task into two subtasks: the user intent detection task and the allocation task. Accordingly, we propose a two-stage solution: at the first stage (detection stage), we put forward a novel Instantaneous Intent Detection Network (IIDN) which takes the user-coupon features as input and predicts user real-time intents; at the second stage (allocation stage), we model the allocation problem as a Multiple-Choice Knapsack Problem (MCKP) and provide a computational efficient allocation method using the intents predicted at the detection stage. Long Short Term Memory (LSTM) and a special attention mechanism are applied on IIDN to better describe temporal dependencies of sequential features. And we manage to solve the imbalanced label problem for the user intent detection task with a brand new perspective by using the logical relationship between multiple user intents. We conduct extensive online and offline experiments and the results show the superiority of our proposed framework, which has brought great profits to the platform and continues to function online.</p>
<p>Keywords:</p>
<h3 id="328. Improving Multi-Scenario Learning to Rank in E-commerce by Exploiting Task Relationships in the Label Space.">328. Improving Multi-Scenario Learning to Rank in E-commerce by Exploiting Task Relationships in the Label Space.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412713">Paper Link</a>    Pages:2605-2612</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/76/7590.html">Pengcheng Li</a> ; <a href="https://dblp.uni-trier.de/pid/01/2608.html">Runze Li</a> ; <a href="https://dblp.uni-trier.de/pid/138/2474.html">Qing Da</a> ; <a href="https://dblp.uni-trier.de/pid/182/7262.html">Anxiang Zeng</a> ; <a href="https://dblp.uni-trier.de/pid/76/4015.html">Lijun Zhang</a></p>
<p>Abstract:
Traditional Learning to Rank (LTR) models in E-commerce are usually trained on logged data from a single domain. However, data may come from multiple domains, such as hundreds of countries in international E-commerce platforms. Learning a single ranking function obscures domain differences, while learning multiple functions for each domain may also be inferior due to ignoring the correlations between domains. It can be formulated as a multi-task learning problem where multiple tasks share the same feature and label space. To solve the above problem, which we name Multi-Scenario Learning to Rank, we propose the Hybrid of implicit and explicit Mixture-of-Experts (HMoE) approach. Our proposed solution takes advantage of Multi-task Mixture-of-Experts to implicitly identify distinctions and commonalities between tasks in the feature space, and improves the performance with a stacked model learning task relationships in the label space explicitly. Furthermore, to enhance the flexibility, we propose an end-to-end optimization method with a task-constrained back-propagation strategy. We empirically verify that the optimization method is more effective than two-stage optimization required by the stacked approach. Experiments on real-world industrial datasets demonstrate that HMoE significantly outperforms the popular multi-task learning methods. HMoE is in-use in the search system of AliExpress and achieved 1.92% revenue gain in the period of one-week online A/B testing. We also release a sampled version of our dataset to facilitate future research.</p>
<p>Keywords:</p>
<h3 id="329. Graph Neural Network for Tag Ranking in Tag-enhanced Video Recommendation.">329. Graph Neural Network for Tag Ranking in Tag-enhanced Video Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3416021">Paper Link</a>    Pages:2613-2620</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/95/2446.html">Qi Liu</a> ; <a href="https://dblp.uni-trier.de/pid/178/8590.html">Ruobing Xie</a> ; <a href="https://dblp.uni-trier.de/pid/09/3666.html">Lei Chen</a> ; <a href="https://dblp.uni-trier.de/pid/142/8980.html">Shukai Liu</a> ; <a href="https://dblp.uni-trier.de/pid/168/1886.html">Ke Tu</a> ; <a href="https://dblp.uni-trier.de/pid/31/891.html">Peng Cui</a> ; <a href="https://dblp.uni-trier.de/pid/36/2259-56.html">Bo Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/218/7323.html">Leyu Lin</a></p>
<p>Abstract:
In tag-enhanced video recommendation systems, videos are attached with some tags that highlight the contents of videos from different aspects. Tag ranking in such recommendation systems provides personalized tag lists for videos from their tag candidates. A better tag ranking model could attract users to click more tags, enter their corresponding tag channels, and watch more tag-specific videos, which improves both tag click rate and video watching time. However, most conventional tag ranking models merely concentrate on tag-video relevance or tag-related behaviors, ignoring the rich information in video-related behaviors. We should consider user preferences on both tags and videos. In this paper, we propose a novel Graph neural network based tag ranking (GraphTR) framework on a huge heterogeneous network with video, tag, user and media. We design a novel graph neural network that combines multi-field transformer, GraphSAGE and neural FM layers in node aggregation. We also propose a neighbor-similarity based loss to encode various user preferences into heterogeneous node representations. In experiments, we conduct both offline and online evaluations on a real-world video recommendation system in WeChat Top Stories. The significant improvements in both video and tag related metrics confirm the effectiveness and robustness in real-world tag-enhanced video recommendation. Currently, GraphTR has been deployed on WeChat Top Stories for more than six months. The source codes are in <a href="https://github.com/lqfarmer/GraphTR">https://github.com/lqfarmer/GraphTR</a>.</p>
<p>Keywords:</p>
<h3 id="330. Decoupled Graph Convolution Network for Inferring Substitutable and Complementary Items.">330. Decoupled Graph Convolution Network for Inferring Substitutable and Complementary Items.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412695">Paper Link</a>    Pages:2621-2628</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/155/1107.html">Yiding Liu</a> ; <a href="https://dblp.uni-trier.de/pid/98/2750.html">Yulong Gu</a> ; <a href="https://dblp.uni-trier.de/pid/14/7676.html">Zhuoye Ding</a> ; <a href="https://dblp.uni-trier.de/pid/15/10939.html">Junchao Gao</a> ; <a href="https://dblp.uni-trier.de/pid/161/5675.html">Ziyi Guo</a> ; <a href="https://dblp.uni-trier.de/pid/52/5055.html">Yongjun Bao</a> ; <a href="https://dblp.uni-trier.de/pid/216/8297.html">Weipeng Yan</a></p>
<p>Abstract:
Inferring substitutable and complementary items is an important and fundamental concern for recommendation in e-commerce websites. However, the item relationships in real-world are usually heterogeneous, posing great challenges to conventional methods that can only deal with homogeneous relationships. More specifically, for this problem, there is a lack of in-depth investigation on 1) decoupling item semantics for modeling heterogeneous item relationships, and at the same time, 2) incorporating mutual influence between different relationships. To fill this gap, we propose a novel solution, namely Decoupled Graph Convolutional Network (DecGCN), to solve the problem of inferring substitutable and complementary items. DecGCN is designed to model item substitutability and complementarity in separated embedding spaces, and is equipped with a two-step integration scheme,where inherent influences between 1) different graph structures and 2) different item semantics are captured. Our experiments on three real-world datasets demonstrate that DecGCN is more effective than the state-of-the-art baselines for the problem at hand. We also conduct offline and online A/B tests on large-scale industrial data, where the results show that DecGCN is effective to be deployed in real-world applications. We release the codes at <a href="https://github.com/liuyiding1993/CIKM2020_DecGCN">https://github.com/liuyiding1993/CIKM2020_DecGCN</a>.</p>
<p>Keywords:</p>
<h3 id="331. Two-Stage Audience Expansion for Financial Targeting in Marketing.">331. Two-Stage Audience Expansion for Financial Targeting in Marketing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412748">Paper Link</a>    Pages:2629-2636</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/195/4399-1.html">Zhining Liu</a> ; <a href="https://dblp.uni-trier.de/pid/198/0639.html">Xiao-Fan Niu</a> ; <a href="https://dblp.uni-trier.de/pid/15/10220.html">Chenyi Zhuang</a> ; <a href="https://dblp.uni-trier.de/pid/272/9924.html">Yize Tan</a> ; <a href="https://dblp.uni-trier.de/pid/276/5049.html">Yixiang Mu</a> ; <a href="https://dblp.uni-trier.de/pid/251/9600.html">Jinjie Gu</a> ; <a href="https://dblp.uni-trier.de/pid/22/4415.html">Guannan Zhang</a></p>
<p>Abstract:
With the revolution of mobile internet, online finance has grown explosively. In this new area, one challenge of significant importance is how to effectively deliver the financial products or services to a set of target users by marketing. Given a product or service to be promoted and a set of users as seeds, audience expansion is such a targeting technique, which aims to find potential audience among a large number of users. However, in the context of finance, financial products and services are dynamic in nature as they co-vary with the socio-economic environment. Moreover, marketing campaigns for promoting products or services always consist of different rules of play, even for the same type of products or services. As a result, there is a strong demand for the timeliness of seeds in financial targeting. Conventional one-stage audience expansion methods, which generate expanded users by expanding over seeds, would encounter two problems under this setting: (1) the seeds would inevitably involve a number of users that are not representative for expansion, and direct expansion over these noisy seeds would dramatically deteriorate the performance; (2) one-stage expansion over fixed seeds cannot timely and accurately capture users' preferences over the currently running campaign due to the lack of timeliness of seeds.</p>
<p>Keywords:</p>
<h3 id="332. Efficiently Training Intelligible Models for Global Explanations.">332. Efficiently Training Intelligible Models for Global Explanations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412702">Paper Link</a>    Pages:2637-2644</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/41/7551.html">Yin Lou</a> ; <a href="https://dblp.uni-trier.de/pid/89/5684.html">Yongliang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5105.html">Shiwei Liang</a> ; <a href="https://dblp.uni-trier.de/pid/37/10208.html">Yang Dong</a></p>
<p>Abstract:
Generalized additive models (GAMs) are one of the popular methods of building intelligible models on classification and regression problems. Fitting the most accurate GAMs is usually done via gradient boosting with bagged shallow trees. However, such method can be expensive for large industrial applications. In this work, we aim to improve the training efficiency of GAM. To this end, we propose to use subsample aggregating (subagging) in place of bootstrap aggregating (bagging). Our key observation is that subsamples of reasonable size (e.g., 60% of the training set) usually overlap. Such property allows us to explore the computation ordering inside a subagged ensemble and we present a novel algorithm to speed up the computation of subagged ensemble with no loss of accuracy. Our experimental results on public datasets demonstrate that our proposed method can achieve up to 3.7x speedup over bagged ensembles with comparable accuracy. Finally, we demonstrate our methodology of finding global explanations on a real application at Alipay. We have developed several strategies from the findings of those explanations and found those strategies achieved significant lift on key metrics through online experiments.</p>
<p>Keywords:</p>
<h3 id="333. TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval.">333. TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412747">Paper Link</a>    Pages:2645-2652</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/15/8207.html">Wenhao Lu</a> ; <a href="https://dblp.uni-trier.de/pid/29/265.html">Jian Jiao</a> ; <a href="https://dblp.uni-trier.de/pid/36/2351.html">Ruofei Zhang</a></p>
<p>Abstract:
Pre-trained language models have achieved great success in a wide variety of natural language processing (NLP) tasks, while the superior performance comes with high demand in computational resources, which hinders the application in low-latency information retrieval (IR) systems. To address the problem, we present TwinBERT model, which has two improvements: 1) represent query and document separately using twin-structured encoders and 2) each encoder is a highly compressed BERT-like model with less than one third of the parameters. The former allows document embeddings to be pre-computed offline and cached in memory, which is different from BERT, where the two input sentences are concatenated and encoded together. The change saves large amount of computation time, however, it is still not sufficient for real-time retrieval considering the complexity of BERT model itself. To further reduce computational cost, a compressed multi-layer transformer encoder is proposed with special training strategies as a substitution of the original complex BERT encoder. Lastly, two versions of TwinBERT are developed to combine the query and keyword embeddings for retrieval and relevance tasks correspondingly. Both of them have met the real-time latency requirement and achieve close or on-par performance to BERT-Base model.</p>
<p>Keywords:</p>
<h3 id="334. Learning to Create Better Ads: Generation and Ranking Approaches for Ad Creative Refinement.">334. Learning to Create Better Ads: Generation and Ranking Approaches for Ad Creative Refinement.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412720">Paper Link</a>    Pages:2653-2660</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/16/7607.html">Shaunak Mishra</a> ; <a href="https://dblp.uni-trier.de/pid/63/9927.html">Manisha Verma</a> ; <a href="https://dblp.uni-trier.de/pid/146/9862.html">Yichao Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/86/4278.html">Kapil Thadani</a> ; <a href="https://dblp.uni-trier.de/pid/w/WeiWang.html">Wei Wang</a></p>
<p>Abstract:
In the online advertising industry, the process of designing an ad creative i.e., ad text and image) requires manual labor. Typically, each advertiser launches multiple creatives via online A/B tests to infer effective creatives for the target audience, that are then refined further in an iterative fashion. Due to the manual nature of this process, it is time-consuming to learn, refine, and deploy the modified creatives. Since major ad platforms typically run A/B tests for multiple advertisers in parallel, we explore the possibility of collaboratively learning ad creative refinement via A/B tests of multiple advertisers. In particular, given an input ad creative, we study approaches to refine the given ad text and image by: (i) generating new ad text, (ii) recommending keyphrases for new ad text, and (iii) recommending image tags (objects in the image) to select new ad image. Based on A/B tests conducted by multiple advertisers, we form pairwise examples of inferior and superior ad creatives and use such pairs to train models for the above tasks. For generating new ad text, we demonstrate the efficacy of an encoder-decoder architecture with copy mechanism, which allows some words from the (inferior) input text to be copied to the output while incorporating new words associated with higher click-through-rate. For the keyphrase and image tag recommendation task, we demonstrate the efficacy of a deep relevance matching model, as well as the relative robustness of ranking approaches compared to ad text generation in cold-start scenarios with unseen advertisers. We also share broadly applicable insights from our experiments using data from the Yahoo Gemini ad platform.</p>
<p>Keywords:</p>
<h3 id="335. Personalizing Natural Language Understanding using Multi-armed Bandits and Implicit Feedback.">335. Personalizing Natural Language Understanding using Multi-armed Bandits and Implicit Feedback.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412736">Paper Link</a>    Pages:2661-2668</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/05/3244.html">Fabian Moerchen</a> ; <a href="https://dblp.uni-trier.de/pid/81/8780.html">Patrick Ernst</a> ; <a href="https://dblp.uni-trier.de/pid/82/8411.html">Giovanni Zappella</a></p>
<p>Abstract:
Natural Language Understanding (NLU) models on voice-controlled speakers face several challenges. In particular, music streaming services have large catalogs, often containing millions of songs, artists, and albums and several thousands of custom playlists and stations. In many cases there is ambiguity and little structural difference between carrier phrases and entity names. In this work, we describe how we leveraged multi-armed bandits in combination with implicit customer feedback to improve accuracy and personalization of responses to voice request in the music domain. Our models are tested in a large-scale industrial system containing several other components. In particular, we focused on using this technology to correct errors made by upstream NLU models and personalize responses based on customer preferences and music provider functionality. The models resulted in significant improvement of playback rate for Amazon Music and are deployed in systems serving several countries and languages. We further used the implicit feedback of the customers to generate weakly labeled training data for the NLU models. This improved the experience for customers using other music providers on all Alexa devices.</p>
<p>Keywords:</p>
<h3 id="336. MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction.">336. MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412728">Paper Link</a>    Pages:2669-2676</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/192/9719.html">Wentao Ouyang</a> ; <a href="https://dblp.uni-trier.de/pid/53/1256.html">Xiuwu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/87/734.html">Lei Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/88/7628.html">Jinmei Luo</a> ; <a href="https://dblp.uni-trier.de/pid/50/671.html">Yu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/61/7995.html">Heng Zou</a> ; <a href="https://dblp.uni-trier.de/pid/33/4880.html">Zhaojie Liu</a> ; <a href="https://dblp.uni-trier.de/pid/242/8804.html">Yanlong Du</a></p>
<p>Abstract:
Click-through rate (CTR) prediction is a critical task in online advertising systems. Existing works mainly address the single-domain CTR prediction problem and model aspects such as feature interaction, user behavior history and contextual information. Nevertheless, ads are usually displayed with natural content, which offers an opportunity for cross-domain CTR prediction. In this paper, we address this problem and leverage auxiliary data from a source domain to improve the CTR prediction performance of a target domain. Our study is based on UC Toutiao (a news feed service integrated with the UC Browser App, serving hundreds of millions of users daily), where the source domain is the news and the target domain is the ad. In order to effectively leverage news data for predicting CTRs of ads, we propose the Mixed Interest Network (MiNet) which jointly models three types of user interest: 1) long-term interest across domains, 2) short-term interest from the source domain and 3) short-term interest in the target domain. MiNet contains two levels of attentions, where the item-level attention can adaptively distill useful information from clicked news / ads and the interest-level attention can adaptively fuse different interest representations. Offline experiments show that MiNet outperforms several state-of-the-art methods for CTR prediction. We have deployed MiNet in UC Toutiao and the A/B test results show that the online CTR is also improved substantially. MiNet now serves the main ad traffic in UC Toutiao.</p>
<p>Keywords:</p>
<h3 id="337. Learning to Infer User Hidden States for Online Sequential Advertising.">337. Learning to Infer User Hidden States for Online Sequential Advertising.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412721">Paper Link</a>    Pages:2677-2684</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/214/5296.html">Zhaoqing Peng</a> ; <a href="https://dblp.uni-trier.de/pid/151/6168.html">Junqi Jin</a> ; <a href="https://dblp.uni-trier.de/pid/18/5122.html">Lan Luo</a> ; <a href="https://dblp.uni-trier.de/pid/170/1496.html">Yaodong Yang</a> ; <a href="https://dblp.uni-trier.de/pid/71/7893.html">Rui Luo</a> ; <a href="https://dblp.uni-trier.de/pid/125/8189.html">Jun Wang</a> ; <a href="https://dblp.uni-trier.de/pid/28/10261-1.html">Weinan Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/80/1339.html">Haiyang Xu</a> ; <a href="https://dblp.uni-trier.de/pid/42/3241.html">Miao Xu</a> ; <a href="https://dblp.uni-trier.de/pid/50/790.html">Chuan Yu</a> ; <a href="https://dblp.uni-trier.de/pid/00/6108.html">Tiejian Luo</a> ; <a href="https://dblp.uni-trier.de/pid/07/1429.html">Han Li</a> ; <a href="https://dblp.uni-trier.de/pid/73/1149.html">Jian Xu</a> ; <a href="https://dblp.uni-trier.de/pid/59/2902.html">Kun Gai</a></p>
<p>Abstract:
To drive purchase in online advertising, it is of the advertiser's great interest to optimize the sequential advertising strategy whose performance and interpretability are both important. The lack of interpretability in existing deep reinforcement learning methods makes it not easy to understand, diagnose and further optimize the strategy.In this paper, we propose our Deep Intents Sequential Advertising (DISA) method to address these issues. The key part of interpretability is to understand a consumer's purchase intent which is, however, unobservable (called hidden states). In this paper, we model this intention as a latent variable and formulate the problem as a Partially Observable Markov Decision Process (POMDP) where the underlying intents are inferred based on the observable behaviors. Large-scale industrial offline and online experiments demonstrate our method's superior performance over several baselines. The inferred hidden states are analyzed, and the results prove the rationality of our inference.</p>
<p>Keywords:</p>
<h3 id="338. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction.">338. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412744">Paper Link</a>    Pages:2685-2692</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/167/0263.html">Qi Pi</a> ; <a href="https://dblp.uni-trier.de/pid/172/0837.html">Guorui Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/150/7124.html">Yujing Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/75/3158.html">Zhe Wang</a> ; <a href="https://dblp.uni-trier.de/pid/196/7974.html">Lejian Ren</a> ; <a href="https://dblp.uni-trier.de/pid/56/137.html">Ying Fan</a> ; <a href="https://dblp.uni-trier.de/pid/118/5116.html">Xiaoqiang Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/59/2902.html">Kun Gai</a></p>
<p>Abstract:
Rich user behavior data has been proven to be of great value for click-through rate prediction tasks, especially in industrial applications such as recommender systems and online advertising. Both industry and academy have paid much attention to this topic and propose different approaches to modeling with long sequential user behavior data. Among them, memory network based model MIMN proposed by Alibaba, achieves SOTA with the co-design of both learning algorithm and serving system. MIMN is the first industrial solution that can model sequential user behavior data with length scaling up to 1000. However, MIMN fails to precisely capture user interests given a specific candidate item when the length of user behavior sequence increases further, say, by 10 times or more. This challenge exists widely in previously proposed approaches.</p>
<p>Keywords:</p>
<h3 id="339. Category-aware Graph Neural Networks for Improving E-commerce Review Helpfulness Prediction.">339. Category-aware Graph Neural Networks for Improving E-commerce Review Helpfulness Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412691">Paper Link</a>    Pages:2693-2700</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/239/3999.html">Xiaoru Qu</a> ; <a href="https://dblp.uni-trier.de/pid/l/ZhaoLi.html">Zhao Li</a> ; <a href="https://dblp.uni-trier.de/pid/52/6458.html">Jialin Wang</a> ; <a href="https://dblp.uni-trier.de/pid/49/4941.html">Zhipeng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/64/6679.html">Pengcheng Zou</a> ; <a href="https://dblp.uni-trier.de/pid/220/7549.html">Junxiao Jiang</a> ; <a href="https://dblp.uni-trier.de/pid/233/6209.html">Jiaming Huang</a> ; <a href="https://dblp.uni-trier.de/pid/75/5560.html">Rong Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/86/1953.html">Ji Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/82/4977.html">Jun Gao</a></p>
<p>Abstract:
Helpful reviews in e-commerce sites can help customers acquire detailed information about a certain item, thus affecting customers' buying decisions. Predicting review helpfulness automatically in Taobao is an essential but challenging task for two reasons: (1) whether a review is helpful not only relies on its text, but also is related with the corresponding item and the user who posts the review, (2) the criteria of classifying review helpfulness under different items are not the same. To handle these two challenges, we propose CA-GNN (Category Aware Graph Neural Networks), which uses graph neural networks (GNNs) to identify helpful reviews in a multi-task manner --- we employ GNNs with one shared and many item-specific graph convolutions to learn the common features and each item's specific criterion for classifying reviews simultaneously. To reduce the number of parameters in CA-GNN and further boost its performance, we partition the items into several clusters according to their category information, such that items in one cluster share a common graph convolution.We conduct solid experiments on two public datasets and demonstrate that CA-GNN outperforms existing methods by up to 10.9% in AUC. We also deployed our system in Taobao with online A/B Test and verify that CA-GNN still outperforms the baseline system in most cases.</p>
<p>Keywords:</p>
<h3 id="340. Expert-in-the-loop AI for Polymer Discovery.">340. Expert-in-the-loop AI for Polymer Discovery.</h3>
<p><a href="https://doi.org/10.1145/3340531.3416020">Paper Link</a>    Pages:2701-2708</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/118/3466.html">Petar Ristoski</a> ; <a href="https://dblp.uni-trier.de/pid/213/1808.html">Dmitry Yu. Zubarev</a> ; <a href="https://dblp.uni-trier.de/pid/13/5231.html">Anna Lisa Gentile</a> ; <a href="https://dblp.uni-trier.de/pid/276/4990.html">Nathaniel Park</a> ; <a href="https://dblp.uni-trier.de/pid/s/DanielPSanders.html">Daniel P. Sanders</a> ; <a href="https://dblp.uni-trier.de/pid/35/2529.html">Daniel Gruhl</a> ; <a href="https://dblp.uni-trier.de/pid/91/770.html">Linda Kato</a> ; <a href="https://dblp.uni-trier.de/pid/20/4115.html">Steve Welch</a></p>
<p>Abstract:
The use of AI in knowledge dense domains, e.g., chemistry, medicine, biology, etc. - is extremely promising, but often suffers from slow deployment and adaptation to different tasks. We propose a methodology to quickly capture the intent and expertise of a domain expert in order to train personalized AI models for specific tasks. Specifically we focus on the domain of polymer materials design and discovery: it often takes 10 years or more to design, synthesize, test, and introduce a new polymer material into the market. One way to accelerate up the design of polymer materials is through the use of computational methods to design the material, such as combinatorial screening, generative models, inverse design, etc. The drawback of these methods is that they generate a large number of candidates for new molecules, which then need to be manually reviewed by subject matter experts who select only a dozen for further investigation. Our solution is a human-in-the-loop methodology where we rank the candidates according to a utility function that is learned via the continued interaction with the subject matter experts, but which is also constrained by specific chemical knowledge. We prove the viability of our proposed methodology in a polymer production lab and we (i) evaluate against datasets of polymers previously produced in the lab as well as (ii) producing several novel materials that are undergoing experimental development, and (iii) quantitatively show that standard synthetic accessibility scores do not inform about patterns of SME decisions.</p>
<p>Keywords:</p>
<h3 id="341. An Extensive Investigation of Machine Learning Techniques for Sleep Apnea Screening.">341. An Extensive Investigation of Machine Learning Techniques for Sleep Apnea Screening.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412686">Paper Link</a>    Pages:2709-2716</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/226/3004.html">Jose F. Rodrigues</a> ; <a href="https://dblp.uni-trier.de/pid/118/6160.html">Jean Louis Ppin</a> ; <a href="https://dblp.uni-trier.de/pid/98/7136.html">Lorraine Goeuriot</a> ; <a href="https://dblp.uni-trier.de/pid/a/SihemAmerYahia.html">Sihem Amer-Yahia</a></p>
<p>Abstract:
The identification of Obstructive Sleep Apnea (OSA) relies on laborious and expensive polysomnography (PSG) exams. However, it is known that other factors, easier to measure, can be good indicators of OSA and its severity. In this work, we extensively investigate the use of Machine Learning techniques in the task of determining which factors are more revealing with respect to OSA along with a discussion of the challenges to perform such a task. We ran extensive experiments over 1,042 patients from the Centre Hospitalier Universitaire of the city of Grenoble, France. The data included ordinary clinical information, and PSG results as baseline. We employed data preparation techniques including cleaning of outliers, imputation of missing values, and synthetic data generation. Following, we performed an exhaustive attribute selection scheme to find the most representative features. We found that the prediction of OSA depends largely on variables related to age, body mass, and sleep habits more than the ones related to alcoholism, tabagism, and depression. Next, we tested 60 regression/classification algorithms to predict the Apnea-Hypopnea Index (AHI), and the AHI-based severity of OSA. We achieved performances significantly superior to the state of the art both for AHI regression and classification. Our results can benefit the development of tools for the automatic screening of patients who should go through polysomnography and further treatments of OSA -- currently, our work in under consideration for production by the Centre Hospitalier Universitaire of Grenoble. Our thorough methodology enables experimental reproducibility on similar OSA-detection problems, and more generally, on other problems with similar data models.</p>
<p>Keywords:</p>
<h3 id="342. Continuous Improvement of Medical Diagnostic Systems with Large Scale Patient Vignette Simulation.">342. Continuous Improvement of Medical Diagnostic Systems with Large Scale Patient Vignette Simulation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412693">Paper Link</a>    Pages:2717-2724</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/173/8996.html">Suhrid Satyal</a> ; <a href="https://dblp.uni-trier.de/pid/276/5048.html">Nick Fletcher</a> ; <a href="https://dblp.uni-trier.de/pid/117/3884.html">Shameek Ghosh</a></p>
<p>Abstract:
Differential diagnostic systems provide a ranked list of highly prob-able diseases given a patient's profile and symptoms. Evaluation of diagnostic algorithms in literature has been limited to a small set of hand-crafted patient vignettes. Testing with high coverage and gaining insights for improvements are challenging because of thesize and complexity of the knowledge base. Furthermore, scalable practical methodologies for evaluation and deployment of such systems are missing in the literature. Here, we address this challenge using a novel patient vignette simulation algorithm within an iterative clinician-in-the-loop methodology for semi-automatically evaluating and deploying medical diagnostic systems in production.We evaluate our algorithms and methodology through a case study of a real product and knowledge base curated by medical experts.We conduct multiple iterations of the methodology, report novel accuracy measures, and discuss insights from our experience in applying this method to production</p>
<p>Keywords:</p>
<h3 id="343. Detection of Novel Social Bots by Ensembles of Specialized Classifiers.">343. Detection of Novel Social Bots by Ensembles of Specialized Classifiers.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412698">Paper Link</a>    Pages:2725-2732</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/35/11536.html">Mohsen Sayyadiharikandeh</a> ; <a href="https://dblp.uni-trier.de/pid/135/8835.html">Onur Varol</a> ; <a href="https://dblp.uni-trier.de/pid/25/10485.html">Kai-Cheng Yang</a> ; <a href="https://dblp.uni-trier.de/pid/78/5715.html">Alessandro Flammini</a> ; <a href="https://dblp.uni-trier.de/pid/79/3056.html">Filippo Menczer</a></p>
<p>Abstract:
Malicious actors create inauthentic social media accounts controlled in part by algorithms, known as social bots, to disseminate misinformation and agitate online discussion. While researchers have developed sophisticated methods to detect abuse, novel bots with diverse behaviors evade detection. We show that different types of bots are characterized by different behavioral features. As a result, supervised learning techniques suffer severe performance deterioration when attempting to detect behaviors not observed in the training data. Moreover, tuning these models to recognize novel bots requires retraining with a significant amount of new annotations, which are expensive to obtain. To address these issues, we propose a new supervised learning method that trains classifiers specialized for each class of bots and combines their decisions through the maximum rule. The ensemble of specialized classifiers (ESC) can better generalize, leading to an average improvement of 56% in F1 score for unseen accounts across datasets. Furthermore, novel bot behaviors are learned with fewer labeled examples during retraining. We deployed ESC in the newest version of Botometer, a popular tool to detect social bots in the wild, with a cross-validation AUC of 0.99.</p>
<p>Keywords:</p>
<h3 id="344. ITAD: Integrative Tensor-based Anomaly Detection System for Reducing False Positives of Satellite Systems.">344. ITAD: Integrative Tensor-based Anomaly Detection System for Reducing False Positives of Satellite Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412716">Paper Link</a>    Pages:2733-2740</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/04/11206.html">Youjin Shin</a> ; <a href="https://dblp.uni-trier.de/pid/225/6690.html">Sangyup Lee</a> ; <a href="https://dblp.uni-trier.de/pid/194/9281.html">Shahroz Tariq</a> ; <a href="https://dblp.uni-trier.de/pid/245/6060.html">Myeong Shin Lee</a> ; <a href="https://dblp.uni-trier.de/pid/54/9733.html">Okchul Jung</a> ; <a href="https://dblp.uni-trier.de/pid/63/9733.html">Daewon Chung</a> ; <a href="https://dblp.uni-trier.de/pid/53/2716.html">Simon S. Woo</a></p>
<p>Abstract:
Reducing false positives while detecting anomalies is of growing importance for various industrial applications and mission-critical infrastructures, including satellite systems. Undesired false positives can be costly for such systems, bringing the operation to a halt for human experts to determine if the anomalies are true anomalies that need to be mitigated. Although rule-based or machine learning-based anomaly detection approaches have been studied, a tensor-based decomposition method has not been extensively explored. In this work, we introduce an Integrative Tensor-based Anomaly Detection (ITAD) framework to detect anomalies in a satellite system with the goal of minimizing false positives. We construct 3rd-order tensors with telemetry data collected from the Korea Multi-Purpose Satellite-2 (KOMPSAT-2) and calculate the anomaly score using one of the component matrices obtained by applying CANDECOMP/PARAFAC decomposition to detect anomalies. Our result shows that our tensor-based approach outperforms existing methods, achieving higher accuracy and lower false positive rates. And we successfully deployed our anomaly detection system in real KOMPSAT-2 mission operation.</p>
<p>Keywords:</p>
<h3 id="345. Helix: DGA Domain Embeddings for Tracking and Exploring Botnets.">345. Helix: DGA Domain Embeddings for Tracking and Exploring Botnets.</h3>
<p><a href="https://doi.org/10.1145/3340531.3416022">Paper Link</a>    Pages:2741-2748</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/175/1664.html">Lior Sidi</a> ; <a href="https://dblp.uni-trier.de/pid/160/6851.html">Yisroel Mirsky</a> ; <a href="https://dblp.uni-trier.de/pid/198/8291.html">Asaf Nadler</a> ; <a href="https://dblp.uni-trier.de/pid/38/4086.html">Yuval Elovici</a> ; <a href="https://dblp.uni-trier.de/pid/56/5380.html">Asaf Shabtai</a></p>
<p>Abstract:
Botnets have been using domain generation algorithms (DGA) for over a decade to covertly and robustly identify the domain name of their command and control servers (C&amp;C). Recent advancements in DGA detection has motivated botnet owners to rapidly alter the C&amp;C domain and use adversarial techniques to evade detection. As a result, it has become increasingly difficult to track botnets in DNS traffic. In this paper, we present Helix, a method for tracking and exploring botnets. Helix uses a spatio-temporal deep neural network autoencoder to convert domains into numerical vectors (embeddings) which capture the DGA and seed used to create the domain. This is made possible by leveraging both convolutional (spatial) and recurrent (temporal) layers, and by using techniques such as attention mechanisms and highways. Furthermore, by using an autoencoder architecture, the network can be trained in an unsupervised manner (no labeling of data) which makes the system practical for real world deployments.</p>
<p>Keywords:</p>
<h3 id="346. Crime Linkage Based on Textual Hebrew Police Reports Utilizing Behavioral Patterns.">346. Crime Linkage Based on Textual Hebrew Police Reports Utilizing Behavioral Patterns.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412694">Paper Link</a>    Pages:2749-2756</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/222/4641.html">Adir Solomon</a> ; <a href="https://dblp.uni-trier.de/pid/276/5128.html">Amit Magen</a> ; <a href="https://dblp.uni-trier.de/pid/276/5002.html">Simo Hanouna</a> ; <a href="https://dblp.uni-trier.de/pid/276/5031.html">Mor Kertis</a> ; <a href="https://dblp.uni-trier.de/pid/74/6180.html">Bracha Shapira</a> ; <a href="https://dblp.uni-trier.de/pid/r/LiorRokach.html">Lior Rokach</a></p>
<p>Abstract:
The identification of criminals' behavioral patterns can be helpful for solving crimes. Currently, in order to perform this task, police investigators manually extract criminals' behavioral patterns (also referred to as criminals' modus operandi) from a large corpus of police reports. These patterns are compared to the patterns observed in an ongoing criminal investigation to identify similarities that may link the suspect to other documented crimes. Due to the large number of historical cases, this manual process is time consuming, very costly in terms of police resources, and limits the investigators' ability to solve open cases. In this study, we propose an automatic and language independent method for extracting behavioral patterns from police reports. Relying on the extracted behavioral patterns as input, we utilize a Siamese neural network to identify burglaries committed by the same criminals. Experiments performed using a large dataset of police reports written in Hebrew provided by the Israel Police demonstrate the proposed method's high performance, achieving an AUC above 0.9. Using our method, we are also able to identify potential suspects for 22.41% of the open burglary cases in Israel.</p>
<p>Keywords:</p>
<h3 id="347. AGATHA: Automatic Graph Mining And Transformer based Hypothesis Generation Approach.">347. AGATHA: Automatic Graph Mining And Transformer based Hypothesis Generation Approach.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412684">Paper Link</a>    Pages:2757-2764</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/195/5740.html">Justin Sybrandt</a> ; <a href="https://dblp.uni-trier.de/pid/258/4746.html">Ilya Tyagin</a> ; <a href="https://dblp.uni-trier.de/pid/195/5771.html">Michael Shtutman</a> ; <a href="https://dblp.uni-trier.de/pid/64/5096.html">Ilya Safro</a></p>
<p>Abstract:
Medical research is risky and expensive. Drug discovery requires researchers to efficiently winnow thousands of potential targets to a small candidate set. However, scientists spend significant time and money long before seeing the intermediate results that ultimately determine this smaller set. Hypothesis generation systems address this challenge by mining the wealth of publicly available scientific information to predict plausible research directions. We present AGATHA, a deep-learning hypothesis generation system that learns a data-driven ranking criteria to recommend new biomedical connections. We massively validate our system with a temporal holdout wherein we predict connections first introduced after 2015 using data published beforehand. We additionally explore biomedical sub-domains, and demonstrate AGATHA's predictive capacity across the twenty most popular relationship types. Furthermore, we perform an ablation study to examine the aspects of our semantic network that most contribute to recommendation quality. Overall, AGATHA achieves best-in-class recommendation quality when compared to other hypothesis generation systems built to predict across all available biomedical literature. Reproducibility: All code, experimental data, and pre-trained models are available online: sybrandt.com/2020/agatha.</p>
<p>Keywords:</p>
<h3 id="348. Query Understanding for Surfacing Under-served Music Content.">348. Query Understanding for Surfacing Under-served Music Content.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412741">Paper Link</a>    Pages:2765-2772</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/194/6475.html">Federico Tomasi</a> ; <a href="https://dblp.uni-trier.de/pid/121/4289.html">Rishabh Mehrotra</a> ; <a href="https://dblp.uni-trier.de/pid/115/5870.html">Aasish Pappu</a> ; <a href="https://dblp.uni-trier.de/pid/175/1785.html">Judith Btepage</a> ; <a href="https://dblp.uni-trier.de/pid/183/0628.html">Brian Brost</a> ; <a href="https://dblp.uni-trier.de/pid/276/5007.html">Hugo Galvo</a> ; <a href="https://dblp.uni-trier.de/pid/l/MLalmas.html">Mounia Lalmas</a></p>
<p>Abstract:
Platform ecosystems have witnessed an explosive growth by facilitating interactions between consumers and suppliers. Search systems powering such platforms play an important role in surfacing content in front of users. To maintain a healthy, sustainable platform, systems designers often need to explicitly consider exposing under-served content to users, content which might otherwise remain undiscovered. In this work, we consider the question when we might surface under-served content in search results, and investigate ways to provide exposure to certain content groups. We propose a framework to develop query understanding techniques to identify potential non-focused search queries on a music streaming platform, where users' information needs are non-specific enough to expose under-served content without severely impacting user satisfaction. We present insights from a search ranker deployed at scale and present results from live A/B test targeting a random sample of 72 million users and 593 million sessions, to compare performance of different methods considered to identify non-focused queries for surfacing under-served content.</p>
<p>Keywords:</p>
<h3 id="349. LiFT: A Scalable Framework for Measuring Fairness in ML Applications.">349. LiFT: A Scalable Framework for Measuring Fairness in ML Applications.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412705">Paper Link</a>    Pages:2773-2780</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/179/3177.html">Sriram Vasudevan</a> ; <a href="https://dblp.uni-trier.de/pid/29/4781.html">Krishnaram Kenthapadi</a></p>
<p>Abstract:
Many internet applications are powered by machine learned models, which are usually trained on labeled datasets obtained through user feedback signals or human judgments. Since societal biases may be present in the generation of such datasets, it is possible for the trained models to be biased, thereby resulting in potential discrimination and harms for disadvantaged groups. Motivated by the need to understand and address algorithmic bias in web-scale ML systems and the limitations of existing fairness toolkits, we present the LinkedIn Fairness Toolkit (LiFT), a framework for scalable computation of fairness metrics as part of large ML systems. We highlight the key requirements in deployed settings, and present the design of our fairness measurement system. We discuss the challenges encountered in incorporating fairness tools in practice and the lessons learned during deployment at LinkedIn. Finally, we provide open problems based on practical experience.</p>
<p>Keywords:</p>
<h3 id="350. Match Tracing: A Unified Framework for Real-time Win Prediction and Quantifiable Performance Evaluation.">350. Match Tracing: A Unified Framework for Real-time Win Prediction and Quantifiable Performance Evaluation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412727">Paper Link</a>    Pages:2781-2788</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/78/2022.html">Kai Wang</a> ; <a href="https://dblp.uni-trier.de/pid/17/5705.html">Hao Li</a> ; <a href="https://dblp.uni-trier.de/pid/223/3141.html">Linxia Gong</a> ; <a href="https://dblp.uni-trier.de/pid/185/4005.html">Jianrong Tao</a> ; <a href="https://dblp.uni-trier.de/pid/180/4550.html">Runze Wu</a> ; <a href="https://dblp.uni-trier.de/pid/71/882.html">Changjie Fan</a> ; <a href="https://dblp.uni-trier.de/pid/01/5394.html">Liang Chen</a> ; <a href="https://dblp.uni-trier.de/pid/31/891.html">Peng Cui</a></p>
<p>Abstract:
Win prediction and performance evaluation are two core subjects in the sport analytics. Traditionally, they are treated separately and studied by two independent communities. However, this is not the intuitive way how humans interpret the matches: we predict the match results with the competition carrying on, and simultaneously evaluate each action based on the game context and its downstream impact. Predicting the match outcomes and evaluating the actions are coupled tasks, and the more accurately we predict, the better the evaluation is</p>
<p>Keywords:</p>
<h3 id="351. Masked-field Pre-training for User Intent Prediction.">351. Masked-field Pre-training for User Intent Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412726">Paper Link</a>    Pages:2789-2796</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/95/4442.html">Peng Wang</a> ; <a href="https://dblp.uni-trier.de/pid/20/4396.html">Jiang Xu</a> ; <a href="https://dblp.uni-trier.de/pid/200/1300.html">Chunyi Liu</a> ; <a href="https://dblp.uni-trier.de/pid/46/4184.html">Hao Feng</a> ; <a href="https://dblp.uni-trier.de/pid/06/6214.html">Zang Li</a> ; <a href="https://dblp.uni-trier.de/pid/03/5454.html">Jieping Ye</a></p>
<p>Abstract:
For many applications, predicting the users' intents can help the system provide the solutions or recommendations to the users. It improves the user experience, and brings economic benefits. The main challenge of user intent prediction is that we lack enough labeled data for training, and some intents (labels) are sparse in the training set. This is a general problem for many real-world prediction tasks. To overcome data sparsity, we propose a masked-field pre-training framework. In pre-training, we exploit massive unlabeled data to learn useful feature interaction patterns. We do this by masking partial field features, and learning to predict them from other unmasked features. We then finetune the pre-trained model for the target intent prediction task. This framework can be used to train various deep models. In the intent prediction task, each intent is only relevant to partial features. To tackle this problem, we propose a Field-Independent Transformer network. This network generates separate representation for each field, and aggregates the relevant field representations with attention mechanism for each intent. We test our method on intent prediction datasets in customer service scenarios as well as several public datasets. The results show that the masked-field pre-training framework significantly improves the prediction precision for deep models. And the Field-Independent Transformer network trained with the masked-field pre-training framework outperforms the state-of-the-art methods in the user intent prediction.</p>
<p>Keywords:</p>
<h3 id="352. Efficient Neural Query Auto Completion.">352. Efficient Neural Query Auto Completion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412701">Paper Link</a>    Pages:2797-2804</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/34/10207.html">Sida Wang</a> ; <a href="https://dblp.uni-trier.de/pid/02/7667.html">Weiwei Guo</a> ; <a href="https://dblp.uni-trier.de/pid/77/9023.html">Huiji Gao</a> ; <a href="https://dblp.uni-trier.de/pid/96/6993.html">Bo Long</a></p>
<p>Abstract:
Query Auto Completion (QAC), as the starting point of information retrieval tasks, is critical to user experience. Generally it has two steps: generating completed query candidates according to query prefixes, and ranking them based on extracted features. Three major challenges are observed for a query auto completion system: (1) QAC has a strict online latency requirement. For each keystroke, results must be returned within tens of milliseconds, which poses a significant challenge in designing sophisticated language models for it. (2) For unseen queries, generated candidates are of poor quality as contextual information is not fully utilized. (3) Traditional QAC systems heavily rely on handcrafted features such as the query candidate frequency in search logs, lacking sufficient semantic understanding of the candidate.</p>
<p>Keywords:</p>
<h3 id="353. A Joint Inverse Reinforcement Learning and Deep Learning Model for Drivers' Behavioral Prediction.">353. A Joint Inverse Reinforcement Learning and Deep Learning Model for Drivers' Behavioral Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412682">Paper Link</a>    Pages:2805-2812</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/200/2455.html">Guojun Wu</a> ; <a href="https://dblp.uni-trier.de/pid/66/580.html">Yanhua Li</a> ; <a href="https://dblp.uni-trier.de/pid/149/2528.html">Shikai Luo</a> ; <a href="https://dblp.uni-trier.de/pid/86/2187.html">Ge Song</a> ; <a href="https://dblp.uni-trier.de/pid/145/5339.html">Qichao Wang</a> ; <a href="https://dblp.uni-trier.de/pid/85/93.html">Jing He</a> ; <a href="https://dblp.uni-trier.de/pid/03/5454.html">Jieping Ye</a> ; <a href="https://dblp.uni-trier.de/pid/62/1827.html">Xiaohu Qie</a> ; <a href="https://dblp.uni-trier.de/pid/03/5683.html">Hongtu Zhu</a></p>
<p>Abstract:
Users' behavioral predictions are crucially important for many domains including major e-commerce companies, ride-hailing platforms, social networking, and education. The success of such prediction strongly depends on the development of representation learning that can effectively model the dynamic evolution of user's behavior. This paper aims to develop a joint framework of combining inverse reinforcement learning (IRL) with deep learning (DL) regression model, called IRL-DL, to predict drivers' future behavior in ride-hailing platforms. Specifically, we formulate the dynamic evolution of each driver as a sequential decision-making problem and then employ IRL as representation learning to learn the preference vector of each driver. Then, we integrate drivers' preference vector with their static features (e.g., age, gender) and other attributes to build a regression model (e.g., LTSM-neural network) to predict drivers' future behavior. We use an extensive driver data set obtained from a ride-sharing platform to verify the effectiveness and efficiency of our IRL-DL framework, and results show that our IRL-DL framework can achieve consistent and remarkable improvements over models without drivers' preference vectors.</p>
<p>Keywords:</p>
<h3 id="354. Deep Behavior Tracing with Multi-level Temporality Preserved Embedding.">354. Deep Behavior Tracing with Multi-level Temporality Preserved Embedding.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412696">Paper Link</a>    Pages:2813-2820</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/180/4550.html">Runze Wu</a> ; <a href="https://dblp.uni-trier.de/pid/15/8092.html">Hao Deng</a> ; <a href="https://dblp.uni-trier.de/pid/185/4005.html">Jianrong Tao</a> ; <a href="https://dblp.uni-trier.de/pid/71/882.html">Changjie Fan</a> ; <a href="https://dblp.uni-trier.de/pid/95/2446-3.html">Qi Liu</a> ; <a href="https://dblp.uni-trier.de/pid/01/5394.html">Liang Chen</a></p>
<p>Abstract:
Behavior tracing or predicting is a key component in various application scenarios like online user modeling and ubiquitous computing, which significantly benefits the system design (e.g., resource pre-caching) and improves the user experience (e.g., personalized recommendation). Traditional behavior tracing methods like Markovian and sequential models take recent behaviors as input and infer the next move by using the most real-time information. However, these existing methods rarely comprehensively model the low-level temporal irregularity in the recent behavior sequence, i.e., the unevenly distributed time intervals between consecutive behaviors, and the high-level periodicity in the long-term activity cycle, i.e., the periodic behavior patterns of each user.</p>
<p>Keywords:</p>
<h3 id="355. Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to Cold-Start Search Retrieval.">355. Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to Cold-Start Search Retrieval.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412752">Paper Link</a>    Pages:2821-2828</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/20/5998.html">Tao Wu</a> ; <a href="https://dblp.uni-trier.de/pid/256/1111.html">Ellie Ka In Chio</a> ; <a href="https://dblp.uni-trier.de/pid/30/8739.html">Heng-Tze Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/27/6228.html">Yu Du</a> ; <a href="https://dblp.uni-trier.de/pid/67/5601.html">Steffen Rendle</a> ; <a href="https://dblp.uni-trier.de/pid/91/2314.html">Dima Kuzmin</a> ; <a href="https://dblp.uni-trier.de/pid/70/774.html">Ritesh Agarwal</a> ; <a href="https://dblp.uni-trier.de/pid/89/5992.html">Li Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/69/2407.html">John R. Anderson</a> ; <a href="https://dblp.uni-trier.de/pid/s/SarvjeetSingh.html">Sarvjeet Singh</a> ; <a href="https://dblp.uni-trier.de/pid/26/477.html">Tushar Chandra</a> ; <a href="https://dblp.uni-trier.de/pid/13/310.html">Ed H. Chi</a> ; <a href="https://dblp.uni-trier.de/pid/06/721.html">Wen Li</a> ; <a href="https://dblp.uni-trier.de/pid/52/7766.html">Ankit Kumar</a> ; <a href="https://dblp.uni-trier.de/pid/52/7004.html">Xiang Ma</a> ; <a href="https://dblp.uni-trier.de/pid/272/4200.html">Alex Soares</a> ; <a href="https://dblp.uni-trier.de/pid/60/4003.html">Nitin Jindal</a> ; <a href="https://dblp.uni-trier.de/pid/87/3674.html">Pei Cao</a></p>
<p>Abstract:
Many recent advances in neural information retrieval models, which predict top-K items given a query, learn directly from a large training set of (query, item) pairs. However, they are often insufficient when there are many previously unseen (query, item) combinations, often referred to as the cold start problem. Furthermore, the search system can be biased towards items that are frequently shown to a query previously, also known as the 'rich get richer' (a.k.a. feedback loop) problem. In light of these problems, we observed that most online content platforms have both a search and a recommender system that, while having heterogeneous input spaces, can be connected through their common output item space and a shared semantic representation. In this paper, we propose a new Zero-Shot Heterogeneous Transfer Learning framework that transfers learned knowledge from the recommender system component to improve the search component of a content platform. First, it learns representations of items and their natural-language features by predicting (item, item) correlation graphs derived from the recommender system as an auxiliary task. Then, the learned representations are transferred to solve the target search retrieval task, performing query-to-item prediction without having seen any (query, item) pairs in training. We conduct online and offline experiments on one of the world's largest search and recommender systems from Google, and present the results and lessons learned. We demonstrate that the proposed approach can achieve high performance on offline search retrieval tasks, and more importantly, achieved significant improvements on relevance and user interactions over the highly-optimized production system in online experiments.</p>
<p>Keywords:</p>
<h3 id="356. Relevance Ranking for Real-Time Tweet Search.">356. Relevance Ranking for Real-Time Tweet Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412743">Paper Link</a>    Pages:2829-2836</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/17/6518.html">Yan Xia</a> ; <a href="https://dblp.uni-trier.de/pid/62/3689.html">Yu Sun</a> ; <a href="https://dblp.uni-trier.de/pid/25/3246.html">Tian Wang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5020.html">Juan Caicedo Carvajal</a> ; <a href="https://dblp.uni-trier.de/pid/16/3382.html">Jinliang Fan</a> ; <a href="https://dblp.uni-trier.de/pid/158/2810.html">Bhargav Mangipudi</a> ; <a href="https://dblp.uni-trier.de/pid/237/3830.html">Lisa Huang</a> ; <a href="https://dblp.uni-trier.de/pid/20/3871.html">Yatharth Saraf</a></p>
<p>Abstract:
Relevance ranking is a key component of many search engines, including the Tweet search engine at Twitter. Users often use Tweet search to discover live discussions and different voices on trending topics or recent events. Tweet search is thus unique due to its focus on real-time content, where both the retrieved content and queries change drastically on an hourly basis. Another important property of Tweet search is that its relevance ranking takes the social endorsements from other users into account, e.g., "likes" and "retweets", which is different from mainly relying on clicks as implicit feedback. The relevance ranking of Tweet search is also subject to strict latency constraints, because every second, a large amount of Tweets are posted and indexed, while tens of thousands of queries are issued to search posted Tweets. Considering the above properties and constraints, we present a relevance ranking system for Tweet search addressing all these challenges at Twitter. We first discuss the formation of the relevance ranking pipeline, which consists of a series of ranking models. We then present the methodology for training the models and the various groups of features we use, including real-time and personalized features. We also investigate approaches of achieving unbiased model training and building up automatic online tuning of system parameters. Experiments using online A/B testing demonstrate the effectiveness of the proposed approaches and we have deployed the proposed relevance ranking system in production for more than three years.</p>
<p>Keywords:</p>
<h3 id="357. Generating Full Spatiotemporal Vehicular Paths: A Data Fusion Approach.">357. Generating Full Spatiotemporal Vehicular Paths: A Data Fusion Approach.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412708">Paper Link</a>    Pages:2837-2844</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/47/2874.html">Nan Xiao</a> ; <a href="https://dblp.uni-trier.de/pid/25/3444.html">Nan Hu</a> ; <a href="https://dblp.uni-trier.de/pid/28/1433.html">Liang Yu</a> ; <a href="https://dblp.uni-trier.de/pid/58/10813.html">Cheng Long</a></p>
<p>Abstract:
Vehicular path flow (trajectories) is an important data source for smart mobility, from which many road traffic parameters can be inferred. However, it has been a long-existing challenge that single source of trajectory data is biased in terms of its spatiotemporal coverage. In this paper, we leverage two types of large traffic datasets - point flows and sample trajectories - to generate the full city-scale vehicular paths. Our method consists of a low-granularity data fusion (LGDF) module, which uses point flow data to estimate the sparse paths that pass through some specific links (where sensors are mounted), and a high-granularity model training (HGMT) component, which uses sample trajectory data to pre-train a bi-gram sequence generation model. Afterwards, the results from LGDF and HGMT are combined to produce detailed on-road spatiotemporal paths. In this way, the data safety of single trajectory is protected while the full-scale city traffic can be reproduced for transportation analytics. The proposed method is verified via real-data case studies. As a result, starting from August 2019, this method has been implemented in Alibaba's city brain project and successively deployed in many cities in China for the purpose of traffic analysis and optimization.</p>
<p>Keywords:</p>
<h3 id="358. Multi-Channel Sellers Traffic Allocation in Large-scale E-commerce Promotion.">358. Multi-Channel Sellers Traffic Allocation in Large-scale E-commerce Promotion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412730">Paper Link</a>    Pages:2845-2852</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/251/9483.html">Shen Xin</a> ; <a href="https://dblp.uni-trier.de/pid/160/7183.html">Yizhou Ye</a> ; <a href="https://dblp.uni-trier.de/pid/e/MartinEster.html">Martin Ester</a> ; <a href="https://dblp.uni-trier.de/pid/58/10813.html">Cheng Long</a> ; <a href="https://dblp.uni-trier.de/pid/84/6889.html">Jie Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/l/ZhaoLi.html">Zhao Li</a> ; <a href="https://dblp.uni-trier.de/pid/276/5073.html">Kaiying Yuan</a> ; <a href="https://dblp.uni-trier.de/pid/260/0773.html">Yanghua Li</a></p>
<p>Abstract:
Large-scale online promotions, such as Double 11 and Black Friday, are of great value to e-commerce platforms nowadays. Traditional methods are not successful when we aim to maximize global Gross Merchandise Volume (GMV) in the promotion scenarios due to three limitations. The first is that the GMV of sellers varies significantly from daily scenarios to promotions. Second, these methods do not consider explosive demands in promotions, so that a consumer may fail to purchase some popular items due to sellers' limited capacities. Third, the traffic distribution over sellers presents divergence in different channels, thus rendering the performance of the traditional single-channel methods far from optimal in creating commercial values. To address these problems, we design a Multi-Channel Sellers Traffic Allocation (MCSTA) optimization model to obtain optimal page view (PV) distribution concerning global GMV. Then we propose a general constrained non-smooth convex optimization solution with a Multi-Objective Shortest Distance (MOSD) hyperparameter tuning method to solve MCSTA. This is the first work to systematically address this issue in the scenario of large-scale online promotions. The empirical results show that MCSTA achieves significant improvement of GMV by 1.1% based on A/B test during Alibaba's "Global Shopping Festival", one of the world's largest online sales events. Furthermore, we deploy MCSTA in other popular scenarios, including everyday promotion and video live stream service, to showcase that MCSTA can be widely applied in e-commerce and online entertainment services.</p>
<p>Keywords:</p>
<h3 id="359. aDMSCN: A Novel Perspective for User Intent Prediction in Customer Service Bots.">359. aDMSCN: A Novel Perspective for User Intent Prediction in Customer Service Bots.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412683">Paper Link</a>    Pages:2853-2860</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/127/3077.html">Kuan Xu</a> ; <a href="https://dblp.uni-trier.de/pid/245/1803.html">Chilin Fu</a> ; <a href="https://dblp.uni-trier.de/pid/48/5176.html">Xiaolu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/152/6215.html">Cen Chen</a> ; <a href="https://dblp.uni-trier.de/pid/204/2994.html">Ya-Lin Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/18/5572.html">Wenge Rong</a> ; <a href="https://dblp.uni-trier.de/pid/260/0351.html">Zujie Wen</a> ; <a href="https://dblp.uni-trier.de/pid/99/3847.html">Jun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/82/6624-5.html">Xiaolong Li</a> ; <a href="https://dblp.uni-trier.de/pid/q/YuQiao1.html">Yu Qiao</a></p>
<p>Abstract:
As one of the core components of customer service bot, User Intent Prediction (UIP) aims at predicting users? intents (usually represented as predefined user questions) before they ask, and has been widely applied in real applications. However, when developing a machine learning system for this problem, two critical issues, i.e., the problem of feature drift and class imbalance, may emerge and seriously deprave the system performance. Moreover, various scenarios may arise due to business demands, making the aforementioned problems much more severe. To address these two problems, we propose an attention-based Deep Multi-instance Sequential Cross Network (aDMSCN) to deal with the UIP task. On the one hand,the UIP task can be subtly formalized as multi-instance learning(MIL) task with an attention-based method proposed to alleviate the influences of feature drift. To the best of our knowledge, this is the first attempt to model the problem from a MIL perspective.On the other hand, a ratio-sensitive loss is also developed in our model, which can mitigate the negative impact of class imbalance. Extensive experiments on both offline real-world datasets and on-line A/B testing show that our proposed framework significantly out performs other state-of-art methods for the UIP task.</p>
<p>Keywords:</p>
<h3 id="360. GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems.">360. GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412754">Paper Link</a>    Pages:2861-2868</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/268/6784.html">Yishi Xu</a> ; <a href="https://dblp.uni-trier.de/pid/174/0010.html">Yingxue Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/71/6601.html">Wei Guo</a> ; <a href="https://dblp.uni-trier.de/pid/152/3785.html">Huifeng Guo</a> ; <a href="https://dblp.uni-trier.de/pid/24/10003.html">Ruiming Tang</a> ; <a href="https://dblp.uni-trier.de/pid/c/MarkCoates.html">Mark Coates</a></p>
<p>Abstract:
Given the convenience of collecting information through online services, recommender systems now consume large scale data and play a more important role in improving user experience. With the recent emergence of Graph Neural Networks (GNNs), GNN-based recommender models have shown the advantage of modeling the recommender system as a user-item bipartite graph to learn representations of users and items. However, such models are expensive to train and difficult to perform frequent updates to provide the most up-to-date recommendations. In this work, we propose to update GNN-based recommender models incrementally so that the computation time can be greatly reduced and models can be updated more frequently. We develop a Graph Structure Aware Incremental Learning framework, GraphSAIL, to address the commonly experienced catastrophic forgetting problem that occurs when training a model in an incremental fashion. Our approach preserves a user's long-term preference (or an item's long-term property) during incremental model updating. GraphSAIL implements a graph structure preservation strategy which explicitly preserves each node's local structure, global structure, and self-information, respectively. We argue that our incremental training framework is the first attempt tailored for GNN based recommender systems and demonstrate its improvement compared to other incremental learning techniques on two public datasets. We further verify the effectiveness of our framework on a large-scale industrial dataset.</p>
<p>Keywords:</p>
<h3 id="361. Ranking User Attributes for Fast Candidate Selection in Recommendation Systems.">361. Ranking User Attributes for Fast Candidate Selection in Recommendation Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412742">Paper Link</a>    Pages:2869-2876</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/66/9281.html">Huichao Xue</a></p>
<p>Abstract:
Many recommendation systems use users' attributes to retrieve documents before ranking. Instead of using all attributes, this work explores algorithms that choose a subset, in order to achieve higher precision. We propose a model that forecasts the relevance of documents matched by each individual attribute. By restricting to top-K attributes based on the forecast, we observed 50% reduction in latency at 99th percentile on LinkedIn's job recommendation system, as well as increased users' engagements.</p>
<p>Keywords:</p>
<h3 id="362. Learning to Build User-tag Profile in Recommendation System.">362. Learning to Build User-tag Profile in Recommendation System.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412719">Paper Link</a>    Pages:2877-2884</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/62/5622.html">Su Yan</a> ; <a href="https://dblp.uni-trier.de/pid/24/1518.html">Xin Chen</a> ; <a href="https://dblp.uni-trier.de/pid/129/4060.html">Ran Huo</a> ; <a href="https://dblp.uni-trier.de/pid/98/5660.html">Xu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/218/7323.html">Leyu Lin</a></p>
<p>Abstract:
User profiling is one of the most important components in recommendation systems, where a user is profiled using demographic (e.g. gender, age, and location) and user behavior information (e.g. browsing and search history). Among different dimensions of user profiling, tagging is an explainable and widely-used representation of user interest. In this paper, we propose a user tag profiling model (UTPM) to study user-tag profiling as a multi-label classification task using deep neural networks. Different from the conventional model, our UTPM model is a multi-head attention mechanism with shared query vectors to learn sparse features across different fields. Besides, we introduce the improved FM-based cross feature layer, which outperforms many state-of-the-art cross feature methods and further enhances model performance. Meanwhile, we design a novel joint method to learn the preference of different tags from a single clicked news article in recommendation systems. Furthermore, our UTPM model is deployed in the WeChat "Top Stories" recommender system, where both online and offline experiments demonstrate the superiority of the proposed model over baseline models.</p>
<p>Keywords:</p>
<h3 id="363. You Are How You Use: Catching Gas Theft Suspects among Diverse Restaurant Users.">363. You Are How You Use: Catching Gas Theft Suspects among Diverse Restaurant Users.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412751">Paper Link</a>    Pages:2885-2892</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5030.html">Xiaodu Yang</a> ; <a href="https://dblp.uni-trier.de/pid/166/5244.html">Xiuwen Yi</a> ; <a href="https://dblp.uni-trier.de/pid/118/4720.html">Shun Chen</a> ; <a href="https://dblp.uni-trier.de/pid/204/3375.html">Sijie Ruan</a> ; <a href="https://dblp.uni-trier.de/pid/75/8471.html">Junbo Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/87/1585.html">Yu Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/47/3003.html">Tianrui Li</a></p>
<p>Abstract:
Gas theft of restaurants is a major concern in the gas industry, which causes revenue losses for gas companies and endangers the public safety seriously. Traditional methods of gas theft detection highly rely on active human efforts that are extremely ineffective. Thanks to the gas consumption data collected by smart meters, we can devise a data-driven method to tackle this issue. In this paper, we propose a gas-theft detection method msRank to discover suspicious restaurant users when only scarce labels are available. Our method contains three main components: 1)data pre-processing, which filters reading noises and excludes data-missing or zero-use users; 2)normal user modeling, which quantifies the self-stable seasonality of normal users and distinguishes them from unstable ones; and 3)gas-theft suspect detection, which discovers gas-theft suspects among unstable users by RankNet-based suspicion scoring on extracted deviation features. By using detected normal users as negative samples to train RankNet, the component of normal user modeling and that of gas-theft suspect detection are seamlessly connected, overcoming the problem of label scarcity. We conduct extensive experiments on three real-world datasets, and the results demonstrate advantages of our approach. We have deployed a system GasShield which provides a gas-theft suspect list weekly for a gas group in northern China.</p>
<p>Keywords:</p>
<h3 id="364. Query-aware Tip Generation for Vertical Search.">364. Query-aware Tip Generation for Vertical Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412740">Paper Link</a>    Pages:2893-2900</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/48/450.html">Yang Yang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5124.html">Junmei Hao</a> ; <a href="https://dblp.uni-trier.de/pid/211/0750.html">Canjia Li</a> ; <a href="https://dblp.uni-trier.de/pid/124/3241.html">Zili Wang</a> ; <a href="https://dblp.uni-trier.de/pid/59/7807.html">Jingang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/134/2883.html">Fuzheng Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/47/4111.html">Rao Fu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5098.html">Peixu Hou</a> ; <a href="https://dblp.uni-trier.de/pid/77/6324.html">Gong Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/84/6394.html">Zhongyuan Wang</a></p>
<p>Abstract:
As a concise form of user reviews, tips have unique advantages to explain the search results, assist users' decision making, and further improve user experience in vertical search scenarios. Existing work on tip generation does not take query into consideration, which limits the impact of tips in search scenarios. To address this issue, this paper proposes a query-aware tip generation framework, integrating query information into encoding and subsequent decoding processes. Two specific adaptations of Transformer and Recurrent Neural Network (RNN) are proposed. For Transformer, the query impact is incorporated into the self-attention computation of both the encoder and the decoder. As for RNN, the query-aware encoder adopts a selective network to distill query-relevant information from the review, while the query-aware decoder integrates the query information into the attention computation during decoding. The framework consistently outperforms the competing methods on both public and real-world industrial datasets. Last but not least, online deployment experiments on Dianping demonstrate the advantage of the proposed framework for tip generation as well as its online business values.</p>
<p>Keywords:</p>
<h3 id="365. BotSpot: A Hybrid Learning Framework to Uncover Bot Install Fraud in Mobile Advertising.">365. BotSpot: A Hybrid Learning Framework to Uncover Bot Install Fraud in Mobile Advertising.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412690">Paper Link</a>    Pages:2901-2908</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/206/5874.html">Tianjun Yao</a> ; <a href="https://dblp.uni-trier.de/pid/181/2689.html">Qing Li</a> ; <a href="https://dblp.uni-trier.de/pid/57/7731.html">Shangsong Liang</a> ; <a href="https://dblp.uni-trier.de/pid/132/3535.html">Yadong Zhu</a></p>
<p>Abstract:
Mobile advertising has become inarguably one of the fastest growing industries all over the world. The influx of capital attracts increasing fraudsters to defraud money from advertisers. There are many tricks a fraudster can leverage, among which bot install fraud is undoubtedly the most insidious one due to its ability to implement sophisticated behavioral patterns and emulate normal users, so as to evade from detection rules defined by human experts. In this work, we propose an anti-fraud method based on heterogeneous graph that incorporates both local context and global context via graph neural networks (GNN) and gradient boosting classifier to detect bot fraud installs at Mobvista, a leading global mobile advertising company. Offline evaluations in two datasets show the proposed method outperforms all the competitive baseline methods by at least 2.2% in the first dataset and 5.75% in the second dataset given the evaluation metric [email protected]% Precision. Furthermore, we deploy our method to tackle million-scale data daily at Mobvista. The online performance also shows that the proposed methods consistently detect more bots than other baseline methods.</p>
<p>Keywords:</p>
<h3 id="366. Community Mitigation: A Data-driven System for COVID-19 Risk Assessment in a Hierarchical Manner.">366. Community Mitigation: A Data-driven System for COVID-19 Risk Assessment in a Hierarchical Manner.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412753">Paper Link</a>    Pages:2909-2916</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/07/4509.html">Yanfang Ye</a> ; <a href="https://dblp.uni-trier.de/pid/169/7114.html">Yujie Fan</a> ; <a href="https://dblp.uni-trier.de/pid/177/8001.html">Shifu Hou</a> ; <a href="https://dblp.uni-trier.de/pid/76/5416-2.html">Yiming Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/261/9059.html">Yiyue Qian</a> ; <a href="https://dblp.uni-trier.de/pid/244/4445.html">Shiyu Sun</a> ; <a href="https://dblp.uni-trier.de/pid/67/6523.html">Qian Peng</a> ; <a href="https://dblp.uni-trier.de/pid/234/2715.html">Mingxuan Ju</a> ; <a href="https://dblp.uni-trier.de/pid/62/1539.html">Wei Song</a> ; <a href="https://dblp.uni-trier.de/pid/09/7644.html">Kenneth A. Loparo</a></p>
<p>Abstract:
The fast evolving and deadly outbreak of coronavirus disease (COVID-19) has posed grand challenges to human society. To slow the spread of virus infections and better respond with actionable strategies for community mitigation, leveraging the large-scale and real-time pandemic related data generated from heterogeneous sources (e.g., disease related data, demographic data, mobility data, and social media data), in this work, we propose and develop a data-driven system (named -satellite), as an initial offering, to provide real-time COVID-19 risk assessment in a hierarchical manner in the United States. More specifically, given a location (either user input or automatic positioning), the system will automatically provide risk indices associated with the specific location, the county that location is in and the state as a whole to enable people to select appropriate actions for protection while minimizing disruptions to daily life to the extent possible. In -satellite, we first construct an attributed heterogeneous information network (AHIN) to model the collected multi-source data in a comprehensive way; and then we utilize meta-path based schemes to model both vertical and horizontal information associated with a given location (i.e., point of interest, POI); finally we devise a novel heterogeneous graph neural network to aggregate its neighborhood information to estimate the risk of the given POI in a hierarchical manner. To comprehensively evaluate the performance of -satellite in real-time COVID-19 risk assessment, a set of studies are first performed to validate its utility; based on a real-world dataset consisting of 6,538 annotated POIs, the experimental results show that -satellite achieves the area of under curve (AUC) of 0.9378, which outperforms the state-of-the-art baselines. After we launched the system for public tests, it had attracted 51,190 users as of May 30. Based on the analysis of its large-scale users, we have a key finding that people from more severe regions (i.e., with larger numbers of COVID-19 cases) have stronger interests using the system for actionable information. Our system and generated benchmark datasets have been made publicly accessible through our website.</p>
<p>Keywords:</p>
<h3 id="367. Who is Delivering My Food?: Detecting Food Delivery Abusers using Variational Reward Inference Networks.">367. Who is Delivering My Food?: Detecting Food Delivery Abusers using Variational Reward Inference Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412750">Paper Link</a>    Pages:2917-2924</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/32/9655.html">Daeyoung Yoon</a> ; <a href="https://dblp.uni-trier.de/pid/53/2716.html">Simon S. Woo</a></p>
<p>Abstract:
The recent paramount success of the gig economy has introduced new business opportunities in different areas such as food delivery service. However, there are food delivery ride abusers who break the company rule by driving unauthorized vehicles that are not stated in the contract. These abusers are particularly problematic because they break the transportation regulations and unfairly take more orders. However, detecting these abusers are challenging because of lack of labeled datasets and these anomalous abusers do not frequently occur compared to normal riders. Furthermore, sequential patterns of abusing behaviors are not easy to model.</p>
<p>Keywords:</p>
<h3 id="368. Elevated Road Network: A Metric Learning Method for Recognizing Whether a Vehicle is on an Elevated Road.">368. Elevated Road Network: A Metric Learning Method for Recognizing Whether a Vehicle is on an Elevated Road.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412703">Paper Link</a>    Pages:2925-2932</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/58/4562.html">Xiaobing Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/127/0990.html">Hailiang Xu</a> ; <a href="https://dblp.uni-trier.de/pid/y/JianYang.html">Jian Yang</a> ; <a href="https://dblp.uni-trier.de/pid/77/90.html">Jia Sun</a> ; <a href="https://dblp.uni-trier.de/pid/38/4539.html">Fan Chen</a> ; <a href="https://dblp.uni-trier.de/pid/276/5113.html">Leiyun Li</a></p>
<p>Abstract:
Mobile navigation is a critical component in mobile maps. Yawing detection (does a vehicle yaw) is an important task in mobile navigation. In regions containing parallel and close elevated and surface roads, it is hard to detect yawing events using traditional methods, which mainly rely on low-accuracy positions and moving directions. Recognizing whether a vehicle is moving on an elevated road can significantly improve the performance of yawing detection.</p>
<p>Keywords:</p>
<h3 id="369. Predicting Quality of Automated Welding with Machine Learning and Semantics: A Bosch Case Study.">369. Predicting Quality of Automated Welding with Machine Learning and Semantics: A Bosch Case Study.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412737">Paper Link</a>    Pages:2933-2940</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5109.html">Baifan Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/207/3564.html">Yulia Svetashova</a> ; <a href="https://dblp.uni-trier.de/pid/276/5084.html">Seongsu Byeon</a> ; <a href="https://dblp.uni-trier.de/pid/198/4369.html">Tim Pychynski</a> ; <a href="https://dblp.uni-trier.de/pid/82/4675.html">Ralf Mikut</a> ; <a href="https://dblp.uni-trier.de/pid/20/4833.html">Evgeny Kharlamov</a></p>
<p>Abstract:
Manufacturing of car bodies heavily relies on demanding welding processes of joining body parts together that introduce thousands of joining welding spots in each car. Quality monitoring for these spots impacts production efficiency and cost. In this paper we develop an ML pipeline to predict the spot quality before the actual welding happens. This pipeline is based on a Feature Engineering~(FE) approach to manually design features using domain knowledge. We evaluated the pipeline with two datasets from industrial plants, achieving very promising results with prediction errors around 2%. Then, we develop an approach to semantically enhance FE pipelines in order to automate the ML process without compromising the prediction accuracy and to facilitate generalisation and transfer of FE-based models to other datasets and processes. Our ML pipeline has been deployed offline on various Bosch manufacturing datasets in a controlled environment since early 2019 and evaluated.</p>
<p>Keywords:</p>
<h3 id="370. Ensembled CTR Prediction via Knowledge Distillation.">370. Ensembled CTR Prediction via Knowledge Distillation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412704">Paper Link</a>    Pages:2941-2958</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/10/2717.html">Jieming Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/36/1731.html">Jinyang Liu</a> ; <a href="https://dblp.uni-trier.de/pid/28/1153.html">Weiqi Li</a> ; <a href="https://dblp.uni-trier.de/pid/261/9752.html">Jincai Lai</a> ; <a href="https://dblp.uni-trier.de/pid/11/5357.html">Xiuqiang He</a> ; <a href="https://dblp.uni-trier.de/pid/01/5394.html">Liang Chen</a> ; <a href="https://dblp.uni-trier.de/pid/z/ZibinZheng.html">Zibin Zheng</a></p>
<p>Abstract:
Recently, deep learning-based models have been widely studied for click-through rate (CTR) prediction and lead to improved prediction accuracy in many industrial applications. However, current research focuses primarily on building complex network architectures to better capture sophisticated feature interactions and dynamic user behaviors. The increased model complexity may slow down online inference and hinder its adoption in real-time applications. Instead, our work targets at a new model training strategy based on knowledge distillation (KD). KD is a teacher-student learning framework to transfer knowledge learned from a teacher model to a student model. The KD strategy not only allows us to simplify the student model as a vanilla DNN model but also achieves significant accuracy improvements over the state-of-the-art teacher models. The benefits thus motivate us to further explore the use of a powerful ensemble of teachers for more accurate student model training. We also propose some novel techniques to facilitate ensembled CTR prediction, including teacher gating and early stopping by distillation loss. We conduct comprehensive experiments against 12 existing models and across three industrial datasets. Both offline and online A/B testing results show the effectiveness of our KD-based training strategy.</p>
<p>Keywords:</p>
<h2 id="Resource Track    32">Resource Track    32</h2>
<h3 id="371. GeoLink Cruises: A Non-Synthetic Benchmark for Co-Reference Resolution on Knowledge Graphs.">371. GeoLink Cruises: A Non-Synthetic Benchmark for Co-Reference Resolution on Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412770">Paper Link</a>    Pages:2959-2966</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/168/1797.html">Reihaneh Amini</a> ; <a href="https://dblp.uni-trier.de/pid/56/6786.html">Lu Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/h/PascalHitzler.html">Pascal Hitzler</a></p>
<p>Abstract:
Since over a decade coreference resolution systems have been developed in order to find simple 1-to-1 equivalent mapping (sameAs relations) between instances of different linked datasets and knowledge graphs. Comparative evaluations of instance matching systems can inform us about the performance of such systems regarding artificial benchmarks or real-world data challenges. However, the lack of real data for evaluating these systems is currently a bottleneck. In this paper, we propose the use of the Cruise entities in the GeoLink data repository as a real-world instance matching benchmark for linked data and knowledge graphs. The GeoLink project has brought together seven datasets related to geoscience research. Both the ontology (T-box) and the instance data (A-box) of GeoLink are significantly larger than current benchmarks, and they have particularly interesting challenges, such as geospatial and temporal data. The benchmark we propose here consists of two real-world datasets in GeoLink called R2R data and BCO-DMO which includes manual curated owl:sameAs links between more than 900 Cruise entities of these two datasets. The reference alignment was discussed and generated by domain experts from different institutions and is expressed in the Alignment API format.</p>
<p>Keywords:</p>
<h3 id="372. MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages and Modalities.">372. MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages and Modalities.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412783">Paper Link</a>    Pages:2967-2974</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/272/8721.html">Jason Armitage</a> ; <a href="https://dblp.uni-trier.de/pid/266/0421.html">Endri Kacupaj</a> ; <a href="https://dblp.uni-trier.de/pid/270/1710.html">Golsa Tahmasebzadeh</a> ; <a href="https://dblp.uni-trier.de/pid/87/10882.html">Swati</a> ; <a href="https://dblp.uni-trier.de/pid/56/7514.html">Maria Maleshkova</a> ; <a href="https://dblp.uni-trier.de/pid/45/52.html">Ralph Ewerth</a> ; <a href="https://dblp.uni-trier.de/pid/71/4882.html">Jens Lehmann</a></p>
<p>Abstract:
In this paper, we introduce the MLM (Multiple Languages and Modalities) dataset - a new resource to train and evaluate multitask systems on samples in multiple modalities and three languages. The generation process and inclusion of semantic data provide a resource that further tests the ability for multitask systems to learn relationships between entities. The dataset is designed for researchers and developers who build applications that perform multiple tasks on data encountered on the web and in digital archives. A second version of MLM provides a geo-representative subset of the data with weighted samples for countries of the European Union. We demonstrate the value of the resource in developing novel applications in the digital humanities with a motivating use case and specify a benchmark set of tasks to retrieve modalities and locate entities in the dataset. Evaluation of baseline multitask and single task systems on the full and geo-representative versions of MLM demonstrate the challenges of generalising on diverse data. In addition to the digital humanities, we expect the resource to contribute to research in multimodal representation learning, location estimation, and scene understanding.</p>
<p>Keywords:</p>
<h3 id="373. MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings.">373. MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412759">Paper Link</a>    Pages:2975-2982</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5032.html">Anders H. Brams</a> ; <a href="https://dblp.uni-trier.de/pid/276/4992.html">Anders L. Jakobsen</a> ; <a href="https://dblp.uni-trier.de/pid/276/5014.html">Theis E. Jendal</a> ; <a href="https://dblp.uni-trier.de/pid/139/1128.html">Matteo Lissandrini</a> ; <a href="https://dblp.uni-trier.de/pid/d/PeterDolog.html">Peter Dolog</a> ; <a href="https://dblp.uni-trier.de/pid/h/KatjaHose.html">Katja Hose</a></p>
<p>Abstract:
Knowledge Graphs (KGs) have been integrated in several models of recommendation to augment the informational value of an item by means of its related entities in the graph. Yet, existing datasets only provide explicit ratings on items and no information is provided about users' opinions of other (non-recommendable) entities. To overcome this limitation, we introduce a new dataset, called the MindReader dataset, providing explicit user ratings both for items and for KG entities. In this first version, the MindReader dataset provides more than 102 thousands explicit ratings collected from 1,174 real users on both items and entities from a KG in the movie domain. This dataset has been collected through an online interview application that we also release as open source. As a demonstration of the importance of this new dataset, we present a comparative study of the effect of the inclusion of ratings on non-item KG entities in a variety of state-of-the-art recommendation models. In particular, we show that most models, whether designed specifically for graph data or not, see improvements in recommendation quality when trained on explicit non-item ratings. Moreover, for some models, we show that non-item ratings can effectively replace item ratings without loss of recommendation quality. This finding, in addition to an observed greater familiarity from users towards certain descriptive entities than movies, motivates the use of KG entities for both warm and cold-start recommendations.</p>
<p>Keywords:</p>
<h3 id="374. ORCAS: 20 Million Clicked Query-Document Pairs for Analyzing Search.">374. ORCAS: 20 Million Clicked Query-Document Pairs for Analyzing Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412779">Paper Link</a>    Pages:2983-2989</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/c/NickCraswell.html">Nick Craswell</a> ; <a href="https://dblp.uni-trier.de/pid/64/1314.html">Daniel Campos</a> ; <a href="https://dblp.uni-trier.de/pid/147/9120.html">Bhaskar Mitra</a> ; <a href="https://dblp.uni-trier.de/pid/36/3270.html">Emine Yilmaz</a> ; <a href="https://dblp.uni-trier.de/pid/96/204.html">Bodo Billerbeck</a></p>
<p>Abstract:
Users of Web search engines reveal their information needs through queries and clicks, making click logs a useful asset for information retrieval. However, click logs have not been publicly released for academic use, because they can be too revealing of personally or commercially sensitive information. This paper describes a click data release related to the TREC Deep Learning Track document corpus. After aggregation and filtering, including a k -anonymity requirement, we find 1.4 million of the TREC DL URLs have 18 million connections to 10 million distinct queries. Our dataset of these queries and connections to TREC documents is of similar size to proprietary datasets used in previous papers on query mining and ranking. We perform some preliminary experiments using the click data to augment the TREC DL training data, offering by comparison: 28x more queries, with 49x more connections to 4.4x more URLs in the corpus. We present a description of the dataset's generation process, characteristics, use in ranking and other potential uses.</p>
<p>Keywords:</p>
<h3 id="375. TweetsCOV19 - A Knowledge Base of Semantically Annotated Tweets about the COVID-19 Pandemic.">375. TweetsCOV19 - A Knowledge Base of Semantically Annotated Tweets about the COVID-19 Pandemic.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412765">Paper Link</a>    Pages:2991-2998</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/25/10007.html">Dimitar Dimitrov</a> ; <a href="https://dblp.uni-trier.de/pid/135/3149.html">Erdal Baran</a> ; <a href="https://dblp.uni-trier.de/pid/02/10847.html">Pavlos Fafalios</a> ; <a href="https://dblp.uni-trier.de/pid/45/8919-1.html">Ran Yu</a> ; <a href="https://dblp.uni-trier.de/pid/23/8495.html">Xiaofei Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/133/9068.html">Matthus Zloch</a> ; <a href="https://dblp.uni-trier.de/pid/25/5167.html">Stefan Dietze</a></p>
<p>Abstract:
Publicly available social media archives facilitate research in the social sciences and provide corpora for training and testing a wide range of machine learning and natural language processing methods. With respect to the recent outbreak of the Coronavirus disease 2019 (COVID-19), online discourse on Twitter reflects public opinion and perception related to the pandemic itself as well as mitigating measures and their societal impact. Understanding such discourse, its evolution, and interdependencies with real-world events or (mis)information can foster valuable insights. On the other hand, such corpora are crucial facilitators for computational methods addressing tasks such as sentiment analysis, event detection, or entity recognition. However, obtaining, archiving, and semantically annotating large amounts of tweets is costly. In this paper, we describe TweetsCOV19, a publicly available knowledge base of currently more than 8 million tweets, spanning October 2019 - April 2020. Metadata about the tweets as well as extracted entities, hashtags, user mentions, sentiments, and URLs are exposed using established RDF/S vocabularies, providing an unprecedented knowledge base for a range of knowledge discovery tasks. Next to a description of the dataset and its extraction and annotation process, we present an initial analysis and use cases of the corpus.</p>
<p>Keywords:</p>
<h3 id="376. LensKit for Python: Next-Generation Software for Recommender Systems Experiments.">376. LensKit for Python: Next-Generation Software for Recommender Systems Experiments.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412778">Paper Link</a>    Pages:2999-3006</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/69/7949.html">Michael D. Ekstrand</a></p>
<p>Abstract:
LensKit is an open-source toolkit for building, researching, and learning about recommender systems. First released in 2010 as a Java framework, it has supported diverse published research, small-scale production deployments, and education in both MOOC and traditional classroom settings. In this paper, I present the next generation of the LensKit project, re-envisioning the original tool's objectives as flexible Python package for supporting recommender systems research and development. LensKit for Python (LKPY) enables researchers and students to build robust, flexible, and reproducible experiments that make use of the large and growing PyData and Scientific Python ecosystem, including scikit-learn, and TensorFlow. To that end, it provides classical collaborative filtering implementations, recommender system evaluation metrics, data preparation routines, and tools for efficiently batch running recommendation algorithms, all usable in any combination with each other or with other Python software.</p>
<p>Keywords:</p>
<h3 id="377. A Multidimensional Dataset Based on Crowdsourcing for Analyzing and Detecting News Bias.">377. A Multidimensional Dataset Based on Crowdsourcing for Analyzing and Detecting News Bias.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412876">Paper Link</a>    Pages:3007-3014</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/129/9499.html">Michael Frber</a> ; <a href="https://dblp.uni-trier.de/pid/276/5101.html">Victoria Burkard</a> ; <a href="https://dblp.uni-trier.de/pid/j/AdamJatowt.html">Adam Jatowt</a> ; <a href="https://dblp.uni-trier.de/pid/168/6216.html">Sora Lim</a></p>
<p>Abstract:
The automatic detection of bias in news articles can have a high impact on society because undiscovered news bias may influence the political opinions, social views, and emotional feelings of readers. While various analyses and approaches to news bias detection have been proposed, large data sets with rich bias annotations on a fine-grained level are still missing. In this paper, we firstly aggregate the aspects of news bias in related works by proposing a new annotation schema for labeling news bias. This schema covers the overall bias, as well as the bias dimensions (1) hidden assumptions, (2) subjectivity, and (3) representation tendencies. Secondly, we propose a methodology based on crowdsourcing for obtaining a large data set for news bias analysis and identification. We then use our methodology to create a dataset consisting of more than 2,000 sentences annotated with 43,000 bias and bias dimension labels. Thirdly, we perform an in-depth analysis of the collected data. We show that the annotation task is difficult with respect to bias and specific bias dimensions. While crowdworkers' labels of representation tendencies correlate with experts' bias labels for articles, subjectivity and hidden assumptions do not correlate with experts' bias labels and, thus, seem to be less relevant when creating data sets with crowdworkers. The experts' article labels better match the inferred crowdworkers' article labels than the crowdworkers' sentence labels. The crowdworkers' countries of origin seem to affect their judgements. In our study, non-Western crowdworkers tend to annotate more bias either directly or in the form of bias dimensions (e.g., subjectivity) than Western crowdworkers do.</p>
<p>Keywords:</p>
<h3 id="378. Feature Extraction for Large-Scale Text Collections.">378. Feature Extraction for Large-Scale Text Collections.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412773">Paper Link</a>    Pages:3015-3022</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/204/0135.html">Luke Gallagher</a> ; <a href="https://dblp.uni-trier.de/pid/204/0179.html">Antonio Mallia</a> ; <a href="https://dblp.uni-trier.de/pid/03/489.html">J. Shane Culpepper</a> ; <a href="https://dblp.uni-trier.de/pid/s/TorstenSuel.html">Torsten Suel</a> ; <a href="https://dblp.uni-trier.de/pid/57/2006.html">Berkant Barla Cambazoglu</a></p>
<p>Abstract:
Feature engineering is a fundamental but poorly documented component in Learning-to-Rank (LTR) search engines. Such features are commonly used to construct learning models for web and product search engines, recommender systems, and question-answering tasks. In each of these domains, there is a growing interest in the creation of open-access test collections that promote reproducible research. However, there are still few open-source software packages capable of extracting high-quality machine learning features from large text collections. Instead, most feature-based LTR research relies on "canned" test collections, which often do not expose critical details about the underlying collection or implementation details of the extracted features. Both of these are crucial to collection creation and deployment of a search engine into production. So in this regard, the experiments are rarely reproducible with new features or collections, or helpful for companies wishing to deploy LTR systems.</p>
<p>Keywords:</p>
<h3 id="379. CauseNet: Towards a Causality Graph Extracted from the Web.">379. CauseNet: Towards a Causality Graph Extracted from the Web.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412763">Paper Link</a>    Pages:3023-3030</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/128/4978.html">Stefan Heindorf</a> ; <a href="https://dblp.uni-trier.de/pid/240/9194.html">Yan Scholten</a> ; <a href="https://dblp.uni-trier.de/pid/73/9281.html">Henning Wachsmuth</a> ; <a href="https://dblp.uni-trier.de/pid/65/4336.html">Axel-Cyrille Ngonga Ngomo</a> ; <a href="https://dblp.uni-trier.de/pid/87/6573.html">Martin Potthast</a></p>
<p>Abstract:
Causal knowledge is seen as one of the key ingredients to advance artificial intelligence. Yet, few knowledge bases comprise causal knowledge to date, possibly due to significant efforts required for validation. Notwithstanding this challenge, we compile CauseNet, a large-scale knowledge base of claimed causal relations between causal concepts. By extraction from different semi- and unstructured web sources, we collect more than 11 million causal relations with an estimated extraction precision of 83% and construct the first large-scale and open-domain causality graph. We analyze the graph to gain insights about causal beliefs expressed on the web and we demonstrate its benefits in basic causal question answering. Future work may use the graph for causal reasoning, computational argumentation, multi-hop question answering, and more.</p>
<p>Keywords:</p>
<h3 id="380. Fine-Grained Relevance Annotations for Multi-Task Document Ranking and Question Answering.">380. Fine-Grained Relevance Annotations for Multi-Task Document Ranking and Question Answering.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412878">Paper Link</a>    Pages:3031-3038</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/238/6322.html">Sebastian Hofsttter</a> ; <a href="https://dblp.uni-trier.de/pid/200/5842.html">Markus Zlabinger</a> ; <a href="https://dblp.uni-trier.de/pid/235/2301.html">Mete Sertkan</a> ; <a href="https://dblp.uni-trier.de/pid/33/1272.html">Michael Schrder</a> ; <a href="https://dblp.uni-trier.de/pid/55/6683.html">Allan Hanbury</a></p>
<p>Abstract:
There are many existing retrieval and question answering datasets. However, most of them either focus on ranked list evaluation or single-candidate question answering. This divide makes it challenging to properly evaluate approaches concerned with ranking documents and providing snippets or answers for a given query. In this work, we present FiRA: a novel dataset of Fine-Grained Relevance Annotations. We extend the ranked retrieval annotations of the Deep Learning track of TREC 2019 with passage and word level graded relevance annotations for all relevant documents. We use our newly created data to study the distribution of relevance in long documents, as well as the attention of annotators to specific positions of the text. As an example, we evaluate the recently introduced TKL document ranking model. We find that although TKL exhibits state-of-the-art retrieval results for long documents, it misses many relevant passages.</p>
<p>Keywords:</p>
<h3 id="381. SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs.">381. SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412881">Paper Link</a>    Pages:3039-3046</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/250/9029.html">Enrique Iglesias</a> ; <a href="https://dblp.uni-trier.de/pid/230/3464.html">Samaneh Jozashoori</a> ; <a href="https://dblp.uni-trier.de/pid/43/7049.html">David Chaves-Fraga</a> ; <a href="https://dblp.uni-trier.de/pid/144/0506.html">Diego Collarana</a> ; <a href="https://dblp.uni-trier.de/pid/92/654.html">Maria-Esther Vidal</a></p>
<p>Abstract:
In recent years, the amount of data has increased exponentially, and knowledge graphs have gained attention as data structures to integrate data and knowledge harvested from myriad data sources. However, data complexity issues like large volume, high-duplicate rate, and heterogeneity usually characterize these data sources, being required data management tools able to address the negative impact of these issues on the knowledge graph creation process. In this paper, we propose the SDM-RDFizer, an interpreter of the RDF Mapping Language (RML), to transform raw data in various formats into an RDF knowledge graph. SDM-RDFizer implements novel algorithms to execute the logical operators between mappings in RML, allowing thus to scale up to complex scenarios where data is not only broad but has a high-duplication rate. We empirically evaluate the SDM-RDFizer performance against diverse testbeds with diverse configurations of data volume, duplicates, and heterogeneity. The observed results indicate that SDM-RDFizer is two orders of magnitude faster than state of the art, thus, meaning that SDM-RDFizer an interoperable and scalable solution for knowledge graph creation. SDM-RDFizer is publicly available as a resource through a Github repository and a DOI.</p>
<p>Keywords:</p>
<h3 id="382. Web Page Segmentation Revisited: Evaluation Framework and Dataset.">382. Web Page Segmentation Revisited: Evaluation Framework and Dataset.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412782">Paper Link</a>    Pages:3047-3054</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/118/3606.html">Johannes Kiesel</a> ; <a href="https://dblp.uni-trier.de/pid/160/7629.html">Florian Kneist</a> ; <a href="https://dblp.uni-trier.de/pid/29/9168.html">Lars Meyer</a> ; <a href="https://dblp.uni-trier.de/pid/177/2029.html">Kristof Komlossy</a> ; <a href="https://dblp.uni-trier.de/pid/69/4806-1.html">Benno Stein</a> ; <a href="https://dblp.uni-trier.de/pid/87/6573.html">Martin Potthast</a></p>
<p>Abstract:
Each web page can be segmented into semantically coherent units that fulfill specific purposes. Though the task of automatic web page segmentation was introduced two decades ago, along with several applications in web content analysis, its foundations are still lacking. Specifically, the developed evaluation methods and datasets presume a certain downstream task, which led to a variety of incompatible datasets and evaluation methods. To address this shortcoming, we contribute two resources: (1) An evaluation framework which can be adjusted to downstream tasks by measuring the segmentation similarity regarding visual, structural, and textual elements, and which includes measures for annotator agreement, segmentation quality, and an algorithm for segmentation fusion. (2) The Webis-WebSeg-20 dataset, comprising 42,450~crowdsourced segmentations for 8,490~web pages, outranging existing sources by an order of magnitude. Our results help to better understand the "mental segmentation model'' of human annotators: Among other things we find that annotators mostly agree on segmentations for all kinds of web page elements (visual, structural, and textual). Disagreement exists mostly regarding the right level of granularity, indicating a general agreement on the visual structure of web pages.</p>
<p>Keywords:</p>
<h3 id="383. The Newspaper Navigator Dataset: Extracting Headlines and Visual Content from 16 Million Historic Newspaper Pages in Chronicling America.">383. The Newspaper Navigator Dataset: Extracting Headlines and Visual Content from 16 Million Historic Newspaper Pages in Chronicling America.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412767">Paper Link</a>    Pages:3055-3062</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/213/1288.html">Benjamin Charles Germain Lee</a> ; <a href="https://dblp.uni-trier.de/pid/247/2919.html">Jaime Mears</a> ; <a href="https://dblp.uni-trier.de/pid/264/4943.html">Eileen Jakeway</a> ; <a href="https://dblp.uni-trier.de/pid/264/4769.html">Meghan Ferriter</a> ; <a href="https://dblp.uni-trier.de/pid/43/55.html">Chris Adams</a> ; <a href="https://dblp.uni-trier.de/pid/18/11514.html">Nathan Yarasavage</a> ; <a href="https://dblp.uni-trier.de/pid/74/382.html">Deborah Thomas</a> ; <a href="https://dblp.uni-trier.de/pid/206/4705.html">Kate Zwaard</a> ; <a href="https://dblp.uni-trier.de/pid/w/DanielSWeld.html">Daniel S. Weld</a></p>
<p>Abstract:
Chronicling America is a product of the National Digital Newspaper Program, a partnership between the Library of Congress and the National Endowment for the Humanities to digitize historic American newspapers. Over 16 million pages have been digitized to date, complete with high-resolution images and machine-readable METS/ALTO OCR. Of considerable interest to Chronicling America users is a semantified corpus, complete with extracted visual content and headlines. To accomplish this, we introduce a visual content recognition model trained on bounding box annotations collected as part of the Library of Congress's Beyond Words crowdsourcing initiative and augmented with additional annotations including those of headlines and advertisements. We describe our pipeline that utilizes this deep learning model to extract 7 classes of visual content: headlines, photographs, illustrations, maps, comics, editorial cartoons, and advertisements, complete with textual content such as captions derived from the METS/ALTO OCR, as well as image embeddings. We report the results of running the pipeline on 16.3 million pages from the Chronicling America corpus and describe the resulting Newspaper Navigator dataset, the largest dataset of extracted visual content from historic newspapers ever produced. The Newspaper Navigator dataset, finetuned visual content recognition model, and all source code are placed in the public domain for unrestricted re-use.</p>
<p>Keywords:</p>
<h3 id="384. MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction.">384. MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412879">Paper Link</a>    Pages:3063-3070</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/155/6074.html">Jiazheng Li</a> ; <a href="https://dblp.uni-trier.de/pid/218/8007.html">Linyi Yang</a> ; <a href="https://dblp.uni-trier.de/pid/s/BarrySmyth.html">Barry Smyth</a> ; <a href="https://dblp.uni-trier.de/pid/94/11082.html">Ruihai Dong</a></p>
<p>Abstract:
In the area of natural language processing, various financial datasets have informed recent research and analysis including financial news, financial reports, social media, and audio data from earnings calls. We introduce a new, large-scale multi-modal, text-audio paired, earnings-call dataset named MAEC, based on S&amp;P 1500 companies. We describe the main features of MAEC, how it was collected and assembled, paying particular attention to the text-audio alignment process used. We present the approach used in this work as providing a suitable framework for processing similar forms of data in the future. The resulting dataset is more than six times larger than those currently available to the research community and we discuss its potential in terms of current and future research challenges and opportunities. All resources of this work are available at <a href="https://github.com/Earnings-Call-Dataset/">https://github.com/Earnings-Call-Dataset/</a></p>
<p>Keywords:</p>
<h3 id="385. Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers.">385. Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412877">Paper Link</a>    Pages:3071-3076</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/43/299.html">Siwei Li</a> ; <a href="https://dblp.uni-trier.de/pid/54/8548.html">Zhiyan Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/274/0705.html">Anish Upadhayay</a> ; <a href="https://dblp.uni-trier.de/pid/191/9147.html">Omar Shaikh</a> ; <a href="https://dblp.uni-trier.de/pid/207/9936.html">Scott Freitas</a> ; <a href="https://dblp.uni-trier.de/pid/205/2860.html">Haekyu Park</a> ; <a href="https://dblp.uni-trier.de/pid/256/1610.html">Zijie J. Wang</a> ; <a href="https://dblp.uni-trier.de/pid/274/0685.html">Susanta Routray</a> ; <a href="https://dblp.uni-trier.de/pid/244/3974.html">Matthew Hull</a> ; <a href="https://dblp.uni-trier.de/pid/10/2670.html">Duen Horng Chau</a></p>
<p>Abstract:
Graph data have become increasingly common. Visualizing them helps people better understand relations among entities. Unfortunately, existing graph visualization tools are primarily designed for single-person desktop use, offering limited support for interactive web-based exploration and online collaborative analysis. To address these issues, we have developed Argo Lite, a new in-browser interactive graph exploration and visualization tool. Argo Lite enables users to publish and share interactive graph visualizations as URLs and embedded web widgets. Users can explore graphs incrementally by adding more related nodes, such as highly cited papers cited by or citing a paper of interest in a citation network. Argo Lite works across devices and platforms, leveraging WebGL for high-performance rendering. Argo Lite has been used by over 1,000 students at Georgia Tech's Data and Visual Analytics class. Argo Lite may serve as a valuable open-source tool for advancing multiple CIKM research areas, from data presentation, to interfaces for information systems and more.</p>
<p>Keywords:</p>
<h3 id="386. CC-News-En: A Large English News Corpus.">386. CC-News-En: A Large English News Corpus.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412762">Paper Link</a>    Pages:3077-3084</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/174/0021.html">Joel Mackenzie</a> ; <a href="https://dblp.uni-trier.de/pid/210/8217.html">Rodger Benham</a> ; <a href="https://dblp.uni-trier.de/pid/61/10435.html">Matthias Petri</a> ; <a href="https://dblp.uni-trier.de/pid/166/2953.html">Johanne R. Trippas</a> ; <a href="https://dblp.uni-trier.de/pid/03/489.html">J. Shane Culpepper</a> ; <a href="https://dblp.uni-trier.de/pid/m/AlistairMoffat.html">Alistair Moffat</a></p>
<p>Abstract:
We describe a static, open-access news corpus using data from the Common Crawl Foundation, who provide free, publicly available web archives, including a continuous crawl of international news articles published in multiple languages. Our derived corpus, CC-News-En, contains 44 million English documents collected between September 2016 and March 2018. The collection is comparable in size with the number of documents typically found in a single shard of a large-scale, distributed search engine, and is four times larger than the news collections previously used in offline information retrieval experiments. To complement the corpus, 173 topics were curated using titles from Reddit threads, forming a temporally representative sampling of relevant news topics over the 583 day collection window. Information needs were then generated using automatic summarization tools to produce textual and audio representations, and used to elicit query variations from crowdworkers, with a total of 10,437 queries collected against the 173 topics. Of these, 10,089 include key-stroke level instrumentation that captures the timings of character insertions and deletions made by the workers while typing their queries. These new resources support a wide variety of experiments, including large-scale efficiency exercises and query auto-completion synthesis, with scope for future addition of relevance judgments to support offline effectiveness experiments and hence batch evaluation campaigns.</p>
<p>Keywords:</p>
<h3 id="387. PrivacyFL: A Simulator for Privacy-Preserving and Secure Federated Learning.">387. PrivacyFL: A Simulator for Privacy-Preserving and Secure Federated Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412771">Paper Link</a>    Pages:3085-3092</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/213/1401.html">Vaikkunth Mugunthan</a> ; <a href="https://dblp.uni-trier.de/pid/259/1540.html">Anton Peraire-Bueno</a> ; <a href="https://dblp.uni-trier.de/pid/75/6949.html">Lalana Kagal</a></p>
<p>Abstract:
Federated learning is a technique that enables distributed clients to collaboratively learn a shared machine learning model without sharing their training data. This reduces data privacy risks, however, privacy concerns still exist since it is possible to leak information about the training dataset from the trained model's weights or parameters. Therefore, it is important to develop federated learning algorithms that train highly accurate models in a privacy-preserving manner. Setting up a federated learning environment, especially with security and privacy guarantees, is a time-consuming process with numerous configurations and parameters that can be manipulated. In order to help clients ensure that collaboration is feasible and to check that it improves their model accuracy, a real-world simulator for privacy-preserving and secure federated learning is required.</p>
<p>Keywords:</p>
<h3 id="388. ContentWise Impressions: An Industrial Dataset with Impressions Included.">388. ContentWise Impressions: An Industrial Dataset with Impressions Included.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412774">Paper Link</a>    Pages:3093-3100</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/271/8369.html">Fernando Benjamn Prez Maurera</a> ; <a href="https://dblp.uni-trier.de/pid/225/7792.html">Maurizio Ferrari Dacrema</a> ; <a href="https://dblp.uni-trier.de/pid/271/8170.html">Lorenzo Saule</a> ; <a href="https://dblp.uni-trier.de/pid/81/701.html">Mario Scriminaci</a> ; <a href="https://dblp.uni-trier.de/pid/03/3233.html">Paolo Cremonesi</a></p>
<p>Abstract:
In this article, we introduce the \dataset dataset, a collection of implicit interactions and impressions of movies and TV series from an Over-The-Top media service, which delivers its media contents over the Internet. The dataset is distinguished from other already available multimedia recommendation datasets by the availability of impressions, \idest the recommendations shown to the user, its size, and by being open-source. We describe the data collection process, the preprocessing applied, its characteristics, and statistics when compared to other commonly used datasets. We also highlight several possible use cases and research questions that can benefit from the availability of user impressions in an open-source dataset. Furthermore, we release software tools to load and split the data, as well as examples of how to use both user interactions and impressions in several common recommendation algorithms.</p>
<p>Keywords:</p>
<h3 id="389. Profiling Entity Matching Benchmark Tasks.">389. Profiling Entity Matching Benchmark Tasks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412781">Paper Link</a>    Pages:3101-3108</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/173/6729.html">Anna Primpeli</a> ; <a href="https://dblp.uni-trier.de/pid/b/ChristianBizer.html">Christian Bizer</a></p>
<p>Abstract:
Entity matching is a central task in data integration which has been researched for decades. Over this time, a wide range of benchmark tasks for evaluating entity matching methods has been developed. This resource paper systematically complements, profiles, and compares 21 entity matching benchmark tasks. In order to better understand the specific challenges associated with different tasks, we define a set of profiling dimensions which capture central aspects of the matching tasks. Using these dimensions, we create groups of benchmark tasks having similar characteristics. Afterwards, we assess the difficulty of the tasks in each group by computing baseline evaluation results using standard feature engineering together with two common classification methods. In order to enable the exact reproducibility of evaluation results, matching tasks need to contain exactly defined sets of matching and non-matching record pairs, as well as a fixed development and test split. As this is not the case for some widely-used benchmark tasks, we complement these tasks with fixed sets of non-matching pairs, as well as fixed splits, and provide the resulting development and test sets for public download. By profiling and complementing the benchmark tasks, we support researchers to select challenging as well as diverse tasks and to compare matching systems on clearly defined grounds.</p>
<p>Keywords:</p>
<h3 id="390. A Large Test Collection for Entity Aspect Linking.">390. A Large Test Collection for Entity Aspect Linking.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412875">Paper Link</a>    Pages:3109-3116</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/209/8112.html">Jordan Ramsdell</a> ; <a href="https://dblp.uni-trier.de/pid/85/5754.html">Laura Dietz</a></p>
<p>Abstract:
Given a text with entity links, the task of entity aspect linking is to identify which aspect of an entity is referred to in the context. For example, if a text passage mentions the entity "USA'', is USA mentioned in the context of the 2008 financial crisis, American cuisine, or else? Complementing efforts of Nanni et al (2018), we provide a large-scale test collection which is derived from Wikipedia hyperlinks in a dump from 01/01/2020. Furthermore, we offer strong baselines with results and broken-out feature sets to stimulate more research in this area.</p>
<p>Keywords:</p>
<h3 id="391. A Dataset of Journalists' Interactions with Their Readership: When Should Article Authors Reply to Reader Comments?">391. A Dataset of Journalists' Interactions with Their Readership: When Should Article Authors Reply to Reader Comments?</h3>
<p><a href="https://doi.org/10.1145/3340531.3412764">Paper Link</a>    Pages:3117-3124</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/161/3383.html">Julian Risch</a> ; <a href="https://dblp.uni-trier.de/pid/60/3309.html">Ralf Krestel</a></p>
<p>Abstract:
The comment sections of online news platforms are an important space to indulge in political conversations and to discuss opinions. Although primarily meant as forums where readers discuss amongst each other, they can also spark a dialog with the journalists who authored the article. A small but important fraction of comments address the journalists directly, e.g., with questions, recommendations for future topics, thanks and appreciation, or article corrections. However, the sheer number of comments makes it infeasible for journalists to follow discussions around their articles in extenso. A better understanding of this data could support journalists in gaining insights into their audience and fostering engaging and respectful discussions. To this end, we present a dataset of dialogs in which journalists of The Guardian replied to reader comments and identify the reasons why. Based on this data, we formulate the novel task of recommending reader comments to journalists that are worth reading or replying to, i.e., ranking comments in such a way that the top comments are most likely to require the journalists' reaction. As a baseline, we trained a neural network model with the help of a pair-wise comment ranking task. Our experiment reveals the challenges of this task and we outline promising paths for future work. The data and our code are available for research purposes from: <a href="https://hpi.de/naumann/projects/repeatability/text-mining.html">https://hpi.de/naumann/projects/repeatability/text-mining.html</a></p>
<p>Keywords:</p>
<h3 id="392. Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on Graphs.">392. Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412757">Paper Link</a>    Pages:3125-3132</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/215/3742.html">Benedek Rozemberczki</a> ; <a href="https://dblp.uni-trier.de/pid/260/6990.html">Oliver Kiss</a> ; <a href="https://dblp.uni-trier.de/pid/82/4961.html">Rik Sarkar</a></p>
<p>Abstract:
Graphs encode important structural properties of complex systems. Machine learning on graphs has therefore emerged as an important technique in research and applications. We present Karate Club - a Python framework combining more than 30 state-of-the-art graph mining algorithms. These unsupervised techniques make it easy to identify and represent common graph features. The primary goal of the package is to make community detection, node and whole graph embedding available to a wide audience of machine learning researchers and practitioners. Karate Club is designed with an emphasis on a consistent application interface, scalability, ease of use, sensible out of the box model behaviour, standardized dataset ingestion, and output generation. This paper discusses the design principles behind the framework with practical examples. We show Karate Club's efficiency in learning performance on a wide range of real world clustering problems and classification tasks along with supporting evidence of its competitive speed.</p>
<p>Keywords:</p>
<h3 id="393. Little Ball of Fur: A Python Library for Graph Sampling.">393. Little Ball of Fur: A Python Library for Graph Sampling.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412758">Paper Link</a>    Pages:3133-3140</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/215/3742.html">Benedek Rozemberczki</a> ; <a href="https://dblp.uni-trier.de/pid/260/6990.html">Oliver Kiss</a> ; <a href="https://dblp.uni-trier.de/pid/82/4961.html">Rik Sarkar</a></p>
<p>Abstract:
Sampling graphs is an important task in data mining. In this paper, we describe Little Ball of Fur a Python library that includes more than twenty graph sampling algorithms. Our goal is to make node, edge, and exploration-based network sampling techniques accessible to a large number of professionals, researchers, and students in a single streamlined framework. We created this framework with a focus on a coherent application public interface which has a convenient design, generic input data requirements, and reasonable baseline settings of algorithms. Here we overview these design foundations of the framework in detail with illustrative code snippets. We show the practical usability of the library by estimating various global statistics of social networks and web graphs. Experiments demonstrate that Little Ball of Fur can speed up node and whole graph embedding techniques considerably with mildly deteriorating the predictive value of distilled features.</p>
<p>Keywords:</p>
<h3 id="394. Falcon 2.0: An Entity and Relation Linking Tool over Wikidata.">394. Falcon 2.0: An Entity and Relation Linking Tool over Wikidata.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412777">Paper Link</a>    Pages:3141-3148</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/210/9084.html">Ahmad Sakor</a> ; <a href="https://dblp.uni-trier.de/pid/81/4530.html">Kuldeep Singh</a> ; <a href="https://dblp.uni-trier.de/pid/228/8411.html">Anery Patel</a> ; <a href="https://dblp.uni-trier.de/pid/92/654.html">Maria-Esther Vidal</a></p>
<p>Abstract:
The Natural Language Processing (NLP) community has significantly contributed to the solutions for entity and relation recognition from a natural language text, and possibly linking them to proper matches in Knowledge Graphs (KGs). Considering Wikidata as the background KG, there are still limited tools to link knowledge within the text to Wikidata. In this paper, we present Falcon 2.0, the first joint entity and relation linking tool over Wikidata. It receives a short natural language text in the English language and outputs a ranked list of entities and relations annotated with the proper candidates in Wikidata. The candidates are represented by their Internationalized Resource Identifier (IRI) in Wikidata. Falcon 2.0 resorts to the English language model for the recognition task (e.g., N-Gram tiling and N-Gram splitting), and then an optimization approach for the linking task. We have empirically studied the performance of Falcon 2.0 on Wikidata and concluded that it outperforms all the existing baselines. Falcon 2.0 is open source and can be reused by the community; all the required instructions of Falcon 2.0 are well-documented at our GitHub repository (<a href="https://github.com/SDM-TIB/falcon2.0">https://github.com/SDM-TIB/falcon2.0</a>). We also demonstrate an online API, which can be run without any technical expertise. Falcon 2.0 and its background knowledge bases are available as resources at <a href="https://labs.tib.eu/falcon/falcon2/">https://labs.tib.eu/falcon/falcon2/</a>.</p>
<p>Keywords:</p>
<h3 id="395. GeoFlink: A Distributed and Scalable Framework for the Real-time Processing of Spatial Streams.">395. GeoFlink: A Distributed and Scalable Framework for the Real-time Processing of Spatial Streams.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412761">Paper Link</a>    Pages:3149-3156</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/50/11145.html">Salman Ahmed Shaikh</a> ; <a href="https://dblp.uni-trier.de/pid/262/3627.html">Komal Mariam</a> ; <a href="https://dblp.uni-trier.de/pid/k/HiroyukiKitagawa.html">Hiroyuki Kitagawa</a> ; <a href="https://dblp.uni-trier.de/pid/35/1144.html">Kyoung-Sook Kim</a></p>
<p>Abstract:
Apache Flink is an open-source system for scalable processing of batch and streaming data. Flink does not natively support efficient processing of spatial data streams, which is a requirement of many applications dealing with spatial data. Besides Flink, other scalable spatial data processing platforms including GeoSpark, Spatial Hadoop, etc. do not support streaming workloads and can only handle static/batch workloads. To fill this gap, we present GeoFlink, which extends Apache Flink to support spatial data types, indexes and continuous queries over spatial data streams. To enable efficient processing of spatial continuous queries and for the effective data distribution across Flink cluster nodes, a gird-based index is introduced. GeoFlink currently supports spatial range, spatial kNN and spatial join queries on point data type. An experimental study on real spatial data streams shows that GeoFlink achieves significantly higher query throughput than ordinary Flink processing.</p>
<p>Keywords:</p>
<h3 id="396. Event-QA: A Dataset for Event-Centric Question Answering over Knowledge Graphs.">396. Event-QA: A Dataset for Event-Centric Question Answering over Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412760">Paper Link</a>    Pages:3157-3164</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/50/9732.html">Tarcsio Souza Costa</a> ; <a href="https://dblp.uni-trier.de/pid/183/0640.html">Simon Gottschalk</a> ; <a href="https://dblp.uni-trier.de/pid/84/2154.html">Elena Demidova</a></p>
<p>Abstract:
Semantic Question Answering (QA) is a crucial technology to facilitate intuitive user access to semantic information stored in knowledge graphs. Whereas most of the existing QA systems and datasets focus on entity-centric questions, very little is known about these systems' performance in the context of events. As new event-centric knowledge graphs emerge, datasets for such questions gain importance. In this paper, we present the Event-QA dataset for answering event-centric questions over knowledge graphs. Event-QA contains 1000 semantic queries and the corresponding English, German and Portuguese verbalizations for EventKG - an event-centric knowledge graph with more than 970 thousand events.</p>
<p>Keywords:</p>
<h3 id="397. ReQue: A Configurable Workflow and Dataset Collection for Query Refinement.">397. ReQue: A Configurable Workflow and Dataset Collection for Query Refinement.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412775">Paper Link</a>    Pages:3165-3172</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/270/6598.html">Mahtab Tamannaee</a> ; <a href="https://dblp.uni-trier.de/pid/166/4506.html">Hossein Fani</a> ; <a href="https://dblp.uni-trier.de/pid/152/9311.html">Fattane Zarrinkalam</a> ; <a href="https://dblp.uni-trier.de/pid/276/5013.html">Jamil Samouh</a> ; <a href="https://dblp.uni-trier.de/pid/74/8183.html">Samad Paydar</a> ; <a href="https://dblp.uni-trier.de/pid/25/806.html">Ebrahim Bagheri</a></p>
<p>Abstract:
In this paper, we implement and publicly share a configurable software workflow and a collection of gold standard datasets for training and evaluating supervised query refinement methods. Existing datasets such as AOL and MS MARCO, which have been extensively used in the literature for this purpose, are based on the weak assumption that users' input queries improve gradually within a search session, i.e., the last query where the user ends her information seeking session is the best reconstructed version of her initial query. In practice, such an assumption is not necessarily accurate for a variety of reasons, e.g., topic drift. The objective of our work is to enable researchers to build gold standard query refinement datasets without having to rely on such weak assumptions. Our software workflow, which generates such gold standard query datasets, takes three inputs: (1) a dataset of queries along with their associated relevance judgements (e.g. TREC topics), (2) an information retrieval method (e.g., BM25), and (3) an evaluation metric (e.g., MAP), and outputs a gold standard dataset. The produced gold standard dataset includes a list of revised queries for each query in the input dataset, each of which effectively improves the performance of the specified retrieval method in terms of the desirable evaluation metric. Since our workflow can be used to generate gold standard datasets for any input query set, in this paper, we have generated and publicly shared gold standard datasets for TREC queries associated with Robust04, Gov2, ClueWeb09, and ClueWeb12. The source code of our software workflow, the generated gold datasets, and benchmark results for three state-of-the-art supervised query refinement methods over these datasets are made publicly available for reproducibility purposes.</p>
<p>Keywords:</p>
<h3 id="398. BioKG: A Knowledge Graph for Relational Learning On Biological Data.">398. BioKG: A Knowledge Graph for Relational Learning On Biological Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412776">Paper Link</a>    Pages:3173-3180</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/13/9980.html">Brian Walsh</a> ; <a href="https://dblp.uni-trier.de/pid/201/0364.html">Sameh K. Mohamed</a> ; <a href="https://dblp.uni-trier.de/pid/79/1204.html">Vt Novcek</a></p>
<p>Abstract:
Knowledge graphs became a popular means for modeling complex biological systems where they model the interactions between biological entities and their effects on the biological system. They also provide support for relational learning models which are known to provide highly scalable and accurate predictions of associations between biological entities. Despite the success of the combination of biological knowledge graph and relation learning models in biological predictive tasks, there is a lack of unified biological knowledge graph resources. This forced all current efforts and studies for applying a relational learning model on biological data to compile and build biological knowledge graphs from open biological databases. This process is often performed inconsistently across such efforts, especially in terms of choosing the original resources, aligning identifiers of the different databases, and assessing the quality of included data. To make relational learning on biomedical data more standardised and reproducible, we propose a new biological knowledge graph which provides a compilation of curated relational data from open biological databases in a unified format with common, interlinked identifiers. We also provide a new module for mapping identifiers and labels from different databases which can be used to align our knowledge graph with biological data from other heterogeneous sources. Finally, to illustrate the practical relevance of our work, we provide a set of benchmarks based on the presented data that can be used to train and assess the relational learning models in various tasks related to pathway and drug discovery.</p>
<p>Keywords:</p>
<h3 id="399. Flexible IR Pipelines with Capreolus.">399. Flexible IR Pipelines with Capreolus.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412780">Paper Link</a>    Pages:3181-3188</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/49/7109.html">Andrew Yates</a> ; <a href="https://dblp.uni-trier.de/pid/139/9683.html">Kevin Martin Jose</a> ; <a href="https://dblp.uni-trier.de/pid/58/4582.html">Xinyu Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/00/7739.html">Jimmy Lin</a></p>
<p>Abstract:
While a number of recent open-source toolkits for training and using neural information retrieval models have greatly simplified experiments with neural reranking methods, they essentially hard code a "search-then-rerank'' experimental pipeline. These pipelines consist of an efficient first-stage ranking method, like BM25, followed by a neural reranking method. Deviations from this setup often require hacks; some improvements, like adding a second reranking step that uses a more expensive neural method, are infeasible without major code changes. In order to improve the flexibility of such toolkits, we propose implementing experimental pipelines as dependency graphs of functional "IR primitives,'' which we call modules, that can be used and combined as needed.</p>
<p>Keywords:</p>
<h3 id="400. MIMICS: A Large-Scale Data Collection for Search Clarification.">400. MIMICS: A Large-Scale Data Collection for Search Clarification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412772">Paper Link</a>    Pages:3189-3196</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/150/5324.html">Hamed Zamani</a> ; <a href="https://dblp.uni-trier.de/pid/80/2310.html">Gord Lueck</a> ; <a href="https://dblp.uni-trier.de/pid/266/7644.html">Everest Chen</a> ; <a href="https://dblp.uni-trier.de/pid/223/4620.html">Rodolfo Quispe</a> ; <a href="https://dblp.uni-trier.de/pid/267/9333.html">Flint Luu</a> ; <a href="https://dblp.uni-trier.de/pid/c/NickCraswell.html">Nick Craswell</a></p>
<p>Abstract:
Search clarification has recently attracted much attention due to its applications in search engines. It has also been recognized as a major component in conversational information seeking systems. Despite its importance, the research community still feels the lack of a large-scale dataset for studying different aspects of search clarification. In this paper, we introduce MIMICS, a collection of search clarification datasets for real web search queries sampled from the Bing query logs. Each clarification in MIMICS is generated by a Bing production algorithm and consists of a clarifying question and up to five candidate answers. MIMICS contains three datasets: (1) MIMICS-Click includes over 400k unique queries, their associated clarification panes, and the corresponding aggregated user interaction signals (i.e., clicks). (2) MIMICS-ClickExplore is an exploration data that includes aggregated user interaction signals for over 60k unique queries, each with multiple clarification panes. (3) MIMICS-Manual includes over 2k unique real search queries. Each query-clarification pair in this dataset has been manually labeled by at least three trained annotators. It contains graded quality labels for the clarifying question, the candidate answer set, and the landing result page for each candidate answer.</p>
<p>Keywords:</p>
<h3 id="401. The Enslaved Dataset: A Real-world Complex Ontology Alignment Benchmark using Wikibase.">401. The Enslaved Dataset: A Real-world Complex Ontology Alignment Benchmark using Wikibase.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412768">Paper Link</a>    Pages:3197-3204</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/56/6786.html">Lu Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/208/4077.html">Cogan Shimizu</a> ; <a href="https://dblp.uni-trier.de/pid/h/PascalHitzler.html">Pascal Hitzler</a> ; <a href="https://dblp.uni-trier.de/pid/268/4601.html">Alicia M. Sheill</a> ; <a href="https://dblp.uni-trier.de/pid/268/4831.html">Seila Gonzalez Estrecha</a> ; <a href="https://dblp.uni-trier.de/pid/222/8662.html">Catherine Foley</a> ; <a href="https://dblp.uni-trier.de/pid/268/4951.html">Duncan Tarr</a> ; <a href="https://dblp.uni-trier.de/pid/68/3151.html">Dean Rehberger</a></p>
<p>Abstract:
Ontology alignment has taken a critical place for helping heterogeneous resources to interoperate. It has been studied for over a decade, and over that time many alignment systems and methods have been developed by researchers to find simple 1:1 equivalence matches between two ontologies. However, very few alignment systems focus on finding complex correspondences. Even if the complex alignment systems are developed, the performance of finding complex relations still has a lot of room for improvement. One reason for this limitation may be that there are still few applicable alignment benchmarks that contain such complex relationships that can raise researchers' interests. In this paper, we propose a real-world dataset from the Enslaved project as a potential complex alignment benchmark. The benchmark consists of two resources, the Enslaved Ontology along with a Wikibase repository holding a large number of instance data from the Enslaved project, as well as a manually created reference alignment between them. The alignment was developed in consultation with domain experts in the digital humanities. The alignment not only includes simple 1:1 equivalence correspondences, but also more complex m:n equivalence and subsumption correspondences and are provided in both Expressive and Declarative Ontology Alignment Language (EDOAL) format and rule syntax. The Enslaved benchmark has been incorporated into the Ontology Alignment Evaluation Initiative (OAEI) 2020 and is completely free for public use to assist the researchers in developing and evaluating their complex alignment algorithms.</p>
<p>Keywords:</p>
<h3 id="402. ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research.">402. ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412880">Paper Link</a>    Pages:3205-3212</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/183/6661.html">Xinyi Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/267/2261.html">Apurva Mulay</a> ; <a href="https://dblp.uni-trier.de/pid/38/8773.html">Emilio Ferrara</a> ; <a href="https://dblp.uni-trier.de/pid/93/909.html">Reza Zafarani</a></p>
<p>Abstract:
First identified in Wuhan, China, in December 2019, the outbreak of COVID-19 has been declared as a global emergency in January, and a pandemic in March 2020 by the World Health Organization (WHO). Along with this pandemic, we are also experiencing an "infodemic" of information with low credibility such as fake news and conspiracies. In this work, we present ReCOVery, a repository designed and constructed to facilitate research on combating such information regarding COVID-19. We first broadly search and investigate ~2,000 news publishers, from which 60 are identified with extreme [high or low] levels of credibility. By inheriting the credibility of the media on which they were published, a total of 2,029 news articles on coronavirus, published from January to May 2020, are collected in the repository, along with 140,820 tweets that reveal how these news articles have spread on the Twitter social network. The repository provides multimodal information of news articles on coronavirus, including textual, visual, temporal, and network information. The way that news credibility is obtained allows a trade-off between dataset scalability and label accuracy. Extensive experiments are conducted to present data statistics and distributions, as well as to provide baseline performances for predicting news credibility so that future methods can be compared. Our repository is available at <a href="http://coronavirus-fakenews.com">http://coronavirus-fakenews.com</a>.</p>
<p>Keywords:</p>
<h2 id="Doctoral Consortium    12">Doctoral Consortium    12</h2>
<h3 id="403. Detecting and Measuring the Exposure of Children and Adolescents to Inappropriate Comments in YouTube.">403. Detecting and Measuring the Exposure of Children and Adolescents to Inappropriate Comments in YouTube.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418511">Paper Link</a>    Pages:3213-3216</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/238/1899.html">Sultan Alshamrani</a></p>
<p>Abstract:
Social media platforms have been growing at a rapid pace, attracting users engagement with contents due to their convenience facilitated by many usable features. Such platforms provide users with interactive options such as likes, dislikes as well as a way of expressing their opinions in the form of text (i.e., comments). The ability of posting comments on these online platforms has allowed some users to post racist, obscene, as well as to spread hate on these platforms. In some cases, this kind of toxic behavior might turn the comment section from a space where users can share their views to a place where hate and profanity are spread. Such issues are observed across various social media platforms and many users are often exposed to these kinds of behaviors which requires comment moderators to spend a lot of time filtering out such inappropriate comments. Moreover, such textual "inappropriate contents" can be targeted towards users irrespective of age, concerning variety of topics (not only controversial), and triggered by various events. My doctoral dissertation work, therefore, is primarily focused on studying, detecting and analyzing users exposure to this kind of toxicity on different social media platforms utilizing the state-of-art techniques in deep learning and natural language processing. This paper presents one example of my works on detecting and measuring kids exposure to inappropriate comments posted on YouTube videos targeting young users. In the meantime, the same pipeline is being examined for measuring users interaction with mainstream news media and sentiment towards various topics in the public discourse in light of the Coronavirus disease 2019 (COVID'19).</p>
<p>Keywords:</p>
<h3 id="404. Tailoring Entity Matching for Industrial Settings.">404. Tailoring Entity Matching for Industrial Settings.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418514">Paper Link</a>    Pages:3217-3220</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5078.html">Nils Barlaug</a></p>
<p>Abstract:
Entity matching has received significant attention from the research community over many years. Despite some limited success, most state-of-the-art methods see no widespread usage in industry.</p>
<p>Keywords:</p>
<h3 id="405. Embedding based Link Prediction for Knowledge Graph Completion.">405. Embedding based Link Prediction for Knowledge Graph Completion.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418512">Paper Link</a>    Pages:3221-3224</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/222/9569.html">Russa Biswas</a></p>
<p>Abstract:
Knowledge Graphs (KGs) have recently gained attention for representing knowledge about a particular domain. Since its advent, the Linked Open Data (LOD) cloud has constantly been growing containing many KGs about many different domains such as government, scholarly data, biomedical domain, etc. Apart from facilitating the inter-connectivity of datasets in the LOD cloud, KGs have been used in a variety of machine learning and Natural Language Processing (NLP) based applications. However, the information present in the KGs are sparse and are often incomplete. Predicting the missing links between the entities is necessary to overcome this issue. Moreover, in the LOD cloud, information about the same entities is available in multiple KGs in different forms. But the information that these entities are the same across KGs is missing. The main focus of this thesis is to do Knowledge Graph Completion by tackling the link prediction tasks within a KG as well as across different KGs. To do so, the latent representation of KGs in a low dimensional vector space has been exploited to predict the missing information in order to complete the KGs.</p>
<p>Keywords:</p>
<h3 id="406. Computational Approaches for Drug Repositioning: Towards a Holistic Perspective based on Knowledge Graphs.">406. Computational Approaches for Drug Repositioning: Towards a Holistic Perspective based on Knowledge Graphs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418510">Paper Link</a>    Pages:3225-3228</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5071.html">Marina Boudin</a></p>
<p>Abstract:
Drug development is a costly and time consuming activity. The traditional process relies on extensive experimental efforts to map out the relevant part of the chemical space. Data about molecules, diseases, genes and other entities are present on many isolated databases, be that internal or external and in heterogeneous formats. They either require costly and inflexible data integration, or time-consuming workflows. Computational approaches, and more recently artificial intelligence based techniques, have emerged as a promising alternative for reducing the development cycle through drug repositioning. Knowledge bases are used to predict new links between old drugs and new targets. We present below the overall approach adopted for my PhD thesis, for a more holistic knowledge graph-based drug repositioning that aims to discover hidden or missing links between existing drugs and targets for which no known treatment is available. Currently, eight data and knowledge resources have already been integrated into the designed knowledge graph.</p>
<p>Keywords:</p>
<h3 id="407. Synthesis of Dependent Multichannel ECG using Generative Adversarial Networks.">407. Synthesis of Dependent Multichannel ECG using Generative Adversarial Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418509">Paper Link</a>    Pages:3229-3232</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/232/2312.html">Eoin Brophy</a></p>
<p>Abstract:
Access to medical data is highly regulated due to its sensitive nature, which can constrain communities' ability to utilise these data for research or clinical purposes. Common de-identification techniques to enable the sharing of data may not provide adequate protection for an individual's personal data in every circumstance. We investigate the ability of Generative Adversarial Networks (GANs) to generate realistic medical time series data to address these privacy and identification concerns. We generate synthetic, and more significantly, multichannel electrocardiogram (ECG) signals that are representative of waveforms observed in patients. Successful generation of high-quality synthetic time series data has the potential to act as an effective substitute for actual patient data. For the first time, we demonstrate a multivariate GAN architecture that can successfully generate dependent multichannel time series signals. We present the first application of multivariate dynamic time warping as a means of evaluating generated GAN samples. Quantitative evidence demonstrates our GAN can generate data that is structurally similar to the training set and diverse across generated samples, all whilst ensuring sufficient privacy guarantees for the underlying training data.</p>
<p>Keywords:</p>
<h3 id="408. Some Issues for Location Dependent Information System Query in Mobile Environment.">408. Some Issues for Location Dependent Information System Query in Mobile Environment.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418504">Paper Link</a>    Pages:3233-3236</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5036.html">Ajay Kr. Gupta</a></p>
<p>Abstract:
Location Based Services (LBS) is a continuous, local, and spatially restricted mobile database system (MDS) technology in the sense of a mobile environment. This domain is associated with many fascinating issues and challenges to be tackled and provided a fertile ground for many researchers and experts to work on it. This paper discusses the issues and challenges derived from the available literature to the research community regarding the latest approaches and experimentation results for location-dependent cache invalidation-replacement, prefetching, location privacy, and map matching (MM) policies. It offers potential future paths for exploring the unanswered questions.</p>
<p>Keywords:</p>
<h3 id="409. Approximate Event Pattern Matching over Heterogeneous and Dirty Sources.">409. Approximate Event Pattern Matching over Heterogeneous and Dirty Sources.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418506">Paper Link</a>    Pages:3237-3240</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/42/4811.html">Ruihong Huang</a></p>
<p>Abstract:
Pattern matching is an important task in the field of Complex Event Processing (CEP). However, exact event pattern matching methods could suffer from low hit rate and loss for meaningful events identification due to the heterogeneous and dirty sources in the big data era. Since both events and patterns could be imprecise, the actual event trace may have different event names as well as structures from the pre-defined pattern. The low-quality data even intensifies the difficulty of matching. In this work, we propose to learn embedding representations for patterns and event traces separately and calculate their similarity as the scores for approximate matching.</p>
<p>Keywords:</p>
<h3 id="410. Controlling Patent Text Generation by Structural Metadata.">410. Controlling Patent Text Generation by Structural Metadata.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418503">Paper Link</a>    Pages:3241-3244</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/70/1658.html">Jieh-Sheng Lee</a></p>
<p>Abstract:
The ultimate goal of my long-term project is "Augmented Inventing." This work is a follow-up effort toward the goal. It leverages the structural metadata in patent documents and the text-to-text mappings between metadata. The structural metadata includes patent title, abstract, independent claim, and dependent claim. By using the structural metadata, it is possible to control what kind of patent text to generate. By using the text-to-text mapping, it is possible to let a generative model generate one type of patent text from another type of patent text. Furthermore, through multiple mappings, it is possible to build a text generation flow, for example, generating from a few words to a patent title, from the title to an abstract, from the abstract to an independent claim, and from the independent claim to multiple dependent claims. The text generation flow can also go backward after training with bi-directional mappings. In addition to those above, the contributions of this work include: (1) released four generative models trained with patent corpus from scratch, (2) released the sample code to demonstrate how to generate patent text bi-directionally, (3) measuring the performances of the models by ROGUE and Universal Sentence Encoder as preliminary evaluations of text generation quality.</p>
<p>Keywords:</p>
<h3 id="411. Neural (Knowledge Graph) Question Answering Using Synthetic Training Data.">411. Neural (Knowledge Graph) Question Answering Using Synthetic Training Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418505">Paper Link</a>    Pages:3245-3248</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/211/8849.html">Trond Linjordet</a></p>
<p>Abstract:
Deep learning requires volume, quality, and variety of training data. In neural question answering, a trade-off between quality and volume comes from the need to either manually curate or construct realistic question answering data, which is costly, or else augmenting, weakly labeling or generating training data from smaller datasets, leading to low variety and sometimes low quality. What can be done to make the best of this necessary trade-off? What can be understood from the endeavor to seek such solutions?</p>
<p>Keywords:</p>
<h3 id="412. Automatic Contextual Storytelling in a Natural Language Corpus.">412. Automatic Contextual Storytelling in a Natural Language Corpus.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418507">Paper Link</a>    Pages:3249-3252</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/207/1942.html">Ishrat Rahman Sami</a></p>
<p>Abstract:
Storytelling is an ancient art and science of conveying wisdom through generations for centuries. Data-driven storytelling in the context of a natural language corpus has a huge potential for conveying fast valuable insights about the corpus for better decision making. But high dimensional unstructured nature of natural language text makes automatic extraction of stories extremely difficult. This PhD research project believes that modern storytelling is a hand in hand approach of contextual topic visualization and contextual summarization. While exploratory data visualization can provide valuable insights into the data, these insights can be used to understand and design models for producing abstract summarization. In this project, the context of a story is defined from three perspectives: a single document, a collection of multiple documents about a topic of interest and the whole corpus. In this project, exploratory data visualization is used to understand the context better and now with the achieved insights, research is focusing on abstract summarization for automatic contextual storytelling.</p>
<p>Keywords:</p>
<h3 id="413. Generating Clarifying Questions in Conversational Search Systems.">413. Generating Clarifying Questions in Conversational Search Systems.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418513">Paper Link</a>    Pages:3253-3256</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/164/1008.html">Leila Tavakoli</a></p>
<p>Abstract:
Asking a clarifying question can be a key element improving the performance of information seeking systems, particularly conversational search systems due to their limited bandwidth interfaces. While generating and asking clarifying questions is important; get-ting an answer for the clarifying question is also essential as a clarifying question without an answer is useless. Therefore, as the first step in current research, we analysed human-generated clarifying questions in a Community Question Answering website as a sample of conversation. This helped us to gain a better insight into how users interact with clarification. We investigated the clarifying questions in terms of whether they add any information to the question and the accepted answer. We further discovered the patterns and types of such clarifying questions. The next phase of this research will then generate clarifying questions in conversational search systems. We will then employ neural network models to generate clarifying questions to maximise clarification in questions. The proposed model will be trained using the MIMICS data collection in addition to our collected dataset. We will also attempt to consider the recognised patterns from the analysis conducted in the first step to enhance the chance that a user will interact with the clarifying questions. Finally, we will aim to minimise the interaction between the search system and the user to reduce the risk of dropping the conversation by the user due to asking too many clarifying questions.</p>
<p>Keywords:</p>
<h3 id="414. How the Quantum-inspired Framework Supports Keyword Searches on Multi-model Databases.">414. How the Quantum-inspired Framework Supports Keyword Searches on Multi-model Databases.</h3>
<p><a href="https://doi.org/10.1145/3340531.3418508">Paper Link</a>    Pages:3257-3260</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/207/8903.html">Gongsheng Yuan</a></p>
<p>Abstract:
With the trend of increasing vendors to develop various multi-model databases, people have reaped benefits from using a single and unified platform to manage both well-structured and NoSQL data. However, it causes a steep learning curve of mastering a multi-model query language for the specific multi-model database, not to mention various languages for different databases. Therefore, this research discusses the motivations of performing keyword searches on multi-model databases and then presents our current research. Methodologically, we attempt to use the quantum-inspired framework to query and explore multi-model databases. Firstly, we apply non-classical probabilities to estimate the relevance between a keyword query and candidate answers for guaranteeing getting good accuracy. Then we use the Principle Component Analysis (PCA) method to optimize the quantum language model for capturing good scalability. Finally, experiments show that our approaches are effective and our framework outperforms the state-of-the-art approaches.</p>
<p>Keywords:</p>
<h2 id="Poster Presentations    25">Poster Presentations    25</h2>
<h3 id="415. Optimal End-Biased Histograms for Hierarchical Data.">415. Optimal End-Biased Histograms for Hierarchical Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417449">Paper Link</a>    Pages:3261-3264</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/216/5088.html">Rachel Behar</a> ; <a href="https://dblp.uni-trier.de/pid/c/SaraCohen.html">Sara Cohen</a></p>
<p>Abstract:
We focus on summarizing hierarchical data by adapting the well-known notion of end biased-histograms to trees. Over relational data, such histograms have been well-studied, as they have a good balance between accuracy and space requirements. Extending histograms to tree data is a non-trivial problem, due to the need to preserve and leverage structure in the output. We develop a fast greedy algorithm, and a polynomial algorithm that finds provably optimal hierarchical end-biased histograms. Preliminary experimentation demonstrates that our histograms work well in practice.</p>
<p>Keywords:</p>
<h3 id="416. Two Test Collections for Retrieval Using Named Entity Markup.">416. Two Test Collections for Retrieval Using Named Entity Markup.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417452">Paper Link</a>    Pages:3265-3268</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5079.html">Jacob Bremerman</a> ; <a href="https://dblp.uni-trier.de/pid/l/DawnLawrie.html">Dawn J. Lawrie</a> ; <a href="https://dblp.uni-trier.de/pid/59/2681.html">James Mayfield</a> ; <a href="https://dblp.uni-trier.de/pid/o/DouglasWOard.html">Douglas W. Oard</a></p>
<p>Abstract:
Studying the effects of semantic analysis on retrieval effectiveness can be difficult using standard test collections because both queries and documents typically lack semantic markup. This paper describes extensions to two test collections, CLEF 2003/2004 Russian and TDT-3 Chinese, to support study of the utility of named entity annotation. A new set of topic aspects that were expected to benefit from named entity markup were defined for topics in those test collections, with two queries for each aspect. One of these queries uses named entities as bag-of-words query terms or as semantic constraints on a free-text query term; the other is a bag-of-words baseline query without named entity markup. Exhaustive judgment of the documents annotated by CLEF or TDT as relevant to each corresponding topic was performed, resulting in relevance judgments for 133 Russian and 33 Chinese topic aspects that each have at least one relevant document. Named entity tags were automatically generated for the documents in both collections. Use of the test collections is illustrated with some preliminary experiments.</p>
<p>Keywords:</p>
<h3 id="417. Improving Anchor-based Explanations.">417. Improving Anchor-based Explanations.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417461">Paper Link</a>    Pages:3269-3272</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/252/4981.html">Julien Delaunay</a> ; <a href="https://dblp.uni-trier.de/pid/70/11083.html">Luis Galrraga</a> ; <a href="https://dblp.uni-trier.de/pid/42/2089.html">Christine Largout</a></p>
<p>Abstract:
Rule-based explanations are a popular method to understand the rationale behind the answers of complex machine learning (ML) classifiers. Recent approaches, such as Anchors, focus on local explanations based on if-then rules that are applicable in the vicinity of a target instance. This has proved effective at producing faithful explanations, yet anchor-based explanations are not free of limitations. These include long overly specific rules as well as explanations of low fidelity. This work presents two simple methods that can mitigate such issues on tabular and textual data. The first approach proposes a careful selection of the discretization method for numerical attributes in tabular datasets. The second one applies the notion of pertinent negatives to explanations on textual data. Our experimental evaluation shows the positive impact of such methods on the quality of anchor-based explanations.</p>
<p>Keywords:</p>
<h3 id="418. Towards Inferring Queries from Simple and Partial Provenance Examples.">418. Towards Inferring Queries from Simple and Partial Provenance Examples.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417451">Paper Link</a>    Pages:3273-3276</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/163/3941.html">Amir Gilad</a> ; <a href="https://dblp.uni-trier.de/pid/135/4661.html">Yuval Moskovitch</a></p>
<p>Abstract:
The field of query-by-example aims at inferring queries from output examples given by non-expert users, by finding the underlying logic that binds the examples. However, for a very small set of examples, it is difficult to correctly infer such logic. To bridge this gap, previous work suggested attaching explanations to each output example, modeled as provenance, allowing users to explain the reason behind their choice of example. In this paper, we explore the problem of inferring queries from a few output examples and intuitive explanations. We propose a two step framework: (1) convert the explanations into (partial) provenance and (2) infer a query that generates the output examples using a novel algorithm that employs a graph based approach. This framework is suitable for non-experts as it does not require the specification of the provenance in its entirety or an understanding of its structure. We show promising initial experimental results of our approach.</p>
<p>Keywords:</p>
<h3 id="419. Enhanced Story Representation by ConceptNet for Predicting Story Endings.">419. Enhanced Story Representation by ConceptNet for Predicting Story Endings.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417466">Paper Link</a>    Pages:3277-3280</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/92/8363.html">Shanshan Huang</a> ; <a href="https://dblp.uni-trier.de/pid/z/KennyQiliZhu.html">Kenny Q. Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5121.html">Qianzi Liao</a> ; <a href="https://dblp.uni-trier.de/pid/06/5089.html">Libin Shen</a> ; <a href="https://dblp.uni-trier.de/pid/25/9282.html">Yinggong Zhao</a></p>
<p>Abstract:
Predicting endings for narrative stories is a grand challenge for machine commonsense reasoning. The task requires ac- curate representation of the story semantics and structured logic knowledge. Pre-trained language models, such as BERT, made progress recently in this task by exploiting spurious statistical patterns in the test dataset, instead of 'understanding' the stories per se. In this paper, we propose to improve the representation of stories by first simplifying the sentences to some key concepts and second modeling the latent relation- ship between the key ideas within the story. Such enhanced sentence representation, when used with pre-trained language models, makes substantial gains in prediction accuracy on the popular Story Cloze Test without utilizing the biased validation data.</p>
<p>Keywords:</p>
<h3 id="420. Empirical Analysis of Impact of Query-Specific Customization of nDCG: A Case-Study with Learning-to-Rank Methods.">420. Empirical Analysis of Impact of Query-Specific Customization of nDCG: A Case-Study with Learning-to-Rank Methods.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417454">Paper Link</a>    Pages:3281-3284</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/150/3985.html">Shubhra (Santu) K. Karmaker</a> ; <a href="https://dblp.uni-trier.de/pid/69/8428.html">Parikshit Sondhi</a> ; <a href="https://dblp.uni-trier.de/pid/z/ChengXiangZhai.html">ChengXiang Zhai</a></p>
<p>Abstract:
In most existing works, nDCG is computed for a fixed cutoff k, i.e., [email protected] and some fixed discounting coefficient. Such a conventional query-independent way to compute nDCG does not accurately reflect the utility of search results perceived by an individual user and is thus non-optimal. In this paper, we conduct a case study of the impact of using query-specific nDCG on the choice of the optimal Learning-to-Rank (LETOR) methods, particularly to see whether using a query-specific nDCG would lead to a different conclusion about the relative performance of multiple LETOR methods than using the conventional query-independent nDCG would otherwise. Our initial results show that the relative ranking of LETOR methods using query-specific nDCG can be dramatically different from those using the query-independent nDCG at the individual query level, suggesting that query-specific nDCG may be useful in order to obtain more reliable conclusions in retrieval experiments.</p>
<p>Keywords:</p>
<h3 id="421. Autonomous Predictive Modeling via Reinforcement Learning.">421. Autonomous Predictive Modeling via Reinforcement Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417448">Paper Link</a>    Pages:3285-3288</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/97/7024.html">Udayan Khurana</a> ; <a href="https://dblp.uni-trier.de/pid/13/2167.html">Horst Samulowitz</a></p>
<p>Abstract:
Building a robust predictive model requires an array of steps such as data imputation, feature transformations, estimator selection, hyper-parameter search, ensemble construction, amongst others. Due to this vast, complex and heterogeneous space of operations, off-the-shelf optimization methods offer infeasible solutions for realistic response time requirements. In practice, much of the predictive modeling process is conducted by experienced data scientists, who selectively make use of available tools. Over time, they develop an understanding of the behavior of operators, and perform serial decision making under uncertainty, colloquially referred to as educated guesswork. With an unprecedented demand for application of supervised machine learning, there is a call for solutions that automatically search for a suitable combination of operators across these tasks while minimize the modeling error. We introduce a novel system called APRL (Autonomous Predictive modeler via Reinforcement Learning), that uses past experience through reinforcement learning to optimize sequential decision making from within a set of diverse actions under a budget constraint. Our experiments demonstrate the superiority of the proposed approach over known AutoML systems that utilize Bayesian optimization or genetic algorithms.</p>
<p>Keywords:</p>
<h3 id="422. A Human-in-the-Loop Approach to Malware Author Classification.">422. A Human-in-the-Loop Approach to Malware Author Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417467">Paper Link</a>    Pages:3289-3292</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5072.html">Eujeanne Kim</a> ; <a href="https://dblp.uni-trier.de/pid/40/9208.html">Sung-Jun Park</a> ; <a href="https://dblp.uni-trier.de/pid/129/2357.html">Dong-Kyu Chae</a> ; <a href="https://dblp.uni-trier.de/pid/83/716.html">Seokwoo Choi</a> ; <a href="https://dblp.uni-trier.de/pid/64/5810.html">Sang-Wook Kim</a></p>
<p>Abstract:
For these few decades malwares have been posing a major concern in the cyber security. Recently, a number of "author groups" have been generating lots of newmalwares by sharing source code within a group and exploiting evasive schemes such as polymorphism and metamorphism. This motivates us to study the problem of identifying the author group of a given malware, which would be able to work for not only blocking malwares but also legally punishing suspected malware authors. In this paper, we propose a human-machine collaborative approach for classifying author groups of malwares accurately. We also propose a visualization method for helping human experts to make the decision easily. We verify the superiority of our framework through extensive experiments using real-world malware data.</p>
<p>Keywords:</p>
<h3 id="423. Deriving Geolocations in Wikipedia.">423. Deriving Geolocations in Wikipedia.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417459">Paper Link</a>    Pages:3293-3296</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/61/9228.html">Amir Krause</a> ; <a href="https://dblp.uni-trier.de/pid/c/SaraCohen.html">Sara Cohen</a></p>
<p>Abstract:
We study the problem of deriving geolocations for Wikipedia pages. To this end, we introduce a general four-step process to location derivation, and consider different instantiations of this process, leveraging both textual and categorical data. Extensive experimentation shows that our methods provide good precision-recall trade-offs and improvements over text-only methods. Hence, our system can be used to augment the geographic information of Wikipedia, and to enable more effective geographic information retrieval.</p>
<p>Keywords:</p>
<h3 id="424. A Cost Estimation Technique for Recursive Relational Algebra.">424. A Cost Estimation Technique for Recursive Relational Algebra.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417460">Paper Link</a>    Pages:3297-3300</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5037.html">Muideen Lawal</a> ; <a href="https://dblp.uni-trier.de/pid/g/PGeneves.html">Pierre Genevs</a> ; <a href="https://dblp.uni-trier.de/pid/l/NabilLayaida.html">Nabil Layada</a></p>
<p>Abstract:
With the increasing popularity of data structures such as graphs, recursion is becoming a key ingredient of query languages in analytic systems. Recursive query evaluation involves an iterative application of a function or operation until some condition is satisfied. It is particularly useful for retrieving nodes reachable along deep paths in a graph. The optimization of recursive queries has remained a challenge for decades. Recently, extensions of Codd's classical relational algebra to support recursive terms and their optimisation gained renewed interest [10]. Query optimization crucially relies on enumeration of query evaluation plans and on cost estimation techniques. Cost estimation for recursive terms is far from trivial, and received less attention. In this paper, we propose a new cost estimation technique for recursive terms of the extended relational algebra. This technique allows to select an estimated cheapest query plan, in terms of computing resources usage e.g. memory footprint, CPU and I/O and evaluation time. We evaluate the effectiveness of our cost estimation technique on a set of recursive graph queries on both generated and real datasets of significant size, including Yago: a graph with more than 62 millions edges and 42 million nodes. Experiments show that our cost estimation technique improves the performance of recursive query evaluation on popular relational database engines such as PostgreSQL.</p>
<p>Keywords:</p>
<h3 id="425. User Taste-Aware Image Search.">425. User Taste-Aware Image Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417462">Paper Link</a>    Pages:3301-3304</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/132/7581.html">Jiyun Luo</a> ; <a href="https://dblp.uni-trier.de/pid/276/4996.html">Pak Ming Cheung</a> ; <a href="https://dblp.uni-trier.de/pid/42/7967.html">Wenyu Huo</a> ; <a href="https://dblp.uni-trier.de/pid/62/2964.html">Ying Huang</a> ; <a href="https://dblp.uni-trier.de/pid/64/4254.html">Rajat Raina</a></p>
<p>Abstract:
Pinterest as a popular image search platform has been widely adopted by users. Every day, people come to Pinterest searching for fashion- and home decor-related content. In these domains, users exhibit stable personal tastes. In this paper, we propose a novel search algorithm which can infer user tastes from their past engagement history and tailor the search results to fit their preferences. The online and offline experiments show that our method can efficiently improve user experience and increase user engagements.</p>
<p>Keywords:</p>
<h3 id="426. RotaryDS: Fast Storage for Massive Data Streams via a Rotation Storage Model.">426. RotaryDS: Fast Storage for Massive Data Streams via a Rotation Storage Model.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417465">Paper Link</a>    Pages:3305-3308</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5068.html">Yanqi Lv</a> ; <a href="https://dblp.uni-trier.de/pid/52/3440.html">Peiquan Jin</a></p>
<p>Abstract:
In this paper, we propose RotaryDS to provide fast storage service for massive data streams. RotaryDS uses a rotation storage model, which employs distributed data buckets to accept highly-arriving data streams. All data buckets have a state, i.e., they can be in the state of data idle waiting, data filling, write waiting, and data dumping. The state of a data bucket is changed according to the data operations. With the rotation storage model, we distribute massive data streams among multiple data buckets, thereby improving the write throughput of the storage system. We implement RotaryDS based on the rotation storage model and conduct preliminary experiments to compare it with MongoDB. The results suggest the efficiency of our proposal.</p>
<p>Keywords:</p>
<h3 id="427. ALEX: Active Learning based Enhancement of a Classification Model's EXplainability.">427. ALEX: Active Learning based Enhancement of a Classification Model's EXplainability.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417456">Paper Link</a>    Pages:3309-3312</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/255/8493.html">Ishani Mondal</a> ; <a href="https://dblp.uni-trier.de/pid/41/7272.html">Debasis Ganguly</a></p>
<p>Abstract:
An active learning (AL) algorithm seeks to construct an effective classifier with a minimal number of labeled examples in a bootstrapping manner. While standard AL heuristics, such as selecting those points for annotation for which a classification model yields least confident predictions, there has been no empirical investigation to see if these heuristics lead to models that are more interpretable to humans. In the era of data-driven learning, this is an important research direction to pursue. This paper describes our work-in-progress towards developing an AL selection function that in addition to model effectiveness also seeks to improve on the interpretability of a model during the bootstrapping steps. Concretely speaking, our proposed selection function trains an 'explainer' model in addition to the classifier model, and favours those instances where a different part of the data is used, on an average, to explain the predicted class. Initial experiments exhibited encouraging trends in showing that such a heuristic can lead to developing more effective and more explainable end-to-end data-driven classifiers.</p>
<p>Keywords:</p>
<h3 id="428. A Capsule Network-based Model for Learning Node Embeddings.">428. A Capsule Network-based Model for Learning Node Embeddings.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417455">Paper Link</a>    Pages:3313-3316</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/35/9125.html">Dai Quoc Nguyen</a> ; <a href="https://dblp.uni-trier.de/pid/129/2628.html">Tu Dinh Nguyen</a> ; <a href="https://dblp.uni-trier.de/pid/23/9125.html">Dat Quoc Nguyen</a> ; <a href="https://dblp.uni-trier.de/pid/245/8638.html">Dinh Phung</a></p>
<p>Abstract:
In this paper, we focus on learning low-dimensional embeddings for nodes in graph-structured data. To achieve this, we propose Caps2NE -- a new unsupervised embedding model leveraging a network of two capsule layers. Caps2NE induces a routing process to aggregate feature vectors of context neighbors of a given target node at the first capsule layer, then feed these features into the second capsule layer to infer a plausible embedding for the target node. Experimental results show that our proposed Caps2NE obtains state-of-the-art performances on benchmark datasets for the node classification task. Our code is available at: <a href="https://github.com/daiquocnguyen/Caps2NE">https://github.com/daiquocnguyen/Caps2NE</a>.</p>
<p>Keywords:</p>
<h3 id="429. Structured Knowledge: Have we made progress? An extrinsic study of KB coverage over 19 years.">429. Structured Knowledge: Have we made progress? An extrinsic study of KB coverage over 19 years.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417447">Paper Link</a>    Pages:3317-3320</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/48/10142.html">Simon Razniewski</a> ; <a href="https://dblp.uni-trier.de/pid/58/9638.html">Priyanka Das</a></p>
<p>Abstract:
Structured world knowledge is at the foundation of knowledge-centric AI applications. Despite considerable research on knowledge base construction, beyond mere statement counts, little is known about the progress of KBs, in particular concerning their coverage, and one may wonder whether there is constant progress, or diminishing returns. In this paper we employ question answering and entity summarization as extrinsic use cases for a longitudinal study of the progress of KB coverage. Our analysis shows a near-continuous improvement of two popular KBs, DBpedia and Wikidata, over the last 19 years, with little signs of flattening out or leveling off.</p>
<p>Keywords:</p>
<h3 id="430. Diverse Enumeration of Maximal Cliques.">430. Diverse Enumeration of Maximal Cliques.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417458">Paper Link</a>    Pages:3321-3324</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5047.html">Liron Sade</a> ; <a href="https://dblp.uni-trier.de/pid/c/SaraCohen.html">Sara Cohen</a></p>
<p>Abstract:
Maximal clique enumeration is a well-studied problem due to its many applications. We present a new algorithm for this problem that enumerates maximal cliques in a diverse ordering. The main idea behind our approach is to adapt the classic Bron-Kerbosch (BK) algorithm by, conceptually, jumping between different nodes in the execution tree. Special care is taken to ensure that (1) each maximal clique is created precisely once, (2) the theoretical runtime remains the same as in the BK algorithm and (3) memory requirements remain reasonable. Experimental results show that we indeed achieve our goals, and moreover, that the cliques are enumerated in a diverse order.</p>
<p>Keywords:</p>
<h3 id="431. Truth be Told: Fake News Detection Using User Reactions on Reddit.">431. Truth be Told: Fake News Detection Using User Reactions on Reddit.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417463">Paper Link</a>    Pages:3325-3328</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/36/8510.html">Vinay Setty</a> ; <a href="https://dblp.uni-trier.de/pid/276/5114.html">Erlend Rekve</a></p>
<p>Abstract:
In this paper, we provide a large dataset for fake news detection using social media comments. The dataset consists of 12,597 claims (of which 63% are labelled as fake) from four different sources (Snopes, Poltifact, Emergent and Twitter). The novel part of the dataset is that it also includes over 662K social media discussion comments related to these claims from Reddit. We make this dataset public for the research community. In addition, for the task of fake news detection using social media comments, we provide a simple but strong baseline solution deep neural network model which beats several solutions in the literature.</p>
<p>Keywords:</p>
<h3 id="432. Ranking Multiple Choice Question Distractors using Semantically Informed Neural Networks.">432. Ranking Multiple Choice Question Distractors using Semantically Informed Neural Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417468">Paper Link</a>    Pages:3329-3332</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/127/0162.html">Manjira Sinha</a> ; <a href="https://dblp.uni-trier.de/pid/72/36.html">Tirthankar Dasgupta</a> ; <a href="https://dblp.uni-trier.de/pid/276/5035.html">Jatin Mandav</a></p>
<p>Abstract:
Automatically generating or ranking distractors for multiple-choice questions (MCQs) is still a challenging problem. In this work, we have focused towards automatic ranking of distractors for MCQs. Accordingly, we have proposed an semantically aware CNN-BiLSTM model. We evaluate our model with different word level embeddings as input over two different openly available datasets. Experimental results demonstrate our proposed model surpasses the performance of the existing baseline models. Furthermore, we have observed that intelligently incorporating word level semantic information along with context specific word embeddings boost up the predictive performance of distractors, which is a promising direction for further research.</p>
<p>Keywords:</p>
<h3 id="433. Exploiting Common Neighbor Graph for Link Prediction.">433. Exploiting Common Neighbor Graph for Link Prediction.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417464">Paper Link</a>    Pages:3333-3336</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/29/1374.html">Hao Tian</a> ; <a href="https://dblp.uni-trier.de/pid/93/909.html">Reza Zafarani</a></p>
<p>Abstract:
Link prediction aims to predict whether two nodes in a network are likely to get connected. Motivated by its applications, e.g., in friend or product recommendation, link prediction has been extensively studied over the years. Most link prediction methods are designed based on specific assumptions that may or may not hold in different networks, leading to link prediction methods that are not generalizable. Here, we address this problem by proposing general link prediction methods that can capture network-specific patterns. Most link prediction methods rely on computing similarities between between nodes. By learning a -decaying model, the proposed methods can measure the pairwise similarities between nodes more accurately, even when only using common neighbor information, which is often used by current techniques.</p>
<p>Keywords:</p>
<h3 id="434. Maximum Signed (k, r)-Truss Identification in Signed Networks.">434. Maximum Signed (k, r)-Truss Identification in Signed Networks.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417457">Paper Link</a>    Pages:3337-3340</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/74/7774.html">Yanping Wu</a> ; <a href="https://dblp.uni-trier.de/pid/274/6445.html">Renjie Sun</a> ; <a href="https://dblp.uni-trier.de/pid/65/4423-17.html">Chen Chen</a> ; <a href="https://dblp.uni-trier.de/pid/81/1832.html">Xiaoyang Wang</a> ; <a href="https://dblp.uni-trier.de/pid/05/6340.html">Qiuyu Zhu</a></p>
<p>Abstract:
Mining cohesive subgraphs is a fundamental problem in social network analysis. The k-truss model has been widely used to measure the cohesiveness of subgraphs. Most existing studies about k-truss focus on unsigned graphs. However, in real applications, the edges in the networks can be either positive or negative, e.g., friend or foe relationships, which represents more information than unsigned networks. Therefore, the traditional k-truss model is not applicable for the signed networks. Motivated by this, in this paper, we propose a novel model, named signed (k,r)-truss, which leverages the property of balanced triangle in singed network analysis. Specifically, a signed (k,r)-truss is a subgraph where each edge has no less than k balanced support and no more than r unbalanced support. We prove that the problem of identifying the maximum signed (k,r)-truss is NP-hard. Due to the hardness of the problem, we tend to the heuristic strategies. A trivial algorithm is first presented. Then, two greedy algorithms are developed to enhance the processing. Finally, we conduct comprehensive experiments on real-world signed networks to verify the performance of proposed techniques.</p>
<p>Keywords:</p>
<h3 id="435. Semi-supervised Consensus Clustering Based on Frequent Closed Itemsets.">435. Semi-supervised Consensus Clustering Based on Frequent Closed Itemsets.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417453">Paper Link</a>    Pages:3341-3344</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/151/2326.html">Tianshu Yang</a> ; <a href="https://dblp.uni-trier.de/pid/p/NicolasPasquier.html">Nicolas Pasquier</a> ; <a href="https://dblp.uni-trier.de/pid/276/5008.html">Antoine Hom</a> ; <a href="https://dblp.uni-trier.de/pid/24/6368.html">Laurent Doll</a> ; <a href="https://dblp.uni-trier.de/pid/83/1407.html">Frdric Precioso</a></p>
<p>Abstract:
Semi-supervised consensus clustering integrates supervised information into consensus clustering in order to improve the quality of clustering. In this paper, we study the novel Semi-MultiCons semi-supervised consensus clustering method extending the previous MultiCons approach. Semi-MultiCons aims to improve the clustering result by integrating pairwise constraints in the consensus creation process and infer the number of clusters K using frequent closed itemsets extracted from the ensemble members. Experimental results show that the proposed method outperforms other state-of-art semi-supervised consensus algorithms.</p>
<p>Keywords:</p>
<h3 id="436. Smarter and Safer Traffic Signal Controlling via Deep Reinforcement Learning.">436. Smarter and Safer Traffic Signal Controlling via Deep Reinforcement Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417450">Paper Link</a>    Pages:3345-3348</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5077.html">Bingquan Yu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5052.html">Jinqiu Guo</a> ; <a href="https://dblp.uni-trier.de/pid/22/6705.html">Qinpei Zhao</a> ; <a href="https://dblp.uni-trier.de/pid/05/7845.html">Jiangfeng Li</a> ; <a href="https://dblp.uni-trier.de/pid/79/5179.html">Weixiong Rao</a></p>
<p>Abstract:
Recently deep reinforcement learning (DRL) has been used for intelligent traffic light control. Unfortunately, we find that state-of-the-art on DRL-based intelligent traffic light essentially adopts discrete decision making and would suffer from the issue of unsafe driving. Moreover, existing feature representation of environment may not capture dynamics of traffic flow and thus cannot precisely predict future traffic flows. To overcome these issues, in this paper, we propose a DDPG-based DRL framework to learn a continuous time duration of traffic signal phases by introducing 1) a transit phase before the change of current phase for better safety, and 2) vehicle moving speed into feature representation for more precise estimation of traffic flow in next phase. Our preliminary evaluation on a well-known simulator SUMO indicates that our work significantly outperforms a recent work by much smaller number of emergency stops, queue length and waiting time.</p>
<p>Keywords:</p>
<h3 id="437. OFFER: A Motif Dimensional Framework for Network Representation Learning.">437. OFFER: A Motif Dimensional Framework for Network Representation Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417446">Paper Link</a>    Pages:3349-3352</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/147/8566.html">Shuo Yu</a> ; <a href="https://dblp.uni-trier.de/pid/62/3147.html">Feng Xia</a> ; <a href="https://dblp.uni-trier.de/pid/97/3265.html">Jin Xu</a> ; <a href="https://dblp.uni-trier.de/pid/28/5916.html">Zhikui Chen</a> ; <a href="https://dblp.uni-trier.de/pid/54/5625.html">Ivan Lee</a></p>
<p>Abstract:
Aiming at better representing multivariate relationships, this paper investigates a motif dimensional framework for higher-order graph learning. The graph learning effectiveness can be improved through OFFER. The proposed framework mainly aims at accelerating and improving higher-order graph learning results. We apply the acceleration procedure from the dimensional of network motifs. Specifically, the refined degree for nodes and edges are conducted in two stages: (1) employ motif degree of nodes to refine the adjacency matrix of the network; and (2) employ motif degree of edges to refine the transition probability matrix in the learning process. In order to assess the efficiency of the proposed framework, four popular network representation algorithms are modified and examined. By evaluating the performance of OFFER, both link prediction results and clustering results demonstrate that the graph representation learning algorithms enhanced with OFFER consistently outperform the original algorithms with higher efficiency.</p>
<p>Keywords:</p>
<h3 id="438. Large Scale Long-tailed Product Recognition System at Alibaba.">438. Large Scale Long-tailed Product Recognition System at Alibaba.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417445">Paper Link</a>    Pages:3353-3356</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/136/5317.html">Xiangzeng Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/44/2104.html">Pan Pan</a> ; <a href="https://dblp.uni-trier.de/pid/96/5223.html">Yun Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/15/2775.html">Yinghui Xu</a> ; <a href="https://dblp.uni-trier.de/pid/j/RongJin.html">Rong Jin</a></p>
<p>Abstract:
A practical large scale product recognition system suffers from the phenomenon of long-tailed imbalanced training data under the E-commercial circumstance at Alibaba. In addition to images of products at Alibaba, plenty of related side information (e.g. title and tags) reveal rich semantic information about images. Prior works mainly focus on addressing the long tail problem from the visual perspective only, but lack of consideration of leveraging the side information. In this paper, we present a novel side information based large scale visual recognition co-training (SICoT) system to deal with the long tail problem by leveraging the image related side information. In the proposed co-training system, we firstly introduce a bilinear word attention module which aims to construct a semantic embedding from the noisy side information. A visual feature and semantic embedding co-training scheme is then designed to transfer knowledge between those classes with abundant training data (head classes) to classes with few training data (tail classes) in an end-to-end fashion. Extensive experiments on four challenging large scale datasets, whose numbers of classes range from one thousand to one million, demonstrate the scalable effectiveness of the proposed SICoT system in alleviating the long tail problem.</p>
<p>Keywords:</p>
<h3 id="439. Exploiting Class Labels to Boost Performance on Embedding-based Text Classification.">439. Exploiting Class Labels to Boost Performance on Embedding-based Text Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417444">Paper Link</a>    Pages:3357-3360</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/34/7374.html">Arkaitz Zubiaga</a></p>
<p>Abstract:
Text classification is one of the most frequent tasks for processing textual data, facilitating among others research from large-scale datasets. Embeddings of different kinds have recently become the de facto standard as features used for text classification. These embeddings have the capacity to capture meanings of words inferred from occurrences in large external collections. While they are built out of external collections, they are unaware of the distributional characteristics of words in the classification dataset at hand, including most importantly the distribution of words across classes in training data. To make the most of these embeddings as features and to boost the performance of classifiers using them, we introduce a weighting scheme, Term Frequency-Category Ratio (TF-CR), which can weight high-frequency, category-exclusive words higher when computing word embeddings. Our experiments on eight datasets show the effectiveness of TF-CR, leading to improved performance scores over the well-known weighting schemes TF-IDF and KLD as well as over the absence of a weighting scheme in most cases.</p>
<p>Keywords:</p>
<h2 id="Demonstrations    35">Demonstrations    35</h2>
<h3 id="440. Gtensor: Fast and Accurate Tensor Analysis System using GPUs.">440. Gtensor: Fast and Accurate Tensor Analysis System using GPUs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417413">Paper Link</a>    Pages:3361-3364</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5018.html">Dawon Ahn</a> ; <a href="https://dblp.uni-trier.de/pid/204/5336.html">Sangjun Son</a> ; <a href="https://dblp.uni-trier.de/pid/276/5046.html">U. Kang</a></p>
<p>Abstract:
Given a large tensor, how can we analyze it efficiently? Multi-dimensional arrays or tensors have been widely used to model real-world data. Tensor decomposition plays an important role in analyzing trends and major factors in tensors. While several tensor analysis tools have been developed, they show slow running time and limited scalability due to their heavy computational requirements.</p>
<p>Keywords:</p>
<h3 id="441. CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine for COVID-19 Information.">441. CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine for COVID-19 Information.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417428">Paper Link</a>    Pages:3365-3368</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/243/7168.html">Heer Ambavi</a> ; <a href="https://dblp.uni-trier.de/pid/276/5087.html">Kavita Vaishnaw</a> ; <a href="https://dblp.uni-trier.de/pid/276/5125.html">Udit Vyas</a> ; <a href="https://dblp.uni-trier.de/pid/276/5067.html">Abhisht Tiwari</a> ; <a href="https://dblp.uni-trier.de/pid/96/4770.html">Mayank Singh</a></p>
<p>Abstract:
The entire world is engulfed in the fight against the COVID-19 pandemic, leading to a significant surge in research experiments, government policies, and social media discussions. A multi-modal information access and data visualization platform can play a critical role in supporting research aimed at understanding and developing preventive measures for the pandemic. In this paper, we present a multi-faceted AI-based search and visualization engine, CovidExplorer. Our system aims to help researchers understand current state-of-the-art COVID-19 research, identify research articles relevant to their domain, and visualize real-time trends and statistics of COVID-19 cases. In contrast to other existing systems, CovidExplorer also brings in India-specific topical discussions on social media to study different aspects of COVID-19. The system, demo video, and the datasets are available at <a href="http://covidexplorer.in">http://covidexplorer.in</a>.</p>
<p>Keywords:</p>
<h3 id="442. Nebula: A Scalable Privacy-Preserving Machine Learning System in Ant Financial.">442. Nebula: A Scalable Privacy-Preserving Machine Learning System in Ant Financial.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417418">Paper Link</a>    Pages:3369-3372</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/152/6215.html">Cen Chen</a> ; <a href="https://dblp.uni-trier.de/pid/207/4843.html">Bingzhe Wu</a> ; <a href="https://dblp.uni-trier.de/pid/58/6810.html">Li Wang</a> ; <a href="https://dblp.uni-trier.de/pid/26/1492-1.html">Chaochao Chen</a> ; <a href="https://dblp.uni-trier.de/pid/15/7663.html">Jin Tan</a> ; <a href="https://dblp.uni-trier.de/pid/181/2817.html">Lei Wang</a> ; <a href="https://dblp.uni-trier.de/pid/99/3847.html">Jun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/z/BenyuZhang.html">Benyu Zhang</a></p>
<p>Abstract:
With the rapid growth of data volume, data-driven machine learning models have become a necessary part of many industrial applications. Intuitively, the more high-quality data used for training leads to better model performance. However, in reality, data are usually scattered and isolated in different organizations or companies. Such a "data isolation" problem stimulates both academia and industry to explore the collaborative learning paradigm to build better models jointly with multiple data sources. Despite the potential performance gains, this learning paradigm inevitably faces privacy issues, especially for the Fintech domain where data are sensitive by nature. In this paper, we present a privacy-preserving collaborative learning system in Ant Financial, named Nebula. Our system aims to facilitate privacy-preserving collaborative model training for industrial-scale applications. Our system is built upon a ring-allreduce MPI based distributed framework. On top of that, with some optimization strategies and novel sharing scheme, our system is able to scale up to tens of millions of data samples with hundreds of thousands of features and achieve more than 100x speedup compared with the existing state-of-the-art implementations.</p>
<p>Keywords:</p>
<h3 id="443. IDEAL: IDEntifying the User's IdeAL Tuple via Sorting in the Database.">443. IDEAL: IDEntifying the User's IdeAL Tuple via Sorting in the Database.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417420">Paper Link</a>    Pages:3373-3376</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/65/4423.html">Chen Chen</a> ; <a href="https://dblp.uni-trier.de/pid/53/2404.html">Jiping Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/276/5092.html">Weijun Yan</a> ; <a href="https://dblp.uni-trier.de/pid/276/5042.html">Meijing Wang</a></p>
<p>Abstract:
Beyond top-k and skyline queries, in the last decade regret minimization queries have played an important role in the database community to solve multi-criteria decision making problems. To reduce the user's regret, interaction is proved to be an efficient way to turn the user's regret ratio to 0, i.e. identifying the user's ideal point from the large dataset. However, existing interactive regret minimization framework needs more rounds of user's interaction to identify her/his ideal point. To reduce the number of interaction rounds, we propose a system, called IDEAL, IDE ntifying the user's ideAL tuple via sorting in the database. In our system, we use the National Basketball Association (NBA) dataset to show our interactive framework via sorting mechanism, which can make the regret minimization query quickly converge to the user's ideal data point from initial displayed several points with few rounds of the user's interaction.</p>
<p>Keywords:</p>
<h3 id="444. PandaSQL: Parallel Randomized Triangle Enumeration with SQL Queries.">444. PandaSQL: Parallel Randomized Triangle Enumeration with SQL Queries.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417429">Paper Link</a>    Pages:3377-3380</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/273/9558.html">Abir Farouzi</a> ; <a href="https://dblp.uni-trier.de/pid/b/LadjelBellatreche.html">Ladjel Bellatreche</a> ; <a href="https://dblp.uni-trier.de/pid/o/CarlosOrdonez.html">Carlos Ordonez</a> ; <a href="https://dblp.uni-trier.de/pid/p/GopalPandurangan.html">Gopal Pandurangan</a> ; <a href="https://dblp.uni-trier.de/pid/90/3009.html">Mimoun Malki</a></p>
<p>Abstract:
Triangles are an important pattern in large-scale graph analysis for their practical use in many real-life applications. However, with the expansion of networks, maintaining a balanced computational load is challenging especially for problems like triangle computations because of skewed vertices. On the other hand, there is a huge amount of data in database management systems (DBMSs) that can be modeled and analyzed as graphs. With these motivations in mind, we developed PandaSQL, a novel approach using SQL queries to enumerate all the triangles in a given graph based on Randomized Triangle Enumeration Algorithm. Our approach is elegant, abstract, and short compared to traditional languages like C++ or Python. Moreover, our partitioning queries ensures perfect load balancing. Thus, the triangle enumeration is independent, local, and parallel.</p>
<p>Keywords:</p>
<h3 id="445. Semantic Search over Structured Data.">445. Semantic Search over Structured Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417426">Paper Link</a>    Pages:3381-3384</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/136/7969.html">Sainyam Galhotra</a> ; <a href="https://dblp.uni-trier.de/pid/97/7024.html">Udayan Khurana</a></p>
<p>Abstract:
Searching through large structured data is a crucial task in enterprise as well as online search. Existing keyword-based search methods were mostly designed for web document search, and support a limited variety of query types suitable for structured data. Their main underlying drawback is the lack of semantic understanding of the data and users' natural language queries, resulting in a fundamental disconnect. In this paper, we bridge that gap through effective semantic type discovery and indexing of structured data. We demonstrate S3D (Semantic Search over Structured Data), a novel system that supports queries such as finding related tables, rows or columns, amongst others, on a large scale of structured data from multiple heterogeneous sources.</p>
<p>Keywords:</p>
<h3 id="446. STREAMER: A Powerful Framework for Continuous Learning in Data Streams.">446. STREAMER: A Powerful Framework for Continuous Learning in Data Streams.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417427">Paper Link</a>    Pages:3385-3388</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/64/4063.html">Sandra Garcia-Rodriguez</a> ; <a href="https://dblp.uni-trier.de/pid/276/4989.html">Mohammad Alshaer</a> ; <a href="https://dblp.uni-trier.de/pid/28/6423.html">Cdric Gouy-Pailler</a></p>
<p>Abstract:
With the proliferation of continuous data generation, data stream processing has become a key topic in research. As a consequence, the need for dedicated tools to apply continuous learning in streams emerges. This paper presents STREAMER, a flexible, scalable, and cross-platform machine learning experimenter with a realistic operational stream environment and visualization capabilities. Oriented to data scientists, this framework provides a set of machine learning algorithms and an API to easily integrate new ones. In order to illustrate how STREAMER works, we show a demonstration of an unsupervised anomaly detection of electrocardiograms (ECG) tested in a streaming context.</p>
<p>Keywords:</p>
<h3 id="447. INforE: Interactive Cross-platform Analytics for Everyone.">447. INforE: Interactive Cross-platform Analytics for Everyone.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417435">Paper Link</a>    Pages:3389-3392</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/17/1242.html">Nikos Giatrakos</a> ; <a href="https://dblp.uni-trier.de/pid/185/2494.html">David Arnu</a> ; <a href="https://dblp.uni-trier.de/pid/276/4999.html">Theodoros Bitsakis</a> ; <a href="https://dblp.uni-trier.de/pid/d/ADeligiannakis.html">Antonios Deligiannakis</a> ; <a href="https://dblp.uni-trier.de/pid/g/MinosNGarofalakis.html">Minos N. Garofalakis</a> ; <a href="https://dblp.uni-trier.de/pid/k/RalfKlinkenberg.html">Ralf Klinkenberg</a> ; <a href="https://dblp.uni-trier.de/pid/276/5085.html">Aris Konidaris</a> ; <a href="https://dblp.uni-trier.de/pid/261/2671.html">Antonis Kontaxakis</a> ; <a href="https://dblp.uni-trier.de/pid/k/YannisKotidis.html">Yannis Kotidis</a> ; <a href="https://dblp.uni-trier.de/pid/17/5839.html">Vasilis Samoladas</a> ; <a href="https://dblp.uni-trier.de/pid/s/ASimitsis.html">Alkis Simitsis</a> ; <a href="https://dblp.uni-trier.de/pid/40/1572.html">George Stamatakis</a> ; <a href="https://dblp.uni-trier.de/pid/225/9460.html">Fabian Temme</a> ; <a href="https://dblp.uni-trier.de/pid/276/5033.html">Mate Torok</a> ; <a href="https://dblp.uni-trier.de/pid/59/10810.html">Edwin Yaqub</a> ; <a href="https://dblp.uni-trier.de/pid/122/8910.html">Arnau Montagud</a> ; <a href="https://dblp.uni-trier.de/pid/74/4153.html">Miguel Ponce de Leon</a> ; <a href="https://dblp.uni-trier.de/pid/47/3719.html">Holger Arndt</a> ; <a href="https://dblp.uni-trier.de/pid/184/9978.html">Stefan Burkard</a></p>
<p>Abstract:
We present INforE, a prototype supporting non-expert programmers in performing optimized, cross-platform, streaming analytics at scale. INforE offers: a) a new extension to the RapidMiner Studio for graphical design of Big streaming Data workflows, (b) a novel optimizer to instruct the execution of workflows across Big Data platforms and clusters, (c) a synopses data engine for interactivity at scale via the use of data summaries, (d) a distributed, online data mining and machine learning module. To our knowledge INforE is the first holistic approach in streaming settings. We demonstrate INforE in the fields of life science and financial data analysis.</p>
<p>Keywords:</p>
<h3 id="448. ArXivDigest: A Living Lab for Personalized Scientific Literature Recommendation.">448. ArXivDigest: A Living Lab for Personalized Scientific Literature Recommendation.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417417">Paper Link</a>    Pages:3393-3396</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/275/3172.html">Kristian Gingstad</a> ; <a href="https://dblp.uni-trier.de/pid/275/3463.html">yvind Jekteberg</a> ; <a href="https://dblp.uni-trier.de/pid/85/4125.html">Krisztian Balog</a></p>
<p>Abstract:
Providing personalized recommendations that are also accompanied by explanations as to why an item is recommended is a research area of growing importance. At the same time, progress is limited by the availability of open evaluation resources. In this work, we address the task of scientific literature recommendation. We present arXivDigest, which is an online service providing personalized arXiv recommendations to end users and operates as a living lab for researchers wishing to work on explainable scientific literature recommendations.</p>
<p>Keywords:</p>
<h3 id="449. Vallum-Med: Protecting Medical Data in Cloud Environments.">449. Vallum-Med: Protecting Medical Data in Cloud Environments.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417421">Paper Link</a>    Pages:3397-3400</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/257/4634.html">Ronny Peterson</a> ; <a href="https://dblp.uni-trier.de/pid/s/ASdaSilva.html">Altigran Soares da Silva</a> ; <a href="https://dblp.uni-trier.de/pid/10/480.html">Andr Carvalho</a> ; <a href="https://dblp.uni-trier.de/pid/f/ChristofFetzer.html">Christof Fetzer</a> ; <a href="https://dblp.uni-trier.de/pid/45/9936.html">Andr Martin</a> ; <a href="https://dblp.uni-trier.de/pid/05/918.html">Ignacio Blanquer</a></p>
<p>Abstract:
Despite the many advantages of cloud computing, keeping information in such an environment increases the risk of cyber attacks, as well as the possibility of unauthorized access by cloud provider employees. Another critical concern is privacy protection, since depending on data access control, confidential information may be exposed even through authorized access. To solve these issues we have previously proposed Vallum, a platform that leverages Intel SGX protection to ensure the security, confidentiality, and integrity of data at rest and during processing. It also provides tools for privacy protection, following policies set by the data owner. In this demo we present Vallum-Med, an application of Vallum for the protection of medical patient personal data, including imaging results of their cardiac examinations. We will demonstrate that this system fully supports cloud protection of such sensitive data as well as the definition of privacy policies and ensuring that all results of queries are compliant to these policies. All processing, data storage and network traffic are protected using SCONE, a docker container-based technology for seamlessly incorporating SGX protection for applications, which provides a fully encrypted memory environment.</p>
<p>Keywords:</p>
<h3 id="450. Weaving Text into Tables.">450. Weaving Text into Tables.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417442">Paper Link</a>    Pages:3401-3404</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/55/3595-1.html">Dhruv Gupta</a> ; <a href="https://dblp.uni-trier.de/pid/b/KlausBerberich.html">Klaus Berberich</a></p>
<p>Abstract:
In this paper, we showcase JIGSAW, a system that is able to shape unstructured text into structured tables for user-defined schemas. In short, to structure text into tables, JIGSAW leverages the lexico-syntactic structure imposed by linguistic annotations (e.g., part-of-speech, named entities, temporal and numerical expressions) on natural language text. We describe how challenging knowledge-centric tasks such as question answering, summarization, and analytics can be greatly simplified with the help of JIGSAW.</p>
<p>Keywords:</p>
<h3 id="451. IAI MovieBot: A Conversational Movie Recommender System.">451. IAI MovieBot: A Conversational Movie Recommender System.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417433">Paper Link</a>    Pages:3405-3408</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/274/2196.html">Javeria Habib</a> ; <a href="https://dblp.uni-trier.de/pid/83/3714-6.html">Shuo Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/85/4125.html">Krisztian Balog</a></p>
<p>Abstract:
Conversational recommender systems support users in accomplishing recommendation-related goals via multi-turn conversations. To better model dynamically changing user preferences and provide the community with a reusable development framework, we introduce IAI MovieBot, a conversational recommender system for movies. It features a task-specific dialogue flow, a multi-modal chat interface, and an effective way to deal with dynamically changing user preferences. The system is made available open source and is operated as a channel on Telegram.</p>
<p>Keywords:</p>
<h3 id="452. Exploration of Dynamic Query-Based Load Balancing for Partially Replicated Database Systems with Node Failures.">452. Exploration of Dynamic Query-Based Load Balancing for Partially Replicated Database Systems with Node Failures.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417419">Paper Link</a>    Pages:3409-3412</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/74/9320.html">Stefan Halfpap</a> ; <a href="https://dblp.uni-trier.de/pid/129/4931.html">Rainer Schlosser</a></p>
<p>Abstract:
Database replication is a mechanism to achieve scalability, for example, by executing queries independently on replica nodes. Partial replication is an approach to minimize the overall memory consumption of a replication cluster while still enabling a balanced load distribution among nodes to scale the query throughput linearly with the number of replicas. Partial replication reduces the cluster costs, speeds up data synchronization, and improves caching. However, load balancing may become skewed in the case of unexpected query distributions, unfavorable query timings, or node failures. To simulate and visualize the load balancing behavior for specific data fragment allocations, we implemented an interactive application. It allows users to retrace and evaluate the end-to-end performance of partially replicated database systems in varying experiments. Using our tool, we find that existing allocation approaches are either not memory-efficient or may result in load imbalances when nodes fail. We show that our novel robust allocation strategy achieves a better workload distribution with even less memory.</p>
<p>Keywords:</p>
<h3 id="453. TiCCo: Time-Centric Content Exploration.">453. TiCCo: Time-Centric Content Exploration.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417432">Paper Link</a>    Pages:3413-3416</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/263/5560.html">Philip Hausner</a> ; <a href="https://dblp.uni-trier.de/pid/263/5587.html">Dennis Aumiller</a> ; <a href="https://dblp.uni-trier.de/pid/g/MichaelGertz.html">Michael Gertz</a></p>
<p>Abstract:
Time is a natural way to order information and can be utilized to summarize events and to construct a chronology of contents within a document collection in many application domains. Structuring the sequence of events along a timeline allows users to grasp information at-a-glance, which enables them to get familiar with a topic in only a short amount of time and can hence support the analysis of more complicated and heterogeneous textual data. The manual construction of timelines, however, is a tedious and error-prone task, leading to static timeline representations that limit users to a passive role. In this paper, TiCCo, an automated extraction pipeline from arbitrary English and German text collections, is provided and presented to the user in an interactive manner. This puts the user in an active role in which she not only absorbs knowledge, but also influences in which ways the information is presented to her. In-depth investigations of a specific point in time are augmented by utilizing time-centric co-occurrence graphs that further summarize information extracted from a document collection, and enable users to explore the chronology of events by allowing them to interact with the constructed graphs as well as the underlying documents.</p>
<p>Keywords:</p>
<h3 id="454. Multimodal Knowledge Graph for Deep Learning Papers and Code.">454. Multimodal Knowledge Graph for Deep Learning Papers and Code.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417439">Paper Link</a>    Pages:3417-3420</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5080.html">Amar Viswanathan Kannan</a> ; <a href="https://dblp.uni-trier.de/pid/16/4728.html">Dmitriy Fradkin</a> ; <a href="https://dblp.uni-trier.de/pid/19/9970.html">Ioannis Akrotirianakis</a> ; <a href="https://dblp.uni-trier.de/pid/196/0547.html">Tugba Kulahcioglu</a> ; <a href="https://dblp.uni-trier.de/pid/03/4986.html">Arquimedes Canedo</a> ; <a href="https://dblp.uni-trier.de/pid/49/2493.html">Aditi Roy</a> ; <a href="https://dblp.uni-trier.de/pid/134/3561.html">Shih-Yuan Yu</a> ; <a href="https://dblp.uni-trier.de/pid/274/3059.html">Arnav V. Malawade</a> ; <a href="https://dblp.uni-trier.de/pid/06/1521.html">Mohammad Abdullah Al Faruque</a></p>
<p>Abstract:
Keeping up with the rapid growth of Deep Learning (DL) research is a daunting task. While existing scientific literature search systems provide text search capabilities and can identify similar papers, gaining an in-depth understanding of a new approach or an application is much more complicated. Many publications leverage multiple modalities to convey their findings and spread their ideas - they include pseudocode, tables, images and diagrams in addition to text, and often make publicly accessible their implementations. It is important to be able to represent and query them as well. We utilize RDF Knowledge graphs (KGs) to represent multimodal information and enable expressive querying over modalities. In our demo we present an approach for extracting KGs from different modalities, namely text, architecture images and source code. We show how graph queries can be used to get insights into different facets (modalities) of a paper, and its associated code implementation. Our innovation lies in the multimodal nature of the KG we create. While our work is of direct interest to DL researchers and practitioners, our approaches can also be leveraged in other scientific domains.</p>
<p>Keywords:</p>
<h3 id="455. UWKGM: A Modular Platform for Knowledge Graph Management.">455. UWKGM: A Modular Platform for Knowledge Graph Management.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417441">Paper Link</a>    Pages:3421-3424</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/124/9246.html">Natthawut Kertkeidkachorn</a> ; <a href="https://dblp.uni-trier.de/pid/141/0924.html">Rungsiman Nararatwong</a> ; <a href="https://dblp.uni-trier.de/pid/24/5382.html">Ryutaro Ichise</a></p>
<p>Abstract:
A knowledge graph becomes a central data hub in the enterprise and the research communities. Nevertheless, the development of knowledge graphs is challenging due to the insufficient functionalities of knowledge graph management platforms. In this paper, we develop a knowledge graph management platform (UWKGM). This platform enables users to integrate arbitrary functionalities as RESTful API services in order to facilitate the knowledge graph development process. In the demonstration, we highlight the main features of UWKGM and its use cases on knowledge graph management tasks.</p>
<p>Keywords:</p>
<h3 id="456. WebLens: Towards Interactive Large-scale Structured Data Profiling.">456. WebLens: Towards Interactive Large-scale Structured Data Profiling.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417443">Paper Link</a>    Pages:3425-3428</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/234/3089.html">Rituparna Khan</a> ; <a href="https://dblp.uni-trier.de/pid/10/5842.html">Michael N. Gubanov</a></p>
<p>Abstract:
Data profiling is a "set of statistical data analysis activities and processes to determine properties of a given dataset". Historically,most of the data profiling tasks were aimed at data. At scale, when a dataset has millions of tables, their meta-data (i.e. titles, attribute names and types) becomes abundant similar to data instances, and its profiling starts playing a vital role.</p>
<p>Keywords:</p>
<h3 id="457. Visualet: Visualizing Shapelets for Time Series Classification.">457. Visualet: Visualizing Shapelets for Time Series Classification.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417414">Paper Link</a>    Pages:3429-3432</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/219/5811.html">Guozhong Li</a> ; <a href="https://dblp.uni-trier.de/pid/07/1560.html">Byron Choi</a> ; <a href="https://dblp.uni-trier.de/pid/b/SSBhowmick.html">Sourav S. Bhowmick</a> ; <a href="https://dblp.uni-trier.de/pid/190/7756.html">Grace Lai-Hung Wong</a> ; <a href="https://dblp.uni-trier.de/pid/276/5019.html">Kwok-Pan Chun</a> ; <a href="https://dblp.uni-trier.de/pid/155/6942.html">Shiwen Li</a></p>
<p>Abstract:
Time series classification (TSC) has attracted considerable attention from both academia and industry. TSC methods that are based on shapelets (intuitively, small highly-discriminative subsequences have been found effective and are particularly known for their interpretability, as shapelets themselves are subsequences. A recent work has significantly improved the efficiency of shapelet discovery. For instance, the shapelets of more than 65% of the datasets in the UCR Archive (containing data from different application domains) can be computed within an hour, whereas those of 12 datasets can be computed within a minute. Such efficiency has made it possible for demo attendees to interact with shapelet discovery and explore high-quality shapelets. In this demo, we present Visualet -- a tool for visualizing shapelets, and exploring effective and interpretable ones.</p>
<p>Keywords:</p>
<h3 id="458. M-Cypher: A GQL Framework Supporting Motifs.">458. M-Cypher: A GQL Framework Supporting Motifs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417440">Paper Link</a>    Pages:3433-3436</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/50/3993.html">Xiaodong Li</a> ; <a href="https://dblp.uni-trier.de/pid/89/2619.html">Reynold Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/276/5051.html">Matin Najafi</a> ; <a href="https://dblp.uni-trier.de/pid/c/KCCChang.html">Kevin Chen-Chuan Chang</a> ; <a href="https://dblp.uni-trier.de/pid/57/10423.html">Xiaolin Han</a> ; <a href="https://dblp.uni-trier.de/pid/276/5053.html">Hongtai Cao</a></p>
<p>Abstract:
Graph databases witness the rise of Graph Query Language (GQL) in recent years, which enables non-programmers to express a graph query. However, the current solution does not support motif-related queries on knowledge graphs, which are proven important in many real-world scenarios. In this paper, we propose a GQL framework for mining knowledge graphs, named M-Cypher. It supports motif-related graph queries in an effective, efficient and user-friendly manner. We demonstrate the usage of the system by the emerging Covid-19 knowledge graph analytic tasks.</p>
<p>Keywords:</p>
<h3 id="459. AURORA: An Information Extraction System of Domain-specific Business Documents with Limited Data.">459. AURORA: An Information Extraction System of Domain-specific Business Documents with Limited Data.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417434">Paper Link</a>    Pages:3437-3440</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/119/2163.html">Minh-Tien Nguyen</a> ; <a href="https://dblp.uni-trier.de/pid/93/1039.html">Le Tien Dung</a> ; <a href="https://dblp.uni-trier.de/pid/260/0583.html">Le Thai Linh</a> ; <a href="https://dblp.uni-trier.de/pid/188/0455.html">Nguyen Hong Son</a> ; <a href="https://dblp.uni-trier.de/pid/276/5003.html">Do Hoang Thai Duong</a> ; <a href="https://dblp.uni-trier.de/pid/266/7640.html">Bui Cong Minh</a> ; <a href="https://dblp.uni-trier.de/pid/276/4991.html">Nguyen Hai Phong</a> ; <a href="https://dblp.uni-trier.de/pid/143/3204.html">Nguyen Huu Hiep</a></p>
<p>Abstract:
Information extraction is a well-known topic that plays a critical role in many NLP applications as its outputs can be considered as an entrance step for digital transformation. However, there still exist gaps when applying research results to actual business cases. This paper introduces AURORA, an information extraction for domain-specific business documents. The intuition of AURORA is to use transfer learning for extraction. To do that, it utilizes the power of transformers for dealing with the limitation of training data in business cases and stacks additional layers for domain adaptation. We demonstrate AURORA in the context of actual scenarios where users are invited to experience two functions: fine-grained and whole paragraph extraction of Japanese business documents. A video of the system is available at <a href="http://y2u.be/xHQpYE41Tqw">http://y2u.be/xHQpYE41Tqw</a>.</p>
<p>Keywords:</p>
<h3 id="460. PrivacyCheck v2: A Tool that Recaps Privacy Policies for You.">460. PrivacyCheck v2: A Tool that Recaps Privacy Policies for You.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417469">Paper Link</a>    Pages:3441-3444</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/99/7855.html">Razieh Nokhbeh Zaeem</a> ; <a href="https://dblp.uni-trier.de/pid/276/5076.html">Safa Anya</a> ; <a href="https://dblp.uni-trier.de/pid/276/5057.html">Alex Issa</a> ; <a href="https://dblp.uni-trier.de/pid/276/5120.html">Jake Nimergood</a> ; <a href="https://dblp.uni-trier.de/pid/276/5005.html">Isabelle Rogers</a> ; <a href="https://dblp.uni-trier.de/pid/62/2641.html">Vinay Shah</a> ; <a href="https://dblp.uni-trier.de/pid/249/4511.html">Ayush Srivastava</a> ; <a href="https://dblp.uni-trier.de/pid/b/KSuzanneBarber.html">K. Suzanne Barber</a></p>
<p>Abstract:
Despite the efforts to regulate privacy policies to protect user privacy, these policies remain lengthy and hard to comprehend. Powered by machine learning, our publicly available browser extension, PrivacyCheck v2, automatically summarizes any privacy policy by answering 20 questions based upon User Control and the General Data Protection Regulation. Furthermore, PrivacyCheck v2 incorporates a competitor analysis tool that highlights the top competitors with the best privacy policies in the same market sector. PrivacyCheck v2 enhances the users' understanding of privacy policies and empowers them to make informed decisions when it comes to selecting services with better privacy policies.</p>
<p>Keywords:</p>
<h3 id="461. Inside Quasimodo: Exploring Construction and Usage of Commonsense Knowledge.">461. Inside Quasimodo: Exploring Construction and Usage of Commonsense Knowledge.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417416">Paper Link</a>    Pages:3445-3448</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/241/9678.html">Julien Romero</a> ; <a href="https://dblp.uni-trier.de/pid/48/10142.html">Simon Razniewski</a></p>
<p>Abstract:
Quasimodo is an open-source commonsense knowledge base that significantly advanced the state of salient commonsense knowledge base construction. It introduced a pipeline that gathers, normalizes, validates and scores statements coming from query log and question answering forums. In this demonstration, we present a companion web portal which allows (i) to explore the data, (ii) to run and analyze the extraction pipeline live, and (iii) inspect the usage of Quasimodo's knowledge in several downstream use cases. The web portal is available at <a href="https://quasimodo.r2.enst.fr">https://quasimodo.r2.enst.fr</a>.</p>
<p>Keywords:</p>
<h3 id="462. Computing and Illustrating Query Rewritings on Path Views with Binding Patterns.">462. Computing and Illustrating Query Rewritings on Path Views with Binding Patterns.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417431">Paper Link</a>    Pages:3449-3452</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/241/9678.html">Julien Romero</a> ; <a href="https://dblp.uni-trier.de/pid/05/2471.html">Nicoleta Preda</a> ; <a href="https://dblp.uni-trier.de/pid/56/9687.html">Antoine Amarilli</a> ; <a href="https://dblp.uni-trier.de/pid/13/1396.html">Fabian M. Suchanek</a></p>
<p>Abstract:
In this system demonstration, we study views with binding patterns, which are a formalization of REST Web services. Such views are database queries that can be evaluated using the service, but only if values for the input variables are provided. We investigate how to use such views to answer a complex user query, by rewriting it as an execution plan, i.e., an orchestration of calls to the views. In general, it is undecidable to determine whether a given user query can be answered with the available views. In this demo, we illustrate a particular scenario studied in our earlier work [11], where the problem is not only decidable but has a particularly intuitive graphical solution. Our demo allows users to play with views defined by real Web services, and to animate the construction of execution plans visually.</p>
<p>Keywords:</p>
<h3 id="463. A Toolkit for Managing Multiple Crowdsourced Top-K Queries.">463. A Toolkit for Managing Multiple Crowdsourced Top-K Queries.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417415">Paper Link</a>    Pages:3453-3456</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/193/1652.html">Caihua Shan</a> ; <a href="https://dblp.uni-trier.de/pid/38/4996.html">Leong Hou U</a> ; <a href="https://dblp.uni-trier.de/pid/34/6253.html">Nikos Mamoulis</a> ; <a href="https://dblp.uni-trier.de/pid/89/2619.html">Reynold Cheng</a></p>
<p>Abstract:
Crowdsourced ranking and top-k queries have attracted significant attention recently. Their goal is to combine human cognitive abilities and machine intelligence to rank computer hostile but human friendly items. Many task assignment algorithms and inference approaches have been proposed to publish suitable micro-tasks to the crowd, obtain informative answers, and aggregate the rank from noisy human answers. However, they are all focused on single query processing. To the best of our knowledge, no prior work helps users manage multiple crowdsourced top-k queries. We propose a toolkit, which seamlessly works with most existing inference and task assignment methods, for crowdsourced top-k query management. Our toolkit attempts to optimize human resource allocation and continuously monitors query quality at any stage of the crowdsourcing process. A user can terminate a query early, if the estimated quality already fulfills her requirements. Besides, the toolkit provides user-friendly interfaces for users to initialize queries, monitor execution status, and do more operations by hand.</p>
<p>Keywords:</p>
<h3 id="464. User and Context Integrated Experience Mining in Online Health Communities.">464. User and Context Integrated Experience Mining in Online Health Communities.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417410">Paper Link</a>    Pages:3457-3460</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/215/5774.html">Jinhe Shi</a> ; <a href="https://dblp.uni-trier.de/pid/88/6466-1.html">Yi Chen</a></p>
<p>Abstract:
Online Health Communities (OHCs) provide a platform for patients, caregivers, and researchers to exchange information and support each other. Identifying information that describes patient health experiences in OHCs has many important applications, such as trustworthy knowledge discovery and recommendation. To identify patient experience description, we observe that the same word may have different strengths as an indicator of patient experiences when written by different users. Based on this observation, we propose a User-Word Context Vector model, that holistically captures linguistic features of text, user information and context information to classify patient experiences in OHCs. Experimental evaluation shows that the proposed method significantly outperforms the existing methods on patient experience classification.</p>
<p>Keywords:</p>
<h3 id="465. Attribution IQ: Scalable Game Theoretic Attribution in Web Analytics.">465. Attribution IQ: Scalable Game Theoretic Attribution in Web Analytics.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417437">Paper Link</a>    Pages:3461-3464</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/127/3163.html">Ritwik Sinha</a> ; <a href="https://dblp.uni-trier.de/pid/276/5106.html">Ivan Andrus</a> ; <a href="https://dblp.uni-trier.de/pid/276/5111.html">Trevor Paulsen</a></p>
<p>Abstract:
Attribution in digital marketing is the task of assigning the credit due to each marketing interaction toward a marketing outcome. Such information helps the brand decide on marketing strategies for the future. In web analytics, attribution goes beyond marketing channels, and can be performed across a broad range of dimensions (e.g. images displayed on a website). This requires attribution algorithms to operate on dimensions with a large number of dimensional elements (hundreds of thousands in the extreme). Additionally, given the many possible metrics a marketer may be interested in, it is infeasible to perform ahead of time computation for all combinations. In this work, we propose a game theoretic attribution model that can be computed at query-time. Our demo of Attribution IQ runs in the Adobe Analytics production system. Our system is highly scalable (it operates on millions of customer journeys), interactive (the user can change the parameters and get updated results instantaneously) and requires no pre-computation (all computation being performed at query time). We demonstrate the effectiveness of Attribution IQ on real-world e-commerce web analytics datasets.</p>
<p>Keywords:</p>
<h3 id="466. April: An Automatic Graph Data Management System Based on Reinforcement Learning.">466. April: An Automatic Graph Data Management System Based on Reinforcement Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417422">Paper Link</a>    Pages:3465-3468</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/81/940.html">Hongzhi Wang</a> ; <a href="https://dblp.uni-trier.de/pid/08/8996.html">Zhixin Qi</a> ; <a href="https://dblp.uni-trier.de/pid/86/5344.html">Lei Zheng</a> ; <a href="https://dblp.uni-trier.de/pid/59/7842.html">Yun Feng</a> ; <a href="https://dblp.uni-trier.de/pid/276/5112.html">Junfei Ouyang</a> ; <a href="https://dblp.uni-trier.de/pid/65/7161.html">Haoqi Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5066.html">Xiangxi Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5056.html">Ziming Shen</a> ; <a href="https://dblp.uni-trier.de/pid/54/183.html">Shirong Liu</a></p>
<p>Abstract:
The great amount and complex structure of graph data bring a big challenge to graph data management. However, traditional management approaches cannot tackle the challenge. Fortunately, reinforcement learning provides a new approach to solve this problem due to its automation and adaptivity in decision making. Motivated by this, we develop April, an automatic graph data management system, which performs storage structure selection, index selection, and query optimization based on reinforcement learning. The system selects storage structure, indices effectively and automatically, and optimizes the SPARQL queries efficiently. April also offers a friendly interface for users, which allows users to interact with the system in a customized mode. We demonstrate the effectiveness and efficiency of April with two graph data benchmarks.</p>
<p>Keywords:</p>
<h3 id="467. Active Hazard Observation via Human in the Loop Social Media Analytics System.">467. Active Hazard Observation via Human in the Loop Social Media Analytics System.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417430">Paper Link</a>    Pages:3469-3472</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/142/7794.html">Zhenyu Wen</a> ; <a href="https://dblp.uni-trier.de/pid/54/984.html">Jedsada Phengsuwan</a> ; <a href="https://dblp.uni-trier.de/pid/249/2470.html">Nipun Balan Thekkummal</a> ; <a href="https://dblp.uni-trier.de/pid/01/3595.html">Rui Sun</a> ; <a href="https://dblp.uni-trier.de/pid/276/5024.html">Pooja jamathi-Chidananda</a> ; <a href="https://dblp.uni-trier.de/pid/142/7854.html">Tejal Shah</a> ; <a href="https://dblp.uni-trier.de/pid/33/1082.html">Philip James</a> ; <a href="https://dblp.uni-trier.de/pid/68/163.html">Rajiv Ranjan</a></p>
<p>Abstract:
We demonstrate AHOM, a system that can Actively Observe Hazards via Monitoring Social Media Streams. AHOM proposes an active way to include the human in the loop of hazard information ac-quisition for social media. Different from state of the art, it supports bi-directional interaction between social media data processing system and social media users, which leads to the establishment of deeper and more accurate situational awareness of hazard events. We demonstrate how AHOM utilizes Twitter streams and bi-directional information exchange with social media users for enhanced hazard observation.</p>
<p>Keywords:</p>
<h3 id="468. UI-FAME.">468. UI-FAME.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417412">Paper Link</a>    Pages:3473-3476</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/54/2088.html">Xuan Wu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5094.html">Wenxing Deng</a> ; <a href="https://dblp.uni-trier.de/pid/10/10150.html">Chang Lu</a> ; <a href="https://dblp.uni-trier.de/pid/46/4184.html">Hao Feng</a> ; <a href="https://dblp.uni-trier.de/pid/163/5197.html">Yizheng Zhao</a></p>
<p>Abstract:
This paper describes a Java-based forgetting system UI-FAME for creating views of ontologies. In relational databases, a view is a subset of the database, while in ontologies, a view is more than a subset; it contains not only axioms that are contained in the original ontology, but also newly-derived axioms that are entailed by the original ontology. Forgetting is a form of non-standard reasoning that can be used to create views of ontologies by eliminating from the ontologies a set of concept and role names, namely the forgetting signature, while keeping all logical consequences over the names in the remaining signature. We compared UI-FAME with publicly accessible forgetting systems, namely LETHE and an early prototypical version of UI-FAME, over the 'AL'-TBox fragment of 494 ontologies taken from the Oxford Ontology Library. The results showed that UI-FAME had better success rates than LETHE and its prototypical version, and outsped LETHE by a large margin. UI-FAME has been integrated as back-end support in Babylon Health's (a leading digital healthcare company based in London) knowledge base (formed by the merger and alignment of medical ontologies from different sources) interfaces for their main concerns of ontology analysis and keeping track of the changes in different versions of its knowledge base.</p>
<p>Keywords:</p>
<h3 id="469. InterNet: Multistep Traffic Forecasting by Interacting Spatial and Temporal Features.">469. InterNet: Multistep Traffic Forecasting by Interacting Spatial and Temporal Features.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417411">Paper Link</a>    Pages:3477-3480</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/239/4458.html">Yilian Xin</a> ; <a href="https://dblp.uni-trier.de/pid/276/5082.html">Dezhuang Miao</a> ; <a href="https://dblp.uni-trier.de/pid/z/MengxiaZhu.html">Mengxia Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/41/2511.html">Cheqing Jin</a> ; <a href="https://dblp.uni-trier.de/pid/63/3963.html">Xuesong Lu</a></p>
<p>Abstract:
Traffic forecasting on the entire road network is challenging due to the non-linear temporal dynamics and complex spatial correlations. Multi-step traffic forecasting further increases the difficulty because of the accumulated prediction errors. Existing forecasting models attempt to extract both spatial and temporal features of all locations on the road network for prediction, but often overlook the interaction between the two types of features, which has led to sub-optimal performance. In this work, we tackle this problem by proposing InterNet, which applies the multi-head attention mechanism on the extracted spatio-temporal features and enables the interaction of the spatial (temporal) features of one location with the temporal (spatial) features of all locations. Moreover, we extract the features of all locations using a graph convolutional layer and a bidirectional LSTM layer, before feeding them into the multi-head attention layer. The three layers are seamlessly integrated and thereby enable end-to-end learning. Experimental results show that the InterNet model outperforms the state-of-the-art models in terms of the prediction accuracy, which demonstrates the potential of such interactions.</p>
<p>Keywords:</p>
<h3 id="470. Sample Driven Data Mapping for Linked Data and Web APIs.">470. Sample Driven Data Mapping for Linked Data and Web APIs.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417438">Paper Link</a>    Pages:3481-3484</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/241/3046.html">Tobias Zeimetz</a> ; <a href="https://dblp.uni-trier.de/pid/s/RalfSchenkel.html">Ralf Schenkel</a></p>
<p>Abstract:
In order to create the most comprehensive RDF Knowledge Base possible, data integration is essential. Many different data sources are used to extend a given dataset or to correct errors in the data. Nowadays, Web APIs (instead of data dumps) are common external data sources, since many data providers make their data publicly available. However, the classic problems of data integration, i.e., which parts of the datasets can be mapped, remain. In addition, Web APIs are often more restrictive than data dumps and of course slower to access due to latencies and other constraints. In this paper we demonstrate the FiLiPo (Finding Linkage Points) system to automatically find connections (i.e., linkage points) between Web APIs and local Knowledge Bases in a reasonable amount of time. To this end, we developed a sample-driven schema matching system, which models Web API services as parameterized queries. These Web API services return a view definition of their data which subsequently need to be connected to the local database scheme. Furthermore, our approach is able to find valid input values for Web API services automatically (e.g. IDs) and can determine combined linkage points (e.g. first and last name) despite different structures. Our results on six real world API services with two local databases show that our linkage point detection algorithm performs well in terms of precision (0.89 up to 1.0) and recall (0.69 up to 1.0).</p>
<p>Keywords:</p>
<h3 id="471. EasyGML: A Fully-functional and Easy-to-use Platform for Industrial Graph Machine Learning.">471. EasyGML: A Fully-functional and Easy-to-use Platform for Industrial Graph Machine Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417423">Paper Link</a>    Pages:3485-3488</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/67/2010.html">Zhiqiang Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/99/3847.html">Jun Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/64/3041.html">Chuan Shi</a></p>
<p>Abstract:
Despite the great success of Graph Machine Learning (GML) in a variety of applications, the industry is still seeking a platform which makes performing industrial-purpose GML convenient. In this demo, we present EasyGML, a fully-functional and easy-to-use platform for general AI practitioners to apply out-of-the-box GML models in industrial scenarios. Leveraging the distributed data warehouse as its data infrastructure, EasyGML adopts AGL, an integrated system for industrial-purpose graph learning, as its core GML engine, and develops a model zoo containing various GML models, supporting both node property prediction and link property prediction. It packs different steps of GML workflow into different components, and provides a user-friendly web-based GUI for users to build their GML workflows simply by connecting several components together, without any coding.</p>
<p>Keywords:</p>
<h3 id="472. SemFE: Facilitating ML Pipeline Development with Semantics.">472. SemFE: Facilitating ML Pipeline Development with Semantics.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417436">Paper Link</a>    Pages:3489-3492</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/276/5109.html">Baifan Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/207/3564.html">Yulia Svetashova</a> ; <a href="https://dblp.uni-trier.de/pid/198/4369.html">Tim Pychynski</a> ; <a href="https://dblp.uni-trier.de/pid/276/5129.html">Ildar Baimuratov</a> ; <a href="https://dblp.uni-trier.de/pid/68/2047.html">Ahmet Soylu</a> ; <a href="https://dblp.uni-trier.de/pid/20/4833.html">Evgeny Kharlamov</a></p>
<p>Abstract:
Machine learning (ML) based data analysis has attracted an increasing attention in the manufacturing industry, however, many challenges hamper their wide spread adoption. The main challenges are the high costs of labour-intensive data preparation from diverse sources and processes, the asymmetrical backgrounds of the experts involved in manufacturing analyses that impede efficient communication between them, and the lack of generalisability of ML models tailored to specific applications. Our semantically enhanced ML pipeline, SemFE, with feature engineering addresses these challenges, serving as a bridge to bring the endeavours of experts together, and making data science accessible to non-ML-experts. SemFE relies on ontologies for discrete manufacturing monitoring that encapsulate domain and ML knowledge; it has five novel semantic modules for automation of ML-pipeline development and user-friendly GUIs. The demo attendees will be able to use our system to build manufacturing monitoring ML pipelines, and to design their own pipelines with minimal prior knowledge of machine learning.</p>
<p>Keywords:</p>
<h3 id="473. Active Search using Meta-Bandits.">473. Active Search using Meta-Bandits.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417409">Paper Link</a>    Pages:3493-3496</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/198/6066.html">Shengli Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/276/5022.html">Jakob Coles</a> ; <a href="https://dblp.uni-trier.de/pid/67/1229.html">Sihong Xie</a></p>
<p>Abstract:
There are many applications where positive instances are rare but important to identify. For example, in NLP, positive sentences for a given relation are rare in a large corpus. Positive data are more informative for learning in these applications, but before one labels a certain amount of data, it is unknown where to find the rare positives. Since random sampling can lead to significant waste in labeling effort, previous 'active search' methods use a single bandit model to learn about the data distribution (exploration) while sampling from the regions potentially containing more positives (exploitation). Many bandit models are possible and a sub-optimal model reduces labeling efficiency, but the optimal model is unknown before any data are labeled. We propose Meta-AS (Meta Active Search) that uses a meta-bandit to evaluate a set of base bandits and aims to label positive examples efficiently, comparing to the optimal base bandit with hindsight. The meta-bandit estimates the mean and variance of the performance of the base bandits and selects a base bandit to propose what data to label next for exploration or exploitation. The feedback in the labels updates both the base bandits and the meta-bandit for the next round. Meta-AS can accommodate a diverse set of base bandits to explore assumptions about the dataset, without over-committing to a single model before labeling starts. Experiments on five datasets for relation extraction demonstrate that Meta-AS labels positives more efficiently than the base bandits and other bandit selection strategies.</p>
<p>Keywords:</p>
<h3 id="474. Towards Rich Qery Blockchain Database.">474. Towards Rich Qery Blockchain Database.</h3>
<p><a href="https://doi.org/10.1145/3340531.3417424">Paper Link</a>    Pages:3497-3500</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/145/0627.html">Yanchao Zhu</a> ; <a href="https://dblp.uni-trier.de/pid/87/6853.html">Zhao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/41/2511.html">Cheqing Jin</a> ; <a href="https://dblp.uni-trier.de/pid/z/AoyingZhou.html">Aoying Zhou</a> ; <a href="https://dblp.uni-trier.de/pid/89/1853.html">Gang Qin</a> ; <a href="https://dblp.uni-trier.de/pid/96/171.html">Yingjie Yang</a></p>
<p>Abstract:
In this demo, we present SEBDB, a novel blockchain database that integrates immutability and transparency properties of blockchain with modeling and query ability of relational database. In summary, SEBDB has the following advantages: First, it adopts the linked structure and full replication of data among multiple participants to guarantee immutability and transparency. Second, it introduces the relational model to blockchain without introducing extra overhead, based on which relational queries are supported. SEBDB supports SQL-like language as the general interface to support convenient application development, in which intrinsic operations are re-defined and re-implemented to suit for blockchain platform. Third, it supports rich verifiable queries based on the proposed authenticated index, thin clients can participate in the system regardless of limitations of storage, network, and computing resources. We demonstrate the usability and scalability of SEBDB using a donation system.</p>
<p>Keywords:</p>
<h2 id="Tutorials    11">Tutorials    11</h2>
<h3 id="475. Neural Bayesian Information Processing.">475. Neural Bayesian Information Processing.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412170">Paper Link</a>    Pages:3501-3502</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/03/3569.html">Jen-Tzung Chien</a></p>
<p>Abstract:
Deep learning is developed as a learning process from source inputs to target outputs where the inference or optimization is performed over an assumed deterministic model with deep structure. A wide range of temporal and spatial data in language and vision are treated as the inputs or outputs to build such a complicated mapping in different information systems. A systematic and elaborate transfer is required to meet the mapping between source and target domains. Also, the semantic structure in natural language and computer vision may not be well represented or trained in mathematical logic or computer programs. The distribution function in discrete or continuous latent variable model for words, sentences, images or videos may not be properly decomposed or estimated. The system robustness to heterogeneous environments may not be assured. This tutorial addresses the fundamentals and advances in statistical models and neural networks, and presents a series of deep Bayesian solutions including variational Bayes, sampling method, Bayesian neural network, variational auto-encoder (VAE), stochastic recurrent neural network, sequence-to-sequence model, attention mechanism, end-to-end network, stochastic temporal convolutional network, temporal difference VAE, normalizing flow and neural ordinary differential equation. Enhancing the prior/posterior representation is addressed in different latent variable models. We illustrate how these models are connected and why they work for a variety of applications on complex patterns in language and vision. The word, sentence and image embeddings are merged with semantic constraint or structural information. Bayesian learning is formulated in the optimization procedure where the posterior collapse is tackled. An informative latent space is trained to incorporate deep Bayesian learning in various information systems.</p>
<p>Keywords:</p>
<h3 id="476. The Battle Against Online Harmful Information: The Cases of Fake News and Hate Speech.">476. The Battle Against Online Harmful Information: The Cases of Fake News and Hate Speech.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412169">Paper Link</a>    Pages:3503-3504</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/118/3830.html">Anastasia Giachanou</a> ; <a href="https://dblp.uni-trier.de/pid/05/3463.html">Paolo Rosso</a></p>
<p>Abstract:
Social media have given the opportunity to users to express their opinions online in a fast and easy way. The ease of generating content online and the anonymity that social media provide have increased the amount of harmful content that is published. This tutorial will focus on the topic of online harmful information. First, we will analyse and explain the different types of online harmful information with a particular focus on fake news and hate speech. In addition, we will explain the different computational approaches proposed in the literature for the detection of fake news and hate speech. Next, we will present details regarding the evaluation process, datasets and shared tasks and finally, we will discuss future directions in the field of online harmful information detection.</p>
<p>Keywords:</p>
<h3 id="477. Multi-Model Data Query Languages and Processing Paradigms.">477. Multi-Model Data Query Languages and Processing Paradigms.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412174">Paper Link</a>    Pages:3505-3506</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/132/8622.html">Qingsong Guo</a> ; <a href="https://dblp.uni-trier.de/pid/l/JiahengLu.html">Jiaheng Lu</a> ; <a href="https://dblp.uni-trier.de/pid/94/3019.html">Chao Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/276/5028.html">Calvin Sun</a> ; <a href="https://dblp.uni-trier.de/pid/211/1249.html">Steven Yuan</a></p>
<p>Abstract:
Specifying users' interests with a formal query language is a typically challenging task, which becomes even harder in the context of multi-model data management because we have to deal with data variety. It usually lacks a unified schema to help the users issuing their queries, or has an incomplete schema as data come from disparate sources. Multi-Model DataBases (MMDBs) have emerged as a promising approach for dealing with this task as they are capable of accommodating and querying the multi-model data in a single system. This tutorial aims to offer a comprehensive presentation of a wide range of query languages for MMDBs and to make comparisons of their properties from multiple perspectives. We will discuss the essence of cross-model query processing and provide insights on the research challenges and directions for future work. The tutorial will also offer the participants hands-on experience in applying MMDBs to issue multi-model data queries.</p>
<p>Keywords:</p>
<h3 id="478. Compression of Deep Learning Models for NLP.">478. Compression of Deep Learning Models for NLP.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412171">Paper Link</a>    Pages:3507-3508</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/181/2823.html">Manish Gupta</a> ; <a href="https://dblp.uni-trier.de/pid/03/4045.html">Vasudeva Varma</a> ; <a href="https://dblp.uni-trier.de/pid/228/9373.html">Sonam Damani</a> ; <a href="https://dblp.uni-trier.de/pid/198/5513.html">Kedhar Nath Narahari</a></p>
<p>Abstract:
In recent years, the fields of NLP and information retrieval have made tremendous progress thanks to deep learning models like RNNs and LSTMs, and Transformer[35] based models like BERT[9]. But these models are humongous in size. Real world applications however demand small model size, low response times and low computational power wattage. We will discuss six different types of methods (pruning, quantization, knowledge distillation, parameter sharing, matrix decomposition, and other Transformer based methods) for compression of such models to enable their deployment in real industry NLP projects. Given the critical need of building applications with efficient and small models, and the large amount of recently published work in this area, we believe that this tutorial is very timely. We will organize related work done by the 'deep learning for NLP' community in the past few years and present it as a coherent story.</p>
<p>Keywords:</p>
<h3 id="479. Knowledge Graphs: A Tutorial on the History of Knowledge Graph's Main Ideas.">479. Knowledge Graphs: A Tutorial on the History of Knowledge Graph's Main Ideas.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412176">Paper Link</a>    Pages:3509-3510</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/g/ClaudioGutierrez.html">Claudio Gutierrez</a> ; <a href="https://dblp.uni-trier.de/pid/93/3423.html">Juan F. Sequeda</a></p>
<p>Abstract:
Knowledge Graphs can be considered as fulfilling an early vision in Computer Science of creating intelligent systems that integrate knowledge and data at large scale. Stemming from scientific advancements in research areas of Semantic Web, Databases, Knowledge representation, NLP, Machine Learning, among others, Knowledge Graphs have rapidly gained popularity in academia and industry in the past years. The integration of such disparate disciplines and techniques give the richness to Knowledge Graphs, but also present the challenge to practitioners and theoreticians to know how current advances develop from early techniques in order, on one hand, take full advantage of them, and on the other, avoid reinventing the wheel. This tutorial will provide a historical context on the roots of Knowledge Graphs grounded in the advancements of Logic, Data and the combination thereof.</p>
<p>Keywords:</p>
<h3 id="480. Fairness in Unsupervised Learning.">480. Fairness in Unsupervised Learning.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412175">Paper Link</a>    Pages:3511-3512</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/33/1882.html">Deepak P</a> ; <a href="https://dblp.uni-trier.de/pid/84/5102.html">Joemon M. Jose</a> ; <a href="https://dblp.uni-trier.de/pid/276/5089.html">Sanil V</a></p>
<p>Abstract:
Data in digital form is expanding at an exponential rate, far outpacing any chance of getting any significant fraction labelled manually. This has resulted in heightened research emphasis on unsupervised learning, learning in the absence of labels. In fact, unsupervised learning has been often dubbed as the next frontier of AI. Unsupervised learning is the most plausible model to analyze the bulk of passively collected data that spans across various domains; e.g., social media footprints, safety/surveilance cameras, IoT devices, sensors, smartphone apps, medical wearables, traffic sensing devices and public wi-fi access. While fairness in supervised learning, such as classification tasks, has inspired a large amount of research in the past few years, work on fair unsupervised learning has been relatively slow in picking up. This tutorial targets to provide an overview of: (i) fairness issues in unsupervised learning drawing abundantly from political philosophy, (ii) current research in fair unsupervised learning, and (iii) new directions to extend the state-of-the-art in fair unsupervised learning. While we intend to broadly cover all tasks in unsupervised learning, our focus will be on clustering, retrieval and representation learning. In a unique departure from conventional data science tutorials, we will place significant emphasis on presenting and debating pertinent literature from ethics and philosophy. Overall, this half-day tutorial brings a strong emphasis on ensuring strong interdisciplinarity.</p>
<p>Keywords:</p>
<h3 id="481. Challenges and Solutions to the Student Dropout Prediction Problem in Online Courses.">481. Challenges and Solutions to the Student Dropout Prediction Problem in Online Courses.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412172">Paper Link</a>    Pages:3513-3514</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/211/9434.html">Bardh Prenkaj</a> ; <a href="https://dblp.uni-trier.de/pid/83/2005.html">Giovanni Stilo</a> ; <a href="https://dblp.uni-trier.de/pid/258/4667.html">Lorenzo Madeddu</a></p>
<p>Abstract:
Online courses and e-degrees, although present since the mid-1990, have received enormous attention only in the last decade. Moreover, the new Coronavirus disease (COVID-19) outbreak forced many nations (e.g. Italy, the US, and other countries) to massively push their education system towards an online environment. Academics now are also looking at the crisis as an opportunity for universities to adopt digital technologies for teaching more broadly. But they will have to understand what possible ways of evaluating and effectively teaching will be in this new scenario. The depicted overview, in conjunction with the utility and ubiquitous access to the educational platforms of online courses, entails a vast amount of enrolments. Nevertheless, a high enrolment rate usually translates into a significant dropout (or withdrawal) rate of students (40-80% of online students drop out). Student dropout prediction (SDP) consists of modelling and fore-casting student behaviour when interacting with e-learning platforms. It is a significant phenomenon that has repercussions on online institutions, the involved students and professors. Early approaches tended to perform manual analytic examinations to devise retention strategies. Recent research has adopted automated policies to thoroughly exploit the advantages of student activities(hereafter e-tivities) in the e-platforms and identify at-risk students. These approaches include machine learning and deep learning techniques to predict the student dropout status. Therefore, being able to cope with the trend shifting of student interactions with the course platforms in real-time has become of paramount importance. In this tutorial, we comprehensively overview the SDP problem in the literature. We provide mathematical formalisation to the different definitions proposed, and we introduce simple and complex predictive methods adhering to the following: Student dropout definition, Input modelling, Underlying machine and deep learning techniques, Evaluation measures, Datasets, and privacy concerns.</p>
<p>Keywords:</p>
<h3 id="482. Introduction to Computer Vision and Realtime Deep Learning-based Object Detection.">482. Introduction to Computer Vision and Realtime Deep Learning-based Object Detection.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412177">Paper Link</a>    Pages:3515-3516</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/88/5622.html">James G. Shanahan</a></p>
<p>Abstract:
The main focus of object detection, one of the most challenging problems in computer vision (CV), is to predict a set of bounding boxes and category labels for each object of interest in an image or in a point cloud. As such, object detection has a variety of exciting downstream applications such as self-driving cars, checkout-less shopping, smart cities, cancer detection, and more. This field has been revolutionized by deep learning over the past five years, where during this time, two-stage approaches to object detection have given way to simpler, more efficient, one-stage models. Mean average precision (mAP) on benchmark problems such as the COCO Object Detection dataset has improved almost 4X over the course of five years from 15% (Fast RCNN, a two-stage approach) to 55% (EfficientDet7x, a one-stage approach). This tutorial looks under the hood of state-of-the-art object detection systems, such as two-stage, one-stage, and also more recent approaches based upon transformers. It builds out some of their associated detection pipelines in a Jupyter Notebook using Python, OpenCV, PyTorch, Keras and Tensorflow. While the primary focus is on object detection in digital images from cameras and videos, this tutorial will also introduce object detection in 3D point clouds.</p>
<p>Keywords:</p>
<h3 id="483. IoT Data Quality.">483. IoT Data Quality.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412173">Paper Link</a>    Pages:3517-3518</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/20/3883.html">Shaoxu Song</a> ; <a href="https://dblp.uni-trier.de/pid/163/0449.html">Aoqian Zhang</a></p>
<p>Abstract:
Data quality issues have been widely recognized in IoT data, and prevent the downstream applications. In this tutorial, we review the state-of-the-art techniques for IoT data quality management. In particular, we discuss how the dedicated approaches improve various data quality dimensions, including validity, completeness and consistency. Among others, we further highlight the recent advances by deep learning techniques for IoT data quality. Finally, we indicate the open problems in IoT data quality management, such as benchmark or interpretation of data quality issues.</p>
<p>Keywords:</p>
<h3 id="484. Mining User Interests from Social Media.">484. Mining User Interests from Social Media.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412167">Paper Link</a>    Pages:3519-3520</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/152/9311.html">Fattane Zarrinkalam</a> ; <a href="https://dblp.uni-trier.de/pid/177/5856.html">Guangyuan Piao</a> ; <a href="https://dblp.uni-trier.de/pid/06/5387.html">Stefano Faralli</a> ; <a href="https://dblp.uni-trier.de/pid/25/806.html">Ebrahim Bagheri</a></p>
<p>Abstract:
Social media users readily share their preferences, life events, sentiment and opinions, and implicitly signal their thoughts, feelings, and psychological behavior. This makes social media a viable source of information to accurately and effectively mine users' interests with the hopes of enabling more effective user engagement, better quality delivery of appropriate services and higher user satisfaction. In this tutorial, we cover five important aspects related to the effective mining of user interests: (1) the foundations of social user interest modeling, such as information sources, various types of representation models and temporal features, (2) techniques that have been adopted or proposed for mining user interests, (3) different evaluation methodologies and benchmark datasets, (4) different applications that have been taking advantage of user interest mining from social media platforms, and (5) existing challenges, open research questions and exciting opportunities for further work.</p>
<p>Keywords:</p>
<h3 id="485. Network Alignment: Recent Advances and Future Directions.">485. Network Alignment: Recent Advances and Future Directions.</h3>
<p><a href="https://doi.org/10.1145/3340531.3412168">Paper Link</a>    Pages:3521-3522</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/119/2063.html">Si Zhang</a> ; <a href="https://dblp.uni-trier.de/pid/58/1757.html">Hanghang Tong</a></p>
<p>Abstract:
In the era of big data, networks are often from multiple sources such as the social networks of diverse platforms (e.g., Facebook, Twitter), protein-protein interaction (PPI) networks of different tissues, transaction networks at multiple financial institutes and knowledge graphs derived from a variety of knowledge bases (e.g., DBpedia, Freebase, etc.). The very first step before exploring insights from these multi-sourced networks is to integrate and unify different networks. In general, network alignment is such a task that aims to uncover the correspondences among nodes across different graphs. The challenges of network alignment include: (1) the heterogeneity of the multi-sourced networks, e.g., different structural patterns, (2) the variety of the real-world networks, e.g., how to leverage the rich contextual information, and (3) the computational complexity. The goal of this tutorial is to (1) provide a comprehensive overview of the recent advances in network alignment, and (2) identify the open challenges and future trends. We believe this can be beneficial to numerous application problems, and attract both researchers and practitioners from both data mining area and other interdisciplinary areas. In particular, we start with introducing the backgrounds, problem definition and key challenges of network alignment. Next, our emphases will be on (1) the recent techniques on addressing network alignment problem and other related problems with a careful balance between the algorithms and applications, and (2) the open challenges and future trends.</p>
<p>Keywords:</p>
<h2 id="Workshop Summaries    9">Workshop Summaries    9</h2>
<h3 id="486. CSSA'20: Workshop on Combining Symbolic and Sub-Symbolic Methods and their Applications.">486. CSSA'20: Workshop on Combining Symbolic and Sub-Symbolic Methods and their Applications.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414072">Paper Link</a>    Pages:3523-3524</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/68/8155.html">Mehwish Alam</a> ; <a href="https://dblp.uni-trier.de/pid/g/PTGroth.html">Paul Groth</a> ; <a href="https://dblp.uni-trier.de/pid/h/PascalHitzler.html">Pascal Hitzler</a> ; <a href="https://dblp.uni-trier.de/pid/39/4064.html">Heiko Paulheim</a> ; <a href="https://dblp.uni-trier.de/pid/s/HaraldSack.html">Harald Sack</a> ; <a href="https://dblp.uni-trier.de/pid/t/VolkerTresp.html">Volker Tresp</a></p>
<p>Abstract:
There has been a rapid growth in the use of symbolic representations along with their applications in many important tasks. Symbolic representations, in the form of Knowledge Graphs (KGs), constitute large networks of real-world entities and their relationships. On the other hand, sub-symbolic artificial intelligence has also become a mainstream area of research. This workshop brought together researchers to discuss and foster collaborations on the intersection of these two areas.</p>
<p>Keywords:</p>
<h3 id="487. SKG4J 2020: 1st International Workshop on Semantic and Knowledge Graph Advances for Journalism.">487. SKG4J 2020: 1st International Workshop on Semantic and Knowledge Graph Advances for Journalism.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414079">Paper Link</a>    Pages:3525-3526</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/154/3282.html">Tareq Al-Moslmi</a> ; <a href="https://dblp.uni-trier.de/pid/01/1768.html">Raphal Troncy</a> ; <a href="https://dblp.uni-trier.de/pid/47/9409.html">Andr Freitas</a> ; <a href="https://dblp.uni-trier.de/pid/56/10142.html">Davide Ceolin</a> ; <a href="https://dblp.uni-trier.de/pid/203/5776.html">Abdullatif Abolohom</a></p>
<p>Abstract:
SKG4J targeted contributions at the interface between Artificial Intelligence, Data Management and its implications for journalistic practice. The first version of the workshop accepted three submissions with topics emphasising the complementary requirements for delivering realistic journalistic knowledge extraction/management platforms.</p>
<p>Keywords:</p>
<h3 id="488. The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020): Special Edition on Dis/Misinformation Mining from Social media.">488. The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020): Special Edition on Dis/Misinformation Mining from Social media.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414078">Paper Link</a>    Pages:3527-3528</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/25/806.html">Ebrahim Bagheri</a> ; <a href="https://dblp.uni-trier.de/pid/92/309.html">Huan Liu</a> ; <a href="https://dblp.uni-trier.de/pid/153/5265.html">Kai Shu</a> ; <a href="https://dblp.uni-trier.de/pid/152/9311.html">Fattane Zarrinkalam</a></p>
<p>Abstract:
For the fifth edition of the workshop on Mining Actionable Insights from Social Networks (MAISoN), we organized a special edition with focus on dis/misinformation mining from social media, co-located with CIKM 2020. This topic has attracted a lot of interest from the community since the Coronavirus (COVID-19) epidemic has given rise to an increase of misinformation on social media. The aim of this edition was to bring together researchers from different disciplines interested in mining dis/misinformation on social media. In particular, the distinguishing focus of this special edition was its emphasis on techniques that use social media data for building diagnostic, predictive and prescriptive analysis models related to misinformation. This means that there is rigorous attention for techniques that can be used to understand how and why dis/misinformation is created and spread, to uncover hidden and unexpected aspects of dis/misinformation content, and to recommend insightful countermeasures to restrict the circulation of dis/misinformation and alleviate their negative effects.</p>
<p>Keywords:</p>
<h3 id="489. AIMLAI'20: Third Workshop on Advances in Interpretable Machine Learning and Artificial Intelligence.">489. AIMLAI'20: Third Workshop on Advances in Interpretable Machine Learning and Artificial Intelligence.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414071">Paper Link</a>    Pages:3529-3530</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/190/7555.html">Adrien Bibal</a> ; <a href="https://dblp.uni-trier.de/pid/64/7833.html">Tassadit Bouadi</a> ; <a href="https://dblp.uni-trier.de/pid/15/4191.html">Benot Frnay</a> ; <a href="https://dblp.uni-trier.de/pid/70/11083.html">Luis Galrraga</a> ; <a href="https://dblp.uni-trier.de/pid/276/5099.html">Jos Oramas</a></p>
<p>Abstract:
The Third Workshop on "Advances in Interpretable Machine Learning and Artificial Intelligence" (AIMLAI) presents contributions in the fields of (i) interpretable ML and AI, i.e., algorithms that are natively interpretable, and (ii) interpretability modules, i.e., explanation layers on top of black-box models, also called post-hoc interpretability. AIMLAI encourages interdisciplinary collaborations with particular emphasis in knowledge management, infovis, human computer interaction and psychology. It also welcomes applied research for use cases where interpretability matters.</p>
<p>Keywords:</p>
<h3 id="490. DataMod2020: 9th International Symposium "From Data to Models and Back".">490. DataMod2020: 9th International Symposium "From Data to Models and Back".</h3>
<p><a href="https://doi.org/10.1145/3340531.3414073">Paper Link</a>    Pages:3531-3532</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/f/JulianaKusterFilipe.html">Juliana Bowles</a> ; <a href="https://dblp.uni-trier.de/pid/207/2093.html">Giovanna Broccia</a> ; <a href="https://dblp.uni-trier.de/pid/60/6693.html">Mirco Nanni</a></p>
<p>Abstract:
DataMod 2020 aims to bring together practitioners and researchers from academia, industry and research institutions interested in the combined application of computational modelling methods with data-driven techniques from the areas of knowledge management, data mining and machine learning. Modelling methodologies of interest include automata, agents, Petri nets, process algebras and rewriting systems. Application domains include social systems, ecology, biology, medicine, smart cities, governance, security, education, software engineering, and any other field that deals with complex systems and large amounts of data. Papers can present research results in any of the themes of interest for the symposium as well as application experiences, tools and promising preliminary ideas. Papers dealing with synergistic approaches that integrate modelling and knowledge management/discovery or that exploit knowledge management/discovery to develop/syntesise system models are especially welcome.</p>
<p>Keywords:</p>
<h3 id="491. 3rd International Workshop on EntitY Retrieval and lEarning (EYRE 2020).">491. 3rd International Workshop on EntitY Retrieval and lEarning (EYRE 2020).</h3>
<p><a href="https://doi.org/10.1145/3340531.3414075">Paper Link</a>    Pages:3533-3534</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/69/1215-1.html">Gong Cheng</a> ; <a href="https://dblp.uni-trier.de/pid/00/9080.html">Kalpa Gunaratna</a> ; <a href="https://dblp.uni-trier.de/pid/125/8189.html">Jun Wang</a></p>
<p>Abstract:
Entity retrieval has received increasing research attention. The recent progress in deep and machine learning techniques provides powerful tools for developing effective entity-centered solutions. This workshop series provides a platform where interdisciplinary studies of entity retrieval and learning can be presented, and focused discussions can take place. We also organize a shared task related to entity retrieval. The 3rd International Workshop on EntitY Retrieval and lEarning (EYRE 2020) was a half-day workshop co-located with the 29th ACM International Conference on Information and Knowledge Management (CIKM 2020) as a virtual event in Ireland.</p>
<p>Keywords:</p>
<h3 id="492. IWILDS'20: The 1st International Workshop on Investigating Learning during Web Search.">492. IWILDS'20: The 1st International Workshop on Investigating Learning during Web Search.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414076">Paper Link</a>    Pages:3535-3536</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/117/9808.html">Anett Hoppe</a> ; <a href="https://dblp.uni-trier.de/pid/45/8919-1.html">Ran Yu</a> ; <a href="https://dblp.uni-trier.de/pid/55/6725.html">Yvonne Kammerer</a> ; <a href="https://dblp.uni-trier.de/pid/62/5642.html">Ladislao Salmern</a></p>
<p>Abstract:
Web search is one of the most ubiquitous online activities and often used for learning purposes, i.e., to extend one's knowledge or skills about certain topics or procedures. The importance of learning as an outcome of Web search has been recognized in research at the intersection of information retrieval, human-computer interaction, psychology, and educational sciences. Search as Learning (SAL) research examines relationships between querying, navigation, and reading behavior during Web search and the resulting learning outcomes, and how they can be measured, predicted, and supported. IWILDS aims to provide a platform to the interdisciplinary SAL community, with the objective to bring together interested researchers, provide room for presentation and discussion of novel research insights, and to inspire future directions of SAL research.</p>
<p>Keywords:</p>
<h3 id="493. DTMBIO 2020: The Fourteenth International Workshop on Data and Text Mining in Biomedical Informatics.">493. DTMBIO 2020: The Fourteenth International Workshop on Data and Text Mining in Biomedical Informatics.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414074">Paper Link</a>    Pages:3537-3538</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/186/5901.html">Hyojung Paik</a> ; <a href="https://dblp.uni-trier.de/pid/153/5412.html">Sunyong Yoo</a> ; <a href="https://dblp.uni-trier.de/pid/71/6205.html">Hojung Nam</a> ; <a href="https://dblp.uni-trier.de/pid/68/6.html">Mark Stevenson</a> ; <a href="https://dblp.uni-trier.de/pid/23/11268.html">Albert No</a></p>
<p>Abstract:
Over a decade, as a specialized workshop in the field of text mining applied to biomedical informatics, DTMBIO (ACM international workshop on Data and Text Mining in Biomedical Informatics) has been held annually in conjunction with one of the largest data management conferences, CIKM. The purpose of DTMBIO is to foster discussions regarding the state-of-the-art applications of data and text mining on biomedical research problems. To address our purpose, we bring together researchers working on computer science and bio/medical informatics area including text mining and high throughput genomic data analysis, such as the next generation Sequencing (NGS) data. DTMBIO 2020 will help scientists navigate emerging trends and opportunities in the evolving area of informatics related techniques and problems in the context of biomedical research.</p>
<p>Keywords:</p>
<h3 id="494. On the Knowledge-Driven Analytics and Systems Impacting Human Quality of Life.">494. On the Knowledge-Driven Analytics and Systems Impacting Human Quality of Life.</h3>
<p><a href="https://doi.org/10.1145/3340531.3414077">Paper Link</a>    Pages:3539-3540</p>
<p>Authors:
<a href="https://dblp.uni-trier.de/pid/84/7494.html">Arijit Ukil</a> ; <a href="https://dblp.uni-trier.de/pid/85/9977.html">Leandro Marn</a> ; <a href="https://dblp.uni-trier.de/pid/78/7047.html">Antonio Jara</a> ; <a href="https://dblp.uni-trier.de/pid/38/2332.html">John R. Farserotu</a></p>
<p>Abstract:
The present scenario of Covid-19 pandemic has disrupted the human life to a larger extent. In such context, human-centric applications and systems that endeavor to positively impact the human quality of life is of utmost importance. Knowledge-driven analytics that help to build such intelligent systems play important role to construct the required eco-system on the macro-scale. It is worth mentioning that Knowledge-Driven Analytics and Systems Impacting Human Quality of Life (KDAH) workshop in ACM International Conference on Information and Knowledge Management (CIKM), attempts to bring out the intricate research direction for enabling a sustainable human society through the positive co-existence of human beings and intelligent systems.</p>
<p>Keywords:</p>
 

<div class="home">
<i title='' onclick="location.href='../index.html'"><i class="fa fa-home fa-lg"></i></i>
</div>

<div class="toc">
<i id="showLeftPush" title=''><i class="fa fa-list fa-lg"></i></i>
</div>

<!-- Classie - class helper functions by @desandro https://github.com/desandro/classie -->
<script>
	var menuLeft = document.getElementById( 'menu-s1' ),
		showLeftPush = document.getElementById( 'showLeftPush' ),
		body = document.body;

	showLeftPush.onclick = function() {
		classie.toggle( this, 'active' );
		classie.toggle( body, 'cbp-spmenu-push-toright' );
		classie.toggle( menuLeft, 'cbp-spmenu-open' );
		disableOther( 'showLeftPush' );
	};
</script>

<div class="go-top" >
<i title='' onclick="window.scrollTo('0', '0')"><i class="fa fa-angle-double-up fa-2x"></i></i>
</div>

<div class="theme" >
<i title='' onclick="change_css()"><i class="fa fa-adjust fa-lg"></i></i>
</div>

<div id="footer">

  <p> <i class="fa fa-envelope-o fa-1x"></i>:&nbsp huntercmd@163.com &nbsp Published under<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh"> (CC) BY-NC-SA 3.0</a></p>

  <p>&copy; 2013 HunterCmd &nbsp <a href="https://github.com/huntercmd/ccf"><i class="fa fa-github fa-1x"></i>
  </p>
</div>

</body>
